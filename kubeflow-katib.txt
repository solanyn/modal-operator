Directory structure:
└── kubeflow-katib/
    ├── README.md
    ├── ADOPTERS.md
    ├── CITATION.cff
    ├── CONTRIBUTING.md
    ├── Dockerfile.conformance
    ├── go.mod
    ├── LICENSE
    ├── Makefile
    ├── OWNERS
    ├── PROJECT
    ├── ROADMAP.md
    ├── SECURITY.md
    ├── .dockerignore
    ├── .flake8
    ├── .gcloudignore
    ├── .pre-commit-config.yaml
    ├── cmd/
    │   ├── db-manager/
    │   │   └── v1beta1/
    │   │       ├── Dockerfile
    │   │       ├── main.go
    │   │       └── main_test.go
    │   ├── earlystopping/
    │   │   └── medianstop/
    │   │       └── v1beta1/
    │   │           ├── Dockerfile
    │   │           ├── main.py
    │   │           └── requirements.txt
    │   ├── katib-controller/
    │   │   └── v1beta1/
    │   │       ├── Dockerfile
    │   │       └── main.go
    │   ├── metricscollector/
    │   │   └── v1beta1/
    │   │       ├── file-metricscollector/
    │   │       │   ├── Dockerfile
    │   │       │   └── main.go
    │   │       └── tfevent-metricscollector/
    │   │           ├── Dockerfile
    │   │           ├── Dockerfile.ppc64le
    │   │           ├── main.py
    │   │           └── requirements.txt
    │   ├── suggestion/
    │   │   ├── goptuna/
    │   │   │   └── v1beta1/
    │   │   │       ├── Dockerfile
    │   │   │       └── main.go
    │   │   ├── hyperband/
    │   │   │   └── v1beta1/
    │   │   │       ├── Dockerfile
    │   │   │       ├── main.py
    │   │   │       └── requirements.txt
    │   │   ├── hyperopt/
    │   │   │   └── v1beta1/
    │   │   │       ├── Dockerfile
    │   │   │       ├── main.py
    │   │   │       └── requirements.txt
    │   │   ├── nas/
    │   │   │   ├── darts/
    │   │   │   │   └── v1beta1/
    │   │   │   │       ├── Dockerfile
    │   │   │   │       ├── main.py
    │   │   │   │       └── requirements.txt
    │   │   │   └── enas/
    │   │   │       └── v1beta1/
    │   │   │           ├── Dockerfile
    │   │   │           ├── main.py
    │   │   │           └── requirements.txt
    │   │   ├── optuna/
    │   │   │   └── v1beta1/
    │   │   │       ├── Dockerfile
    │   │   │       ├── main.py
    │   │   │       └── requirements.txt
    │   │   ├── pbt/
    │   │   │   └── v1beta1/
    │   │   │       ├── Dockerfile
    │   │   │       ├── main.py
    │   │   │       └── requirements.txt
    │   │   └── skopt/
    │   │       └── v1beta1/
    │   │           ├── Dockerfile
    │   │           ├── main.py
    │   │           └── requirements.txt
    │   └── ui/
    │       └── v1beta1/
    │           ├── Dockerfile
    │           └── main.go
    ├── conformance/
    │   └── run.sh
    ├── docs/
    │   ├── README.md
    │   ├── images-location.md
    │   ├── presentations.md
    │   ├── proposals/
    │   │   ├── README.md
    │   │   ├── 1214-custom-crd-in-trial/
    │   │   │   └── README.md
    │   │   ├── 2044-conformance-program/
    │   │   │   └── README.md
    │   │   ├── 2339-hpo-for-llm-fine-tuning/
    │   │   │   └── README.md
    │   │   ├── 2340-push-based-metrics-collector/
    │   │   │   └── README.md
    │   │   ├── 2374-parameter-distribution/
    │   │   │   └── README.md
    │   │   ├── 507-suggestion-crd/
    │   │   │   └── README.md
    │   │   └── 685-metrics-collector/
    │   │       └── README.md
    │   └── release/
    │       ├── README.md
    │       └── changelog.py
    ├── examples/
    │   └── v1beta1/
    │       ├── README.md
    │       ├── argo/
    │       │   ├── README.md
    │       │   └── argo-workflow.yaml
    │       ├── early-stopping/
    │       │   ├── median-stop-with-json-format.yaml
    │       │   └── median-stop.yaml
    │       ├── fpga/
    │       │   ├── README.md
    │       │   ├── OWNERS
    │       │   └── xgboost-example.yaml
    │       ├── hp-tuning/
    │       │   ├── bayesian-optimization.yaml
    │       │   ├── cma-es.yaml
    │       │   ├── grid.yaml
    │       │   ├── hyperband.yaml
    │       │   ├── hyperopt-distribution.yaml
    │       │   ├── multivariate-tpe.yaml
    │       │   ├── optuna-distribution.yaml
    │       │   ├── random.yaml
    │       │   ├── simple-pbt.yaml
    │       │   ├── sobol.yaml
    │       │   └── tpe.yaml
    │       ├── kind-cluster/
    │       │   ├── README.md
    │       │   └── deploy.sh
    │       ├── kubeflow-pipelines/
    │       │   ├── README.md
    │       │   ├── early-stopping.ipynb
    │       │   ├── mpi-job-horovod.py
    │       │   └── images/
    │       │       └── 9.bmp
    │       ├── kubeflow-trainer/
    │       │   └── trainjob-pytorch.yaml
    │       ├── kubeflow-training-operator/
    │       │   ├── mpijob-horovod.yaml
    │       │   ├── pytorchjob-mnist.yaml
    │       │   ├── tfjob-mnist-with-summaries.yaml
    │       │   └── xgboostjob-lightgbm.yaml
    │       ├── metrics-collector/
    │       │   ├── custom-metrics-collector.yaml
    │       │   ├── file-metrics-collector-with-json-format.yaml
    │       │   ├── file-metrics-collector.yaml
    │       │   └── metrics-collection-strategy.yaml
    │       ├── nas/
    │       │   ├── darts-cpu.yaml
    │       │   ├── darts-gpu.yaml
    │       │   ├── enas-cpu.yaml
    │       │   └── enas-gpu.yaml
    │       ├── resume-experiment/
    │       │   ├── from-volume-resume.yaml
    │       │   └── long-running-resume.yaml
    │       ├── sdk/
    │       │   ├── README.md
    │       │   ├── cmaes-and-resume-policies.ipynb
    │       │   ├── mnist-with-push-metrics-collection.ipynb
    │       │   └── nas-with-darts.ipynb
    │       ├── tekton/
    │       │   ├── README.md
    │       │   └── pipeline-run.yaml
    │       ├── trial-images/
    │       │   ├── darts-cnn-cifar10/
    │       │   │   ├── README.md
    │       │   │   ├── architect.py
    │       │   │   ├── Dockerfile.cpu
    │       │   │   ├── Dockerfile.gpu
    │       │   │   ├── model.py
    │       │   │   ├── operations.py
    │       │   │   ├── run_trial.py
    │       │   │   ├── search_space.py
    │       │   │   └── utils.py
    │       │   ├── enas-cnn-cifar10/
    │       │   │   ├── README.md
    │       │   │   ├── Dockerfile.cpu
    │       │   │   ├── Dockerfile.gpu
    │       │   │   ├── ModelConstructor.py
    │       │   │   ├── op_library.py
    │       │   │   ├── requirements.txt
    │       │   │   └── RunTrial.py
    │       │   ├── pytorch-mnist/
    │       │   │   ├── README.md
    │       │   │   ├── Dockerfile.cpu
    │       │   │   ├── Dockerfile.gpu
    │       │   │   ├── mnist.py
    │       │   │   └── requirements.txt
    │       │   ├── simple-pbt/
    │       │   │   ├── README.md
    │       │   │   ├── Dockerfile
    │       │   │   ├── pbt_test.py
    │       │   │   └── requirements.txt
    │       │   └── tf-mnist-with-summaries/
    │       │       ├── README.md
    │       │       ├── Dockerfile
    │       │       ├── mnist.py
    │       │       └── requirements.txt
    │       └── trial-template/
    │           ├── trial-configmap-source.yaml
    │           └── trial-metadata-substitution.yaml
    ├── hack/
    │   ├── install-shellcheck.sh
    │   ├── tools.go
    │   ├── update-codegen.sh
    │   ├── update-gofmt.sh
    │   ├── update-mockgen.sh
    │   ├── update-openapigen.sh
    │   ├── update-proto.sh
    │   ├── verify-generated-codes.sh
    │   ├── verify-gofmt.sh
    │   ├── verify-golangci-lint.sh
    │   ├── verify-shellcheck.sh
    │   ├── verify-yamllint.sh
    │   ├── violation_exception_v1beta1.list
    │   ├── boilerplate/
    │   │   ├── boilerplate.go.txt
    │   │   ├── boilerplate.py.txt
    │   │   ├── boilerplate.sh.txt
    │   │   └── update-boilerplate.sh
    │   ├── gen-python-sdk/
    │   │   ├── gen-sdk.sh
    │   │   ├── post_gen.py
    │   │   └── swagger_config.json
    │   └── swagger/
    │       └── main.go
    ├── manifests/
    │   └── v1beta1/
    │       ├── components/
    │       │   ├── controller/
    │       │   │   ├── controller.yaml
    │       │   │   ├── kustomization.yaml
    │       │   │   ├── rbac.yaml
    │       │   │   ├── service.yaml
    │       │   │   └── trial-templates.yaml
    │       │   ├── crd/
    │       │   │   ├── experiment.yaml
    │       │   │   ├── kustomization.yaml
    │       │   │   ├── suggestion.yaml
    │       │   │   └── trial.yaml
    │       │   ├── db-manager/
    │       │   │   ├── db-manager.yaml
    │       │   │   ├── kustomization.yaml
    │       │   │   └── service.yaml
    │       │   ├── mysql/
    │       │   │   ├── kustomization.yaml
    │       │   │   ├── mysql.yaml
    │       │   │   ├── pvc.yaml
    │       │   │   ├── secret.yaml
    │       │   │   └── service.yaml
    │       │   ├── namespace/
    │       │   │   ├── kustomization.yaml
    │       │   │   └── namespace.yaml
    │       │   ├── postgres/
    │       │   │   ├── kustomization.yaml
    │       │   │   ├── postgres.yaml
    │       │   │   ├── pvc.yaml
    │       │   │   ├── secret.yaml
    │       │   │   └── service.yaml
    │       │   ├── ui/
    │       │   │   ├── kustomization.yaml
    │       │   │   ├── rbac.yaml
    │       │   │   ├── service.yaml
    │       │   │   └── ui.yaml
    │       │   └── webhook/
    │       │       ├── kustomization.yaml
    │       │       └── webhooks.yaml
    │       └── installs/
    │           ├── katib-cert-manager/
    │           │   ├── certificate.yaml
    │           │   ├── katib-config.yaml
    │           │   ├── kustomization.yaml
    │           │   ├── params.yaml
    │           │   └── patches/
    │           │       └── katib-cert-injection.yaml
    │           ├── katib-external-db/
    │           │   ├── katib-config.yaml
    │           │   ├── kustomization.yaml
    │           │   ├── secrets.env
    │           │   └── patches/
    │           │       └── db-manager.yaml
    │           ├── katib-leader-election/
    │           │   ├── katib-config.yaml
    │           │   ├── kustomization.yaml
    │           │   └── leader-election-rbac.yaml
    │           ├── katib-openshift/
    │           │   ├── katib-config.yaml
    │           │   ├── kustomization.yaml
    │           │   └── patches/
    │           │       ├── service-serving-cert.yaml
    │           │       └── webhook-inject-cabundle.yaml
    │           ├── katib-standalone/
    │           │   ├── katib-config.yaml
    │           │   └── kustomization.yaml
    │           ├── katib-standalone-postgres/
    │           │   ├── katib-config.yaml
    │           │   ├── kustomization.yaml
    │           │   └── patches/
    │           │       └── db-manager.yaml
    │           └── katib-with-kubeflow/
    │               ├── istio-authorizationpolicy.yaml
    │               ├── kubeflow-katib-roles.yaml
    │               ├── kustomization.yaml
    │               ├── params.yaml
    │               ├── ui-virtual-service.yaml
    │               └── patches/
    │                   ├── enable-ui-authz-checks.yaml
    │                   ├── istio-sidecar-injection.yaml
    │                   ├── remove-namespace.yaml
    │                   └── ui-rbac.yaml
    ├── scripts/
    │   └── v1beta1/
    │       ├── build.sh
    │       ├── deploy.sh
    │       ├── push.sh
    │       ├── release.sh
    │       ├── undeploy.sh
    │       └── update-images.sh
    ├── sdk/
    │   └── python/
    │       └── v1beta1/
    │           ├── README.md
    │           ├── OWNERS
    │           ├── setup.py
    │           ├── docs/
    │           │   ├── KatibClient.md
    │           │   ├── V1beta1AlgorithmSetting.md
    │           │   ├── V1beta1AlgorithmSpec.md
    │           │   ├── V1beta1CollectorSpec.md
    │           │   ├── V1beta1ConfigMapSource.md
    │           │   ├── V1beta1EarlyStoppingRule.md
    │           │   ├── V1beta1EarlyStoppingSetting.md
    │           │   ├── V1beta1EarlyStoppingSpec.md
    │           │   ├── V1beta1Experiment.md
    │           │   ├── V1beta1ExperimentCondition.md
    │           │   ├── V1beta1ExperimentList.md
    │           │   ├── V1beta1ExperimentSpec.md
    │           │   ├── V1beta1ExperimentStatus.md
    │           │   ├── V1beta1FeasibleSpace.md
    │           │   ├── V1beta1FileSystemPath.md
    │           │   ├── V1beta1FilterSpec.md
    │           │   ├── V1beta1GraphConfig.md
    │           │   ├── V1beta1Metric.md
    │           │   ├── V1beta1MetricsCollectorSpec.md
    │           │   ├── V1beta1MetricStrategy.md
    │           │   ├── V1beta1NasConfig.md
    │           │   ├── V1beta1ObjectiveSpec.md
    │           │   ├── V1beta1Observation.md
    │           │   ├── V1beta1Operation.md
    │           │   ├── V1beta1OptimalTrial.md
    │           │   ├── V1beta1ParameterAssignment.md
    │           │   ├── V1beta1ParameterSpec.md
    │           │   ├── V1beta1SourceSpec.md
    │           │   ├── V1beta1Suggestion.md
    │           │   ├── V1beta1SuggestionCondition.md
    │           │   ├── V1beta1SuggestionList.md
    │           │   ├── V1beta1SuggestionSpec.md
    │           │   ├── V1beta1SuggestionStatus.md
    │           │   ├── V1beta1Trial.md
    │           │   ├── V1beta1TrialAssignment.md
    │           │   ├── V1beta1TrialCondition.md
    │           │   ├── V1beta1TrialList.md
    │           │   ├── V1beta1TrialParameterSpec.md
    │           │   ├── V1beta1TrialSource.md
    │           │   ├── V1beta1TrialSpec.md
    │           │   ├── V1beta1TrialStatus.md
    │           │   └── V1beta1TrialTemplate.md
    │           └── kubeflow/
    │               ├── __init__.py
    │               └── katib/
    │                   ├── __init__.py
    │                   ├── api_client.py
    │                   ├── configuration.py
    │                   ├── exceptions.py
    │                   ├── rest.py
    │                   ├── api/
    │                   │   ├── __init__.py
    │                   │   ├── katib_client_test.py
    │                   │   ├── report_metrics.py
    │                   │   ├── report_metrics_test.py
    │                   │   └── search.py
    │                   ├── constants/
    │                   │   ├── __init__.py
    │                   │   └── constants.py
    │                   ├── models/
    │                   │   ├── __init__.py
    │                   │   ├── v1beta1_algorithm_setting.py
    │                   │   ├── v1beta1_algorithm_spec.py
    │                   │   ├── v1beta1_collector_spec.py
    │                   │   ├── v1beta1_config_map_source.py
    │                   │   ├── v1beta1_early_stopping_rule.py
    │                   │   ├── v1beta1_early_stopping_setting.py
    │                   │   ├── v1beta1_early_stopping_spec.py
    │                   │   ├── v1beta1_experiment.py
    │                   │   ├── v1beta1_experiment_condition.py
    │                   │   ├── v1beta1_experiment_list.py
    │                   │   ├── v1beta1_experiment_spec.py
    │                   │   ├── v1beta1_experiment_status.py
    │                   │   ├── v1beta1_feasible_space.py
    │                   │   ├── v1beta1_file_system_path.py
    │                   │   ├── v1beta1_filter_spec.py
    │                   │   ├── v1beta1_graph_config.py
    │                   │   ├── v1beta1_metric.py
    │                   │   ├── v1beta1_metric_strategy.py
    │                   │   ├── v1beta1_metrics_collector_spec.py
    │                   │   ├── v1beta1_nas_config.py
    │                   │   ├── v1beta1_objective_spec.py
    │                   │   ├── v1beta1_observation.py
    │                   │   ├── v1beta1_operation.py
    │                   │   ├── v1beta1_optimal_trial.py
    │                   │   ├── v1beta1_parameter_assignment.py
    │                   │   ├── v1beta1_parameter_spec.py
    │                   │   ├── v1beta1_source_spec.py
    │                   │   ├── v1beta1_suggestion.py
    │                   │   ├── v1beta1_suggestion_condition.py
    │                   │   ├── v1beta1_suggestion_list.py
    │                   │   ├── v1beta1_suggestion_spec.py
    │                   │   ├── v1beta1_suggestion_status.py
    │                   │   ├── v1beta1_trial.py
    │                   │   ├── v1beta1_trial_assignment.py
    │                   │   ├── v1beta1_trial_condition.py
    │                   │   ├── v1beta1_trial_list.py
    │                   │   ├── v1beta1_trial_parameter_spec.py
    │                   │   ├── v1beta1_trial_source.py
    │                   │   ├── v1beta1_trial_spec.py
    │                   │   ├── v1beta1_trial_status.py
    │                   │   └── v1beta1_trial_template.py
    │                   ├── types/
    │                   │   ├── __init__.py
    │                   │   └── types.py
    │                   └── utils/
    │                       ├── __init__.py
    │                       └── utils.py
    ├── test/
    │   ├── __init__.py
    │   ├── conftest.py
    │   ├── e2e/
    │   │   └── v1beta1/
    │   │       ├── hack/
    │   │       │   └── aws/
    │   │       │       ├── argo_workflow.py
    │   │       │       └── run-e2e-experiment.go
    │   │       ├── scripts/
    │   │       │   ├── aws/
    │   │       │   │   ├── run-e2e-experiment.sh
    │   │       │   │   └── setup-katib.sh
    │   │       │   └── gh-actions/
    │   │       │       ├── build-load.sh
    │   │       │       ├── run-e2e-experiment.py
    │   │       │       ├── run-e2e-experiment.sh
    │   │       │       ├── run-e2e-tune-api.py
    │   │       │       ├── run-e2e-tune-api.sh
    │   │       │       ├── setup-katib.sh
    │   │       │       ├── setup-minikube.sh
    │   │       │       └── verify.py
    │   │       └── testdata/
    │   │           ├── invalid-experiment.yaml
    │   │           └── valid-experiment.yaml
    │   └── unit/
    │       └── v1beta1/
    │           ├── requirements.txt
    │           ├── earlystopping/
    │           │   ├── test_medianstop_service.py
    │           │   └── utils.py
    │           ├── metricscollector/
    │           │   ├── test_tfevent_metricscollector.py
    │           │   └── utils.py
    │           └── suggestion/
    │               ├── test_darts_service.py
    │               ├── test_enas_service.py
    │               ├── test_hyperband_service.py
    │               ├── test_hyperopt_service.py
    │               ├── test_nas_common.py
    │               ├── test_optuna_service.py
    │               ├── test_skopt_service.py
    │               └── utils.py
    └── .github/
        ├── PULL_REQUEST_TEMPLATE.md
        ├── ISSUE_TEMPLATE/
        │   ├── bug_report.yaml
        │   ├── config.yml
        │   └── feature_request.yaml
        └── workflows/
            ├── build-and-publish-images.yaml
            ├── e2e-test-darts-cifar10.yaml
            ├── e2e-test-enas-cifar10.yaml
            ├── e2e-test-pytorch-mnist.yaml
            ├── e2e-test-simple-pbt.yaml
            ├── e2e-test-tf-mnist-with-summaries.yaml
            ├── e2e-test-tune-api.yaml
            ├── e2e-test-ui-random-search-postgres.yaml
            ├── publish-algorithm-images.yaml
            ├── publish-conformance-images.yaml
            ├── publish-core-images.yaml
            ├── publish-trial-images.yaml
            ├── stale.yaml
            ├── test-go.yaml
            ├── test-lint.yaml
            ├── test-node.yaml
            ├── test-python.yaml
            ├── trivy-scan.yaml
            ├── free-up-disk-space/
            │   └── action.yaml
            ├── template-e2e-test/
            │   └── action.yaml
            ├── template-publish-image/
            │   └── action.yaml
            └── template-setup-e2e-test/
                └── action.yaml

================================================
FILE: README.md
================================================
# Kubeflow Katib

[![Build Status](https://github.com/kubeflow/katib/actions/workflows/test-go.yaml/badge.svg?branch=master)](https://github.com/kubeflow/katib/actions/workflows/test-go.yaml?branch=master)
[![Coverage Status](https://coveralls.io/repos/github/kubeflow/katib/badge.svg?branch=master)](https://coveralls.io/github/kubeflow/katib?branch=master)
[![Go Report Card](https://goreportcard.com/badge/github.com/kubeflow/katib)](https://goreportcard.com/report/github.com/kubeflow/katib)
[![Releases](https://img.shields.io/github/release-pre/kubeflow/katib.svg?sort=semver)](https://github.com/kubeflow/katib/releases)
[![Slack Status](https://img.shields.io/badge/slack-join_chat-white.svg?logo=slack&style=social)](https://www.kubeflow.org/docs/about/community/#kubeflow-slack-channels)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/9941/badge)](https://www.bestpractices.dev/projects/9941)
[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fkubeflow%2Fkatib.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Fkubeflow%2Fkatib?ref=badge_shield)

<h1 align="center">
    <img src="./docs/images/logo-title.png" alt="logo" width="200">
  <br>
</h1>

Kubeflow Katib is a Kubernetes-native project for automated machine learning (AutoML).
Katib supports
[Hyperparameter Tuning](https://en.wikipedia.org/wiki/Hyperparameter_optimization),
[Early Stopping](https://en.wikipedia.org/wiki/Early_stopping) and
[Neural Architecture Search](https://en.wikipedia.org/wiki/Neural_architecture_search).

Katib is the project which is agnostic to machine learning (ML) frameworks.
It can tune hyperparameters of applications written in any language of the
users’ choice and natively supports many ML frameworks, such as
[TensorFlow](https://www.tensorflow.org/), [PyTorch](https://pytorch.org/), [XGBoost](https://xgboost.readthedocs.io/en/latest/), and others.

Katib can perform training jobs using any Kubernetes
[Custom Resources](https://www.kubeflow.org/docs/components/katib/trial-template/)
with out of the box support for [Kubeflow Training Operator](https://github.com/kubeflow/training-operator),
[Argo Workflows](https://github.com/argoproj/argo-workflows), [Tekton Pipelines](https://github.com/tektoncd/pipeline)
and many more.

Katib stands for `secretary` in Arabic.

## Search Algorithms

Katib supports several search algorithms. Follow the
[Kubeflow documentation](https://www.kubeflow.org/docs/components/katib/user-guides/hp-tuning/configure-algorithm/#hp-tuning-algorithms)
to know more about each algorithm and check the
[this guide](https://www.kubeflow.org/docs/components/katib/user-guides/hp-tuning/configure-algorithm/#use-custom-algorithm-in-katib)
to implement your custom algorithm.

<table>
  <tbody>
    <tr align="center">
      <td>
        <b>Hyperparameter Tuning</b>
      </td>
      <td>
        <b>Neural Architecture Search</b>
      </td>
      <td>
        <b>Early Stopping</b>
      </td>
    </tr>
    <tr align="center">
      <td>
        <a href="https://www.kubeflow.org/docs/components/katib/experiment/#random-search">Random Search</a>
      </td>
      <td>
        <a href="https://www.kubeflow.org/docs/components/katib/experiment/#neural-architecture-search-based-on-enas">ENAS</a>
      </td>
      <td>
        <a href="https://www.kubeflow.org/docs/components/katib/early-stopping/#median-stopping-rule">Median Stop</a>
      </td>
    </tr>
    <tr align="center">
      <td>
        <a href="https://www.kubeflow.org/docs/components/katib/experiment/#grid-search">Grid Search</a>
      </td>
      <td>
        <a href="https://www.kubeflow.org/docs/components/katib/experiment/#differentiable-architecture-search-darts">DARTS</a>
      </td>
      <td>
      </td>
    </tr>
    <tr align="center">
      <td>
        <a href="https://www.kubeflow.org/docs/components/katib/experiment/#bayesian-optimization">Bayesian Optimization</a>
      </td>
      <td>
      </td>
      <td>
      </td>
    </tr>
    <tr align="center">
      <td>
        <a href="https://www.kubeflow.org/docs/components/katib/experiment/#tree-of-parzen-estimators-tpe">TPE</a>
      </td>
      <td>
      </td>
      <td>
      </td>
    </tr>
    <tr align="center">
      <td>
        <a href="https://www.kubeflow.org/docs/components/katib/experiment/#multivariate-tpe">Multivariate TPE</a>
      </td>
      <td>
      </td>
      <td>
      </td>
    </tr>
    <tr align="center">
      <td>
        <a href="https://www.kubeflow.org/docs/components/katib/experiment/#covariance-matrix-adaptation-evolution-strategy-cma-es">CMA-ES</a>
      </td>
      <td>
      </td>
      <td>
      </td>
    </tr>
    <tr align="center">
      <td>
        <a href="https://www.kubeflow.org/docs/components/katib/experiment/#sobols-quasirandom-sequence">Sobol's Quasirandom Sequence</a>
      </td>
      <td>
      </td>
      <td>
      </td>
    </tr>
    <tr align="center">
      <td>
        <a href="https://www.kubeflow.org/docs/components/katib/experiment/#hyperband">HyperBand</a>
      </td>
      <td>
      </td>
      <td>
      </td>
    </tr>
    <tr align="center">
      <td>
        <a href="https://www.kubeflow.org/docs/components/katib/experiment/#pbt">Population Based Training</a>
      </td>
      <td>
      </td>
      <td>
      </td>
    </tr>
  </tbody>
</table>

To perform the above algorithms Katib supports the following frameworks:

- [Goptuna](https://github.com/c-bata/goptuna)
- [Hyperopt](https://github.com/hyperopt/hyperopt)
- [Optuna](https://github.com/optuna/optuna)
- [Scikit Optimize](https://github.com/scikit-optimize/scikit-optimize)

## Prerequisites

Please check [the official Kubeflow documentation](https://www.kubeflow.org/docs/components/katib/installation/#prerequisites)
for prerequisites to install Katib.

## Installation

Please follow [the Kubeflow Katib guide](https://www.kubeflow.org/docs/components/katib/installation/#installing-katib)
for the detailed instructions on how to install Katib.

### Installing the Control Plane

Run the following command to install the latest stable release of Katib control plane:

```
kubectl apply -k "github.com/kubeflow/katib.git/manifests/v1beta1/installs/katib-standalone?ref=v0.17.0"
```

Run the following command to install the latest changes of Katib control plane:

```
kubectl apply -k "github.com/kubeflow/katib.git/manifests/v1beta1/installs/katib-standalone?ref=master"
```

For the Katib Experiments check the [complete examples list](./examples/v1beta1).

### Installing the Python SDK

Katib implements [a Python SDK](https://pypi.org/project/kubeflow-katib/) to simplify creation of
hyperparameter tuning jobs for Data Scientists.

Run the following command to install the latest stable release of Katib SDK:

```sh
pip install -U kubeflow-katib
```

## Getting Started

Please refer to [the getting started guide](https://www.kubeflow.org/docs/components/katib/getting-started/#getting-started-with-katib-python-sdk)
to quickly create your first hyperparameter tuning Experiment using the Python SDK.

## Community

The following links provide information on how to get involved in the community:

- Attend [the bi-weekly AutoML and Training Working Group](https://bit.ly/2PWVCkV)
  community meeting.
- Join our [`#kubeflow-katib`](https://www.kubeflow.org/docs/about/community/#kubeflow-slack-channels)
  Slack channel.
- Check out [who is using Katib](ADOPTERS.md) and [presentations about Katib project](docs/presentations.md).

## Contributing

Please refer to the [CONTRIBUTING guide](CONTRIBUTING.md).

## Citation

If you use Katib in a scientific publication, we would appreciate
citations to the following paper:

[A Scalable and Cloud-Native Hyperparameter Tuning System](https://arxiv.org/abs/2006.02085), George _et al._, arXiv:2006.02085, 2020.

Bibtex entry:

```
@misc{george2020katib,
    title={A Scalable and Cloud-Native Hyperparameter Tuning System},
    author={Johnu George and Ce Gao and Richard Liu and Hou Gang Liu and Yuan Tang and Ramdoot Pydipaty and Amit Kumar Saha},
    year={2020},
    eprint={2006.02085},
    archivePrefix={arXiv},
    primaryClass={cs.DC}
}
```



================================================
FILE: ADOPTERS.md
================================================
# Adopters of Kubeflow Katib

Below are the adopters of project Katib. If you are using Katib
please add yourself into the following list by a pull request.
Please keep the list in alphabetical order.

| Organization                                     | Contact                                              | Description of Use                                                   |
|--------------------------------------------------|------------------------------------------------------|----------------------------------------------------------------------|
| [Akuity](https://akuity.io/)                     | [@terrytangyuan](https://github.com/terrytangyuan)   |                                                                      |
| [Ant Group](https://www.antgroup.com/)           | [@ohmystack](https://github.com/ohmystack)           | Automatic training in Ant Group internal AI Platform                 |
| [babylon health](https://www.babylonhealth.com/) | [@jeremievallee](https://github.com/jeremievallee)   | Hyperparameter tuning for AIR internal AI Platform                   |
| [caicloud](https://caicloud.io/)                 | [@gaocegege](https://github.com/gaocegege)           | Hyperparameter tuning in Caicloud Cloud-Native AI Platform           |
| [canonical](https://ubuntu.com/)                 | [@RFMVasconcelos](https://github.com/rfmvasconcelos) | Hyperparameter tuning for customer projects in Defense and Fintech   |
| [CERN](https://home.cern/)                       | [@d-gol](https://github.com/d-gol)                   | Hyperparameter tuning within the ML platform on private cloud   |
| [cisco](https://cisco.com/)                      | [@ramdootp](https://github.com/ramdootp)             | Hyperparameter tuning for conversational AI interface using Rasa     |
| [cubonacci](https://www.cubonacci.com)           | [@janvdvegt](https://github.com/janvdvegt)           | Hyperparameter tuning within the Cubonacci machine learning platform |
| [CyberAgent](https://www.cyberagent.co.jp/en/)   | [@tenzen-y](https://github.com/tenzen-y)             | Experiment in CyberAgent internal ML Platform on Private Cloud       |
| [fuzhi](http://www.fuzhi.ai/)                    | [@planck0591](https://github.com/planck0591)         | Experiment and Trial in autoML Platform                              |
| [karrot](https://uk.karrotmarket.com/)           | [@muik](https://github.com/muik)                     | Hyperparameter tuning in Karrot ML Platform                          |
| [PITS Global Data Recovery Services](https://www.pitsdatarecovery.net/) | [@pheianox](https://github.com/pheianox) | CyberAgent and ML Platform |



================================================
FILE: CITATION.cff
================================================
cff-version: 1.2.0
message: "If you use Katib in your scientific publication, please cite it as below."
authors:
  - family-names: "George"
    given-names: "Johnu"
  - family-names: "Gao"
    given-names: "Ce"
  - family-names: "Liu"
    given-names: "Richard"
  - family-names: "Liu"
    given-names: "Hou Gang"
  - family-names: "Tang"
    given-names: "Yuan"
  - family-names: "Pydipaty"
    given-names: "Ramdoot"
  - family-names: "Saha"
    given-names: "Amit Kumar"
title: "Katib"
type: software
repository-code: "https://github.com/kubeflow/katib"
preferred-citation:
  type: misc
  title: "A Scalable and Cloud-Native Hyperparameter Tuning System"
  authors:
    - family-names: "George"
      given-names: "Johnu"
    - family-names: "Gao"
      given-names: "Ce"
    - family-names: "Liu"
      given-names: "Richard"
    - family-names: "Liu"
      given-names: "Hou Gang"
    - family-names: "Tang"
      given-names: "Yuan"
    - family-names: "Pydipaty"
      given-names: "Ramdoot"
    - family-names: "Saha"
      given-names: "Amit Kumar"
  year: 2020
  url: "https://arxiv.org/abs/2006.02085"
  identifiers:
    - type: "other"
      value: "arXiv:2006.02085"



================================================
FILE: CONTRIBUTING.md
================================================
# Developer Guide

This developer guide is for people who want to contribute to the Katib project.
If you're interesting in using Katib in your machine learning project,
see the following guides:

- [Getting started with Katib](https://kubeflow.org/docs/components/katib/hyperparameter/).
- [How to configure Katib Experiment](https://kubeflow.org/docs/components/katib/experiment/).
- [Katib architecture and concepts](https://www.kubeflow.org/docs/components/katib/reference/architecture/)
  for hyperparameter tuning and neural architecture search.

## Requirements

- [Go](https://golang.org/) (1.22 or later)
- [Docker](https://docs.docker.com/) (24.0 or later)
- [Docker Buildx](https://docs.docker.com/build/buildx/) (0.8.0 or later)
- [Java](https://docs.oracle.com/javase/8/docs/technotes/guides/install/install_overview.html) (8 or later)
- [Python](https://www.python.org/) (3.11 or later)
- [kustomize](https://kustomize.io/) (4.0.5 or later)
- [pre-commit](https://pre-commit.com/)

## Build from source code

**Note** that your Docker Desktop should
[enable containerd image store](https://docs.docker.com/desktop/containerd/#enable-the-containerd-image-store)
to build multi-arch images. Check source code as follows:

```bash
make build REGISTRY=<image-registry> TAG=<image-tag>
```

If you are using an Apple Silicon machine and encounter the "rosetta error: bss_size overflow," go to Docker Desktop -> General and uncheck "Use Rosetta for x86_64/amd64 emulation on Apple Silicon."

To use your custom images for the Katib components, modify
[Kustomization file](https://github.com/kubeflow/katib/blob/master/manifests/v1beta1/installs/katib-standalone/kustomization.yaml)
and [Katib Config](https://github.com/kubeflow/katib/blob/master/manifests/v1beta1/installs/katib-standalone/katib-config.yaml)

You can deploy Katib v1beta1 manifests into a Kubernetes cluster as follows:

```bash
make deploy
```

You can undeploy Katib v1beta1 manifests from a Kubernetes cluster as follows:

```bash
make undeploy
```

## Technical and style guide

The following guidelines apply primarily to Katib,
but other projects like [Training Operator](https://github.com/kubeflow/training-operator) might also adhere to them.

## Go Development

When coding:

- Follow [effective go](https://go.dev/doc/effective_go) guidelines.
- Run locally [`make check`](https://github.com/kubeflow/katib/blob/46173463027e4fd2e604e25d7075b2b31a702049/Makefile#L31)
  to verify if changes follow best practices before submitting PRs.

Testing:

- Use [`cmp.Diff`](https://pkg.go.dev/github.com/google/go-cmp/cmp#Diff) instead of `reflect.Equal`, to provide useful comparisons.
- Define test cases as maps instead of slices to avoid dependencies on the running order.
  Map key should be equal to the test case name.

## Modify controller APIs

If you want to modify Katib controller APIs, you have to
generate deepcopy, clientset, listers, informers, open-api and Python SDK with the changed APIs.
You can update the necessary files as follows:

```bash
make generate
```

## Controller Flags

Below is a list of command-line flags accepted by Katib controller:

| Name         | Type   | Default | Description                                                                                                                      |
| ------------ | ------ | ------- | -------------------------------------------------------------------------------------------------------------------------------- |
| katib-config | string | ""      | The katib-controller will load its initial configuration from this file. Omit this flag to use the default configuration values. |

## DB Manager Flags

Below is a list of command-line flags accepted by Katib DB Manager:

| Name            | Type          | Default      | Description                                                         |
| --------------- | ------------- | -------------| ------------------------------------------------------------------- |
| connect-timeout | time.Duration | 60s          | Timeout before calling error during database connection             |
| listen-address  | string        | 0.0.0.0:6789 | The network interface or IP address to receive incoming connections |

## Katib admission webhooks

Katib uses three [Kubernetes admission webhooks](https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/).

1. `validator.experiment.katib.kubeflow.org` -
   [Validating admission webhook](https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#validatingadmissionwebhook)
   to validate the Katib Experiment before the creation.

1. `defaulter.experiment.katib.kubeflow.org` -
   [Mutating admission webhook](https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#mutatingadmissionwebhook)
   to set the [default values](../pkg/apis/controller/experiments/v1beta1/experiment_defaults.go)
   in the Katib Experiment before the creation.

1. `mutator.pod.katib.kubeflow.org` - Mutating admission webhook to inject the metrics
   collector sidecar container to the training pod. Learn more about the Katib's
   metrics collector in the
   [Kubeflow documentation](https://www.kubeflow.org/docs/components/katib/user-guides/metrics-collector/).

You can find the YAMLs for the Katib webhooks
[here](../manifests/v1beta1/components/webhook/webhooks.yaml).

**Note:** If you are using a private Kubernetes cluster, you have to allow traffic
via `TCP:8443` by specifying the firewall rule and you have to update the master
plane CIDR source range to use the Katib webhooks

### Katib cert generator

Katib Controller has the internal `cert-generator` to generate certificates for the webhooks.

Once Katib is deployed in the Kubernetes cluster, the `cert-generator` follows these steps:

- Generate the self-signed certificate and private key.

- Update a Kubernetes Secret with the self-signed TLS certificate and private key.
- Patch the webhooks with the `CABundle`.

Once the `cert-generator` finished, the Katib controller starts to register controllers such as `experiment-controller` to the manager.

You can find the `cert-generator` source code [here](../pkg/certgenerator/v1beta1).

NOTE: the Katib also supports the [cert-manager](https://cert-manager.io/) to generate certs for the admission webhooks instead of using cert-generator.
You can find the installation with the cert-manager [here](../manifests/v1beta1/installs/katib-cert-manager).

## Implement a new algorithm and use it in Katib

Please see [new-algorithm-service.md](./new-algorithm-service.md).

## Katib UI documentation

Please see [Katib UI README](../pkg/ui/v1beta1).

## Design proposals

Please see [proposals](./proposals).

## Code Style

### pre-commit

Make sure to install [pre-commit](https://pre-commit.com/) (`pip install
pre-commit`) and run `pre-commit install` from the root of the repository at
least once before creating git commits.

The pre-commit [hooks](../.pre-commit-config.yaml) ensure code quality and
consistency. They are executed in CI. PRs that fail to comply with the hooks
will not be able to pass the corresponding CI gate. The hooks are only executed
against staged files unless you run `pre-commit run --all`, in which case,
they'll be executed against every file in the repository.

Specific programmatically generated files listed in the `exclude` field in
[.pre-commit-config.yaml](../.pre-commit-config.yaml) are deliberately excluded
from the hooks.



================================================
FILE: Dockerfile.conformance
================================================
# Copyright 2023 The Kubeflow Authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Dockerfile for building the source code of conformance tests
FROM python:3.10-slim

WORKDIR /kubeflow/katib

COPY sdk/ /kubeflow/katib/sdk/
COPY examples/ /kubeflow/katib/examples/
COPY test/ /kubeflow/katib/test/
COPY pkg/ /kubeflow/katib/pkg/

COPY conformance/run.sh .

# Add test script.
RUN chmod +x run.sh

RUN pip install --prefer-binary -e sdk/python/v1beta1

ENTRYPOINT [ "./run.sh" ]


================================================
FILE: go.mod
================================================
module github.com/kubeflow/katib

go 1.24.0

require (
	github.com/DATA-DOG/go-sqlmock v1.5.0
	github.com/awalterschulze/gographviz v2.0.3+incompatible
	github.com/c-bata/goptuna v0.8.0
	github.com/go-sql-driver/mysql v1.5.0
	github.com/google/go-cmp v0.7.0
	github.com/google/go-containerregistry v0.20.6
	github.com/google/go-containerregistry/pkg/authn/k8schain v0.0.0-20250613215107-59a4b8593039
	github.com/grpc-ecosystem/go-grpc-middleware v1.3.0
	github.com/lib/pq v1.10.6
	github.com/mattbaird/jsonpatch v0.0.0-20171005235357-81af80346b1a
	github.com/nxadm/tail v1.4.11
	github.com/onsi/gomega v1.37.0
	github.com/open-policy-agent/cert-controller v0.13.0
	github.com/prometheus/client_golang v1.22.0
	github.com/shirou/gopsutil/v3 v3.22.5
	github.com/spf13/viper v1.9.0
	github.com/tidwall/gjson v1.14.1
	go.uber.org/mock v0.4.0
	google.golang.org/grpc v1.72.1
	google.golang.org/protobuf v1.36.6
	k8s.io/api v0.34.0
	k8s.io/apimachinery v0.34.0
	k8s.io/client-go v0.34.0
	k8s.io/code-generator v0.34.0
	k8s.io/klog/v2 v2.130.1
	k8s.io/kube-openapi v0.0.0-20250710124328-f3f2b991d03b
	k8s.io/utils v0.0.0-20250604170112-4c0f3b243397
	sigs.k8s.io/controller-runtime v0.22.0
	sigs.k8s.io/structured-merge-diff/v6 v6.3.0
	sigs.k8s.io/yaml v1.6.0
)

require (
	cloud.google.com/go/compute/metadata v0.7.0 // indirect
	github.com/Azure/azure-sdk-for-go v68.0.0+incompatible // indirect
	github.com/Azure/go-autorest v14.2.0+incompatible // indirect
	github.com/Azure/go-autorest/autorest v0.11.30 // indirect
	github.com/Azure/go-autorest/autorest/adal v0.9.24 // indirect
	github.com/Azure/go-autorest/autorest/azure/auth v0.5.13 // indirect
	github.com/Azure/go-autorest/autorest/azure/cli v0.4.7 // indirect
	github.com/Azure/go-autorest/autorest/date v0.3.1 // indirect
	github.com/Azure/go-autorest/logger v0.2.2 // indirect
	github.com/Azure/go-autorest/tracing v0.6.1 // indirect
	github.com/aws/aws-sdk-go-v2 v1.36.3 // indirect
	github.com/aws/aws-sdk-go-v2/config v1.29.14 // indirect
	github.com/aws/aws-sdk-go-v2/credentials v1.17.67 // indirect
	github.com/aws/aws-sdk-go-v2/feature/ec2/imds v1.16.30 // indirect
	github.com/aws/aws-sdk-go-v2/internal/configsources v1.3.34 // indirect
	github.com/aws/aws-sdk-go-v2/internal/endpoints/v2 v2.6.34 // indirect
	github.com/aws/aws-sdk-go-v2/internal/ini v1.8.3 // indirect
	github.com/aws/aws-sdk-go-v2/service/ecr v1.44.0 // indirect
	github.com/aws/aws-sdk-go-v2/service/ecrpublic v1.33.0 // indirect
	github.com/aws/aws-sdk-go-v2/service/internal/accept-encoding v1.12.3 // indirect
	github.com/aws/aws-sdk-go-v2/service/internal/presigned-url v1.12.15 // indirect
	github.com/aws/aws-sdk-go-v2/service/sso v1.25.3 // indirect
	github.com/aws/aws-sdk-go-v2/service/ssooidc v1.30.1 // indirect
	github.com/aws/aws-sdk-go-v2/service/sts v1.33.19 // indirect
	github.com/aws/smithy-go v1.22.3 // indirect
	github.com/awslabs/amazon-ecr-credential-helper/ecr-login v0.9.1 // indirect
	github.com/beorn7/perks v1.0.1 // indirect
	github.com/cespare/xxhash/v2 v2.3.0 // indirect
	github.com/chrismellard/docker-credential-acr-env v0.0.0-20230304212654-82a0ddb27589 // indirect
	github.com/containerd/stargz-snapshotter/estargz v0.16.3 // indirect
	github.com/davecgh/go-spew v1.1.2-0.20180830191138-d8f796af33cc // indirect
	github.com/dimchansky/utfbom v1.1.1 // indirect
	github.com/docker/cli v28.2.2+incompatible // indirect
	github.com/docker/distribution v2.8.3+incompatible // indirect
	github.com/docker/docker-credential-helpers v0.9.3 // indirect
	github.com/emicklei/go-restful/v3 v3.12.2 // indirect
	github.com/evanphx/json-patch v5.6.0+incompatible // indirect
	github.com/evanphx/json-patch/v5 v5.9.11 // indirect
	github.com/fsnotify/fsnotify v1.9.0 // indirect
	github.com/fxamacker/cbor/v2 v2.9.0 // indirect
	github.com/go-logr/logr v1.4.3 // indirect
	github.com/go-logr/zapr v1.3.0 // indirect
	github.com/go-ole/go-ole v1.2.6 // indirect
	github.com/go-openapi/jsonpointer v0.21.1 // indirect
	github.com/go-openapi/jsonreference v0.21.0 // indirect
	github.com/go-openapi/swag v0.23.1 // indirect
	github.com/gogo/protobuf v1.3.2 // indirect
	github.com/golang-jwt/jwt/v4 v4.5.2 // indirect
	github.com/google/btree v1.1.3 // indirect
	github.com/google/gnostic-models v0.7.0 // indirect
	github.com/google/go-containerregistry/pkg/authn/kubernetes v0.0.0-20250225234217-098045d5e61f // indirect
	github.com/google/uuid v1.6.0 // indirect
	github.com/hashicorp/hcl v1.0.0 // indirect
	github.com/josharian/intern v1.0.0 // indirect
	github.com/json-iterator/go v1.1.12 // indirect
	github.com/klauspost/compress v1.18.0 // indirect
	github.com/lufia/plan9stats v0.0.0-20211012122336-39d0f177ccd0 // indirect
	github.com/magiconair/properties v1.8.5 // indirect
	github.com/mailru/easyjson v0.9.0 // indirect
	github.com/mitchellh/go-homedir v1.1.0 // indirect
	github.com/mitchellh/mapstructure v1.4.2 // indirect
	github.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd // indirect
	github.com/modern-go/reflect2 v1.0.3-0.20250322232337-35a7c28c31ee // indirect
	github.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822 // indirect
	github.com/opencontainers/go-digest v1.0.0 // indirect
	github.com/opencontainers/image-spec v1.1.1 // indirect
	github.com/pelletier/go-toml v1.9.4 // indirect
	github.com/pkg/errors v0.9.1 // indirect
	github.com/pmezard/go-difflib v1.0.0 // indirect
	github.com/power-devops/perfstat v0.0.0-20210106213030-5aafc221ea8c // indirect
	github.com/prometheus/client_model v0.6.1 // indirect
	github.com/prometheus/common v0.62.0 // indirect
	github.com/prometheus/procfs v0.15.1 // indirect
	github.com/sirupsen/logrus v1.9.3 // indirect
	github.com/spf13/afero v1.6.0 // indirect
	github.com/spf13/cast v1.4.1 // indirect
	github.com/spf13/jwalterweatherman v1.1.0 // indirect
	github.com/spf13/pflag v1.0.6 // indirect
	github.com/subosito/gotenv v1.2.0 // indirect
	github.com/tidwall/match v1.1.1 // indirect
	github.com/tidwall/pretty v1.2.0 // indirect
	github.com/tklauser/go-sysconf v0.3.10 // indirect
	github.com/tklauser/numcpus v0.4.0 // indirect
	github.com/vbatts/tar-split v0.12.1 // indirect
	github.com/x448/float16 v0.8.4 // indirect
	github.com/yusufpapurcu/wmi v1.2.2 // indirect
	go.uber.org/atomic v1.11.0 // indirect
	go.uber.org/multierr v1.11.0 // indirect
	go.uber.org/zap v1.27.0 // indirect
	go.yaml.in/yaml/v2 v2.4.2 // indirect
	go.yaml.in/yaml/v3 v3.0.4 // indirect
	golang.org/x/crypto v0.39.0 // indirect
	golang.org/x/mod v0.25.0 // indirect
	golang.org/x/net v0.41.0 // indirect
	golang.org/x/oauth2 v0.30.0 // indirect
	golang.org/x/sync v0.15.0 // indirect
	golang.org/x/sys v0.33.0 // indirect
	golang.org/x/term v0.32.0 // indirect
	golang.org/x/text v0.26.0 // indirect
	golang.org/x/time v0.11.0 // indirect
	golang.org/x/tools v0.34.0 // indirect
	gomodules.xyz/jsonpatch/v2 v2.4.0 // indirect
	gonum.org/v1/gonum v0.8.2 // indirect
	google.golang.org/genproto/googleapis/rpc v0.0.0-20250303144028-a0af3efb3deb // indirect
	gopkg.in/evanphx/json-patch.v4 v4.12.0 // indirect
	gopkg.in/inf.v0 v0.9.1 // indirect
	gopkg.in/ini.v1 v1.63.2 // indirect
	gopkg.in/tomb.v1 v1.0.0-20141024135613-dd632973f1e7 // indirect
	gopkg.in/yaml.v2 v2.4.0 // indirect
	gopkg.in/yaml.v3 v3.0.1 // indirect
	k8s.io/apiextensions-apiserver v0.34.0 // indirect
	k8s.io/gengo/v2 v2.0.0-20250604051438-85fd79dbfd9f // indirect
	sigs.k8s.io/json v0.0.0-20241014173422-cfa47c3a1cc8 // indirect
	sigs.k8s.io/randfill v1.0.0 // indirect
)



================================================
FILE: LICENSE
================================================
                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.



================================================
FILE: Makefile
================================================
HAS_LINT := $(shell command -v golangci-lint;)
HAS_YAMLLINT := $(shell command -v yamllint;)
HAS_SHELLCHECK := $(shell command -v shellcheck;)
HAS_SETUP_ENVTEST := $(shell command -v setup-envtest;)
HAS_MOCKGEN := $(shell command -v mockgen;)

COMMIT := v1beta1-$(shell git rev-parse --short=7 HEAD)
KATIB_REGISTRY := ghcr.io/kubeflow/katib
CPU_ARCH ?= linux/amd64,linux/arm64
CONTROLLER_GEN_VERSION ?= v0.18.0
ENVTEST_K8S_VERSION ?= 1.34.0
ENVTEST_VERSION ?= release-0.22
MOCKGEN_VERSION ?= $(shell grep 'go.uber.org/mock' go.mod | cut -d ' ' -f 2)
GO_VERSION=$(shell grep '^go' go.mod | cut -d ' ' -f 2)
GOPATH ?= $(shell go env GOPATH)

TEST_TENSORFLOW_EVENT_FILE_PATH ?= $(CURDIR)/test/unit/v1beta1/metricscollector/testdata/tfevent-metricscollector/logs

# Run tests
.PHONY: test
test: envtest
	KUBEBUILDER_ASSETS="$(shell setup-envtest use $(ENVTEST_K8S_VERSION) -p path)" go test ./pkg/... ./cmd/... -coverprofile coverage.out

envtest:
ifndef HAS_SETUP_ENVTEST
	go install sigs.k8s.io/controller-runtime/tools/setup-envtest@$(ENVTEST_VERSION)
	$(info "setup-envtest has been installed")
endif
	$(info "setup-envtest has already installed")

check: generated-codes go-mod fmt vet lint

fmt:
	hack/verify-gofmt.sh

lint:
ifndef HAS_LINT
	go install github.com/golangci/golangci-lint/cmd/golangci-lint@v1.64.7
	$(info "golangci-lint has been installed")
endif
	hack/verify-golangci-lint.sh

yamllint:
ifndef HAS_YAMLLINT
	pip install --prefer-binary yamllint
	$(info "yamllint has been installed")
endif
	hack/verify-yamllint.sh

vet:
	go vet ./pkg/... ./cmd/...

shellcheck:
ifndef HAS_SHELLCHECK
	bash hack/install-shellcheck.sh
	$(info "shellcheck has been installed")
endif
	hack/verify-shellcheck.sh

update:
	hack/update-gofmt.sh

# Deploy Katib v1beta1 manifests using Kustomize into a k8s cluster.
deploy:
	bash scripts/v1beta1/deploy.sh $(WITH_DATABASE_TYPE)

# Undeploy Katib v1beta1 manifests using Kustomize from a k8s cluster
undeploy:
	bash scripts/v1beta1/undeploy.sh

generated-codes: generate
ifneq ($(shell bash hack/verify-generated-codes.sh '.'; echo $$?),0)
	$(error 'Please run "make generate" to generate codes')
endif

go-mod: sync-go-mod
ifneq ($(shell bash hack/verify-generated-codes.sh 'go.*'; echo $$?),0)
	$(error 'Please run "go mod tidy -go $(GO_VERSION)" to sync Go modules')
endif

sync-go-mod:
	go mod tidy -go $(GO_VERSION)

.PHONY: go-mod-download
go-mod-download:
	go mod download

CONTROLLER_GEN = $(shell pwd)/bin/controller-gen
.PHONY: controller-gen
controller-gen:
	@GOBIN=$(shell pwd)/bin GO111MODULE=on go install sigs.k8s.io/controller-tools/cmd/controller-gen@${CONTROLLER_GEN_VERSION}

# Run this if you update any existing controller APIs.
# 1. Generate deepcopy, clientset, listers, informers for the APIs (hack/update-codegen.sh)
# 2. Generate open-api for the APIs (hack/update-openapigen)
# 3. Generate Python SDK for Katib (hack/gen-python-sdk/gen-sdk.sh)
# 4. Generate gRPC manager APIs (pkg/apis/manager/v1beta1/build.sh and pkg/apis/manager/health/build.sh)
# 5. Generate Go mock codes
generate: go-mod-download controller-gen
ifndef HAS_MOCKGEN
	go install go.uber.org/mock/mockgen@$(MOCKGEN_VERSION)
	$(info "mockgen has been installed")
endif
	go generate ./pkg/... ./cmd/...
	hack/gen-python-sdk/gen-sdk.sh
	hack/update-proto.sh
	hack/update-mockgen.sh

# Build images for the Katib v1beta1 components.
build: generate
ifeq ($(and $(REGISTRY),$(TAG),$(CPU_ARCH)),)
	$(error REGISTRY and TAG must be set. Usage: make build REGISTRY=<registry> TAG=<tag> CPU_ARCH=<cpu-architecture>)
endif
	bash scripts/v1beta1/build.sh $(REGISTRY) $(TAG) $(CPU_ARCH)

# Build and push Katib images from the latest master commit.
push-latest: generate
	bash scripts/v1beta1/build.sh $(KATIB_REGISTRY) latest $(CPU_ARCH)
	bash scripts/v1beta1/build.sh $(KATIB_REGISTRY) $(COMMIT) $(CPU_ARCH)
	bash scripts/v1beta1/push.sh $(KATIB_REGISTRY) latest
	bash scripts/v1beta1/push.sh $(KATIB_REGISTRY) $(COMMIT)

# Build and push Katib images for the given tag.
push-tag:
ifeq ($(TAG),)
	$(error TAG must be set. Usage: make push-tag TAG=<release-tag>)
endif
	bash scripts/v1beta1/build.sh $(KATIB_REGISTRY) $(TAG) $(CPU_ARCH)
	bash scripts/v1beta1/push.sh $(KATIB_REGISTRY) $(TAG)

# Release a new version of Katib.
release:
ifeq ($(and $(BRANCH),$(TAG)),)
	$(error BRANCH and TAG must be set. Usage: make release BRANCH=<branch> TAG=<tag>)
endif
	bash scripts/v1beta1/release.sh $(BRANCH) $(TAG)

# Update all Katib images.
update-images:
ifeq ($(and $(OLD_PREFIX),$(NEW_PREFIX),$(TAG)),)
	$(error OLD_PREFIX, NEW_PREFIX, and TAG must be set. \
	Usage: make update-images OLD_PREFIX=<old-prefix> NEW_PREFIX=<new-prefix> TAG=<tag> \
	For more information, check this file: scripts/v1beta1/update-images.sh)
endif
	bash scripts/v1beta1/update-images.sh $(OLD_PREFIX) $(NEW_PREFIX) $(TAG)

# Prettier UI format check for Katib v1beta1.
prettier-check:
	npm run format:check --prefix pkg/ui/v1beta1/frontend

# Update boilerplate for the source code.
update-boilerplate:
	./hack/boilerplate/update-boilerplate.sh

prepare-pytest:
	pip install --prefer-binary -r test/unit/v1beta1/requirements.txt
	pip install --prefer-binary -r cmd/suggestion/hyperopt/v1beta1/requirements.txt
	pip install --prefer-binary -r cmd/suggestion/optuna/v1beta1/requirements.txt
	pip install --prefer-binary -r cmd/suggestion/hyperband/v1beta1/requirements.txt
	pip install --prefer-binary -r cmd/suggestion/nas/enas/v1beta1/requirements.txt
	pip install --prefer-binary -r cmd/suggestion/nas/darts/v1beta1/requirements.txt
	pip install --prefer-binary -r cmd/suggestion/pbt/v1beta1/requirements.txt
	pip install --prefer-binary -r cmd/earlystopping/medianstop/v1beta1/requirements.txt
	pip install --prefer-binary -r cmd/metricscollector/v1beta1/tfevent-metricscollector/requirements.txt
	# `TypeIs` was introduced in typing-extensions 4.10.0, and torch 2.6.0 requires typing-extensions>=4.10.0.
	# REF: https://github.com/kubeflow/katib/pull/2504
	# TODO (tenzen-y): Once we upgrade libraries depended on typing-extensions==4.5.0, we can remove this line.
	pip install typing-extensions==4.10.0

prepare-pytest-testdata:
ifeq ("$(wildcard $(TEST_TENSORFLOW_EVENT_FILE_PATH))", "")
	python examples/v1beta1/trial-images/tf-mnist-with-summaries/mnist.py --epochs 5 --batch-size 200 --log-path $(TEST_TENSORFLOW_EVENT_FILE_PATH)
endif

# TODO(Electronic-Waste): Remove the import rewrite when protobuf supports `python_package` option.
# REF: https://github.com/protocolbuffers/protobuf/issues/7061
pytest: prepare-pytest prepare-pytest-testdata
	pytest ./test/unit/v1beta1/suggestion --ignore=./test/unit/v1beta1/suggestion/test_skopt_service.py
	pytest ./test/unit/v1beta1/earlystopping
	pytest ./test/unit/v1beta1/metricscollector
	cp ./pkg/apis/manager/v1beta1/python/api_pb2.py ./sdk/python/v1beta1/kubeflow/katib/katib_api_pb2.py
	cp ./pkg/apis/manager/v1beta1/python/api_pb2_grpc.py ./sdk/python/v1beta1/kubeflow/katib/katib_api_pb2_grpc.py
	sed -i "s/api_pb2/kubeflow\.katib\.katib_api_pb2/g" ./sdk/python/v1beta1/kubeflow/katib/katib_api_pb2_grpc.py
	pytest ./sdk/python/v1beta1/kubeflow/katib
	rm ./sdk/python/v1beta1/kubeflow/katib/katib_api_pb2.py ./sdk/python/v1beta1/kubeflow/katib/katib_api_pb2_grpc.py

# The skopt service doesn't work appropriately with Python 3.11.
# So, we need to run the test with Python 3.9.
# TODO (tenzen-y): Once we stop to support skopt, we can remove this test.
# REF: https://github.com/kubeflow/katib/issues/2280
pytest-skopt:
	pip install six
	pip install --prefer-binary -r test/unit/v1beta1/requirements.txt
	pip install --prefer-binary -r cmd/suggestion/skopt/v1beta1/requirements.txt
	pytest ./test/unit/v1beta1/suggestion/test_skopt_service.py



================================================
FILE: OWNERS
================================================
approvers:
  - andreyvelich
  - Electronic-Waste
  - gaocegege
  - johnugeorge
reviewers:
  - anencore94
  - c-bata
emeritus_approvers:
  - tenzen-y



================================================
FILE: PROJECT
================================================
version: "3"
domain: kubeflow.org
repo: github.com/kubeflow/katib



================================================
FILE: ROADMAP.md
================================================
# Katib 2022/2023 Roadmap

## AutoML Features

- Support advance HyperParameter tuning algorithms:

  - Population Based Training (PBT) - [#1382](https://github.com/kubeflow/katib/issues/1382)
  - Tree of Parzen Estimators (TPE)
  - Multivariate TPE
  - Sobol’s Quasirandom Sequence
  - Asynchronous Successive Halving - [ASHA](https://arxiv.org/pdf/1810.05934.pdf)

- Support multi-objective optimization - [#1549](https://github.com/kubeflow/katib/issues/1549)
- Support various HP distributions (log-uniform, uniform, normal) - [#1207](https://github.com/kubeflow/katib/issues/1207)
- Support Auto Model Compression - [#460](https://github.com/kubeflow/katib/issues/460)
- Support Auto Feature Engineering - [#475](https://github.com/kubeflow/katib/issues/475)
- Improve Neural Architecture Search design

## Backend and API Enhancements

- Conformance tests for Katib - [#2044](https://github.com/kubeflow/katib/issues/2044)
- Support push-based metrics collection in Katib - [#577](https://github.com/kubeflow/katib/issues/577)
- Support PostgreSQL as a Katib DB - [#915](https://github.com/kubeflow/katib/issues/915)
- Improve Katib scalability - [#1847](https://github.com/kubeflow/katib/issues/1847)
- Promote Katib APIs to the `v1` version
- Support multiple CRD versions (`v1beta1`, `v1`) with conversion webhook

## Improve Katib User Experience

- Simplify Katib Experiment creation with Katib SDK - [#1951](https://github.com/kubeflow/katib/pull/1951)
- Fully migrate to a new Katib UI - [Project 1](https://github.com/kubeflow/katib/projects/1)
- Expose Trial logs in Katib UI - [#971](https://github.com/kubeflow/katib/issues/971)
- Enhance Katib UI visualization metrics for AutoML Experiments
- Improve Katib Config UX - [#2150](https://github.com/kubeflow/katib/issues/2150)

## Integration with Kubeflow Components

- Kubeflow Pipeline as a Katib Trial target - [#1914](https://github.com/kubeflow/katib/issues/1914)
- Improve data passing when Katib Experiment is part of Kubeflow Pipeline - [#1846](https://github.com/kubeflow/katib/issues/1846)

# History

# Katib 2021 Roadmap

## New Features

### AutoML

- Support Population Based Training [#1382](https://github.com/kubeflow/katib/issues/1382)
- Support [ASHA](https://arxiv.org/pdf/1810.05934.pdf)
- Support Auto Model Compression [#460](https://github.com/kubeflow/katib/issues/460)
- Support Auto Feature Engineering [#475](https://github.com/kubeflow/katib/issues/475)
- Various CRDs for HP, NAS and other AutoML techniques.

### UI

- Migrate to the new Katib UI [Project 1](https://github.com/kubeflow/katib/projects/1)
- Hyperparameter importances visualization with fANOVA algorithm

## Enhancements

- Finish AWS CI/CD migration
- Support various parameter distribution [#1207](https://github.com/kubeflow/katib/issues/1207)
- Finish validation for Algorithms [#1126](https://github.com/kubeflow/katib/issues/1126)
- Refactor Hyperband [#1389](https://github.com/kubeflow/katib/issues/1389)
- Support multiple CRD version with conversion webhook
- MLMD integration with Katib Experiments

# Katib 2020 Roadmap

## New Features

### Hyperparameter Tuning

- Support Early Stopping [#692](https://github.com/kubeflow/katib/issues/692)

### Neural Architecture Search

- Support Advanced NAS Algorithms like DARTs, ProxylessNAS [#461](https://github.com/kubeflow/katib/issues/461)

### Other Features

- Support Auto Model Compression [#460](https://github.com/kubeflow/katib/issues/460)
- Support Auto Feature Engineering [#475](https://github.com/kubeflow/katib/issues/475)

## Enhancements

### Common

- Delete Suggestion deployment after Experiment is finished [#1061](https://github.com/kubeflow/katib/issues/1061)
- Save Suggestion state after deployment is deleted [#1062](https://github.com/kubeflow/katib/issues/1062)
- Reconsider the design of Trial Template [#906](https://github.com/kubeflow/katib/issues/906)
- Design an extensible model for integrating with custom resources.
- Add validation for algorithms (a.k.a suggestions) [#1126](https://github.com/kubeflow/katib/issues/1126)
- Katib UI fixes and enhancements
- Investigate Kubeflow Metadata integration
- Investigate the alignment with concept and implementation of "experiments" and "jobs/runs" in KFP [#4955](https://github.com/kubeflow/kubeflow/issues/4955)

### Neural Architecture Search

- Refactor structure for NAS algorithms [#1125](https://github.com/kubeflow/katib/issues/1125)
- Refactor the design for NAS model constructor [#1127](https://github.com/kubeflow/katib/issues/1127)
- ENAS enhancements such as micro mode, RNN support



================================================
FILE: SECURITY.md
================================================
# Security Policy

## Supported Versions

Kubeflow Katib versions are expressed as `vX.Y.Z`, where X is the major version,
Y is the minor version, and Z is the patch version, following the
[Semantic Versioning](https://semver.org/) terminology.

The Kubeflow Katib project maintains release branches for the most recent two minor releases.
Applicable fixes, including security fixes, may be backported to those two release branches,
depending on severity and feasibility.

Users are encouraged to stay updated with the latest releases to benefit from security patches and
improvements.

## Reporting a Vulnerability

We're extremely grateful for security researchers and users that report vulnerabilities to the
Kubeflow Open Source Community. All reports are thoroughly investigated by Kubeflow projects owners.

You can use the following ways to report security vulnerabilities privately:

- Using the Kubeflow Katib repository [GitHub Security Advisory](https://github.com/kubeflow/katib/security/advisories/new).
- Using our private Kubeflow Steering Committee mailing list: ksc@kubeflow.org.

Please provide detailed information to help us understand and address the issue promptly.

## Disclosure Process

**Acknowledgment**: We will acknowledge receipt of your report within 10 business days.

**Assessment**: The Kubeflow projects owners will investigate the reported issue to determine its
validity and severity.

**Resolution**: If the issue is confirmed, we will work on a fix and prepare a release.

**Notification**: Once a fix is available, we will notify the reporter and coordinate a public
disclosure.

**Public Disclosure**: Details of the vulnerability and the fix will be published in the project's
release notes and communicated through appropriate channels.

## Prevention Mechanisms

Kubeflow Katib employs several measures to prevent security issues:

**Code Reviews**: All code changes are reviewed by maintainers to ensure code quality and security.

**Dependency Management**: Regular updates and monitoring of dependencies (e.g. Dependabot) to
address known vulnerabilities.

**Continuous Integration**: Automated testing and security checks are integrated into the CI/CD pipeline.

**Image Scanning**: Container images are scanned for vulnerabilities.

## Communication Channels

For the general questions please join the following resources:

- Kubeflow [Slack channels](https://www.kubeflow.org/docs/about/community/#kubeflow-slack-channels).

- Kubeflow discuss [mailing list](https://www.kubeflow.org/docs/about/community/#kubeflow-mailing-list).

Please **do not report** security vulnerabilities through public channels.



================================================
FILE: .dockerignore
================================================
.git
.gitignore
docs
manifests
pkg/ui/*/frontend/node_modules
pkg/ui/*/frontend/build



================================================
FILE: .flake8
================================================
[flake8]
max-line-length = 100
# E203 is ignored to avoid conflicts with Black's formatting, as it's not PEP 8 compliant
extend-ignore = W503, E203



================================================
FILE: .gcloudignore
================================================
.git
.gitignore
docs
examples
manifests



================================================
FILE: .pre-commit-config.yaml
================================================
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v2.3.0
    hooks:
      - id: check-yaml
        args: [--allow-multiple-documents]
      - id: check-json
  - repo: https://github.com/pycqa/isort
    rev: 5.11.5
    hooks:
      - id: isort
        name: isort
        entry: isort --profile black
  - repo: https://github.com/psf/black
    rev: 24.2.0
    hooks:
      - id: black
        files: (sdk|examples|pkg)/.*
  - repo: https://github.com/pycqa/flake8
    rev: 7.1.1
    hooks:
      - id: flake8
        files: (sdk|examples|pkg)/.*
exclude: |
  (?x)^(
    .*zz_generated.deepcopy.*|
    .*pb.go|
    pkg/apis/manager/.*pb2(?:_grpc)?.py(?:i)?|
    pkg/apis/v1beta1/openapi_generated.go|
    pkg/mock/.*|
    pkg/client/controller/.*|
    sdk/python/v1beta1/kubeflow/katib/configuration.py|
    sdk/python/v1beta1/kubeflow/katib/rest.py|
    sdk/python/v1beta1/kubeflow/katib/__init__.py|
    sdk/python/v1beta1/kubeflow/katib/exceptions.py|
    sdk/python/v1beta1/kubeflow/katib/api_client.py|
    sdk/python/v1beta1/kubeflow/katib/models/.*
  )$



================================================
FILE: cmd/db-manager/v1beta1/Dockerfile
================================================
# Build the Katib DB manager.
FROM golang:alpine AS build-env

ARG TARGETARCH

WORKDIR /go/src/github.com/kubeflow/katib

# Download packages.
COPY go.mod .
COPY go.sum .
RUN go mod download -x

# Copy sources.
COPY cmd/ cmd/
COPY pkg/ pkg/

# Build the binary.
RUN CGO_ENABLED=0 GOOS=linux GOARCH="${TARGETARCH}" go build -a -o katib-db-manager ./cmd/db-manager/v1beta1

# Copy the db-manager into a thin image.
FROM alpine:3.15
WORKDIR /app
COPY --from=build-env /go/src/github.com/kubeflow/katib/katib-db-manager /app/
ENTRYPOINT ["./katib-db-manager"]



================================================
FILE: cmd/db-manager/v1beta1/main.go
================================================
/*
Copyright 2022 The Kubeflow Authors.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package main

import (
	"context"
	"flag"
	"fmt"
	"net"
	"os"
	"time"

	health_pb "github.com/kubeflow/katib/pkg/apis/manager/health"
	api_pb "github.com/kubeflow/katib/pkg/apis/manager/v1beta1"
	db "github.com/kubeflow/katib/pkg/db/v1beta1"
	"github.com/kubeflow/katib/pkg/db/v1beta1/common"
	"k8s.io/klog/v2"

	"google.golang.org/grpc"
	"google.golang.org/grpc/reflection"
)

const (
	defaultListenAddress  = "0.0.0.0:6789"
	defaultConnectTimeout = time.Second * 60
)

var dbIf common.KatibDBInterface

type server struct {
}

// Report a log of Observations for a Trial.
// The log consists of timestamp and value of metric.
// Katib store every log of metrics.
// You can see accuracy curve or other metric logs on UI.
func (s *server) ReportObservationLog(ctx context.Context, in *api_pb.ReportObservationLogRequest) (*api_pb.ReportObservationLogReply, error) {
	err := dbIf.RegisterObservationLog(in.TrialName, in.ObservationLog)
	return &api_pb.ReportObservationLogReply{}, err
}

// Get all log of Observations for a Trial.
func (s *server) GetObservationLog(ctx context.Context, in *api_pb.GetObservationLogRequest) (*api_pb.GetObservationLogReply, error) {
	ol, err := dbIf.GetObservationLog(in.TrialName, in.MetricName, in.StartTime, in.EndTime)
	return &api_pb.GetObservationLogReply{
		ObservationLog: ol,
	}, err
}

// Delete all log of Observations for a Trial.
func (s *server) DeleteObservationLog(ctx context.Context, in *api_pb.DeleteObservationLogRequest) (*api_pb.DeleteObservationLogReply, error) {
	err := dbIf.DeleteObservationLog(in.TrialName)
	return &api_pb.DeleteObservationLogReply{}, err
}

func (s *server) Check(ctx context.Context, in *health_pb.HealthCheckRequest) (*health_pb.HealthCheckResponse, error) {
	resp := health_pb.HealthCheckResponse{
		Status: health_pb.HealthCheckResponse_SERVING,
	}

	// We only accept optional service name only if it's set to suggested format.
	if in != nil && in.Service != "" && in.Service != "grpc.health.v1.Health" {
		resp.Status = health_pb.HealthCheckResponse_UNKNOWN
		return &resp, fmt.Errorf("grpc.health.v1.Health can only be accepted if you specify service name.")
	}

	// Check if connection to katib db driver is okay since otherwise manager could not serve most of its methods.
	err := dbIf.SelectOne()
	if err != nil {
		resp.Status = health_pb.HealthCheckResponse_NOT_SERVING
		return &resp, fmt.Errorf("Failed to execute `SELECT 1` probe: %v", err)
	}

	return &resp, nil
}

func main() {
	var connectTimeout time.Duration
	var listenAddress string
	flag.DurationVar(&connectTimeout, "connect-timeout", defaultConnectTimeout, "Timeout before calling error during database connection. (e.g. 120s)")
	flag.StringVar(&listenAddress, "listen-address", defaultListenAddress, "The network interface or IP address to receive incoming connections. (e.g. 0.0.0.0:6789)")
	flag.Parse()

	var err error
	dbNameEnvName := common.DBNameEnvName
	dbName := os.Getenv(dbNameEnvName)
	if dbName == "" {
		klog.Fatal("DB_NAME env is not set. Exiting")
	}
	dbIf, err = db.NewKatibDBInterface(dbName, connectTimeout)
	if err != nil {
		klog.Fatalf("Failed to open db connection: %v", err)
	}
	dbIf.DBInit()
	listener, err := net.Listen("tcp", listenAddress)
	if err != nil {
		klog.Fatalf("Failed to listen: %v", err)
	}

	size := 1<<31 - 1
	klog.Infof("Start Katib manager: %s", listenAddress)
	s := grpc.NewServer(grpc.MaxRecvMsgSize(size), grpc.MaxSendMsgSize(size))
	api_pb.RegisterDBManagerServer(s, &server{})
	health_pb.RegisterHealthServer(s, &server{})
	reflection.Register(s)
	if err = s.Serve(listener); err != nil {
		klog.Fatalf("Failed to serve: %v", err)
	}
}



================================================
FILE: cmd/db-manager/v1beta1/main_test.go
================================================
/*
Copyright 2022 The Kubeflow Authors.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package main

import (
	"context"
	"testing"

	"go.uber.org/mock/gomock"

	health_pb "github.com/kubeflow/katib/pkg/apis/manager/health"
	api_pb "github.com/kubeflow/katib/pkg/apis/manager/v1beta1"
	mockdb "github.com/kubeflow/katib/pkg/mock/v1beta1/db"
)

func TestReportObservationLog(t *testing.T) {
	ctrl := gomock.NewController(t)
	defer ctrl.Finish()
	s := &server{}
	mockDB := mockdb.NewMockKatibDBInterface(ctrl)
	dbIf = mockDB

	req := &api_pb.ReportObservationLogRequest{
		TrialName: "test1-trial1",
		ObservationLog: &api_pb.ObservationLog{
			MetricLogs: []*api_pb.MetricLog{
				{
					TimeStamp: "2019-02-03T04:05:06+09:00",
					Metric: &api_pb.Metric{
						Name:  "f1_score",
						Value: "88.95",
					},
				},
				{
					TimeStamp: "2019-02-03T04:05:06+09:00",
					Metric: &api_pb.Metric{
						Name:  "loss",
						Value: "0.5",
					},
				},
				{
					TimeStamp: "2019-02-03T04:05:06+09:00",
					Metric: &api_pb.Metric{
						Name:  "precision",
						Value: "88.7",
					},
				},
				{
					TimeStamp: "2019-02-03T04:05:06+09:00",
					Metric: &api_pb.Metric{
						Name:  "recall",
						Value: "89.2",
					},
				},
			},
		},
	}
	mockDB.EXPECT().RegisterObservationLog(req.TrialName, req.ObservationLog).Return(nil)
	_, err := s.ReportObservationLog(context.Background(), req)
	if err != nil {
		t.Fatalf("ReportObservationLog Error %v", err)
	}
}

func TestGetObservationLog(t *testing.T) {
	ctrl := gomock.NewController(t)
	defer ctrl.Finish()
	s := &server{}
	mockDB := mockdb.NewMockKatibDBInterface(ctrl)
	dbIf = mockDB

	req := &api_pb.GetObservationLogRequest{
		TrialName: "test1-trial1",
		StartTime: "2019-02-03T03:05:06+09:00",
		EndTime:   "2019-02-03T05:05:06+09:00",
	}

	obs := &api_pb.ObservationLog{
		MetricLogs: []*api_pb.MetricLog{
			{
				TimeStamp: "2019-02-03T04:05:06+09:00",
				Metric: &api_pb.Metric{
					Name:  "f1_score",
					Value: "88.95",
				},
			},
			{
				TimeStamp: "2019-02-03T04:05:06+09:00",
				Metric: &api_pb.Metric{
					Name:  "loss",
					Value: "0.5",
				},
			},
			{
				TimeStamp: "2019-02-03T04:05:06+09:00",
				Metric: &api_pb.Metric{
					Name:  "precision",
					Value: "88.7",
				},
			},
			{
				TimeStamp: "2019-02-03T04:05:06+09:00",
				Metric: &api_pb.Metric{
					Name:  "recall",
					Value: "89.2",
				},
			},
		},
	}

	mockDB.EXPECT().GetObservationLog(req.TrialName, req.MetricName, req.StartTime, req.EndTime).Return(obs, nil)
	ret, err := s.GetObservationLog(context.Background(), req)
	if err != nil {
		t.Fatalf("GetObservationLog Error %v", err)
	}
	if len(obs.MetricLogs) != len(ret.ObservationLog.MetricLogs) {
		t.Fatalf("GetObservationLog Test fail expect metrics number %d got %d", len(obs.MetricLogs), len(ret.ObservationLog.MetricLogs))
	}
}

func TestDeleteObservationLog(t *testing.T) {
	ctrl := gomock.NewController(t)
	defer ctrl.Finish()
	s := &server{}
	mockDB := mockdb.NewMockKatibDBInterface(ctrl)
	dbIf = mockDB

	req := &api_pb.DeleteObservationLogRequest{
		TrialName: "test1-trial1",
	}
	mockDB.EXPECT().DeleteObservationLog(req.TrialName).Return(nil)
	_, err := s.DeleteObservationLog(context.Background(), req)
	if err != nil {
		t.Fatalf("DeleteExperiment Error %v", err)
	}
}

func TestCheck(t *testing.T) {
	ctrl := gomock.NewController(t)
	defer ctrl.Finish()
	s := &server{}
	mockDB := mockdb.NewMockKatibDBInterface(ctrl)
	dbIf = mockDB
	testCases := []struct {
		Request        *health_pb.HealthCheckRequest
		ExpectedStatus health_pb.HealthCheckResponse_ServingStatus
		Name           string
	}{
		{
			Request: &health_pb.HealthCheckRequest{
				Service: "grpc.health.v1.Health",
			},
			ExpectedStatus: health_pb.HealthCheckResponse_SERVING,
			Name:           "Valid Request",
		},
		{
			Request: &health_pb.HealthCheckRequest{
				Service: "grpc.health.v1.1.Health",
			},
			ExpectedStatus: health_pb.HealthCheckResponse_UNKNOWN,
			Name:           "Invalid service name",
		},
	}

	mockDB.EXPECT().SelectOne().Return(nil)

	for _, tc := range testCases {
		response, _ := s.Check(context.Background(), tc.Request)
		if response.Status != tc.ExpectedStatus {
			t.Fatalf("Case %v failed. ExpectedStatus %v, got %v", tc.Name, tc.ExpectedStatus, response.Status)
		}
	}
}



================================================
FILE: cmd/earlystopping/medianstop/v1beta1/Dockerfile
================================================
FROM python:3.11-slim

ARG TARGETARCH
ENV TARGET_DIR /opt/katib
ENV EARLY_STOPPING_DIR cmd/earlystopping/medianstop/v1beta1
ENV PYTHONPATH ${TARGET_DIR}:${TARGET_DIR}/pkg/apis/manager/v1beta1/python

RUN if [ "${TARGETARCH}" = "ppc64le" ] || [ "${TARGETARCH}" = "arm64" ]; then \
    apt-get -y update && \
    apt-get -y install gfortran libopenblas-dev liblapack-dev && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*; \
  fi

ADD ./pkg/ ${TARGET_DIR}/pkg/
ADD ./${EARLY_STOPPING_DIR}/ ${TARGET_DIR}/${EARLY_STOPPING_DIR}/

WORKDIR  ${TARGET_DIR}/${EARLY_STOPPING_DIR}

RUN pip install --prefer-binary --no-cache-dir -r requirements.txt
RUN chgrp -R 0 ${TARGET_DIR} \
  && chmod -R g+rwX ${TARGET_DIR}

ENTRYPOINT ["python", "main.py"]



================================================
FILE: cmd/earlystopping/medianstop/v1beta1/main.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging
import time
from concurrent import futures

import grpc

from pkg.apis.manager.v1beta1.python import api_pb2_grpc
from pkg.earlystopping.v1beta1.medianstop.service import MedianStopService

_ONE_DAY_IN_SECONDS = 60 * 60 * 24
DEFAULT_PORT = "0.0.0.0:6788"

logger = logging.getLogger()
logging.basicConfig(level=logging.INFO)


def serve():
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    service = MedianStopService()
    api_pb2_grpc.add_EarlyStoppingServicer_to_server(service, server)

    server.add_insecure_port(DEFAULT_PORT)
    logger.info("Start Median Stop service at address {}".format(DEFAULT_PORT))
    server.start()
    try:
        while True:
            time.sleep(_ONE_DAY_IN_SECONDS)
    except KeyboardInterrupt:
        server.stop(0)


if __name__ == "__main__":
    serve()



================================================
FILE: cmd/earlystopping/medianstop/v1beta1/requirements.txt
================================================
grpcio>=1.64.1
protobuf>=4.21.12,<5
googleapis-common-protos==1.6.0
kubernetes==22.6.0
cython>=0.29.24



================================================
FILE: cmd/katib-controller/v1beta1/Dockerfile
================================================
# Build the Katib controller.
FROM golang:alpine AS build-env

ARG TARGETARCH

WORKDIR /go/src/github.com/kubeflow/katib

# Download packages.
COPY go.mod .
COPY go.sum .
RUN go mod download -x

# Copy sources.
COPY cmd/ cmd/
COPY pkg/ pkg/

# Build the binary.
RUN CGO_ENABLED=0 GOOS=linux GOARCH=${TARGETARCH} go build -a -o katib-controller ./cmd/katib-controller/v1beta1

# Copy the controller-manager into a thin image.
FROM alpine:3.15
WORKDIR /app
COPY --from=build-env /go/src/github.com/kubeflow/katib/katib-controller .
ENTRYPOINT ["./katib-controller"]



================================================
FILE: cmd/katib-controller/v1beta1/main.go
================================================
/*
Copyright 2022 The Kubeflow Authors.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

/*
Katib-controller is a controller (operator) for Experiments and Trials
*/
package main

import (
	"flag"
	"os"

	"github.com/spf13/viper"
	"k8s.io/apimachinery/pkg/runtime"
	_ "k8s.io/client-go/plugin/pkg/client/auth/gcp"
	"sigs.k8s.io/controller-runtime/pkg/client/config"
	"sigs.k8s.io/controller-runtime/pkg/healthz"
	logf "sigs.k8s.io/controller-runtime/pkg/log"
	"sigs.k8s.io/controller-runtime/pkg/log/zap"
	"sigs.k8s.io/controller-runtime/pkg/manager"
	"sigs.k8s.io/controller-runtime/pkg/manager/signals"
	metricsserver "sigs.k8s.io/controller-runtime/pkg/metrics/server"
	"sigs.k8s.io/controller-runtime/pkg/webhook"

	configv1beta1 "github.com/kubeflow/katib/pkg/apis/config/v1beta1"
	apis "github.com/kubeflow/katib/pkg/apis/controller"
	cert "github.com/kubeflow/katib/pkg/certgenerator/v1beta1"
	"github.com/kubeflow/katib/pkg/controller.v1beta1"
	"github.com/kubeflow/katib/pkg/controller.v1beta1/consts"
	"github.com/kubeflow/katib/pkg/util/v1beta1/katibconfig"
	webhookv1beta1 "github.com/kubeflow/katib/pkg/webhook/v1beta1"
	utilruntime "k8s.io/apimachinery/pkg/util/runtime"
	clientgoscheme "k8s.io/client-go/kubernetes/scheme"
)

var (
	scheme = runtime.NewScheme()
	log    = logf.Log.WithName("entrypoint")
)

func init() {
	utilruntime.Must(apis.AddToScheme(scheme))
	utilruntime.Must(configv1beta1.AddToScheme(scheme))
	utilruntime.Must(clientgoscheme.AddToScheme(scheme))
}

func main() {
	logf.SetLogger(zap.New())

	var katibConfigFile string
	flag.StringVar(&katibConfigFile, "katib-config", "",
		"The katib-controller will load its initial configuration from this file. "+
			"Omit this flag to use the default configuration values. ")
	flag.Parse()

	initConfig, err := katibconfig.GetInitConfigData(scheme, katibConfigFile)
	if err != nil {
		log.Error(err, "Failed to get KatibConfig")
		os.Exit(1)
	}

	// Set the config in viper.
	viper.Set(consts.ConfigExperimentSuggestionName, initConfig.ControllerConfig.ExperimentSuggestionName)
	viper.Set(consts.ConfigInjectSecurityContext, initConfig.ControllerConfig.InjectSecurityContext)
	viper.Set(consts.ConfigEnableGRPCProbeInSuggestion, initConfig.ControllerConfig.EnableGRPCProbeInSuggestion)

	trialGVKs, err := katibconfig.TrialResourcesToGVKs(initConfig.ControllerConfig.TrialResources)
	if err != nil {
		log.Error(err, "Failed to parse trialResources")
		os.Exit(1)
	}
	viper.Set(consts.ConfigTrialResources, trialGVKs)

	log.Info("Config:",
		consts.ConfigExperimentSuggestionName,
		viper.GetString(consts.ConfigExperimentSuggestionName),
		"webhook-port",
		initConfig.ControllerConfig.WebhookPort,
		"metrics-addr",
		initConfig.ControllerConfig.MetricsAddr,
		"healthz-addr",
		initConfig.ControllerConfig.HealthzAddr,
		consts.ConfigInjectSecurityContext,
		viper.GetBool(consts.ConfigInjectSecurityContext),
		consts.ConfigEnableGRPCProbeInSuggestion,
		viper.GetBool(consts.ConfigEnableGRPCProbeInSuggestion),
		"trial-resources",
		viper.Get(consts.ConfigTrialResources),
	)

	// Get a config to talk to the apiserver
	cfg, err := config.GetConfig()
	if err != nil {
		log.Error(err, "Fail to get the config")
		os.Exit(1)
	}

	// Create a new katib controller to provide shared dependencies and start components
	mgr, err := manager.New(cfg, manager.Options{
		Metrics: metricsserver.Options{
			BindAddress: initConfig.ControllerConfig.MetricsAddr,
		},
		HealthProbeBindAddress: initConfig.ControllerConfig.HealthzAddr,
		LeaderElection:         initConfig.ControllerConfig.EnableLeaderElection,
		LeaderElectionID:       initConfig.ControllerConfig.LeaderElectionID,
		Scheme:                 scheme,
	})
	if err != nil {
		log.Error(err, "Failed to create the manager")
		os.Exit(1)
	}

	log.Info("Registering Components.")

	// Create a webhook server.
	hookServer := webhook.NewServer(webhook.Options{
		Port:    *initConfig.ControllerConfig.WebhookPort,
		CertDir: consts.CertDir,
	})

	ctx := signals.SetupSignalHandler()
	certsReady := make(chan struct{})
	defer close(certsReady)

	// The setupControllers will register controllers to the manager
	// after generated certs for the admission webhooks.
	go setupControllers(mgr, certsReady, hookServer)

	if initConfig.CertGeneratorConfig.Enable {
		if err = cert.AddToManager(mgr, initConfig.CertGeneratorConfig, certsReady); err != nil {
			log.Error(err, "Failed to set up cert-generator")
		}
	} else {
		certsReady <- struct{}{}
	}

	log.Info("Setting up health checker.")
	if err := mgr.AddReadyzCheck("readyz", hookServer.StartedChecker()); err != nil {
		log.Error(err, "Unable to add readyz endpoint to the manager")
		os.Exit(1)
	}
	if err = mgr.AddHealthzCheck("healthz", healthz.Ping); err != nil {
		log.Error(err, "Add webhook server health checker to the manager failed")
		os.Exit(1)
	}

	// Start the Cmd
	log.Info("Starting the manager.")
	if err = mgr.Start(ctx); err != nil {
		log.Error(err, "Unable to run the manager")
		os.Exit(1)
	}
}

func setupControllers(mgr manager.Manager, certsReady chan struct{}, hookServer webhook.Server) {
	// The certsReady blocks to register controllers until generated certs.
	<-certsReady
	log.Info("Certs ready")

	// Setup all Controllers
	log.Info("Setting up controller.")
	if err := controller.AddToManager(mgr); err != nil {
		log.Error(err, "Unable to register controllers to the manager")
		os.Exit(1)
	}

	log.Info("Setting up webhooks.")
	if err := webhookv1beta1.AddToManager(mgr, hookServer); err != nil {
		log.Error(err, "Unable to register webhooks to the manager")
		os.Exit(1)
	}
}



================================================
FILE: cmd/metricscollector/v1beta1/file-metricscollector/Dockerfile
================================================
# Build the Katib file metrics collector.
FROM golang:alpine AS build-env

ARG TARGETARCH

WORKDIR /go/src/github.com/kubeflow/katib

# Download packages.
COPY go.mod .
COPY go.sum .
RUN go mod download -x

# Copy sources.
COPY cmd/ cmd/
COPY pkg/ pkg/

# Build the binary.
RUN CGO_ENABLED=0 GOOS=linux GOARCH=${TARGETARCH} go build -a -o file-metricscollector ./cmd/metricscollector/v1beta1/file-metricscollector

# Copy the file metrics collector into a thin image.
FROM alpine:3.15
WORKDIR /app
COPY --from=build-env /go/src/github.com/kubeflow/katib/file-metricscollector .
ENTRYPOINT ["./file-metricscollector"]



================================================
FILE: cmd/metricscollector/v1beta1/file-metricscollector/main.go
================================================
/*
Copyright 2022 The Kubeflow Authors.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

/*
MetricsCollector is a default metricscollector for worker.
It will collect metrics from pod log.
You should print metrics in {{MetricsName}}={{MetricsValue}} format.
For example, the objective value name is F1 and the metrics are loss, your training code should print like below.
     ---
     epoch 1:
     batch1 loss=0.8
     batch2 loss=0.6

     F1=0.4

     epoch 2:
     batch1 loss=0.4
     batch2 loss=0.2

     F1=0.7
     ---
The metrics collector will collect all logs of metrics.
*/

package main

import (
	"context"
	"encoding/json"
	"flag"
	"fmt"
	"os"
	"path/filepath"
	"regexp"
	"strconv"
	"strings"
	"time"

	"github.com/nxadm/tail"
	psutil "github.com/shirou/gopsutil/v3/process"
	"google.golang.org/grpc"
	"google.golang.org/grpc/credentials/insecure"
	"k8s.io/klog/v2"

	commonv1beta1 "github.com/kubeflow/katib/pkg/apis/controller/common/v1beta1"
	api "github.com/kubeflow/katib/pkg/apis/manager/v1beta1"
	"github.com/kubeflow/katib/pkg/metricscollector/v1beta1/common"
	filemc "github.com/kubeflow/katib/pkg/metricscollector/v1beta1/file-metricscollector"
)

type stopRulesFlag []commonv1beta1.EarlyStoppingRule

func (flag *stopRulesFlag) String() string {
	stopRuleStrings := []string{}
	for _, r := range *flag {
		stopRuleStrings = append(stopRuleStrings, r.Name)
		stopRuleStrings = append(stopRuleStrings, r.Value)
		stopRuleStrings = append(stopRuleStrings, string(r.Comparison))
		stopRuleStrings = append(stopRuleStrings, strconv.Itoa(r.StartStep))
	}
	return strings.Join(stopRuleStrings, ";")
}

func (flag *stopRulesFlag) Set(value string) error {
	stopRuleParsed := strings.Split(value, ";")
	if len(stopRuleParsed) != 4 {
		return fmt.Errorf("Invalid Early Stopping rule: %v", value)
	}

	// Get int start step.
	startStep, err := strconv.Atoi(stopRuleParsed[3])
	if err != nil {
		klog.Fatalf("Parse start step: %v to int error: %v", stopRuleParsed[3], err)
	}

	// For each stop rule this order: 1 - metric name, 2 - metric value, 3 - comparison type, 4 - start step.
	// Start step is equal to 0, if it's not defined.
	stopRule := commonv1beta1.EarlyStoppingRule{
		Name:       stopRuleParsed[0],
		Value:      stopRuleParsed[1],
		Comparison: commonv1beta1.ComparisonType(stopRuleParsed[2]),
		StartStep:  startStep,
	}

	*flag = append(*flag, stopRule)
	return nil
}

var (
	dbManagerServiceAddr = flag.String("s-db", "", "Katib DB Manager service endpoint")
	earlyStopServiceAddr = flag.String("s-earlystop", "", "Katib Early Stopping service endpoint")
	trialName            = flag.String("t", "", "Trial Name")
	metricsFilePath      = flag.String("path", "", "Metrics File Path")
	metricsFileFormat    = flag.String("format", "", "Metrics File Format")
	metricNames          = flag.String("m", "", "Metric names")
	objectiveType        = flag.String("o-type", "", "Objective type")
	metricFilters        = flag.String("f", "", "Metric filters")
	pollInterval         = flag.Duration("p", common.DefaultPollInterval, "Poll interval between running processes check")
	timeout              = flag.Duration("timeout", common.DefaultTimeout, "Timeout before invoke error during running processes check")
	waitAllProcesses     = flag.String("w", common.DefaultWaitAllProcesses, "Whether wait for all other main process of container exiting")
	stopRules            stopRulesFlag
	isEarlyStopped       = false
)

func checkMetricFile(mFile string) {
	for {
		_, err := os.Stat(mFile)
		if err == nil {
			break
		} else if os.IsNotExist(err) {
			continue
		} else {
			klog.Fatalf("Could not watch metrics file: %v", err)
		}
	}
}

func printMetricsFile(mFile string) {

	// Check that metric file exists.
	checkMetricFile(mFile)

	// Print lines from metrics file.
	t, err := tail.TailFile(mFile, tail.Config{Follow: true, ReOpen: true})
	if err != nil {
		klog.Errorf("Failed to open metrics file: %v", err)
	}

	for line := range t.Lines {
		klog.Info(line.Text)
	}
}

func watchMetricsFile(mFile string, stopRules stopRulesFlag, filters []string, fileFormat commonv1beta1.FileFormat) {

	// metricStartStep is the dict where key = metric name, value = start step.
	// We should apply early stopping rule only if metric is reported at least "start_step" times.
	metricStartStep := make(map[string]int)
	for _, stopRule := range stopRules {
		if stopRule.StartStep != 0 {
			metricStartStep[stopRule.Name] = stopRule.StartStep
		}
	}

	// For objective metric we calculate best optimal value from the recorded metrics.
	// This is workaround for Median Stop algorithm.
	// TODO (andreyvelich): Think about it, maybe define latest, max or min strategy type in stop-rule as well ?
	var optimalObjValue *float64

	// Check that metric file exists.
	checkMetricFile(mFile)

	// Get Main process.
	// Extract the metric file dir path based on the file name.
	mDirPath, _ := filepath.Split(mFile)
	_, mainProcPid, err := common.GetMainProcesses(mDirPath)
	if err != nil {
		klog.Fatalf("GetMainProcesses failed: %v", err)
	}
	mainProc, err := psutil.NewProcess(int32(mainProcPid))
	if err != nil {
		klog.Fatalf("Failed to create new Process from pid %v, error: %v", mainProcPid, err)
	}

	// Start watch log lines.
	t, _ := tail.TailFile(mFile, tail.Config{Follow: true})
	for line := range t.Lines {
		logText := line.Text
		// Print log line
		klog.Info(logText)

		switch fileFormat {
		case commonv1beta1.TextFormat:
			// Get list of regural expressions from filters.
			var metricRegList []*regexp.Regexp
			metricRegList = filemc.GetFilterRegexpList(filters)

			// Check if log line contains metric from stop rules.
			isRuleLine := false
			for _, rule := range stopRules {
				if strings.Contains(logText, rule.Name) {
					isRuleLine = true
					break
				}
			}
			// If log line doesn't contain appropriate metric, continue track file.
			if !isRuleLine {
				continue
			}

			// If log line contains appropriate metric, find all submatches from metric filters.
			for _, metricReg := range metricRegList {
				matchStrings := metricReg.FindAllStringSubmatch(logText, -1)
				for _, subMatchList := range matchStrings {
					if len(subMatchList) < 3 {
						continue
					}
					// Submatch must have metric name and float value
					metricName := strings.TrimSpace(subMatchList[1])
					metricValue, err := strconv.ParseFloat(strings.TrimSpace(subMatchList[2]), 64)
					if err != nil {
						klog.Fatalf("Unable to parse value %v to float for metric %v", metricValue, metricName)
					}

					// stopRules contains array of EarlyStoppingRules that has not been reached yet.
					// After rule is reached we delete appropriate element from the array.
					for idx, rule := range stopRules {
						if metricName != rule.Name {
							continue
						}
						stopRules, optimalObjValue = updateStopRules(stopRules, optimalObjValue, metricValue, metricStartStep, rule, idx)
					}
				}
			}
		case commonv1beta1.JsonFormat:
			var logJsonObj map[string]interface{}
			if err = json.Unmarshal([]byte(logText), &logJsonObj); err != nil {
				klog.Fatalf("Failed to unmarshal logs in %v format, log: %s, error: %v", commonv1beta1.JsonFormat, logText, err)
			}
			// Check if log line contains metric from stop rules.
			isRuleLine := false
			for _, rule := range stopRules {
				if _, exist := logJsonObj[rule.Name]; exist {
					isRuleLine = true
					break
				}
			}
			// If log line doesn't contain appropriate metric, continue track file.
			if !isRuleLine {
				continue
			}

			// stopRules contains array of EarlyStoppingRules that has not been reached yet.
			// After rule is reached we delete appropriate element from the array.
			for idx, rule := range stopRules {
				value, exist := logJsonObj[rule.Name].(string)
				if !exist {
					continue
				}
				metricValue, err := strconv.ParseFloat(strings.TrimSpace(value), 64)
				if err != nil {
					klog.Fatalf("Unable to parse value %v to float for metric %v", metricValue, rule.Name)
				}
				stopRules, optimalObjValue = updateStopRules(stopRules, optimalObjValue, metricValue, metricStartStep, rule, idx)
			}
		default:
			klog.Fatalf("Format must be set to %v or %v", commonv1beta1.TextFormat, commonv1beta1.JsonFormat)
		}

		// If stopRules array is empty, Trial is early stopped.
		if len(stopRules) == 0 {
			klog.Info("Training container is early stopped")
			isEarlyStopped = true

			// Create ".pid" file with "early-stopped" line.
			// Which means that training is early stopped and Trial status is updated.
			markFile := filepath.Join(filepath.Dir(mFile), fmt.Sprintf("%d.pid", mainProcPid))
			_, err := os.Create(markFile)
			if err != nil {
				klog.Fatalf("Create mark file %v error: %v", markFile, err)
			}

			err = os.WriteFile(markFile, []byte(common.TrainingEarlyStopped), 0)
			if err != nil {
				klog.Fatalf("Write to file %v error: %v", markFile, err)
			}

			// Get child process from main PID.
			childProc, err := mainProc.Children()
			if err != nil {
				klog.Fatalf("Get children proceses for main PID: %v failed: %v", mainProcPid, err)
			}

			// TODO (andreyvelich): Currently support only single child process.
			if len(childProc) != 1 {
				klog.Fatalf("Multiple children processes are not supported. Children processes: %v", childProc)
			}

			// Terminate the child process.
			err = childProc[0].Terminate()
			if err != nil {
				klog.Fatalf("Unable to terminate child process %v, error: %v", childProc[0], err)
			}

			// Report metrics to DB.
			reportMetrics(filters, fileFormat)

			// Wait until main process is completed.
			timeout := 60 * time.Second
			endTime := time.Now().Add(timeout)
			isProcRunning := true
			for isProcRunning && time.Now().Before(endTime) {
				isProcRunning, err = mainProc.IsRunning()
				// Ignore "no such file error". It means that process is complete.
				if err != nil && !os.IsNotExist(err) {
					klog.Fatalf("Check process status for main PID: %v failed: %v", mainProcPid, err)
				}
			}

			// Create connection and client for Early Stopping service.
			conn, err := grpc.NewClient(*earlyStopServiceAddr, grpc.WithTransportCredentials(insecure.NewCredentials()))
			if err != nil {
				klog.Fatalf("Could not connect to Early Stopping service, error: %v", err)
			}
			c := api.NewEarlyStoppingClient(conn)

			setTrialStatusReq := &api.SetTrialStatusRequest{
				TrialName: *trialName,
			}

			// Send request to change Trial status to early stopped.
			_, err = c.SetTrialStatus(context.Background(), setTrialStatusReq)
			if err != nil {
				klog.Fatalf("Set Trial status error: %v", err)
			}
			conn.Close()

			klog.Infof("Trial status is successfully updated")
		}
	}
}

func updateStopRules(
	stopRules []commonv1beta1.EarlyStoppingRule,
	optimalObjValue *float64,
	metricValue float64,
	metricStartStep map[string]int,
	rule commonv1beta1.EarlyStoppingRule,
	ruleIdx int,
) ([]commonv1beta1.EarlyStoppingRule, *float64) {

	// First metric is objective in metricNames array.
	objMetric := strings.Split(*metricNames, ";")[0]
	objType := commonv1beta1.ObjectiveType(*objectiveType)

	// Calculate optimalObjValue.
	if rule.Name == objMetric {
		if optimalObjValue == nil {
			optimalObjValue = &metricValue
		} else if objType == commonv1beta1.ObjectiveTypeMaximize && metricValue > *optimalObjValue {
			optimalObjValue = &metricValue
		} else if objType == commonv1beta1.ObjectiveTypeMinimize && metricValue < *optimalObjValue {
			optimalObjValue = &metricValue
		}
		// Assign best optimal value to metric value.
		metricValue = *optimalObjValue
	}

	// Reduce steps if appropriate metric is reported.
	// Once rest steps are empty we apply early stopping rule.
	if _, ok := metricStartStep[rule.Name]; ok {
		metricStartStep[rule.Name]--
		if metricStartStep[rule.Name] != 0 {
			return stopRules, optimalObjValue
		}
	}

	ruleValue, err := strconv.ParseFloat(rule.Value, 64)
	if err != nil {
		klog.Fatalf("Unable to parse value %v to float for rule metric %v", rule.Value, rule.Name)
	}

	// Metric value can be equal, less or greater than stop rule.
	// Deleting suitable stop rule from the array.
	if rule.Comparison == commonv1beta1.ComparisonTypeEqual && metricValue == ruleValue {
		return deleteStopRule(stopRules, ruleIdx), optimalObjValue
	} else if rule.Comparison == commonv1beta1.ComparisonTypeLess && metricValue < ruleValue {
		return deleteStopRule(stopRules, ruleIdx), optimalObjValue
	} else if rule.Comparison == commonv1beta1.ComparisonTypeGreater && metricValue > ruleValue {
		return deleteStopRule(stopRules, ruleIdx), optimalObjValue
	}
	return stopRules, optimalObjValue
}

func deleteStopRule(stopRules []commonv1beta1.EarlyStoppingRule, idx int) []commonv1beta1.EarlyStoppingRule {
	if idx >= len(stopRules) {
		klog.Fatalf("Index %v out of range stopRules: %v", idx, stopRules)
	}
	stopRules[idx] = stopRules[len(stopRules)-1]
	stopRules[len(stopRules)-1] = commonv1beta1.EarlyStoppingRule{}
	return stopRules[:len(stopRules)-1]
}

func main() {
	flag.Var(&stopRules, "stop-rule", "The list of early stopping stop rules")
	flag.Parse()
	klog.Infof("Trial Name: %s", *trialName)

	var filters []string
	if len(*metricFilters) != 0 {
		filters = strings.Split(*metricFilters, ";")
	}

	fileFormat := commonv1beta1.FileFormat(*metricsFileFormat)

	// If stop rule is set we need to parse metrics during run.
	if len(stopRules) != 0 {
		go watchMetricsFile(*metricsFilePath, stopRules, filters, fileFormat)
	} else {
		go printMetricsFile(*metricsFilePath)
	}

	waitAll, _ := strconv.ParseBool(*waitAllProcesses)

	wopts := common.WaitPidsOpts{
		PollInterval:           *pollInterval,
		Timeout:                *timeout,
		WaitAll:                waitAll,
		CompletedMarkedDirPath: filepath.Dir(*metricsFilePath),
	}
	if err := common.WaitMainProcesses(wopts); err != nil {
		klog.Fatalf("Failed to wait for worker container: %v", err)
	}

	// If training was not early stopped, report the metrics.
	if !isEarlyStopped {
		reportMetrics(filters, fileFormat)
	}
}

func reportMetrics(filters []string, fileFormat commonv1beta1.FileFormat) {

	conn, err := grpc.NewClient(*dbManagerServiceAddr, grpc.WithTransportCredentials(insecure.NewCredentials()))
	if err != nil {
		klog.Fatalf("Could not connect to DB manager service, error: %v", err)
	}
	defer conn.Close()
	c := api.NewDBManagerClient(conn)
	ctx := context.Background()
	var metricList []string
	if len(*metricNames) != 0 {
		metricList = strings.Split(*metricNames, ";")
	}
	olog, err := filemc.CollectObservationLog(*metricsFilePath, metricList, filters, fileFormat)
	if err != nil {
		klog.Fatalf("Failed to collect logs: %v", err)
	}
	reportreq := &api.ReportObservationLogRequest{
		TrialName:      *trialName,
		ObservationLog: olog,
	}
	_, err = c.ReportObservationLog(ctx, reportreq)
	if err != nil {
		klog.Fatalf("Failed to Report logs: %v", err)
	}
	klog.Infof("Metrics reported. :\n%v", olog)
}



================================================
FILE: cmd/metricscollector/v1beta1/tfevent-metricscollector/Dockerfile
================================================
FROM python:3.11-slim

ARG TARGETARCH
ENV TARGET_DIR /opt/katib
ENV METRICS_COLLECTOR_DIR cmd/metricscollector/v1beta1/tfevent-metricscollector
ENV PYTHONPATH ${TARGET_DIR}:${TARGET_DIR}/pkg/apis/manager/v1beta1/python:${TARGET_DIR}/pkg/metricscollector/v1beta1/tfevent-metricscollector/::${TARGET_DIR}/pkg/metricscollector/v1beta1/common/

ADD ./pkg/ ${TARGET_DIR}/pkg/
ADD ./${METRICS_COLLECTOR_DIR}/ ${TARGET_DIR}/${METRICS_COLLECTOR_DIR}/

WORKDIR  ${TARGET_DIR}/${METRICS_COLLECTOR_DIR}

RUN if [ "${TARGETARCH}" = "arm64" ]; then \
    apt-get -y update && apt-get -y install gfortran libpcre2-dev && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*; \
    fi

RUN pip install --prefer-binary --no-cache-dir -r requirements.txt
RUN chgrp -R 0 ${TARGET_DIR} \
  && chmod -R g+rwX ${TARGET_DIR}

ENTRYPOINT ["python", "main.py"]



================================================
FILE: cmd/metricscollector/v1beta1/tfevent-metricscollector/Dockerfile.ppc64le
================================================
FROM ibmcom/tensorflow-ppc64le:2.2.0-py3
ADD . /usr/src/app/github.com/kubeflow/katib
WORKDIR /usr/src/app/github.com/kubeflow/katib/cmd/metricscollector/v1beta1/tfevent-metricscollector/
RUN pip install --prefer-binary --no-cache-dir -r requirements.txt
ENV PYTHONPATH /usr/src/app/github.com/kubeflow/katib:/usr/src/app/github.com/kubeflow/katib/pkg/apis/manager/v1beta1/python:/usr/src/app/github.com/kubeflow/katib/pkg/metricscollector/v1beta1/tfevent-metricscollector/:/usr/src/app/github.com/kubeflow/katib/pkg/metricscollector/v1beta1/common/
ENTRYPOINT ["python", "main.py"]



================================================
FILE: cmd/metricscollector/v1beta1/tfevent-metricscollector/main.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import argparse
from logging import INFO, StreamHandler, getLogger

import api_pb2
import api_pb2_grpc
import const
import grpc
from pns import WaitMainProcesses
from tfevent_loader import MetricsCollector

timeout_in_seconds = 60


def parse_options():
    parser = argparse.ArgumentParser(
        description='TF-Event MetricsCollector',
        add_help=True
    )

    # TODO (andreyvelich): Add early stopping flags.
    parser.add_argument("-s-db", "--db_manager_server_addr", type=str, default="")
    parser.add_argument("-t", "--trial_name", type=str, default="")
    parser.add_argument("-path", "--metrics_file_dir", type=str, default=const.DEFAULT_METRICS_FILE_DIR)
    parser.add_argument("-m", "--metric_names", type=str, default="")
    parser.add_argument("-o-type", "--objective_type", type=str, default="")
    parser.add_argument("-f", "--metric_filters", type=str, default="")
    parser.add_argument("-p", "--poll_interval", type=int, default=const.DEFAULT_POLL_INTERVAL)
    parser.add_argument("-timeout", "--timeout", type=int, default=const.DEFAULT_TIMEOUT)
    parser.add_argument("-w", "--wait_all_processes", type=str, default=const.DEFAULT_WAIT_ALL_PROCESSES)

    opt = parser.parse_args()
    return opt


if __name__ == '__main__':
    logger = getLogger(__name__)
    handler = StreamHandler()
    handler.setLevel(INFO)
    logger.setLevel(INFO)
    logger.addHandler(handler)
    logger.propagate = False
    opt = parse_options()
    wait_all_processes = opt.wait_all_processes.lower() == "true"
    db_manager_server = opt.db_manager_server_addr.split(':')
    if len(db_manager_server) != 2:
        raise Exception(
            f"Invalid Katib DB manager service address: {opt.db_manager_server_addr}"
        )

    WaitMainProcesses(
        pool_interval=opt.poll_interval,
        timout=opt.timeout,
        wait_all=wait_all_processes,
        completed_marked_dir=opt.metrics_file_dir,
    )

    mc = MetricsCollector(opt.metric_names.split(";"))
    observation_log = mc.parse_file(opt.metrics_file_dir)

    with grpc.insecure_channel(opt.db_manager_server_addr) as channel:
        stub = api_pb2_grpc.DBManagerStub(channel)
        logger.info(
            f"In {opt.trial_name} {str(len(observation_log.metric_logs))} metrics will be reported."
        )
        stub.ReportObservationLog(
            api_pb2.ReportObservationLogRequest(
                trial_name=opt.trial_name, observation_log=observation_log
            ),
            timeout=timeout_in_seconds,
        )



================================================
FILE: cmd/metricscollector/v1beta1/tfevent-metricscollector/requirements.txt
================================================
psutil==5.9.4
rfc3339>=6.2
grpcio>=1.64.1
googleapis-common-protos==1.6.0
tensorflow==2.16.1
protobuf>=4.21.12,<5



================================================
FILE: cmd/suggestion/goptuna/v1beta1/Dockerfile
================================================
# Build the Goptuna Suggestion.
FROM golang:alpine AS build-env

ARG TARGETARCH

WORKDIR /go/src/github.com/kubeflow/katib

# Download packages.
COPY go.mod .
COPY go.sum .
RUN go mod download -x

# Copy sources.
COPY cmd/ cmd/
COPY pkg/ pkg/

# Build the binary.
RUN CGO_ENABLED=0 GOOS=linux GOARCH=${TARGETARCH} go build -a -o goptuna-suggestion ./cmd/suggestion/goptuna/v1beta1

# Copy the Goptuna suggestion into a thin image.
FROM alpine:3.15

ENV TARGET_DIR /opt/katib

WORKDIR ${TARGET_DIR}

COPY --from=build-env /go/src/github.com/kubeflow/katib/goptuna-suggestion ${TARGET_DIR}/

RUN chgrp -R 0 ${TARGET_DIR} \
  && chmod -R g+rwX ${TARGET_DIR}

ENTRYPOINT ["./goptuna-suggestion"]



================================================
FILE: cmd/suggestion/goptuna/v1beta1/main.go
================================================
/*
Copyright 2022 The Kubeflow Authors.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package main

import (
	"context"
	"net"

	health_pb "github.com/kubeflow/katib/pkg/apis/manager/health"
	api_v1_beta1 "github.com/kubeflow/katib/pkg/apis/manager/v1beta1"
	suggestion "github.com/kubeflow/katib/pkg/suggestion/v1beta1/goptuna"
	"google.golang.org/grpc"
	"k8s.io/klog/v2"
)

const (
	address = "0.0.0.0:6789"
)

type healthService struct {
}

func (s *healthService) Check(ctx context.Context, in *health_pb.HealthCheckRequest) (*health_pb.HealthCheckResponse, error) {
	return &health_pb.HealthCheckResponse{
		Status: health_pb.HealthCheckResponse_SERVING,
	}, nil
}

func main() {
	l, err := net.Listen("tcp", address)
	if err != nil {
		klog.Fatalf("Failed to listen: %v", err)
	}
	srv := grpc.NewServer()
	api_v1_beta1.RegisterSuggestionServer(srv, suggestion.NewSuggestionService())
	health_pb.RegisterHealthServer(srv, &healthService{})

	klog.Infof("Start Goptuna suggestion service: %s", address)
	err = srv.Serve(l)
	if err != nil {
		klog.Fatalf("Failed to serve: %v", err)
	}
}



================================================
FILE: cmd/suggestion/hyperband/v1beta1/Dockerfile
================================================
FROM python:3.11-slim

ARG TARGETARCH
ENV TARGET_DIR /opt/katib
ENV SUGGESTION_DIR cmd/suggestion/hyperband/v1beta1
ENV PYTHONPATH ${TARGET_DIR}:${TARGET_DIR}/pkg/apis/manager/v1beta1/python:${TARGET_DIR}/pkg/apis/manager/health/python

RUN if [ "${TARGETARCH}" = "ppc64le" ] || [ "${TARGETARCH}" = "arm64" ]; then \
    apt-get -y update && \
    apt-get -y install gfortran libopenblas-dev liblapack-dev && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*; \
    fi

ADD ./pkg/ ${TARGET_DIR}/pkg/
ADD ./${SUGGESTION_DIR}/ ${TARGET_DIR}/${SUGGESTION_DIR}/

WORKDIR  ${TARGET_DIR}/${SUGGESTION_DIR}

RUN pip install --prefer-binary --no-cache-dir -r requirements.txt
RUN chgrp -R 0 ${TARGET_DIR} \
  && chmod -R g+rwX ${TARGET_DIR}

ENTRYPOINT ["python", "main.py"]



================================================
FILE: cmd/suggestion/hyperband/v1beta1/main.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import time
from concurrent import futures

import grpc

from pkg.apis.manager.health.python import health_pb2_grpc
from pkg.apis.manager.v1beta1.python import api_pb2_grpc
from pkg.suggestion.v1beta1.hyperband.service import HyperbandService

_ONE_DAY_IN_SECONDS = 60 * 60 * 24
DEFAULT_PORT = "0.0.0.0:6789"


def serve():
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    service = HyperbandService()
    api_pb2_grpc.add_SuggestionServicer_to_server(service, server)
    health_pb2_grpc.add_HealthServicer_to_server(service, server)

    server.add_insecure_port(DEFAULT_PORT)
    print("Listening...")
    server.start()
    try:
        while True:
            time.sleep(_ONE_DAY_IN_SECONDS)
    except KeyboardInterrupt:
        server.stop(0)


if __name__ == "__main__":
    serve()



================================================
FILE: cmd/suggestion/hyperband/v1beta1/requirements.txt
================================================
grpcio>=1.64.1
cloudpickle==0.5.6
numpy>=1.25.2
scikit-learn>=0.24.0
scipy>=1.5.4
forestci==0.3
protobuf>=4.21.12,<5
googleapis-common-protos==1.6.0
cython>=0.29.24



================================================
FILE: cmd/suggestion/hyperopt/v1beta1/Dockerfile
================================================
FROM python:3.11-slim

ARG TARGETARCH
ENV TARGET_DIR /opt/katib
ENV SUGGESTION_DIR cmd/suggestion/hyperopt/v1beta1
ENV PYTHONPATH ${TARGET_DIR}:${TARGET_DIR}/pkg/apis/manager/v1beta1/python:${TARGET_DIR}/pkg/apis/manager/health/python

RUN if [ "${TARGETARCH}" = "ppc64le" ]; then \
    apt-get -y update && \
    apt-get -y install gfortran libopenblas-dev liblapack-dev && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*; \
    fi

ADD ./pkg/ ${TARGET_DIR}/pkg/
ADD ./${SUGGESTION_DIR}/ ${TARGET_DIR}/${SUGGESTION_DIR}/

WORKDIR  ${TARGET_DIR}/${SUGGESTION_DIR}

RUN pip install --prefer-binary --no-cache-dir -r requirements.txt
RUN chgrp -R 0 ${TARGET_DIR} \
  && chmod -R g+rwX ${TARGET_DIR}

ENTRYPOINT ["python", "main.py"]



================================================
FILE: cmd/suggestion/hyperopt/v1beta1/main.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import time
from concurrent import futures

import grpc

from pkg.apis.manager.health.python import health_pb2_grpc
from pkg.apis.manager.v1beta1.python import api_pb2_grpc
from pkg.suggestion.v1beta1.hyperopt.service import HyperoptService

_ONE_DAY_IN_SECONDS = 60 * 60 * 24
DEFAULT_PORT = "0.0.0.0:6789"


def serve():
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    service = HyperoptService()
    api_pb2_grpc.add_SuggestionServicer_to_server(service, server)
    health_pb2_grpc.add_HealthServicer_to_server(service, server)
    server.add_insecure_port(DEFAULT_PORT)
    print("Listening...")
    server.start()
    try:
        while True:
            time.sleep(_ONE_DAY_IN_SECONDS)
    except KeyboardInterrupt:
        server.stop(0)


if __name__ == "__main__":
    serve()



================================================
FILE: cmd/suggestion/hyperopt/v1beta1/requirements.txt
================================================
grpcio>=1.64.1
cloudpickle==0.5.6
numpy>=1.25.2
scikit-learn>=0.24.0
scipy>=1.5.4
forestci==0.3
protobuf>=4.21.12,<5
googleapis-common-protos==1.6.0
hyperopt==0.2.5
cython>=0.29.24



================================================
FILE: cmd/suggestion/nas/darts/v1beta1/Dockerfile
================================================
FROM python:3.11-slim

ARG TARGETARCH
ENV TARGET_DIR /opt/katib
ENV SUGGESTION_DIR cmd/suggestion/nas/darts/v1beta1
ENV PYTHONPATH ${TARGET_DIR}:${TARGET_DIR}/pkg/apis/manager/v1beta1/python:${TARGET_DIR}/pkg/apis/manager/health/python

RUN if [ "${TARGETARCH}" = "ppc64le" ]; then \
    apt-get -y update && \
    apt-get -y install gfortran libopenblas-dev liblapack-dev && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*; \
    fi

ADD ./pkg/ ${TARGET_DIR}/pkg/
ADD ./${SUGGESTION_DIR}/ ${TARGET_DIR}/${SUGGESTION_DIR}/

WORKDIR  ${TARGET_DIR}/${SUGGESTION_DIR}

RUN pip install --prefer-binary --no-cache-dir -r requirements.txt
RUN chgrp -R 0 ${TARGET_DIR} \
  && chmod -R g+rwX ${TARGET_DIR}

ENTRYPOINT ["python", "main.py"]



================================================
FILE: cmd/suggestion/nas/darts/v1beta1/main.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import time
from concurrent import futures

import grpc

from pkg.apis.manager.health.python import health_pb2_grpc
from pkg.apis.manager.v1beta1.python import api_pb2_grpc
from pkg.suggestion.v1beta1.nas.darts.service import DartsService

_ONE_DAY_IN_SECONDS = 60 * 60 * 24
DEFAULT_PORT = "0.0.0.0:6789"


def serve():
    print("Darts Suggestion Service")
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    service = DartsService()
    api_pb2_grpc.add_SuggestionServicer_to_server(service, server)
    health_pb2_grpc.add_HealthServicer_to_server(service, server)
    server.add_insecure_port(DEFAULT_PORT)
    print("Listening...")
    server.start()
    try:
        while True:
            time.sleep(_ONE_DAY_IN_SECONDS)
    except KeyboardInterrupt:
        server.stop(0)


if __name__ == "__main__":
    serve()



================================================
FILE: cmd/suggestion/nas/darts/v1beta1/requirements.txt
================================================
grpcio>=1.64.1
protobuf>=4.21.12,<5
googleapis-common-protos==1.6.0
cython>=0.29.24



================================================
FILE: cmd/suggestion/nas/enas/v1beta1/Dockerfile
================================================
FROM python:3.11-slim

ARG TARGETARCH
ENV TARGET_DIR /opt/katib
ENV SUGGESTION_DIR cmd/suggestion/nas/enas/v1beta1
ENV PYTHONPATH ${TARGET_DIR}:${TARGET_DIR}/pkg/apis/manager/v1beta1/python:${TARGET_DIR}/pkg/apis/manager/health/python

RUN if [ "${TARGETARCH}" = "ppc64le" ]; then \
    apt-get -y update && \
    apt-get -y install gfortran libopenblas-dev liblapack-dev && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*; \
    fi

ADD ./pkg/ ${TARGET_DIR}/pkg/
ADD ./${SUGGESTION_DIR}/ ${TARGET_DIR}/${SUGGESTION_DIR}/

WORKDIR  ${TARGET_DIR}/${SUGGESTION_DIR}

RUN pip install --prefer-binary --no-cache-dir -r requirements.txt
RUN chgrp -R 0 ${TARGET_DIR} \
  && chmod -R g+rwX ${TARGET_DIR}

ENTRYPOINT ["python", "main.py"]



================================================
FILE: cmd/suggestion/nas/enas/v1beta1/main.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import time
from concurrent import futures

import grpc

from pkg.apis.manager.health.python import health_pb2_grpc
from pkg.apis.manager.v1beta1.python import api_pb2_grpc
from pkg.suggestion.v1beta1.nas.enas.service import EnasService

_ONE_DAY_IN_SECONDS = 60 * 60 * 24
DEFAULT_PORT = "0.0.0.0:6789"


def serve():
    print("ENAS Suggestion Service")
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    service = EnasService()
    api_pb2_grpc.add_SuggestionServicer_to_server(service, server)
    health_pb2_grpc.add_HealthServicer_to_server(service, server)
    server.add_insecure_port(DEFAULT_PORT)
    print("Listening...")
    server.start()
    try:
        while True:
            time.sleep(_ONE_DAY_IN_SECONDS)
    except KeyboardInterrupt:
        server.stop(0)


if __name__ == "__main__":
    serve()



================================================
FILE: cmd/suggestion/nas/enas/v1beta1/requirements.txt
================================================
grpcio>=1.64.1
googleapis-common-protos==1.6.0
cython>=0.29.24
tensorflow==2.16.1
protobuf>=4.21.12,<5



================================================
FILE: cmd/suggestion/optuna/v1beta1/Dockerfile
================================================
FROM python:3.11-slim

ARG TARGETARCH
ENV TARGET_DIR /opt/katib
ENV SUGGESTION_DIR cmd/suggestion/optuna/v1beta1
ENV PYTHONPATH ${TARGET_DIR}:${TARGET_DIR}/pkg/apis/manager/v1beta1/python:${TARGET_DIR}/pkg/apis/manager/health/python

RUN if [ "${TARGETARCH}" = "ppc64le" ]; then \
    apt-get -y update && \
    apt-get -y install gfortran libopenblas-dev liblapack-dev && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*; \
    fi

ADD ./pkg/ ${TARGET_DIR}/pkg/
ADD ./${SUGGESTION_DIR}/ ${TARGET_DIR}/${SUGGESTION_DIR}/

WORKDIR  ${TARGET_DIR}/${SUGGESTION_DIR}

RUN pip install --prefer-binary --no-cache-dir -r requirements.txt
RUN chgrp -R 0 ${TARGET_DIR} \
  && chmod -R g+rwX ${TARGET_DIR}

ENTRYPOINT ["python", "main.py"]



================================================
FILE: cmd/suggestion/optuna/v1beta1/main.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import time
from concurrent import futures

import grpc

from pkg.apis.manager.health.python import health_pb2_grpc
from pkg.apis.manager.v1beta1.python import api_pb2_grpc
from pkg.suggestion.v1beta1.optuna.service import OptunaService

_ONE_DAY_IN_SECONDS = 60 * 60 * 24
DEFAULT_PORT = "0.0.0.0:6789"


def serve():
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    service = OptunaService()
    api_pb2_grpc.add_SuggestionServicer_to_server(service, server)
    health_pb2_grpc.add_HealthServicer_to_server(service, server)
    server.add_insecure_port(DEFAULT_PORT)
    print("Listening...")
    server.start()
    try:
        while True:
            time.sleep(_ONE_DAY_IN_SECONDS)
    except KeyboardInterrupt:
        server.stop(0)


if __name__ == "__main__":
    serve()



================================================
FILE: cmd/suggestion/optuna/v1beta1/requirements.txt
================================================
grpcio>=1.64.1
protobuf>=4.21.12,<5
googleapis-common-protos==1.53.0
optuna==3.3.0



================================================
FILE: cmd/suggestion/pbt/v1beta1/Dockerfile
================================================
FROM python:3.11-slim

ARG TARGETARCH
ENV TARGET_DIR /opt/katib
ENV SUGGESTION_DIR cmd/suggestion/pbt/v1beta1
ENV PYTHONPATH ${TARGET_DIR}:${TARGET_DIR}/pkg/apis/manager/v1beta1/python:${TARGET_DIR}/pkg/apis/manager/health/python

RUN if [ "${TARGETARCH}" = "ppc64le" ]; then \
    apt-get -y update && \
    apt-get -y install gfortran libopenblas-dev liblapack-dev && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*; \
    fi

ADD ./pkg/ ${TARGET_DIR}/pkg/
ADD ./${SUGGESTION_DIR}/ ${TARGET_DIR}/${SUGGESTION_DIR}/

WORKDIR  ${TARGET_DIR}/${SUGGESTION_DIR}

RUN pip install --prefer-binary --no-cache-dir -r requirements.txt
RUN chgrp -R 0 ${TARGET_DIR} \
  && chmod -R g+rwX ${TARGET_DIR}

ENTRYPOINT ["python", "main.py"]



================================================
FILE: cmd/suggestion/pbt/v1beta1/main.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import time
from concurrent import futures

import grpc

from pkg.apis.manager.health.python import health_pb2_grpc
from pkg.apis.manager.v1beta1.python import api_pb2_grpc
from pkg.suggestion.v1beta1.pbt.service import PbtService

_ONE_DAY_IN_SECONDS = 60 * 60 * 24
DEFAULT_PORT = "0.0.0.0:6789"


def serve():
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    service = PbtService()
    api_pb2_grpc.add_SuggestionServicer_to_server(service, server)
    health_pb2_grpc.add_HealthServicer_to_server(service, server)

    server.add_insecure_port(DEFAULT_PORT)
    print("Listening...")
    server.start()
    try:
        while True:
            time.sleep(_ONE_DAY_IN_SECONDS)
    except KeyboardInterrupt:
        server.stop(0)


if __name__ == "__main__":
    serve()



================================================
FILE: cmd/suggestion/pbt/v1beta1/requirements.txt
================================================
grpcio>=1.64.1
protobuf>=4.21.12,<5
googleapis-common-protos==1.53.0
numpy==1.25.2



================================================
FILE: cmd/suggestion/skopt/v1beta1/Dockerfile
================================================
FROM python:3.10-slim

ARG TARGETARCH
ENV TARGET_DIR /opt/katib
ENV SUGGESTION_DIR cmd/suggestion/skopt/v1beta1
ENV PYTHONPATH ${TARGET_DIR}:${TARGET_DIR}/pkg/apis/manager/v1beta1/python:${TARGET_DIR}/pkg/apis/manager/health/python

RUN if [ "${TARGETARCH}" = "ppc64le" ]; then \
    apt-get -y update && \
    apt-get -y install gfortran libopenblas-dev liblapack-dev && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*; \
    fi

ADD ./pkg/ ${TARGET_DIR}/pkg/
ADD ./${SUGGESTION_DIR}/ ${TARGET_DIR}/${SUGGESTION_DIR}/

WORKDIR  ${TARGET_DIR}/${SUGGESTION_DIR}

RUN pip install --prefer-binary --no-cache-dir -r requirements.txt
RUN chgrp -R 0 ${TARGET_DIR} \
  && chmod -R g+rwX ${TARGET_DIR}

ENTRYPOINT ["python", "main.py"]



================================================
FILE: cmd/suggestion/skopt/v1beta1/main.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import time
from concurrent import futures

import grpc

from pkg.apis.manager.health.python import health_pb2_grpc
from pkg.apis.manager.v1beta1.python import api_pb2_grpc
from pkg.suggestion.v1beta1.skopt.service import SkoptService

_ONE_DAY_IN_SECONDS = 60 * 60 * 24
DEFAULT_PORT = "0.0.0.0:6789"


def serve():
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    service = SkoptService()
    api_pb2_grpc.add_SuggestionServicer_to_server(service, server)
    health_pb2_grpc.add_HealthServicer_to_server(service, server)
    server.add_insecure_port(DEFAULT_PORT)
    print("Listening...")
    server.start()
    try:
        while True:
            time.sleep(_ONE_DAY_IN_SECONDS)
    except KeyboardInterrupt:
        server.stop(0)


if __name__ == "__main__":
    serve()



================================================
FILE: cmd/suggestion/skopt/v1beta1/requirements.txt
================================================
grpcio>=1.64.1
cloudpickle==0.5.6
# This is a workaround to avoid the following error.
# AttributeError: module 'numpy' has no attribute 'int'
# See more: https://github.com/numpy/numpy/pull/22607
numpy==1.23.5
scikit-learn>=0.24.0, <=1.3.0
scipy>=1.5.4
forestci==0.3
protobuf>=4.21.12,<5
googleapis-common-protos==1.6.0
scikit-optimize>=0.9.0
cython>=0.29.24



================================================
FILE: cmd/ui/v1beta1/Dockerfile
================================================
# --- Clone the kubeflow/kubeflow code ---
FROM alpine/git AS fetch-kubeflow-kubeflow

WORKDIR /kf
COPY ./pkg/ui/v1beta1/frontend/COMMIT ./
RUN git clone https://github.com/kubeflow/kubeflow.git && \
    COMMIT=$(cat ./COMMIT) && \
    cd kubeflow && \
    git checkout $COMMIT

# --- Build the frontend kubeflow library ---
FROM node:16-alpine AS frontend-kubeflow-lib

WORKDIR /src

ARG LIB=/kf/kubeflow/components/crud-web-apps/common/frontend/kubeflow-common-lib
COPY --from=fetch-kubeflow-kubeflow $LIB/package*.json ./
RUN npm config set fetch-retry-mintimeout 200000 && \
    npm config set fetch-retry-maxtimeout 1200000 && \
    npm config get registry && \
    npm config set registry https://registry.npmjs.org/ && \
    npm config delete https-proxy && \
    npm config set loglevel verbose && \
    npm cache clean --force && \
    npm ci --force --prefer-offline --no-audit

COPY --from=fetch-kubeflow-kubeflow $LIB/ ./
RUN npm run build

# --- Build the frontend ---
FROM node:16-alpine AS frontend

WORKDIR /src
COPY ./pkg/ui/v1beta1/frontend/package*.json ./
RUN npm config set fetch-retry-mintimeout 200000 && \
    npm config set fetch-retry-maxtimeout 1200000 && \
    npm config get registry && \
    npm config set registry https://registry.npmjs.org/ && \
    npm config delete https-proxy && \
    npm config set loglevel verbose && \
    npm cache clean --force && \
    npm ci --force --prefer-offline --no-audit

COPY ./pkg/ui/v1beta1/frontend/ .
COPY --from=frontend-kubeflow-lib /src/dist/kubeflow/ ./node_modules/kubeflow/

RUN npm run build:prod

# --- Build the backend ---
FROM golang:alpine AS go-build

ARG TARGETARCH

WORKDIR /go/src/github.com/kubeflow/katib

# Download packages.
COPY go.mod .
COPY go.sum .
RUN go mod download -x

# Copy sources.
COPY cmd/ cmd/
COPY pkg/ pkg/

# Build the binary.
RUN CGO_ENABLED=0 GOOS=linux GOARCH=${TARGETARCH} go build -a -o katib-ui  ./cmd/ui/v1beta1

# --- Compose the web app ---
FROM alpine:3.15
WORKDIR /app
COPY --from=go-build /go/src/github.com/kubeflow/katib/katib-ui /app/
COPY --from=frontend /src/dist/static /app/build/static/
ENTRYPOINT ["./katib-ui"]



================================================
FILE: cmd/ui/v1beta1/main.go
================================================
/*
Copyright 2022 The Kubeflow Authors.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package main

import (
	"flag"
	"fmt"
	"log"
	"net/http"

	_ "k8s.io/client-go/plugin/pkg/client/auth/gcp"

	common_v1beta1 "github.com/kubeflow/katib/pkg/common/v1beta1"
	ui "github.com/kubeflow/katib/pkg/ui/v1beta1"
)

var (
	port, host, buildDir, dbManagerAddr *string
)

func init() {
	port = flag.String("port", "8080", "The port to listen to for incoming HTTP connections")
	host = flag.String("host", "0.0.0.0", "The host to listen to for incoming HTTP connections")
	buildDir = flag.String("build-dir", "/app/build", "The dir of frontend")
	dbManagerAddr = flag.String("db-manager-address", common_v1beta1.GetDBManagerAddr(), "The address of Katib DB manager")
}

func main() {
	flag.Parse()
	kuh := ui.NewKatibUIHandler(*dbManagerAddr)

	log.Printf("Serving the frontend dir %s", *buildDir)
	frontend := http.FileServer(http.Dir(*buildDir))
	http.HandleFunc("/katib/", kuh.ServeIndex(*buildDir))
	http.Handle("/katib/static/", http.StripPrefix("/katib/", frontend))

	http.HandleFunc("/katib/fetch_experiments/", kuh.FetchExperiments)

	http.HandleFunc("/katib/create_experiment/", kuh.CreateExperiment)

	http.HandleFunc("/katib/delete_experiment/", kuh.DeleteExperiment)

	http.HandleFunc("/katib/fetch_experiment/", kuh.FetchExperiment)
	http.HandleFunc("/katib/fetch_trial/", kuh.FetchTrial)
	http.HandleFunc("/katib/fetch_suggestion/", kuh.FetchSuggestion)

	http.HandleFunc("/katib/fetch_hp_job_info/", kuh.FetchHPJobInfo)
	http.HandleFunc("/katib/fetch_hp_job_trial_info/", kuh.FetchHPJobTrialInfo)
	http.HandleFunc("/katib/fetch_nas_job_info/", kuh.FetchNASJobInfo)

	http.HandleFunc("/katib/fetch_trial_templates/", kuh.FetchTrialTemplates)
	http.HandleFunc("/katib/add_template/", kuh.AddTemplate)
	http.HandleFunc("/katib/edit_template/", kuh.EditTemplate)
	http.HandleFunc("/katib/delete_template/", kuh.DeleteTemplate)
	http.HandleFunc("/katib/fetch_namespaces", kuh.FetchNamespaces)
	http.HandleFunc("/katib/fetch_trial_logs/", kuh.FetchTrialLogs)

	log.Printf("Serving at %s:%s", *host, *port)
	if err := http.ListenAndServe(fmt.Sprintf("%s:%s", *host, *port), nil); err != nil {
		panic(err)
	}
}



================================================
FILE: conformance/run.sh
================================================
#!/bin/sh

# Run conformance test and generate test report.
python test/e2e/v1beta1/scripts/gh-actions/run-e2e-experiment.py --experiment-path examples/v1beta1/hp-tuning/random.yaml --namespace kf-conformance \
--trial-pod-labels '{"sidecar.istio.io/inject": "false"}' | tee /tmp/katib-conformance.log


# Create the done file.
touch /tmp/katib-conformance.done
echo "Done..."

# Keep the container running so the test logs can be downloaded.
while true; do sleep 10000; done


================================================
FILE: docs/README.md
================================================
# Katib Documentation

Welcome to Kubeflow Katib!

The Katib documentation is available on [kubeflow.org](https://www.kubeflow.org/docs/components/katib/).



================================================
FILE: docs/images-location.md
================================================
# Katib Images Location

Here you can find the location for images that are used in Katib.

## Katib Components Images

The following table shows images for the
[Katib components](https://www.kubeflow.org/docs/components/katib/reference/architecture/#katib-control-plane-components).

<table>
  <tbody>
    <tr align="center">
      <td>
        <b>Image Name</b>
      </td>
      <td>
        <b>Description</b>
      </td>
      <td>
        <b>Location</b>
      </td>
    </tr>
    <tr align="center">
      <td>
        <code>ghcr.io/kubeflow/katib/katib-controller</code>
      </td>
      <td>
        Katib Controller
      </td>
      <td>
        <a href="https://github.com/kubeflow/katib/tree/master/cmd/katib-controller/v1beta1/Dockerfile">Dockerfile</a>
      </td>
    </tr>
    <tr align="center">
      <td>
        <code>ghcr.io/kubeflow/katib/katib-ui</code>
      </td>
      <td>
        Katib User Interface
      </td>
      <td>
        <a href="https://github.com/kubeflow/katib/tree/master/cmd/ui/v1beta1/Dockerfile">Dockerfile</a>
      </td>
    </tr>
    <tr align="center">
      <td>
        <code>ghcr.io/kubeflow/katib/katib-db-manager</code>
      </td>
      <td>
        Katib DB Manager
      </td>
      <td>
        <a href="https://github.com/kubeflow/katib/tree/master/cmd/db-manager/v1beta1/Dockerfile">Dockerfile</a>
      </td>
    </tr>
    <tr align="center">
      <td>
        <code>docker.io/mysql</code>
      </td>
      <td>
        Katib MySQL DB
      </td>
      <td>
        <a href="https://github.com/docker-library/mysql/blob/c506174eab8ae160f56483e8d72410f8f1e1470f/8.0/Dockerfile.debian">Dockerfile</a>
      </td>
    </tr>
  </tbody>
</table>

## Katib Metrics Collectors Images

The following table shows images for the
[Katib Metrics Collectors](https://www.kubeflow.org/docs/components/katib/user-guides/metrics-collector/).

<table>
  <tbody>
    <tr align="center">
      <td>
        <b>Image Name</b>
      </td>
      <td>
        <b>Description</b>
      </td>
      <td>
        <b>Location</b>
      </td>
    </tr>
    <tr align="center">
      <td>
        <code>ghcr.io/kubeflow/katib/file-metrics-collector</code>
      </td>
      <td>
        File Metrics Collector
      </td>
      <td>
        <a href="https://github.com/kubeflow/katib/blob/master/cmd/metricscollector/v1beta1/file-metricscollector/Dockerfile">Dockerfile</a>
      </td>
    </tr>
    <tr align="center">
      <td>
        <code>ghcr.io/kubeflow/katib/tfevent-metrics-collector</code>
      </td>
      <td>
        Tensorflow Event Metrics Collector
      </td>
      <td>
        <a href="https://github.com/kubeflow/katib/blob/master/cmd/metricscollector/v1beta1/tfevent-metricscollector/Dockerfile">Dockerfile</a>
      </td>
    </tr>
  </tbody>
</table>

## Katib Suggestions and Early Stopping Images

The following table shows images for the
[Katib Suggestion services](https://www.kubeflow.org/docs/components/katib/reference/architecture/#suggestion)
and the [Katib Early Stopping algorithms](https://www.kubeflow.org/docs/components/katib/user-guides/early-stopping/#early-stopping-algorithms).

<table>
  <tbody>
    <tr align="center">
      <td>
        <b>Image Name</b>
      </td>
      <td>
        <b>Description</b>
      </td>
      <td>
        <b>Location</b>
      </td>
    </tr>
    <tr align="center">
      <td>
        <code>ghcr.io/kubeflow/katib/suggestion-hyperopt</code>
      </td>
      <td>
        <a href="https://github.com/hyperopt/hyperopt">Hyperopt</a> Suggestion
      </td>
      <td>
        <a href="https://github.com/kubeflow/katib/blob/master/cmd/suggestion/hyperopt/v1beta1/Dockerfile">Dockerfile</a>
      </td>
    </tr>
    <tr align="center">
      <td>
        <code>ghcr.io/kubeflow/katib/suggestion-skopt</code>
      </td>
      <td>
        <a href="https://github.com/scikit-optimize/scikit-optimize">Skopt</a> Suggestion
      </td>
      <td>
        <a href="https://github.com/kubeflow/katib/blob/master/cmd/suggestion/skopt/v1beta1/Dockerfile">Dockerfile</a>
      </td>
    </tr>
    <tr align="center">
      <td>
        <code>ghcr.io/kubeflow/katib/suggestion-optuna</code>
      </td>
      <td>
        <a href="https://github.com/optuna/optuna">Optuna</a> Suggestion
      </td>
      <td>
        <a href="https://github.com/kubeflow/katib/blob/master/cmd/suggestion/optuna/v1beta1/Dockerfile">Dockerfile</a>
      </td>
    </tr>
    <tr align="center">
      <td>
        <code>ghcr.io/kubeflow/katib/suggestion-goptuna</code>
      </td>
      <td>
        <a href="https://github.com/c-bata/goptuna">Goptuna</a> Suggestion
      </td>
      <td>
        <a href="https://github.com/kubeflow/katib/blob/master/cmd/suggestion/goptuna/v1beta1/Dockerfile">Dockerfile</a>
      </td>
    </tr>
    <tr align="center">
      <td>
        <code>ghcr.io/kubeflow/katib/suggestion-hyperband</code>
      </td>
      <td>
        <a href="https://www.kubeflow.org/docs/components/katib/experiment/#hyperband">Hyperband</a> Suggestion
      </td>
      <td>
        <a href="https://github.com/kubeflow/katib/blob/master/cmd/suggestion/hyperband/v1beta1/Dockerfile">Dockerfile</a>
      </td>
    </tr>
    <tr align="center">
      <td>
        <code>ghcr.io/kubeflow/katib/suggestion-enas</code>
      </td>
      <td>
        <a href="https://www.kubeflow.org/docs/components/katib/experiment/#enas">ENAS</a> Suggestion
      </td>
      <td>
        <a href="https://github.com/kubeflow/katib/blob/master/cmd/suggestion/nas/enas/v1beta1/Dockerfile">Dockerfile</a>
      </td>
    </tr>
    <tr align="center">
      <td>
        <code>ghcr.io/kubeflow/katib/suggestion-darts</code>
      </td>
      <td>
        <a href="https://www.kubeflow.org/docs/components/katib/experiment/#differentiable-architecture-search-darts">DARTS</a> Suggestion
      </td>
      <td>
        <a href="https://github.com/kubeflow/katib/blob/master/cmd/suggestion/nas/darts/v1beta1/Dockerfile">Dockerfile</a>
      </td>
    </tr>
    <tr align="center">
      <td>
        <code>ghcr.io/kubeflow/katib/earlystopping-medianstop</code>
      </td>
      <td>
        <a href="https://www.kubeflow.org/docs/components/katib/early-stopping/#median-stopping-rule">Median Stopping Rule</a>
      </td>
      <td>
        <a href="https://github.com/kubeflow/katib/blob/master/cmd/earlystopping/medianstop/v1beta1/Dockerfile">Dockerfile</a>
      </td>
    </tr>
  </tbody>
</table>

## Training Containers Images

The following table shows images for training containers which are used in the
[Katib Trials](https://www.kubeflow.org/docs/components/katib/reference/architecture/#trial).

<table>
  <tbody>
    <tr align="center">
      <td>
        <b>Image Name</b>
      </td>
      <td>
        <b>Description</b>
      </td>
      <td>
        <b>Location</b>
      </td>
    </tr>
    <tr align="center">
      <td>
        <code>ghcr.io/kubeflow/katib/pytorch-mnist-cpu</code>
      </td>
      <td>
        PyTorch MNIST example with printing metrics to the file or StdOut with CPU support
      </td>
      <td>
        <a href="https://github.com/kubeflow/katib/blob/master/examples/v1beta1/trial-images/pytorch-mnist/Dockerfile.cpu">Dockerfile</a>
      </td>
    </tr>
    <tr align="center">
      <td>
        <code>ghcr.io/kubeflow/katib/pytorch-mnist-gpu</code>
      </td>
      <td>
        PyTorch MNIST example with printing metrics to the file or StdOut with GPU support
      </td>
      <td>
        <a href="https://github.com/kubeflow/katib/blob/master/examples/v1beta1/trial-images/pytorch-mnist/Dockerfile.gpu">Dockerfile</a>
      </td>
    </tr>
    <tr align="center">
      <td>
        <code>ghcr.io/kubeflow/katib/tf-mnist-with-summaries</code>
      </td>
      <td>
        Tensorflow MNIST example with saving metrics in the summaries
      </td>
      <td>
        <a href="https://github.com/kubeflow/katib/blob/master/examples/v1beta1/trial-images/tf-mnist-with-summaries/Dockerfile">Dockerfile</a>
      </td>
    </tr>
    <tr align="center">
      <td>
        <code>ghcr.io/kubeflow/katib/xgboost-lightgbm</code>
      </td>
      <td>
        Distributed LightGBM example for XGBoostJob
      </td>
      <td>
        <a href="https://github.com/kubeflow/xgboost-operator/blob/9c8c97d0125a8156f12b8ef5b93f99e709fb57ea/config/samples/lightgbm-dist/Dockerfile">Dockerfile</a>
      </td>
    </tr>
    <tr align="center">
      <td>
        <code>docker.io/kubeflow/mpi-horovod-mnist</code>
      </td>
      <td>
        Distributed Horovod example for MPIJob
      </td>
      <td>
        <a href="https://github.com/kubeflow/mpi-operator/blob/947d396a9caf70d3c94bf587d5e5da32b70f0f53/examples/horovod/Dockerfile.cpu">Dockerfile</a>
      </td>
    </tr>
    <tr align="center">
      <td>
        <code>docker.io/inaccel/jupyter:lab</code>
      </td>
      <td>
        FPGA XGBoost with parameter tuning
      </td>
      <td>
        <a href="https://github.com/inaccel/jupyter/blob/master/lab/Dockerfile">Dockerfile</a>
      </td>
    </tr>
    <tr align="center">
      <td>
        <code>ghcr.io/kubeflow/katib/enas-cnn-cifar10-gpu</code>
      </td>
      <td>
        Keras CIFAR-10 CNN example for ENAS with GPU support
      </td>
      <td>
        <a href="https://github.com/kubeflow/katib/blob/master/examples/v1beta1/trial-images/enas-cnn-cifar10/Dockerfile.gpu">Dockerfile</a>
      </td>
    </tr>
    <tr align="center">
      <td>
        <code>ghcr.io/kubeflow/katib/enas-cnn-cifar10-cpu</code>
      </td>
      <td>
        Keras CIFAR-10 CNN example for ENAS with CPU support
      </td>
      <td>
        <a href="https://github.com/kubeflow/katib/blob/master/examples/v1beta1/trial-images/enas-cnn-cifar10/Dockerfile.cpu">Dockerfile</a>
      </td>
    </tr>
    <tr align="center">
      <td>
        <code>ghcr.io/kubeflow/katib/darts-cnn-cifar10-gpu</code>
      </td>
      <td>
        PyTorch CIFAR-10 CNN example for DARTS with GPU support
      </td>
      <td>
        <a href="https://github.com/kubeflow/katib/blob/master/examples/v1beta1/trial-images/darts-cnn-cifar10/Dockerfile.gpu">Dockerfile</a>
      </td>
    </tr>
    <tr align="center">
      <td>
        <code>ghcr.io/kubeflow/katib/darts-cnn-cifar10-cpu</code>
      </td>
      <td>
        PyTorch CIFAR-10 CNN example for DARTS with CPU support
      </td>
      <td>
        <a href="https://github.com/kubeflow/katib/blob/master/examples/v1beta1/trial-images/darts-cnn-cifar10/Dockerfile.cpu">Dockerfile</a>
      </td>
    </tr>
</table>



================================================
FILE: docs/presentations.md
================================================
# Katib Presentations and Demos

Below are the list of Katib presentations and demos. If you want to add your
presentation or demo in this list please send a pull request. Please keep the
list in reverse chronological order.

| Title | Presenters | Event | Date |
| --- | --- | --- | --- |
| [Hiding Kubernetes Complexity for ML Engineers Using Kubeflow](https://docs.google.com/presentation/d/1Fepo9TUgbsO7YpxenCq17Y9KKQU_VgqYjAVBFWAFIU4/edit?usp=sharing) | Andrey Velichkevich | RE-WORK MLOps Summit | 2022-11-10 |
| [Managing Thousands of Automatic Machine Learning Experiments with Argo and Katib](https://youtu.be/0jBNXZjQ01I) | Andrey Velichkevich, [Yuan Tang](https://terrytangyuan.github.io/about/) | ArgoCon | 2022-09-21 |
| [Cloud Native AutoML with Argo Workflows and Katib](https://youtu.be/KjHqmS4gIxM?t=181) | Andrey Velichkevich, Johnu George | Argo Community Meeting | 2022-02-16 |
| [When Machine Learning Toolkit for Kubernetes Meets PaddlePaddle](https://github.com/terrytangyuan/public-talks/tree/main/talks/when-machine-learning-toolkit-for-kubernetes-meets-paddlepaddle-wave-summit-2021) | [Yuan Tang](https://terrytangyuan.github.io/about/) | Wave Summit | 2021-12-12 |
| [Bridging into Python Ecosystem with Cloud-Native Distributed Machine Learning Pipelines](https://github.com/terrytangyuan/public-talks/tree/main/talks/bridging-into-python-ecosystem-with-cloud-native-distributed-machine-learning-pipelines-argocon-2021) | [Yuan Tang](https://terrytangyuan.github.io/about/) | ArgoCon | 2021-12-08 |
| [Towards Cloud-Native Distributed Machine Learning Pipelines at Scale](https://github.com/terrytangyuan/public-talks/tree/main/talks/towards-cloud-native-distributed-machine-learning-pipelines-at-scale-pydata-global-2021) | [Yuan Tang](https://terrytangyuan.github.io/about/) | PyData | 2021-10-29 |
| [AutoML and Training WG Summit July 2021](https://youtube.com/playlist?list=PL2gwy7BdKoGd9HQBCz1iC7vyFVN7Wa9N2) | Kubeflow Community | Kubeflow Summit | 2021-07-16 |
| [MLOps and AutoML in Cloud-Native Way with Kubeflow and Katib](https://youtu.be/33VJ6KNBBvU) | Andrey Velichkevich | MLREPA | 2021-04-25 |
| [A Tour of Katib's new UI for Kubeflow 1.3](https://youtu.be/1DtjB_boWcQ) | Kimonas Sotirchos | Kubeflow Community Meeting | 2021-03-30 |
| [New UI for Kubeflow components](https://youtu.be/OKqx3IS2_G4) | Stefano Fioravanzo | Kubeflow Community Meeting | 2020-12-08 |
| [Using Pipelines in Katib](https://youtu.be/BszcHMkGLgc) | Andrey Velichkevich | Kubeflow Community Meeting | 2020-11-10 |
| [From Notebook to Kubeflow Pipelines with HP Tuning](https://youtu.be/QK0NxhyADpM) | Stefano Fioravanzo, Ilias Katsakioris | KubeCon | 2020-09-04 |
| [Distributed Training and HPO Deep Dive](https://youtu.be/KJFOlhD3L1E) | Andrew Butler, Qianyang Yu, Tommy Li, Animesh Singh | Kubeflow Dojo | 2020-07-17 |
| [Hyperparameter Tuning with Katib](https://youtu.be/nIKVlosDvrc) | Stephanie Wong | Kubeflow 101 | 2020-06-21 |
| [Hyperparameter Tuning Using Kubeflow](https://youtu.be/OkAoiA6A2Ac) | Richard Liu, Johnu George | KubeCon | 2019-07-05 |
| [Kubeflow Katib & Hyperparameter Tuning](https://youtu.be/1PKH_D6zjoM) | Richard Liu | Kubeflow Community Meeting | 2019-03-29 |
| [Neural Architecture Search System on Kubeflow](https://youtu.be/WAK37UW7spo) | Andrey Velichkevich, Kirill Prosvirov, Jinan Zhou, Anubhav Garg | Kubeflow Community Meeting | 2019-03-26 |



================================================
FILE: docs/proposals/README.md
================================================
# Proposals

Kubeflow uses the KEP process to document large scale changes to the project.

Details on the process (including the KEP template, recommendations, etc.) can be found at
[kubeflow/community/proposals](https://github.com/kubeflow/community/blob/master/proposals/README.md)



================================================
FILE: docs/proposals/1214-custom-crd-in-trial/README.md
================================================
# KEP-1214: Support custom CRD in Trial Job proposal

<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->

## Table of Contents

- [Motivation](#motivation)
- [Goals](#goals)
- [Non-Goals](#non-goals)
- [Implementation](#implementation)
  - [API](#api)
  - [Trial controller watchers](#trial-controller-watchers)
  - [Primary pod label location](#primary-pod-label-location)
  - [Training container name](#training-container-name)
  - [Start metrics collector parser](#start-metrics-collector-parser)
  - [Succeeded status of running CRD](#succeeded-status-of-running-crd)
  - [Istio sidecar container](#istio-sidecar-container)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

Created by [doctoc](https://github.com/thlorenz/doctoc).

## Motivation

Running trial is one of the essential steps of executing Katib experiments.
We have implemented new trial template design in Katib v1beta1 ([katib/pull#1202](https://github.com/kubeflow/katib/pull/1202)
and [katib/pull#1215](https://github.com/kubeflow/katib/pull/1215)) to make
experiments valid YAML and make Katib more Kubernetes native.
After migrating to the new API, users still can run only [BatchJob](https://kubernetes.io/docs/concepts/workloads/controllers/job/),
[TFJob](https://github.com/kubeflow/tf-operator) or [PyTorchJob](https://github.com/kubeflow/pytorch-operator) in trial job.
If we want to support new CRD, we need to manually change Katib controller source code.

This approach makes impossible to use other CRDs in trial template, even if they satisfy trial job design.
The number of various Kubernetes CRDs grows significantly and many users would like to use them in Katib
(e.g, [katib/issue#1081, support Argo Workflow](https://github.com/kubeflow/katib/issues/1081)).
Another reason to design unified approach is that CRD controller can have `Go` package versions
that Katib controller doesn't support (e.g, [katib/issue#1081](https://github.com/kubeflow/katib/issues/1081#issuecomment-635338276)).

That is why we propose a new controller design to support custom CRD in trial job and make Katib usable for various Kubernetes resources.
To make this possible, we are changing API, trial controller, job provider, mutation webhook, metrics collector.

## Goals

1. Allow dynamic watchers for the custom CRD.
2. Inject Katib sidecar container on training pod.
3. Indicate training container for metrics collector execution.
4. Run metrics collector parser after all pod processes completion.
5. Get succeeded condition of running CRD.
6. Verify that `sidecar.istio.io/inject: false` label is added.

## Non-Goals

1. Inject Katib sidecar container on more than one pod simultaneously.
2. Specify list of succeeded conditions for the custom CRD.
3. Dynamically add new trial watcher for the custom CRD without Katib restart.

## Implementation

During implementation this feature, we should not brake current Katib controller logic.
Also, we need to make sure that CI is stable and it does not block other Katib work tasks.
After completion, we can clean-up redundant code.

### API

To achieve above goals, we introduce these `TrialTemplate` API changes.

```go

// TrialTemplate describes structure of Trial template
type TrialTemplate struct {
  // Retain indicates that Trial resources must be not cleanup
  Retain bool `json:"retain,omitempty"`

  // Source for Trial template (unstructured structure or config map)
  TrialSource `json:",inline"`

  // List of parameters that are used in Trial template
  TrialParameters []TrialParameterSpec `json:"trialParameters,omitempty"`

  // Label that determines if pod needs to be injected by Katib sidecar container
  PrimaryPodLabel map[string]string `json:"primaryPodLabel,omitempty"`

  // Name of training container where training is running
  PrimaryContainerName string `json:"primaryContainerName,omitempty"`

  // Name of condition when Trial custom resource is succeeded
  SucceededCondition string `json:"succeededCondition,omitempty"`

}
```

### Trial controller watchers

In the current design trial controller watches
[three supported resource](https://github.com/kubeflow/katib/blob/master/pkg/controller.v1beta1/trial/trial_controller.go#L94-L125).
To generate these parameters dynamically when Katib starts, we add additional flag (`-trial-resource`)
to Katib controller, which represents resources that can be used in trial template.
This flag contains custom CRD's `Group`, `Version`, `Kind` in `kind.version.group` format which needs to create controller watchers.
Trial controller iterates over these parameters and creates watchers.

For example, if trial can run TFJob, Argo Workflow and Kubernetes Batch Jobs, Katib controller flags must be:

```yaml
. . .
args:
  - "-webhook-port=8443"
  - "-trial-resource=TFJob.v1.kubeflow.org".
  - "-trial-resource=Workflow.v1alpha1.argoproj.io"
  - "-trial-resource=Job.v1.batch"
. . .
```

### Primary pod label location

Right now, we [inject](https://github.com/kubeflow/katib/blob/master/pkg/webhook/v1beta1/pod/utils.go#L58-L72)
metrics collector for TFJob and PyTorchJob only for _master_ pods with labels previously saved in controller constants.

We added a new `PrimaryPodLabel` parameter in `TrialTemplate` API to find primary pod that needs to be injected by Katib sidecar container.
User can define the key and value of the pod label which Katib must inject with sidecar container.

For example, for TFJob:

```yaml
. . .
PrimaryPodLabel:
  "training.kubeflow.org/job-role": "master"
. . .
```

### Training container name

In the current design we compare container name with
[default value](https://github.com/kubeflow/katib/blob/master/pkg/job/v1beta1/kubeflow.go#L63-L78) for TFJob and PyTorchJob
to find pod container where actual training is happening and metrics collector must parse metrics.

We introduce a new `PrimaryContainerName` field, where user can set container name with running training program to find proper training container.

For example, if training is running on container with `pytorch` name:

```yaml
. . .
PrimaryContainerName: "pytorch"
. . .
```

### Start metrics collector parser

As discussed in [katib/issue#1214](https://github.com/kubeflow/katib/issues/1214#issuecomment-642168716),
metrics collector starts parsing metrics only after all injected pod processes were finished.
That can avoid problems with other sidecar containers that various CRD can have.

We need to verify that [distributive training](https://docs.fast.ai/distributed.html#launch-your-training)
with more than one active process also works with this approach.

### Succeeded condition of running CRD

We have already [designed Kubeflow provider](https://github.com/kubeflow/katib/blob/master/pkg/job/v1alpha3/kubeflow.go#L27-L60)
to check succeeded conditions for the TFJob and PyTorchJob as `unstructured` objects by
[comparing](https://github.com/kubeflow/katib/blob/master/pkg/controller.v1beta1/trial/trial_controller_util.go#L161)
`.status.conditions[x].type` value with `Succeeded` value.

Different CRD can have unique status design (e.g, Kubernetes batch job succeeded condition is
[`Complete`](https://github.com/kubernetes/api/blob/master/batch/v1/types.go#L167-L173)).
We add a new parameter `SucceededCondition` to get CRD succeeded condition value and trigger trial controller.
Trial controller checks all running job conditions and verifies that running job has appropriate `type`
in `.status.conditions` with `status=True`.
We also should transform `reason` and `message` from custom CRD to the trial conditions, if it is available.

For example, for TFJob:

```yaml
. . .
SucceededCondition: Succeeded
. . .
```

### Istio sidecar container

Previously, we had problems with Istio sidecar containers,
check [kubeflow/issue#1081](https://github.com/kubeflow/kubeflow/issues/4742).
In some cases, it is unable to properly download datasets in training pod.
It was fixed by adding label `sidecar.istio.io/inject: false` to appropriate Trial job in Katib controller.

Various CRD can have unified design and it is hard to understand where annotation must be specified
to disable Istio injection for the running pods.
We need to update all Katib examples manually and add this annotation to every trial template.

This exception has to be documented and new Katib examples have to include this annotation in templates.



================================================
FILE: docs/proposals/2044-conformance-program/README.md
================================================
# KEP-2044: Conformance Test for AutoML and Training Working Group

Andrey Velichkevich ([@andreyvelich](https://github.com/andreyvelich))
Johnu George ([@johnugeorge](https://github.com/johnugeorge))
2022-11-21
[Original Google Doc](https://docs.google.com/document/d/1TRUKUY1zCCMdgF-nJ7QtzRwifsoQop0V8UnRo-GWlpI/edit#).

## Motivation

Kubeflow community needs to design conformance program so the distributions can
become
[Certified Kubeflow](https://docs.google.com/document/d/1a9ufoe_6DB1eSjpE9eK5nRBoH3ItoSkbPfxRA0AjPIc/edit?resourcekey=0-IRtbQzWfw5L_geRJ7F7GWQ#).
Recently, Kubeflow Pipelines Working Group (WG) implemented the first version of
[their conformance tests](https://github.com/kubeflow/kubeflow/issues/6485).
We should design the same program for AutoML and Training WG.

This document is based on the original proposal for
[the Kubeflow Pipelines conformance program](https://docs.google.com/document/d/1_til1HkVBFQ1wCgyUpWuMlKRYI4zP1YPmNxr75mzcps/edit#).

## Objective

Conformance program for AutoML and Training WG should follow the same goals as Pipelines program:

- The tests should be fully automated and executable by anyone who has public
  access to the Kubeflow repository.
- The test results should be easy to verify by the Kubeflow Conformance Committee.
- The tests should not depend on cloud provider (e.g. AWS or GCP).
- The tests should cover basic functionality of Katib and the Training Operator.
  It will not cover all features.
- The tests are expected to evolve in the future versions.
- The tests should have a well documented and short list of set-up requirements.
- The tests should install and complete in a relatively short period of time
  with suggested minimum infrastructure requirements
  (e.g. 3 nodes, 24 vCPU, 64 GB RAM, 500 GB Disk).

## Kubeflow Conformance

Initially the Kubeflow conformance will include the CRD based tests.
In the future, API and UI based tests may be added. Kubeflow conformance consists
the 3 category of tests:

- CRD-based tests

  Most of Katib and Training Operator functionality are based on Kubernetes CRD.

  **This document will define a design for CRD-based tests for Katib and the Training Operator.**

- API-based tests

  Currently, Katib or Training Operator doesn’t have an API server that receives
  requests from the users. However, Katib has the DB Manager component that is
  responsible for writing/reading ML Training metrics.

  In the following versions, we should design conformance program for the
  Katib API-based tests.

- UI-based tests

  UI tests are valuable but complex to design, document and execute. In the following
  versions, we should design conformance program for the Katib UI-based tests.

## Design for the CRD-based tests

![conformance-crd-test](conformance-crd-test.png)

The design is similar to the KFP conformance program for the API-based tests.

For Katib, tests will be based on
[the `run-e2e-experiment.go` script](https://github.com/kubeflow/katib/blob/570a3e68fff7b963889692d54ee1577fbf65e2ef/test/e2e/v1beta1/hack/gh-actions/run-e2e-experiment.go)
that we run for our e2e tests.

This script will be converted to use Katib SDK. Tracking issue: https://github.com/kubeflow/katib/issues/2024.

For the Training Operator, tests will be based on [the SDK e2e test.](https://github.com/kubeflow/training-operator/tree/05badc6ee8a071400efe9019d8d60fc242818589/sdk/python/test/e2e)

### Test Workflow

All tests will be run in the _kf-conformance_ namespace inside the separate container.
That will help to avoid environment variance and improve fault tolerance. Driver is required to trigger the deployment and download the results.

- We are going to use
  [the unified Makefile](https://github.com/kubeflow/kubeflow/blob/2fa0d3665234125aeb8cebe8fe44f0a5a50791c5/conformance/1.5/Makefile)
  for all Kubeflow conformance tests. Distributions (_driver_ on the diagram)
  need to run the following Makefile commands:

  ```makefile

  # Run the conformance program.
  run: setup run-katib run-training-operator

  # Sets up the Kubernetes resources (Kubeflow Profile, RBAC) that needs to run the test.
  # Create temporary folder for the conformance report.
  setup:
    kubectl apply -f ./setup.yaml
    mkdir -p /tmp/kf-conformance

  # Create deployment and run the e2e tests for Katib and Training Operator.
  run-katib:
    kubectl apply -f ./katib-conformance.yaml

  run-training-operator:
    kubectl apply -f ./training-operator-conformance.yaml

  # Download the test deployment results to create PR for the Kubeflow Conformance Committee.
  report:
    ./report-conformance.sh

  # Cleans up created resources and directories.
  cleanup:
    kubectl delete -f ./setup.yaml
    kubectl delete -f ./katib-conformance.yaml
    kubectl delete -f ./training-operator-conformance.yaml
    rm -rf /tmp/kf-conformance
  ```

- Katib and Training Operator conformance deployment will have the appropriate
  RBAC to Create/Read/Delete Katib Experiment and Training Operator Jobs in the
  _kf-conformance_ namespace.

- Distribution should have access to the internet to download the training datasets
  (e.g. MNIST) while running the tests.

- When the job is finished, the script generates output.

  For Katib Experiment the output should be as follows:

  ```
  Test 1 - passed.
  Experiment name: random-search
  Experiment status: Experiment has succeeded because max trial count has reached
  ```

  For Training Operator the output should be as follows:

  ```
  Test 1 - passed.
  TFJob name: tfjob-mnist
  TFJob status: TFJob tfjob-mnist is successfully completed.
  ```

- The above report can be downloaded from the test deployment by running `make report`.

- When all reports have been collected, the distributions are going to create PR
  to publish the reports and to update the appropriate [Kubeflow Documentation](https://www.kubeflow.org/)
  on conformant Kubeflow distributions. The Kubeflow Conformance Committee will
  verify it and make the distribution
  [Certified Kubeflow](https://github.com/kubeflow/community/blob/master/proposals/kubeflow-conformance-program-proposal.md#overview).



================================================
FILE: docs/proposals/2339-hpo-for-llm-fine-tuning/README.md
================================================
# KEP-2339: HyperParameter Optimization API for LLM Fine-Tuning

- [HyperParameter Optimization API for LLM Fine-Tuning](#hyperparameter-optimization-api-for-llm-fine-tuning)
  - [Links](#links)
  - [Motivation](#motivation)
  - [Goals](#goals)
  - [Non-Goals](#non-goals)
  - [Design for API](#design-for-api)
    - [Example](#example)
  - [Implementation](#implementation)

## Links

- [katib/issues#2291 (Tuning API in Katib for LLMs)](https://github.com/kubeflow/katib/issues/2291)

## Motivation

The rapid advancements and growing popularity of Large Language Models (LLMs) have driven an increased need for effective LLMOps in Kubernetes environments. To address this, we developed a [train API](https://www.kubeflow.org/docs/components/training/user-guides/fine-tuning/) within the Training Python SDK, simplifying the process of fine-tuning LLMs using distributed PyTorchJob workers. However, hyperparameter optimization remains a crucial yet labor-intensive task for enhancing model performance. Automating this tuning process through a dedicated API will facilitate efficient and scalable exploration of hyperparameters, ultimately improving model performance and reducing manual effort.

## Goals

Our goal is to develop a high-level API for tuning hyperparameters of LLMs that simplifies the process of hyperparameter optimization in Kubernetes. This API will seamlessly integrate with external platforms like HuggingFace and S3 for importing pretrained models and datasets. By specifying parameters for the training objective, trial configurations, and PyTorch worker configurations, the API will automate the creation of experiments and execution of trials. This abstraction of Kubernetes infrastructure complexities will enable data scientists to optimize hyperparameters efficiently and effectively.

## Non-Goals

1. Incorporate early stopping strategy into the API to optimize training efficiency.
2. Expand support for distributed training in frameworks beyond PyTorch by leveraging their distributed training capabilities.
3. Support adding custom providers through configmap or CRD approach to enhance flexibility.
4. Enable users to deploy tuned models for inference within their applications or seamlessly integrate them into existing NLP pipelines for specialized tasks.

## Design for API

![Design for API](hp-optimization-api-design.jpg)

```python
import kubeflow.katib as katib
from kubeflow.katib import KatibClient

class KatibClient(object):

	def tune(
		self,
		name: str,
		namespace: Optional[str] = None,
		model_provider_parameters: Optional[HuggingFaceModelParams] = None,
		dataset_provider_parameters: Optional[Union[HuggingFaceDatasetParams, S3DatasetParams]] = None,
		trainer_parameters: Union[HuggingFaceTrainerParams, Dict[str, Any]] = None,
		storage_config: Dict[str, Optional[Union[str, List[str]]]] = {
            "size": constants.PVC_DEFAULT_SIZE,
            "storage_class": None,
            "access_modes": constants.PVC_DEFAULT_ACCESS_MODES,
        },
		objective: Optional[Callable] = None,
		base_image: Optional[str] = None,
		algorithm_name: str = "random",
		algorithm_settings: Union[dict, List[models.V1beta1AlgorithmSetting], None] = None,
		objective_metric_name: str = "eval_accuracy",
		additional_metric_names: List[str] = [],
		objective_type: str = "maximize",
		objective_goal: float = None,
		max_trial_count: int = None,
		parallel_trial_count: int = None,
		max_failed_trial_count: int = None,
		resources_per_trial = Union[dict, client.V1ResourceRequirements, types.TrainerResources, None] = None,
		retain_trials: bool = False,
		env_per_trial: Optional[Union[Dict[str, str], List[Union[client.V1EnvVar, client.V1EnvFromSource]]]] = None,
		packages_to_install: List[str] = None,
		pip_index_url: str = "https://pypi.org/simple",
	):
		"""
        Initiates a hyperparameter tuning experiment in Katib.
		Model, dataset and parameters can be configured using one of the following options:
		- Using the Storage Initializer: Specify `model_provider_parameters`, `dataset_provider_parameters`, and `trainer_parameters`. This option downloads models and datasets from external platforms like HuggingFace and S3, and utilizes `Trainer.train()` in HuggingFace to train the model.
		- Defining a custom objective function: Specify the `objective` parameter to define your own objective function, and use the `base_image` parameter to execute the objective function.

        Parameters:
		- name: Name for the experiment.
		- namespace: Namespace for the experiment. Defaults to the namespace of the 'KatibClient' object.
		- model_provider_parameters: Parameters for providing the model. Compatible with model providers like HuggingFace.
		- dataset_provider_parameters: Parameters for providing the dataset. Compatible with dataset providers like HuggingFace or S3.
		- trainer_parameters: Parameters for configuring the training process, including settings for hyperparameters search space.
		- storage_config: Configuration for Storage Initializer PVC to download pre-trained model and dataset.
		- objective: Objective function that Katib uses to train the model.
		- base_image: Image to use when executing the objective function.
		- algorithm_name: Tuning algorithm name (e.g., 'random', 'bayesian').
		- algorithm_settings: Settings for the tuning algorithm.
		- objective_metric_name: Primary metric to optimize.
		- additional_metric_names: List of additional metrics to collect.
		- objective_type: Optimization direction for the objective metric, "minimize" or "maximize".
		- objective_goal: Desired value of the objective metric.
		- max_trial_count: Maximum number of trials to run.
		- parallel_trial_count: Number of trials to run in parallel.
		- max_failed_trial_count: Maximum number of allowed failed trials.
		- resources_per_trial: Resources assigned to per trial, which can be specified using one of the following options:
			- Non-distributed Training: Specify a kubernetes.client.V1ResourceRequirements object or a dicitionary that includes one or more of the following keys: `cpu`, `memory`, or `gpu` (other keys will be ignored).
			- Distributed Training in Pytorch: Specify a types.TrainerResources, which includes the following parameters:
				- num_workers: Number of PyTorchJob workers.
				- num_procs_per_worker: Number of processes per PyTorchJob worker.
				- resources_per_worker: Resources assigned to per PyTorchJob worker container, specified as either a kubernetes.client.V1ResourceRequirements object or a dicitionary that includes one or more of the following keys: `cpu`, `memory`, or `gpu` (other keys will be ignored).
		- retain_trials: Whether to retain trial resources after completion.
		- env_per_trial: Environment variables for worker containers.
		- packages_to_install: Additional Python packages to install.
		- pip_index_url: URL of the PyPI index for installing packages.
        """
        pass  # Implementation logic for initiating the experiment
```

### Example

```python
import kubeflow.katib as katib
from kubeflow.katib import KatibClient

import transformers
from peft import LoraConfig

from kubeflow.storage_initializer.hugging_face import (
	HuggingFaceModelParams,
	HuggingFaceDatasetParams,
	HuggingFaceTrainerParams,
)

# Create a Katib client.
cl = KatibClient(namespace="kubeflow")

# Run the tuning experiment.
exp_name = "llm-experiment1"
cl.tune(
	name = exp_name,
	# BERT model URI and type of Transformer to train it.
	model_provider_parameters = HuggingFaceModelParams(
		model_uri = "hf://google-bert/bert-base-cased",
		transformer_type = transformers.AutoModelForSequenceClassification,
	),
	# Use 3000 samples from Yelp dataset.
	dataset_provider_parameters = HuggingFaceDatasetParams(
		repo_id = "yelp_review_full",
		split = "train[:3000]",
	),
	# Specify HuggingFace Trainer parameters.
	trainer_parameters = HuggingFaceTrainerParams(
		training_parameters = transformers.TrainingArguments(
			output_dir = "test_tune_api",
			save_strategy = "no",
			learning_rate = katib.search.double(min=1e-05, max=5e-05),
			num_train_epochs=3,
		),
		# Set LoRA config to reduce number of trainable model parameters.
		lora_config = LoraConfig(
			r = katib.search.int(min=8, max=32),
			lora_alpha = 8,
			lora_dropout = 0.1,
			bias = "none",
		),
	),
	objective_metric_name = "train_loss",
	objective_type = "minimize",
	algorithm_name = "random",
	max_trial_count = 10,
	parallel_trial_count = 2,
	resources_per_trial={
		"gpu": "2",
		"cpu": "4",
		"memory": "10G",
	},
	# For distribued training, please specify `resources_per_trial` using `types.TrainerResources` (To be implemented).
)

# Wait until Katib Experiment is complete
cl.wait_for_experiment_condition(name=exp_name)

# Get the best hyperparameters.
print(cl.get_optimal_hyperparameters(exp_name))
```

## Implementation

By passing the specified parameters, this API will automate hyperparameter optimization for LLMs. The implementation will focus on the following aspects:

**Model and Dataset Management**: We will leverage the [storage_initializer](https://github.com/kubeflow/training-operator/tree/master/sdk/python/kubeflow/storage_initializer) from the Training Python SDK for seamless integration of pretrained models and datasets from platforms like HuggingFace and S3. This component manages downloading and storing pretrained models and datasets via a PersistentVolumeClaim (PVC), which is shared across containers, ensuring efficient access to the pretrained model and dataset without redundant downloads.

**Hyperparameter Configuration**: Users specify training parameters and the hyperparameters to be optimized within `trainer_parameters`. The API will first traverse `trainer_parameters.training_parameters` and `trainer_parameters.lora_config` to identify tunable hyperparameters and set up their values for the Experiment and Trials. These parameters are then passed as `args` to the container spec of workers.

```python
# Traverse and set up hyperparameters
input_params = {}
experiment_params = []
trial_params = []

training_args = trainer_parameters.training_parameters
for p_name, p_value in training_args.to_dict().items():
	if not hasattr(training_args, p_name):
		logger.warning(f"Training parameter {p_name} is not supported by the current transformer.")
		continue
	if isinstance(p_value, models.V1beta1ParameterSpec):
		value = f"${{trialParameters.{p_name}}}"
		setattr(training_args, p_name, value)
		p_value.name = p_name
		experiment_params.append(p_value)
		trial_params.append(models.V1beta1TrialParameterSpec(name=p_name, reference=p_name))
	elif p_value is not None:
		value = type(old_attr)(p_value)
		setattr(training_args, p_name, value)
input_params['training_args'] = training_args

# Note: Repeat similar logic for `lora_config`

# create container spec of worker
container_spec = client.V1Container(
	...
	args=[
		"--model_uri",
		model_provider_parameters.model_uri,
		"--transformer_type",
		model_provider_parameters.transformer_type.__name__,
		"--model_dir",
		"REPLACE_WITH_ACTUAL_MODEL_PATH",
		"--dataset_dir",
		"REPLACE_WITH_ACTUAL_DATASET_PATH",
		"--lora_config",
		json.dumps(input_params['lora_config'].__dict__, cls=utils.SetEncoder),
		"--training_parameters",
		json.dumps(input_params['training_args'].to_dict()),
	],
	...
)
```

**Hyperparameter Optimization**: This API will create an Experiment that defines the search space for identified tunable hyperparameters, the objective metric, optimization algorithm, etc. The Experiment will orchestrate the hyperparameter tuning process, generating Trials for each configuratin. Each Trial will be implemented as a Kubernete PyTorchJob, with the `trialTemplate` specifying the exact values for hyperparameters. The `trialTemplate` will also define master and worker containers, facilitating effective resource distribution and parallel execution of Trials. Trial results will then be fed back to the Experiment, which will evaluate the outcomes to identify the optimal set of hyperparameters.

**Dependencies Update**: To reuse existing assets from the Training Python SDK and integrate packages from HuggingFace, dependencies will be added to the `setup.py` of the Katib Python SDK as follows:

```python
setuptools.setup(
	...// Configurations of the package
	extras_require={
		"huggingface": ["kubeflow-training[huggingface]==1.8.0rc1"],
	},
)
```



================================================
FILE: docs/proposals/2340-push-based-metrics-collector/README.md
================================================
# KEP-2340: Push-based Metrics Collection Proposal

## Links

- [katib/issues#577([Enhancement Request] Metrics Collector Push-based Implementation)](https://github.com/kubeflow/katib/issues/577)

## Motivation

[Katib](https://github.com/kubeflow/katib) is a Kubernetes-native project for automated machine learning (AutoML). It can not only tune hyperparameters of applications written in any language and natively supports many ML frameworks, but also supports features like early stopping and neural architecture search.

In the procedure of tuning hyperparameters, Metrics Collector, which is implemented as a sidecar container attached to each training container in the [current design](https://github.com/kubeflow/katib/blob/master/docs/proposals/metrics-collector.md), will collect training logs from Trials once the training is complete. Then, the Metrics Collector will parse training logs to get appropriate metrics like accuracy or loss and pass the evaluation results to the HyperParameter tuning algorithm.

However, current implementation of Metrics Collector is pull-based, raising some [design problems](https://github.com/kubeflow/training-operator/issues/722#issuecomment-405669269) such as determining the frequency we scrape the metrics, performance issues like the overhead caused by too many sidecar containers, and restrictions on developing environments which must support sidecar containers. Thus, we should implement a new API for Katib Python SDK to offer users a push-based way to store metrics directly into the Katib DB and resolve those issues raised by pull-based metrics collection.

![](./push-based-metrics-collection.png)

Fig.1 Architecture of the new design

### Goals

1. **A new parameter in Python SDK function `tune`**: allow users to specify the method of collecting metrics(push-based/pull-based).

2. **A new interface `report_metrics` in Python SDK**: push the metrics to Katib DB directly.

3. The final metrics of worker pods should be **pushed to Katib DB directly** in the push mode of metrics collection.

### Non-Goals

1. Implement authentication model for Katib DB to push metrics.

2. Support pushing data to different types of storage system(prometheus, self-defined interface etc.)

## API

### New Parameter in Python SDK Function `tune`

We decided to add `metrics_collector_config` to `tune` function in Python SDK.

```Python
def tune(
    self,
    name: str,
    objective: Callable,
    parameters: Dict[str, Any],
    base_image: str = constants.BASE_IMAGE_TENSORFLOW,
    namespace: Optional[str] = None,
    env_per_trial: Optional[Union[Dict[str, str], List[Union[client.V1EnvVar, client.V1EnvFromSource]]]] = None,
    algorithm_name: str = "random",
    algorithm_settings: Union[dict, List[models.V1beta1AlgorithmSetting], None] = None,
    objective_metric_name: str = None,
    additional_metric_names: List[str] = [],
    objective_type: str = "maximize",
    objective_goal: float = None,
    max_trial_count: int = None,
    parallel_trial_count: int = None,
    max_failed_trial_count: int = None,
    resources_per_trial: Union[dict, client.V1ResourceRequirements, None] = None,
    retain_trials: bool = False,
    packages_to_install: List[str] = None,
    pip_index_url: str = "https://pypi.org/simple",
    # The newly added parameter metrics_collector_config.
    # It specifies the config of metrics collector, for example,
    # metrics_collector_config={"kind": "Push"},
    metrics_collector_config: Dict[str, Any] = {"kind": "StdOut"},
)
```

### New Interface `report_metrics` in Python SDK

```Python
"""Push Metrics Directly to Katib DB

    [!!!] Trial name should always be passed into Katib Trials as env variable `KATIB_TRIAL_NAME`.

    Args:
        metrics: Dict of metrics pushed to Katib DB.
            For examle, `metrics = {"loss": 0.01, "accuracy": 0.99}`.
        db-manager-address: Address for the Katib DB Manager in this format: `ip-address:port`.
        timeout: Optional, gRPC API Server timeout in seconds to report metrics.

    Raises:
        RuntimeError: Unable to push Trial metrics to Katib DB.
"""
def report_metrics(
    metrics: Dict[str, Any],
    db_manager_address: str = constants.DEFAULT_DB_MANAGER_ADDRESS,
    timeout: int = constants.DEFAULT_TIMEOUT,
)
```

### A Simple Example:

```Python
import kubeflow.katib as katib

# Step 1. Create an objective function with push-based metrics collection.
def objective(parameters):
    # Import required packages.
    import kubeflow.katib as katib
    # Calculate objective function.
    result = 4 * int(parameters["a"]) - float(parameters["b"]) ** 2
    # Push metrics to Katib DB.
    katib.report_metrics({"result": result})

# Step 2. Create HyperParameter search space.
parameters = {
    "a": katib.search.int(min=10, max=20),
    "b": katib.search.double(min=0.1, max=0.2)
}

# Step 3. Create Katib Experiment with 12 Trials and 2 GPUs per Trial.
katib_client = katib.KatibClient(namespace="kubeflow")
name = "tune-experiment"
katib_client.tune(
    name=name,
    objective=objective,
    parameters=parameters,
    objective_metric_name="result",
    max_trial_count=12,
    resources_per_trial={"gpu": "2"},
    metrics_collector_config={"kind": "Push"},
)

# Step 4. Get the best HyperParameters.
print(katib_client.get_optimal_hyperparameters(name))
```

## Implementation

### Add New Parameter in `tune`

As mentioned above, we decided to add `metrics_collector_config` to the tune function in Python SDK. Also, we have some changes to be made:

1. Configure the way of metrics collection: set the configuration `spec.metricsCollectionSpec.collector.kind`(specify the way of metrics collection) to `Push`.

2. Rename metrics collector from `None` to `Push`: It's not correct to call push-based metrics collection `None`. We should modify related code to rename it.

3. Write env variables into Trial spec: set `KATIB_TRIAL_NAME` for `report_metrics` function to dial db manager.

### New Interface `report_metrics` in Python SDK

We decide to implement this funcion to push metrics directly to Katib DB with the help of grpc. Trial name should always be passed into Katib Trials (and then into this function) as env variable `KATIB_TRIAL_NAME`.

Also, the function is supposed to be implemented as **global function** because it is called in the user container.

Steps:

1. Wrap metrics into `katib_api_pb2.ReportObservationLogRequest`:

Firstly, convert metrics (in dict format) into `katib_api_pb2.ReportObservationLogRequest` type for the following grpc call, referring to https://github.com/kubeflow/katib/blob/master/pkg/apis/manager/v1beta1/gen-doc/api.md#reportobservationlogrequest

2. Dial Katib DBManager Service

We'll create a DBManager Stub and make a grpc call to report metrics to Katib DB.

### Compatibility Changes in Trial Controller

We need to make appropriate changes in the Trial controller to make sure we insert unavailable value into Katib DB, if user doesn't report metric accidentally. The current implementation handles unavailable metrics in:

```Golang
// If observation is empty metrics collector doesn't finish.
// For early stopping metrics collector are reported logs before Trial status is changed to EarlyStopped.
if jobStatus.Condition == trialutil.JobSucceeded && instance.Status.Observation == nil {
	logger.Info("Trial job is succeeded but metrics are not reported, reconcile requeued")
	return errMetricsNotReported
}
```

1. Distinguish pull-based and push-based metrics collection

We decide to add a if-else statement in the code above to distinguish pull-based and push-based metrics collection. In the push-based collection, the Trial does not need to be requeued. Instead, we'll insert a unavailable value to Katib DB.

2. Update the status of Trial to `MetricsUnavailable`

In the current implementation of pull-based metrics collection, Trials will be re-queued when the metrics collector finds the `.Status.Observation` is empty. However, it's not compatible with push-based metrics collection because the forgotten metrics won't be reported in the new round of reconcile. So, we need to update its status in the function `UpdateTrialStatusCondition` in accommodation with the pull-based metrics collection. The following code will be insert into lines before [trial_controller_util.go#L69](https://github.com/kubeflow/katib/blob/7959ffd54851216dbffba791e1da13c8485d1085/pkg/controller.v1beta1/trial/trial_controller_util.go#L69)

```Golang
else if instance.Spec.MetricCollector.Collector.Kind == "Push" {
    ... // Update the status of this Trial to `MetricsUnavailable` and output the reason.
}
```

### Collection of Final Metrics

The final metrics of worker pods should be pushed to Katib DB directly in the push mode of metrics collection.



================================================
FILE: docs/proposals/2374-parameter-distribution/README.md
================================================
# KEP-2374: Proposal for Supporting various parameter distributions in Katib

## Summary
The goal of this project is to enhance the existing Katib Experiment APIs to support various parameter distributions such as uniform, log-uniform, and qlog-uniform. Then extend the suggestion services to be able to configure distributions for search space using libraries provided in each framework.

## Motivation
Currently, [Katib](https://github.com/kubeflow/katib) is limited to supporting only uniform distribution for integer, float, and categorical hyperparameters. By introducing additional distributions, Katib will become more flexible and powerful in conducting hyperparameter optimization tasks.

A Data Scientist requires Katib to support multiple hyperparameter distributions, such as log-uniform, normal, and log-normal, in addition to the existing uniform distribution. This enhancement is crucial for more flexible and precise hyperparameter optimization. For instance, learning rates often benefit from a log-uniform distribution because small values can significantly impact performance. Similarly, normal distributions are useful for parameters that are expected to vary around a central value.

### Goals
- Add `Distribution` field to `FeasibleSpace` alongside `ParameterType`.
- Support for the log-uniform, normal, and log-normal Distributions.
- Update the Experiment and gRPC API to support `Distribution`.
- Update logic to handle the new parameter distributions for each suggestion service (e.g., Optuna, Hyperopt).
- Extend the Python SDK to support the new `Distribution` field.
### Non-Goals
- This proposal do not aim to create new version for CRD APIs.
- This proposal do not aim to make the necessary Katib UI changes.
- No changes will be made to the core optimization algorithms beyond supporting new distributions.

## Proposal

### Parameter Distribution Comparison Table

| Distribution Type             | Hyperopt              | Optuna                                          | Ray Tune              | Nevergrad                                    |
|-------------------------------|-----------------------|-------------------------------------------------|-----------------------|---------------------------------------------|
| **Uniform Continuous**        | `hp.uniform`          | `FloatDistribution`                             | `tune.uniform`        | `p.Scalar` with uniform transformation      |
| **Quantized Uniform**         | `hp.quniform`         | `DiscreteUniformDistribution` (deprecated)      | `tune.quniform`       | `p.Scalar` with uniform and step specified  |
| **Log Uniform**               | `hp.loguniform`       | `LogUniformDistribution` (deprecated)           | `tune.loguniform`     | `p.Log` with uniform transformation         |
| **Uniform Integer**           | `hp.randint` or quantized distributions with step size `q` set to 1 | `IntDistribution`                    | `tune.randint`        | `p.Scalar` with integer transformation     |
| **Categorical**               | `hp.choice`           | `CategoricalDistribution`                       | `tune.choice`         | `p.Choice`                                  |
| **Quantized Log Uniform**     | `hp.qloguniform`      | Custom Implementation                           | `tune.qloguniform`    | `p.Log` with uniform and step specified    |
| **Normal**                    | `hp.normal`           | (Not directly supported)                        | `tune.randn`          | (Not directly supported)                    |
| **Quantized Normal**          | `hp.qnormal`          | (Not directly supported)                        | `tune.qrandn`         | (Not directly supported)                    |
| **Log Normal**                | `hp.lognormal`        | (Not directly supported)                        | (Use custom transformation in `tune.randn`) | (Not directly supported)                    |
| **Quantized Log Normal**      | `hp.qlognormal`       | (Not directly supported)                        | (Use custom transformation in `tune.qrandn`) | (Not directly supported)                    |
| **Quantized Integer**         | `hp.quniformint`      | `IntUniformDistribution` (deprecated)           |                       | `p.Scalar` with integer and step specified  |
| **Log Integer**               |                       | `IntLogUniformDistribution` (deprecated)        | `tune.lograndint`     | `p.Scalar` with log-integer transformation |


- Note:
In `Nevergrad`, parameter types like `p.Scalar`, `p.Log`, and `p.Choice` are mapped to corresponding `Hyperopt` search space definitions like `hp.uniform`, `hp.loguniform`, and `hp.choice` using internal functions to convert parameter bounds and distributions.

## API Design
### FeasibleSpace
Feasible space for optimization.
Int and Double type use Max/Min.
Discrete and Categorical type use List.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| max | [string](#string) |  | Max Value |
| min | [string](#string) |  | Minimum Value |
| list | [string](#string) | repeated | List of Values. |
| step | [string](#string) |  | Step for double or int parameter or q for quantization|
| distribution | [Distribution](#api-v1-beta1-Distribution) |  | Type of the Distribution. |


<a name="api-v1-beta1-Distribution"></a>

### Distribution
- Types of value for HyperParameter Distributions.
- We add the `distribution` field to represent the hyperparameters search space rather than [`ParameterType`](https://github.com/kubeflow/katib/blob/2c575227586ff1c03cf6b5190d066e2f3061a404/pkg/apis/controller/experiments/v1beta1/experiment_types.go#L199-L207).
- The `distribution` allows users to configure more granular search space customizations.
- In this enhancement, we would propose the following 4 distributions:

| Name | Number | Description |
| ---- | ------ | ----------- |
| UNIFORM | 0 | Continuous uniform distribution. Samples values evenly between a minimum and maximum value. Use &#34;Max/Min&#34;. Use &#34;Step&#34; for `q`. |
| LOGUNIFORM | 1 | Samples values such that their logarithm is uniformly distributed. Use &#34;Max/Min&#34;. Use &#34;Step&#34; for `q`. |
| NORMAL | 2 | Normal (Gaussian) distribution type. Samples values according to a normal distribution characterized by a mean and standard deviation. Use &#34;Max/Min&#34;. Use &#34;Step&#34; for `q`. |
| LOGNORMAL | 3 | Log-normal distribution type. Samples values such that their logarithm is normally distributed. Use &#34;Max/Min&#34;. Use &#34;Step&#34; for `q`. |


## Experiment API changes
Scope: `pkg/apis/controller/experiments/v1beta1/experiment_types.go`

```go
type ParameterSpec struct {
	Name          string        `json:"name,omitempty"`
	ParameterType ParameterType `json:"parameterType,omitempty"`
	FeasibleSpace FeasibleSpace `json:"feasibleSpace,omitempty"`
}
```
- Adding new field `Distribution` to `FeasibleSpace`

- The `Step` field can be used to define quantization steps for uniform or log-uniform distributions, effectively covering q-quantization requirements.

Updated `FeasibleSpace` struct
```diff
type FeasibleSpace struct {
	Max           string        `json:"max,omitempty"`
	Min           string        `json:"min,omitempty"`
	List          []string      `json:"list,omitempty"`
	Step          string        `json:"step,omitempty"` // Step can be used to define q-quantization
+       Distribution  Distribution  `json:"distribution,omitempty"` // Added Distribution field
}
```
 - New Field Description: `Distribution`
  - Type: `Distribution`
  - Description: The Distribution field specifies the type of statistical distribution to be applied to the parameter. This allows the definition of various distributions, such as uniform, log-uniform, or other supported types.

- Defining `Distribution` type
```go
type Distribution string

const (
	DistributionUniform    Distribution = "uniform"
	DistributionLogUniform Distribution = "logUniform"
	DistributionNormal     Distribution = "normal"
	DistributionLogNormal  Distribution = "logNormal"
)
```

## gRPC API changes
Scope: `pkg/apis/manager/v1beta1/api.proto`
- Add the `Distribution` field to the `FeasibleSpace` message
```diff
/**
 * Feasible space for optimization.
 * Int and Double type use Max/Min.
 * Discrete and Categorical type use List.
 */
message FeasibleSpace {
    string max = 1; /// Max Value
    string min = 2; /// Minimum Value
    repeated string list = 3; /// List of Values.
    string step = 4; /// Step for double or int parameter
+   Distribution distribution = 4; // Distribution of the parameter.
}
```
- Define the `Distribution` enum
```
/**
 * Distribution types for HyperParameter.
 */
enum Distribution {
    UNIFORM = 0;
    LOG_UNIFORM = 1;
    NORMAL = 2;
    LOG_NORMAL = 3;
}
```

## Suggestion Service Logic
- For each suggestion service (e.g., Optuna, Hyperopt), the logic will be updated to handle the new parameter distributions.
- This involves modifying the conversion functions to map Katib distributions to the corresponding framework-specific distributions.

#### Optuna
ref: https://optuna.readthedocs.io/en/stable/reference/distributions.html

For example:
- Update the `_get_optuna_search_space` for new Distributions.
scope: `pkg/suggestion/v1beta1/optuna/base_service.py`

#### Goptuna
ref: https://github.com/c-bata/goptuna/blob/2245ddd9e8d1edba750839893c8a618f852bc1cf/distribution.go

#### Hyperopt
ref: http://hyperopt.github.io/hyperopt/getting-started/search_spaces/#parameter-expressions

#### Ray-tune
ref: https://docs.ray.io/en/latest/tune/api/search_space.html

## Python SDK
Extend the Python SDK to support the new `Distribution` field.




================================================
FILE: docs/proposals/507-suggestion-crd/README.md
================================================
# KEP-507: Suggestion CRD Design Document

# Table of Contents

- [Suggestion CRD Design Document](#suggestion-crd-design-document)
- [Table of Contents](#table-of-contents)
  - [Background](#background)
  - [Goals](#goals)
  - [Non-Goals](#non-goals)
  - [Design](#design)
    - [Kubernetes API](#kubernetes-api)
    - [GRPC API](#grpc-api)
    - [Workflow](#workflow)
      - [Example](#example)
  - [Algorithm Supports](#algorithm-supports)
    - [Random](#random)
    - [Grid](#grid)
    - [Bayes Optimization](#bayes-optimization)
    - [HyperBand](#hyperband)
    - [BOHB](#bohb)
    - [TPE](#tpe)
    - [SMAC](#smac)
    - [CMA-ES](#cma-es)
    - [Sobol](#sobol)

Created by [gh-md-toc](https://github.com/ekalinin/github-markdown-toc)

## Background

Katib makes suggestions long-running in v1alpha3. And the suggestions need to communicate with Katib DB manager to get experiments and trials from Katib db driver. This design hurts high availability.

Thus we proposed a new design to implement a CRD for suggestion and remove Katib db communication from main workflow. The new design simplifies the implementation of experiment and trial controller, and makes Katib Kubernetes native.

This document is to illustrate the details of the new design.

## Goals

- Propose the Suggestion CRD.
- Propose new GRPC API for Suggestion service.
- Suggest the approaches to implement suggestion algorithms.

## Non-Goals

- Metrics collection (See [Metrics Collector Design Document](./metrics-collector.md))
- Database-related refactor

## Design

### Kubernetes API

```go
// SuggestionSpec defines the desired state of Suggestion
type SuggestionSpec struct {
	AlgorithmName string `json:"algorithmName"`
	// Number of suggestions requested
	Requests int32 `json:"requests,omitempty"`
}

// SuggestionStatus defines the observed state of Suggestion
type SuggestionStatus struct {
	// Algorithmsettings set by the algorithm services.
	AlgorithmSettings []common.AlgorithmSetting `json:"algorithmSettings,omitempty"`

	// Number of suggestion results
	SuggestionCount int32 `json:"suggestionCount,omitempty"`

	// Suggestion results
	Suggestions []TrialAssignment `json:"suggestions,omitempty"`
}

// TrialAssignment is the assignment for one trial.
type TrialAssignment struct {
	// Suggestion results
	ParameterAssignments []common.ParameterAssignment `json:"parameterAssignments,omitempty"`

	//Name of the suggestion
	Name string `json:"name,omitempty"`
}
```

### GRPC API

```protobuf
syntax = "proto3";

package api.v1.alpha3;

import "google/api/annotations.proto";

service Suggestion {
    rpc GetSuggestions(GetSuggestionsRequest) returns (GetSuggestionsReply);
}

message GetSuggestionsRequest {
    Experiment experiment = 1;
    repeated Trial trials = 2; // all completed trials owned by the experiment.
    int32 request_number = 3; ///The number of Suggestion you request at one time. When you set 3 to request_number, you can get three Suggestions at one time.
}

message GetSuggestionsReply {
    message ParameterAssignments{
        repeated ParameterAssignment assignments = 1;
    }
    repeated ParameterAssignments parameter_assignments = 1;
    AlgorithmSpec algorithm = 2;
}

message Experiment {
    string name = 1;
    ExperimentSpec experiment_spec = 2;
}

message ExperimentSpec {
   AlgorithmSpec algorithm = 3;
   ParameterSpecs parameter_specs = 1;
   ObjectiveSpec objective = 2;
}

message ParameterSpecs {
    repeated ParameterSpec parameters = 1;
}

message AlgorithmSpec {
    string algorithm_name = 1;
    repeated AlgorithmSetting algorithm_settings = 2;
}

message AlgorithmSetting {
    string name = 1;
    string value = 2;
}

message ParameterSpec {
    string name = 1; /// Name of the parameter.
    ParameterType parameter_type = 2; /// Type of the parameter.
    FeasibleSpace feasible_space = 3; /// FeasibleSpace for the parameter.
}

message FeasibleSpace {
    string max = 1; /// Max Value
    string min = 2; /// Minimum Value
    repeated string list = 3; /// List of Values.
    string step = 4; /// Step for double or int parameter
}

enum ParameterType {
    UNKNOWN_TYPE = 0; /// Undefined type and not used.
    DOUBLE = 1; /// Double float type. Use "Max/Min".
    INT = 2; /// Int type. Use "Max/Min".
    DISCRETE = 3; /// Discrete number type. Use "List" as float.
    CATEGORICAL = 4; /// Categorical type. Use "List" as string.
}

enum ObjectiveType {
    UNKNOWN = 0; /// Undefined type and not used.
    MINIMIZE = 1; /// Minimize
    MAXIMIZE = 2; /// Maximize
}

message ObjectiveSpec {
    ObjectiveType type = 1;
    double goal = 2;
    string objective_metric_name = 3;
}

message Trial {
   string name = 1;
   TrialSpec spec = 2;
   TrialStatus status = 3;
}

message TrialSpec {
   ParameterAssignments parameter_assignments = 2;
   string run_spec = 3;
}

message ParameterAssignments {
    repeated ParameterAssignment assignments = 1;
}

message ParameterAssignment {
    string name = 1;
    string value = 2;
}

message TrialStatus {
   Observation observation = 4; // The best observation in logs.
}

message Observation {
    repeated Metric metrics = 1;
}

message Metric {
    string name = 1;
    string value = 2;
}
```

### Workflow

![](../images/katib-workflow.png)

When the user creates a Experiment, we will create a Suggestion for the Experiment. When the Experiment needs some suggestions, Experiment controller updates the `Suggestions`, then Suggestion controller communicates with the Suggestion to get parameter assignments and set them in Suggestion status.

#### Example

Now the workflow will be illustrated with an example.

```yaml
apiVersion: "kubeflow.org/v1alpha3"
kind: Experiment
metadata:
  namespace: kubeflow
  name: random-experiment
spec:
  parallelTrialCount: 3
  maxTrialCount: 12
  maxFailedTrialCount: 3
  objective:
    type: maximize
    goal: 0.99
    objectiveMetricName: Validation-accuracy
    additionalMetricNames:
      - accuracy
  algorithm:
    algorithmName: random
  trialTemplate:
    goTemplate:
      rawTemplate: |-
        apiVersion: batch/v1
        kind: Job
        metadata:
          name: {{.Trial}}
          namespace: {{.NameSpace}}
        spec:
          template:
            spec:
              containers:
              - name: {{.Trial}}
                image: katib/mxnet-mnist-example
                command:
                - "python"
                - "/mxnet/example/image-classification/train_mnist.py"
                - "--batch-size=64"
                {{- with .HyperParameters}}
                {{- range .}}
                - "{{.Name}}={{.Value}}"
                {{- end}}
                {{- end}}
              restartPolicy: Never
  parameters:
    - name: --lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.03"
    - name: --num-layers
      parameterType: int
      feasibleSpace:
        min: "2"
        max: "5"
    - name: --optimizer
      parameterType: categorical
      feasibleSpace:
        list:
          - sgd
          - adam
          - ftrl
```

Then, Experiment controller needs 3 parallel trials to run. It creates the Suggestions:

```yaml
apiVersion: "kubeflow.org/v1alpha3"
kind: Suggestion
metadata:
  namespace: kubeflow
  name: random-experiment
spec:
  algorithmName: random
  requests: 3
```

After that, Suggestion controller communicates with the Suggestion via GRPC and updates the status:

```yaml
apiVersion: "kubeflow.org/v1alpha3"
kind: Suggestion
metadata:
  namespace: kubeflow
  name: random-experiment
spec:
  algorithmName: random
  requests: 3
status:
  suggestions:
    - assignments:
        - name: --lr
          value: 0.02
        - name: --num-layers
          value: 4
        - name: --optimizer
          value: sgd
    - assignments:
        - name: --lr
          value: 0.021
        - name: --num-layers
          value: 3
        - name: --optimizer
          value: adam
    - assignments:
        - name: --lr
          value: 0.03
        - name: --num-layers
          value: 5
        - name: --optimizer
          value: adam
```

Then Experiment controller creates the trial. When there is one trial finished, Experiment controller will ask Suggestion controller for a new suggestion:

```yaml
apiVersion: "kubeflow.org/v1alpha3"
kind: Suggestion
metadata:
  namespace: kubeflow
  name: random-experiment
spec:
  algorithmName: random
  requests: 4
status:
  suggestions:
    - assignments:
        - name: --lr
          value: 0.02
        - name: --num-layers
          value: 4
        - name: --optimizer
          value: sgd
    - assignments:
        - name: --lr
          value: 0.021
        - name: --num-layers
          value: 3
        - name: --optimizer
          value: adam
    - assignments:
        - name: --lr
          value: 0.03
        - name: --num-layers
          value: 5
        - name: --optimizer
          value: adam
    - assignments:
        - name: --lr
          value: 0.012
        - name: --num-layers
          value: 4
        - name: --optimizer
          value: adam
```

## Algorithm Supports

### Random

We can use the implementation in Katib or [hyperopt](https://github.com/hyperopt/hyperopt).

### Grid

We can use the length of the trials to know which grid we are in. Please refer to the [implementation in advisor](https://github.com/tobegit3hub/advisor/blob/master/advisor_server/suggestion/algorithm/grid_search.py).

Or we can use [chocolate](https://github.com/AIworx-Labs/chocolate).

### Bayes Optimization

We can use [skopt](https://github.com/scikit-optimize/scikit-optimize) to run bayes optimization.

### HyperBand

We can use [HpBandSter](https://github.com/automl/HpBandSter) to run HyperBand.

### BOHB

We can use [HpBandSter](https://github.com/automl/HpBandSter) to run BOHB.

### TPE

We can use [hyperopt](https://github.com/hyperopt/hyperopt) to run TPE.

### SMAC

We can use [SMAC3](https://github.com/automl/SMAC3) to run SMAC.

### CMA-ES

We can use [goptuna](https://github.com/c-bata/goptuna) to run CMA-ES.

### Sobol

We can use [goptuna](https://github.com/c-bata/goptuna) to run Sobol.



================================================
FILE: docs/proposals/685-metrics-collector/README.md
================================================
# KEP-685: Metrics Collector Proposal

- [Metrics Collector Proposal](#metrics-collector-proposal)
  - [Links](#links)
  - [Motivation](#motivation)
  - [Goal](#goal)
  - [API](#api)
    - [Metric Collector](#metric-collector)
  - [Implementation](#implementation)
    - [Mutating Webhook](#mutating-webhook)
    - [Metric Collector](#metric-collector-1)
    - [Collection of Final Metrics](#collection-of-final-metrics)

## Links

- [katib/issues#685 (Katib metrics collector solution)](https://github.com/kubeflow/katib/issues/685)
- [katib/pull#697 (API for metricCollector)](https://github.com/kubeflow/katib/pull/697#issuecomment-516264282)
- [katib/pull#716 (Add pod level inject webhook)](https://github.com/kubeflow/katib/pull/716)
- [katib/pull#729 (Inject pod sidecar for specified namespace)](https://github.com/kubeflow/katib/pull/729)
- [katib/pull#730 (fix: Add build for sidecar)](https://github.com/kubeflow/katib/pull/730)

## Motivation

[Katib](https://github.com/kubeflow/katib) is a hyperparameter tuning (HPT) and neural architecture search (NAS) system based on Kubernetes.
During the auto-training, the metrics collection is an essential step.
In the current design, the metrics collector is pulled-based.
Katib runs a metrics collector cron job for each Trial.
The cron job pulls the targeted pod logs periodically and then persist the logs into MySQL.
However, the pulled-based design has [some problems](https://github.com/kubeflow/tf-operator/issues/722#issuecomment-405669269), such as, at what frequency should we scrape the metrics and so on.

To enhance the extensibility and support EarlyStopping, we propose a new design of the metrics collector.
In the new design, Katib use mutating webhook to inject metrics collector container as a sidecar into Job/Tfjob/PytorchJob pod.
The sidecar collects metrics of the master and then store them on the persistent layer (e.x. katib-db-manager and metadata server).

<center>
<img src="./metrics-collector-design.png" width="80%">

Fig. 1 Architecture of the new design

</center>

## Goal

1. **A mutating webhook**: inject metrics collector as a sidecar into master pod.
2. **A metric collector**: collect metrics and store them on the persistent layer (katib-db-manager).
3. **The final metrics** of worker pods should be collected by trail controller and then be stored into trial status.

## API

### Metric Collector

For more detail, see [here](https://github.com/kubeflow/katib/pull/697#issuecomment-516264282).

    type MetricsCollectorSpec struct {
        Retain     bool       `json:"retain,omitempty"`
        // Deprecated Retain
        Retain bool `json:"retain,omitempty"`
        // Deprecated GoTemplate
        GoTemplate GoTemplate `json:"goTemplate,omitempty"`

        Source    *SourceSpec    `json:"source,omitempty"`
        Collector *CollectorSpec `json:"collector,omitempty"`
    }

    type SourceSpec struct {
        // Model-train source code can expose metrics by http, such as HTTP endpoint in
        // prometheus metric format
        HttpGet *v1.HTTPGetAction `json:"httpGet,omitempty"`
        // During training model, metrics may be persisted into local file in source
        // code, such as tfEvent use case
        FileSystemPath *FileSystemPath `json:"fileSystemPath,omitempty"`
        // Default metric output format is {"metric": "<metric_name>",
        // "value": <int_or_float>, "epoch": <int>, "step": <int>}, but if the output doesn't
        // follow default format, please extend it here
        Filter *FilterSpec `json:"filter,omitempty"`
        }

    type FilterSpec struct {
        // When the metrics output follows format as this field specified, metricsCollector
        // collects it and reports to metrics server, it can be "<metric_name>: <float>" or else
        MetricsFormat []string `json:"metricsFormat,omitempty"`
    }

    type FileSystemKind string

    const (
        DirectoryKind FileSystemKind = "diretory"
        FileKind      FileSystemKind = "file"
    )

    type FileSystemPath struct {
        Path string         `json:"path,omitempty"`
        Kind FileSystemKind `json:"kind,omitempty"`
    }

    type CollectorKind string

    const (
        StdOutCollector           CollectorKind = "stdOutCollector"
        FileCollector             CollectorKind = "fileCollector"
        TfEventCollector          CollectorKind = "tfEventCollector"
        PrometheusMetricCollector CollectorKind = "prometheusMetricCollector"
        CustomCollector           CollectorKind = "customCollector"
        // When model training source code persists metrics into persistent layer
        // directly, metricsCollector isn't in need, and its kind is "noneCollector"
        NoneCollector CollectorKind = "noneCollector"
    )

    type CollectorSpec struct {
        Kind CollectorKind `json:"kind"`
        // When kind is "customCollector", this field will be used
        CustomCollector *v1.Container `json:"customCollector,omitempty"`
    }

## Implementation

### Mutating Webhook

To avoid collecting duplicated metrics, as we discuss in [kubeflow/katib#685](https://github.com/kubeflow/katib/issues/685), only one metrics collector sidecar will be injected into the master pod during one Experiment.
In the new design, there are two modes for Katib mutating webhook to inject the sidecar: **Pod Level Injecting** and **Job Level Injecting**.
The webhook decides which mode to be used based on the `katib.kubeflow.org/metrics-collector-injection=enabled` label tagged on the namespace.
In the namespace with `katib.kubeflow.org/metrics-collector-injection=enabled` label, the webhook inject the sidecar in the pod level. Otherwise, without this label, injecting in the job level.

In **Pod Level Injecting**,

1. Job operators (_e.x. TFjob/PyTorchjob_) tag the `training.kubeflow.org/job-role: master` ([#1064](https://github.com/kubeflow/tf-operator/pull/1064)) label on the master pod.
2. The webhook inject the metric collector only if the webhook recognizes this label.
3. The webhook uses [ObjectSelector](https://github.com/kubernetes/kubernetes/pull/78505) to skip on irrelevant objects in order to optimize the performance.
4. ObjectSelector is only supported above _Kubernetes v1.15_. Without this new feature, there may be a [performance issue](https://github.com/kubeflow/katib/issues/685#issuecomment-516226070) in webhook. In this situation, the following **Job Level Injecting** mode may be a better option.

In **Job Level Injecting**,

1. The webhook use different strategies to inject sidecar according to different job operators. For now, the webhook support PytorchJob and TfJob.
2. For PytorchJob, the metrics collector sidecar is injected into master template.
3. For TfJob, the metrics collector sidecar is injected into master template if master exists. Otherwise, the sidecar is injected into worker template with 0 index.

After injecting, the sidecar collects metrics of the master and then store them on the persistent layer (e.x. katib-db-manager and metadata server).

### Metric Collector

In [katib/pull#716](https://github.com/kubeflow/katib/pull/716), we implement a mutating webhook and a new [sidecarmetricscollector](https://github.com/kubeflow/katib/pull/716/files?file-filters%5B%5D=.go#diff-94d1b936fc88df26ddebf78ccc45805d) which differ from the original metrics collector.
The mutating webhook inject a sidecar metrics collector into every master pod.

While running as a sidecar, the collector container needs to keep running to make sure the master pod does training normally.
Otherwise, if the sidecar container is completed or error before the master container finishes, this master pod with sidecar will be invisible to other worker pods.
Therefore, in the implementation, the sidecar collector collects the logs from the Kubernetes client in the `Follow` mode and keep on retrying while error encountered.

### Collection of Final Metrics

The final metrics of worker pods should be collected by trail controller and then be stored into trial status.

_#WIP_



================================================
FILE: docs/release/README.md
================================================
# Release the Katib Project

This is the instruction on how to make a new release for the Katib project.

## Prerequisite

- Tools, defined in the [Contributing Guide](./../../CONTRIBUTING.md#requirements).

- [Write](https://docs.github.com/en/organizations/managing-access-to-your-organizations-repositories/repository-permission-levels-for-an-organization#permission-levels-for-repositories-owned-by-an-organization)
  permission for the Katib repository.

- Maintainer access to the [Katib SDK](https://pypi.org/project/kubeflow-katib/).

- Owner access to the [Katib Dockerhub](https://hub.docker.com/u/kubeflowkatib).

- Create a [GitHub Token](https://docs.github.com/en/github/authenticating-to-github/keeping-your-account-and-data-secure/creating-a-personal-access-token).

- Install `PyGithub` to generate the [Changelog](./../../CHANGELOG.md): `pip install PyGithub==1.55`

- Install `twine` to publish the SDK package: `pip install twine==3.4.1`

  - Create a [PyPI Token](https://pypi.org/help/#apitoken) to publish Katib SDK.

  - Add the following config to your `~/.pypirc` file:

    ```
    [pypi]
       username = __token__
       password = <PYPI_TOKEN>
    ```

## Release Process

### Versioning Policy

Katib version format follows [Semantic Versioning](https://semver.org/).
Katib versions are in the format of `vX.Y.Z`, where `X` is the major version, `Y` is
the minor version, and `Z` is the patch version.
The patch version contains only bug fixes.

Additionally, Katib does pre-releases in this format: `vX.Y.Z-rc.N` where `N` is a number
of the `Nth` release candidate (RC) before an upcoming public release named `vX.Y.Z`.

### Release Branches and Tags

Katib releases are tagged with tags like `vX.Y.Z`, for example `v0.11.0`.

Release branches are in the format of `release-X.Y`, where `X.Y` stands for
the minor release.

`vX.Y.Z` releases are released from the `release-X.Y` branch. For example,
`v0.11.1` release should be on `release-0.11` branch.

If you want to push changes to the `release-X.Y` release branch, you have to
cherry pick your changes from the `master` branch and submit a PR.

### Versions for Katib Components

Katib release ([git tag](https://git-scm.com/book/en/v2/Git-Basics-Tagging))
includes releases for the following components:

- Manifest images with tags equal to the release
  (e.g [`v0.11.1`](https://github.com/kubeflow/katib/blob/v0.11.1/manifests/v1beta1/installs/katib-standalone/kustomization.yaml#L21-L33)).

- Katib Python SDK where version is in this format: `X.Y.Z` or `X.Y.ZrcN`
  (e.g [`0.11.1`](https://github.com/kubeflow/katib/blob/v0.11.1/sdk/python/v1beta1/setup.py#L22)).

### Create a new Katib Release

Follow these steps to cut a new Katib release:

1. Clone Katib repository under `$GOPATH/src` directory:

   ```
   git clone git@github.com:kubeflow/katib.git $GOPATH/src/github.com/kubeflow/katib
   ```

1. Make sure that you can build all Katib images. **Note** that
   your Docker Desktop should
   [enable containerd image store](https://docs.docker.com/desktop/containerd/#enable-the-containerd-image-store)
   to build multi-arch images:

   ```
   make build REGISTRY=private-registry TAG=latest
   ```

1. Create the new release:

   ```
   make release BRANCH=release-X.Y TAG=vX.Y.Z
   ```

   The above script is doing the following:

   - Create the new branch: `release-X.Y`, if it doesn't exist.

   - Create the new tag: `vX.Y.Z` from the release branch: `release-X.Y`.

   - Publish Katib images with the tag: `vX.Y.Z` and update manifests.

   - Publish Katib Python SDK with the version: `X.Y.Z`.

   - Push above changes to the Katib upstream `release-X.Y` branch with this commit:
     `Katib official release vX.Y.Z`

1. Submit a PR to update the SDK version on the `master` branch to the latest release.
   (e.g. [`#1640`](https://github.com/kubeflow/katib/pull/1640)).

1. Update the Changelog by running:

   ```
   python docs/release/changelog.py --token=<github-token> --range=<previous-release>..<current-release>
   ```

   If you are creating the **first minor pre-release** or the **minor** release (`X.Y`), your
   `previous-release` is equal to the latest release on the `release-X.Y-1` branch.
   For example: `--range=v0.11.1..v0.12.0`

   Otherwise, your `previous-release` is equal to the latest release on the `release-X.Y` branch.
   For example: `--range=v0.12.0-rc.0..v0.12.0-rc.1`

   Group PRs in the Changelog into Features, Bug fixes, Documentation, etc.
   Check this example: [v0.11.0](https://github.com/kubeflow/katib/releases/tag/v0.11.0)

   Finally, submit a PR with the updated Changelog.

1. If it is not a pre-release, draft [a new GitHub Release](https://github.com/kubeflow/katib/releases/new).



================================================
FILE: docs/release/changelog.py
================================================
import argparse

from github import Github

REPO_NAME = "kubeflow/katib"
CHANGELOG_FILE = "CHANGELOG.md"

parser = argparse.ArgumentParser()
parser.add_argument("--token", type=str, help="GitHub Access Token")
parser.add_argument(
    "--range", type=str, help="Changelog is generated for this release range"
)
args = parser.parse_args()

if args.token is None:
    raise Exception("GitHub Token must be set")
try:
    previous_release = args.range.split("..")[0]
    current_release = args.range.split("..")[1]
except Exception:
    raise Exception("Release range must be set in this format: v0.11.0..v0.12.0")

# Get list of commits from the range.
github_repo = Github(args.token).get_repo(REPO_NAME)
comparison = github_repo.compare(previous_release, current_release)
commits = comparison.commits

# The latest commit contains the release date.
release_date = str(commits[-1].commit.author.date).split(" ")[0]
release_url = "https://github.com/{}/tree/{}".format(REPO_NAME, current_release)

# Get all PRs in reverse chronological order from the commits.
pr_list = ""
pr_set = set()
for commit in reversed(commits):
    # Only add commits with PRs.
    for pr in commit.get_pulls():
        # Each PR is added only one time to the list.
        if pr.number in pr_set:
            continue
        pr_set.add(pr.number)

        new_pr = "- {title} ([#{id}]({pr_link}) by [@{user_id}]({user_url}))\n".format(
            title=pr.title,
            id=pr.number,
            pr_link=pr.html_url,
            user_id=pr.user.login,
            user_url=pr.user.html_url,
        )
        pr_list += new_pr

change_log = [
    "# Changelog" "\n\n",
    "# [{}]({}) ({})".format(current_release, release_url, release_date),
    "\n\n",
    "## TODO: Group PRs into Breaking Changes, New Features, Bug fixes, Documentation, etc. "
    + "For example: [v0.11.0](https://github.com/kubeflow/katib/releases/tag/v0.11.0)",
    "\n\n",
    pr_list,
    "\n" "[Full Changelog]({})\n".format(comparison.html_url),
]

# Update Changelog with the new changes.
with open(CHANGELOG_FILE, "r+") as f:
    lines = f.readlines()
    f.seek(0)
    lines = lines[0:0] + change_log + lines[1:]
    f.writelines(lines)

print("Changelog has been updated\n")
print("Group PRs in the Changelog into Features, Bug fixes, Documentation, etc.\n")
print("After that, submit a PR with the updated Changelog")



================================================
FILE: examples/v1beta1/README.md
================================================
# Katib Examples

Katib is an open source project which uses Kubernetes CRD to run Automated
Machine Learning (AutoML) tasks. To know more about Katib follow the
[official guides](https://www.kubeflow.org/docs/components/katib/overview/).

This directory contains examples of Katib Experiments in action. To install Katib on your
Kubernetes cluster check the
[setup guide](https://www.kubeflow.org/docs/components/katib/hyperparameter/#katib-setup).
You can use various [Katib interfaces](https://www.kubeflow.org/docs/components/katib/overview/#katib-interfaces)
to run these examples.

For a complete description of the Katib Experiment specification follow the
[configuration guide](https://www.kubeflow.org/docs/components/katib/experiment/#configuration-spec)

## Local Cluster Example

Get started with Katib Experiments from your **local laptop** and
[Kind](https://github.com/kubernetes-sigs/kind/) cluster by following
[this example](./kind-cluster).

## AutoML Algorithms

The following examples show various AutoML algorithms in Katib.

### Hyperparameter Tuning

Check the [Hyperparameter Tuning](https://www.kubeflow.org/docs/components/katib/overview/#hyperparameters-and-hyperparameter-tuning)
Experiments for the following algorithms:

- [Random Search](./hp-tuning/random.yaml)

- [Grid Search](./hp-tuning/grid.yaml)

- [Bayesian Optimization](./hp-tuning/bayesian-optimization.yaml)

- [Tree of Parzen Estimators (TPE)](./hp-tuning/tpe.yaml)

- [Multivariate TPE](./hp-tuning/multivariate-tpe.yaml)

- [Covariance Matrix Adaptation Evaluation Strategy (CMA-ES)](./hp-tuning/cma-es.yaml)

- [Sobol's Quasirandom Sequence](./hp-tuning/sobol.yaml)

- [HyperBand](./hp-tuning/hyperband.yaml)

- [PBT](./hp-tuning/simple-pbt.yaml)

### Neural Architecture Search

Check the [Neural Architecture Search](https://www.kubeflow.org/docs/components/katib/overview/#neural-architecture-search)
Experiments for the following algorithms:

- [Efficient Neural Architecture Search (ENAS)](./nas/enas-gpu.yaml)

- [Differentiable Architecture Search (DARTS)](./nas/darts-gpu.yaml)

### Early Stopping

Improve your Hyperparameter Tuning Experiments with the following
[Early Stopping](https://www.kubeflow.org/docs/components/katib/early-stopping/) algorithms:

- [Median Stopping Rule](./early-stopping/median-stop.yaml)

## Katib Python SDK Examples

To learn more about Katib Python SDK check [this directory](./sdk).

## Resume Katib Experiments

You can use different resume policies in Katib Experiments. Follow
[this guide](https://www.kubeflow.org/docs/components/katib/resume-experiment/)
to know more about it. Check the following examples:

- [Resume From Volume](./resume-experiment/from-volume-resume.yaml)

- [Resume Long Running Experiment](./resume-experiment/long-running-resume.yaml)

## Metrics Collector

Katib supports the various metrics collectors and metrics strategies.
Check the [official guide](https://www.kubeflow.org/docs/components/katib/experiment/#configuration-spec)
to know more about it. In this directory you can find the following examples:

- [File Metrics Collector](./metrics-collector/file-metrics-collector.yaml)

- [Custom Metrics Collector](./metrics-collector/custom-metrics-collector.yaml)

- [Metrics Collection Strategy](./metrics-collector/metrics-collection-strategy.yaml)

## Trial Template

You can specify different settings for your Trial template. To know more about it
follow [this guide](https://www.kubeflow.org/docs/components/katib/trial-template/#use-trial-template-to-submit-experiment).
Check the following examples:

- [Trial with ConfigMap Source](./trial-template/trial-configmap-source.yaml)

- [Trial with Metadata Substitution](./trial-template/trial-metadata-substitution.yaml)

## Trial Images

Check the following images for the Trial containers:

- [Tensorflow MNIST with summaries](./trial-images/tf-mnist-with-summaries)

- [PyTorch MNIST](./trial-images/pytorch-mnist)

- [ENAS Keras CNN CIFAR-10](./trial-images/enas-cnn-cifar10)

- [DARTS PyTorch CNN CIFAR-10](./trial-images/darts-cnn-cifar10)

- [PBT proof of concept](./trial-images/simple-pbt)

## Katib with Kubeflow Training Operator

Katib has out of the box support for the [Kubeflow Training Operators](https://github.com/kubeflow/training-operator) to
perform Trial's [Worker job](https://www.kubeflow.org/docs/components/katib/overview/#trial).
Check the following examples for the various distributed operators:

- [TFJob MNIST with summaries](./kubeflow-training-operator/tfjob-mnist-with-summaries.yaml)

- [PyTorchJob MNIST](./kubeflow-training-operator/pytorchjob-mnist.yaml)

- [XGBoostJob LightGBM](./kubeflow-training-operator/xgboostjob-lightgbm.yaml)

- [MPIJob Horovod](./kubeflow-training-operator/mpijob-horovod.yaml)

## Katib with Kubeflow Pipelines

To run Katib with [Kubeflow Pipelines](https://github.com/kubeflow/pipelines) check
[these examples](./kubeflow-pipelines).

## Katib with Argo Workflows

To know more about using [Argo Workflows](https://github.com/argoproj/argo-workflows)
in Katib check [this directory](./argo).

## Katib with Tekton Pipelines

To know more about using [Tekton Pipelines](https://github.com/tektoncd/pipeline)
in Katib check [this directory](./tekton).

## FPGA Support in Katib Experiments

You can run Katib Experiments on [FPGA](https://en.wikipedia.org/wiki/Field-programmable_gate_array)
based instances. For more information check [these examples](./fpga).



================================================
FILE: examples/v1beta1/argo/README.md
================================================
# Katib Examples with Argo Workflows Integration

Here you can find examples of using Katib with [Argo Workflows](https://github.com/argoproj/argo-workflows).

**Note:** You have to install `Argo Workflows >= v3.1.3` to use it in Katib Experiments.

## Installation

### Argo Workflow

To deploy Argo Workflows `v3.1.3`, run the following commands:

```bash
kubectl create namespace argo
kubectl apply -n argo -f https://github.com/argoproj/argo-workflows/releases/download/v3.1.3/install.yaml
```

Check that Argo Workflow components are running:

```bash
$ kubectl get pods -n argo

NAME                                  READY   STATUS    RESTARTS   AGE
argo-server-5bbd69cc6b-6nvb6          1/1     Running   0          20s
workflow-controller-5f48fb7c8-vw9bp   1/1     Running   0          20s
```

After that, run below command to enable
[Katib Metrics Collector sidecar injection](https://www.kubeflow.org/docs/components/katib/experiment/#metrics-collector):

```bash
kubectl patch namespace argo -p '{"metadata":{"labels":{"katib.kubeflow.org/metrics-collector-injection":"enabled"}}}'
```

**Note:** Argo Workflows are using `docker` as a
[default container runtime executor](https://argoproj.github.io/argo-workflows/workflow-executors/#workflow-executors).
Since Katib is using Metrics Collector sidecar container and Argo Workflows controller
should not kill sidecar containers, you have to modify this
executor to [`emissary`](https://argoproj.github.io/argo-workflows/workflow-executors/#emissary-emissary).

Run the following command to change the `containerRuntimeExecutor` to `emissary` in the
Argo `workflow-controller-configmap`

```bash
kubectl patch ConfigMap -n argo workflow-controller-configmap --type='merge' -p='{"data":{"containerRuntimeExecutor":"emissary"}}'
```

Verify that `containerRuntimeExecutor` has been modified:

```bash
$ kubectl get ConfigMap -n argo workflow-controller-configmap -o yaml | grep containerRuntimeExecutor

  containerRuntimeExecutor: emissary
```

### Katib Controller

To run Argo Workflow within Katib Trials you have to update Katib
[ClusterRole's rules](https://github.com/kubeflow/katib/blob/master/manifests/v1beta1/components/controller/rbac.yaml#L5)
with the appropriate permission:

```yaml
- apiGroups:
    - argoproj.io
  resources:
    - workflows
  verbs:
    - "get"
    - "list"
    - "watch"
    - "create"
    - "delete"
```

Run the following command to update Katib ClusterRole:

```bash
kubectl patch ClusterRole katib-controller -n kubeflow --type=json \
  -p='[{"op": "add", "path": "/rules/-", "value": {"apiGroups":["argoproj.io"],"resources":["workflows"],"verbs":["get", "list", "watch", "create", "delete"]}}]'
```

Run the following command to update [Katib config](https://www.kubeflow.org/docs/components/katib/user-guides/katib-config/#katib-controller-parameters):

```bash
kubectl edit configMap katib-config -n kubeflow
```

For example, to support Workflow Pipelines, add `Workflow.v1alpha1.argoproj.io` in `trialResources`:

```bash
trialResources:
  - Workflow.v1alpha1.argoproj.io
```

After that, you need to restart the Katib controller Pod:

```bash
kubectl delete pod -n kubeflow -l katib.kubeflow.org/component=controller
```

Check that Katib Controller's pod was restarted:

```bash
$ kubectl get pods -n kubeflow

NAME                                         READY   STATUS      RESTARTS   AGE
katib-controller-784994d449-9bgj9            1/1     Running     0          28s
katib-db-manager-78697c7bd4-ck7l8            1/1     Running     0          6m13s
katib-mysql-854cdb87c4-krcm9                 1/1     Running     0          6m13s
katib-ui-57b9d7f6dd-cv6gn                    1/1     Running     0          6m13s
```

Check logs from Katib Controller to verify Argo Workflow integration:

```bash
$ kubectl logs $(kubectl get pods -n kubeflow -o name | grep katib-controller) -n kubeflow | grep '"CRD Kind":"Workflow"'

{"level":"info","ts":"2024-07-13T10:02:10Z","logger":"trial-controller","msg":"Job watch added successfully","CRD Group":"argoproj.io","CRD Version":"v1alpha1","CRD Kind":"Workflow"}
```

If you ran the above steps successfully, you should be able to run Argo Workflow examples.

Learn more about using custom Kubernetes resource as a Trial template in the
[official Kubeflow guides](https://www.kubeflow.org/docs/components/katib/trial-template/#use-custom-kubernetes-resource-as-a-trial-template).



================================================
FILE: examples/v1beta1/argo/argo-workflow.yaml
================================================
---
# This example shows how you can use Argo Workflows in Katib, transfer parameters from one Step to another and run HP job.
# It uses a simple random algorithm and tunes only learning rate.
# Workflow contains 2 Steps, first is data-preprocessing second is model-training.
# First Step shows how you can prepare your training data (here: simply divide number of training examples) before running HP job.
# Number of training examples is transferred to the second Step.
# Second Step is the actual training which metrics collector sidecar is injected.
# Note that for this example Argo Container Runtime Executor must be "emissary".
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: argo
  name: katib-argo-workflow
spec:
  objective:
    type: minimize
    goal: 0.001
    objectiveMetricName: loss
  algorithm:
    algorithmName: random
  parallelTrialCount: 2
  maxTrialCount: 5
  maxFailedTrialCount: 1
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.03"
  trialTemplate:
    retain: true
    primaryPodLabels:
      katib.kubeflow.org/model-training: "true"
    primaryContainerName: main
    successCondition: status.[@this].#(phase=="Succeeded")#
    failureCondition: status.[@this].#(phase=="Failed")#
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
    trialSpec:
      apiVersion: argoproj.io/v1alpha1
      kind: Workflow
      spec:
        serviceAccountName: argo
        entrypoint: hp-workflow
        templates:
          - name: hp-workflow
            steps:
              - - name: data-preprocessing
                  template: gen-epochs
              - - name: model-training
                  template: model-training
                  arguments:
                    parameters:
                      - name: epochs
                        value: "{{steps.data-preprocessing.outputs.result}}"

          - name: gen-epochs
            script:
              image: python:alpine3.6
              command:
                - python
              source: |
                import random
                print(60000//random.randint(3000, 30000))

          - name: model-training
            metadata:
              labels:
                katib.kubeflow.org/model-training: "true"
            inputs:
              parameters:
                - name: epochs
            container:
              name: model-training
              image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
              command:
                - "python3"
                - "/opt/pytorch-mnist/mnist.py"
                - "--lr=${trialParameters.learningRate}"
                - "--epochs={{inputs.parameters.epochs}}"
                - "--batch-size=16"



================================================
FILE: examples/v1beta1/early-stopping/median-stop-with-json-format.yaml
================================================
---
# This is example with median stopping early stopping rule with logs in JSON format.
# It has bad feasible space for learning rate to show more early stopped Trials.
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: median-stop-with-json-format
spec:
  objective:
    type: maximize
    goal: 0.99
    objectiveMetricName: accuracy
    additionalMetricNames:
      - loss
  metricsCollectorSpec:
    source:
      fileSystemPath:
        path: "/katib/mnist.json"
        kind: File
        format: JSON
    collector:
      kind: File
  algorithm:
    algorithmName: random
  earlyStopping:
    algorithmName: medianstop
    algorithmSettings:
      - name: min_trials_required
        value: "1"
      - name: start_step
        value: "2"
  parallelTrialCount: 2
  maxTrialCount: 15
  maxFailedTrialCount: 3
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.5"
    - name: num-epochs
      parameterType: int
      feasibleSpace:
        min: "3"
        max: "4"
  trialTemplate:
    retain: true
    primaryContainerName: training-container
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: numberEpochs
        description: Number of epochs to train the model
        reference: num-epochs
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
                command:
                  - "python3"
                  - "/opt/pytorch-mnist/mnist.py"
                  - "--epochs=${trialParameters.numberEpochs}"
                  - "--log-path=/katib/mnist.json"
                  - "--lr=${trialParameters.learningRate}"
                  - "--logger=hypertune"
            restartPolicy: Never



================================================
FILE: examples/v1beta1/early-stopping/median-stop.yaml
================================================
---
# This is example with median stopping early stopping rule.
# It has bad feasible space for learning rate to show more early stopped Trials.
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: median-stop
spec:
  objective:
    type: minimize
    goal: 0.001
    objectiveMetricName: loss
  algorithm:
    algorithmName: random
  earlyStopping:
    algorithmName: medianstop
    algorithmSettings:
      - name: min_trials_required
        value: "1"
      - name: start_step
        value: "2"
  parallelTrialCount: 2
  maxTrialCount: 15
  maxFailedTrialCount: 3
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.05"
    - name: momentum
      parameterType: double
      feasibleSpace:
        min: "0.5"
        max: "0.9"
  trialTemplate:
    retain: true
    primaryContainerName: training-container
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: momentum
        description: Momentum for the training model
        reference: momentum
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
                command:
                  - "python3"
                  - "/opt/pytorch-mnist/mnist.py"
                  - "--epochs=1"
                  - "--batch-size=16"
                  - "--lr=${trialParameters.learningRate}"
                  - "--momentum=${trialParameters.momentum}"
            restartPolicy: Never



================================================
FILE: examples/v1beta1/fpga/README.md
================================================
# FPGA support for your Katib Experiments

Let's spawn [F1 instances](https://aws.amazon.com/ec2/instance-types/f1) and
accelerate time-consuming Katib experiments on AWS, with zero FPGA knowledge!

If you want to read more about provisioning FPGA resources and deploying
accelerated applications (e.g. Kubeflow Pipelines) on any Kubernetes cluster,
visit the [InAccel](https://docs.inaccel.com) documentation.

## Simplifying FPGA management in EKS\* (Elastic Kubernetes Service)

\*_For development and testing purposes you can still [deploy Kubeflow Katib
using MicroK8s](https://ubuntu.com/tutorials/accelerated-ml-experiments-on-microk8s-with-inaccel-fpga-operator-and-kubeflow-katib)
in a single AMI instance. In production environments, Amazon's managed
Kubernetes service ([EKS](https://aws.amazon.com/eks)) is recommended._

The InAccel FPGA Operator allows administrators of Kubernetes clusters to manage
FPGA nodes just like CPU nodes in the cluster. Instead of provisioning a special
OS image for FPGA nodes, administrators can rely on a standard OS image for both
CPU and FPGA nodes and then rely on the FPGA Operator to provision the required
software components for FPGAs.

Note that the FPGA Operator is specifically useful for scenarios where the
Kubernetes cluster needs to scale quickly - for example provisioning additional
FPGA nodes on the cloud and managing the lifecycle of the underlying software
components.

## Enabling FPGA based workloads

The following section describes how to run a workload on an FPGA based instance
with the InAccel FPGA Operator.

After your FPGA worker nodes join your cluster, you must apply the [InAccel FPGA
Operator](https://artifacthub.io/packages/helm/inaccel/fpga-operator) for
Kubernetes, as a Helm app on your cluster, with the following command.

```sh
helm repo add inaccel https://setup.inaccel.com/helm

helm install -n kube-system inaccel inaccel/fpga-operator
```

You can verify that your nodes have available FPGAs with the following command:

```sh
kubectl get nodes -o custom-columns=NAME:metadata.name,FPGAS:.status.capacity.xilinx/aws-vu9p-f1,SHELL:.metadata.labels.xilinx/aws-vu9p-f1
```

## Experiment

You can submit a new accelerated Experiment and check your Experiment results
using the Web UI, as usual.

#### XGBoost Parameter Tuning [[source](https://github.com/inaccel/jupyter/blob/master/lab/dot/XGBoost/parameter-tuning.py)]

```sh
kubectl apply -f xgboost-example.yaml
```



================================================
FILE: examples/v1beta1/fpga/OWNERS
================================================
approvers:
  - eliaskoromilas
  - jstamel



================================================
FILE: examples/v1beta1/fpga/xgboost-example.yaml
================================================
---
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  name: xgb-svhn-fpga
  namespace: kubeflow
spec:
  algorithm:
    algorithmName: random
  maxFailedTrialCount: 3
  maxTrialCount: 10
  objective:
    additionalMetricNames:
      - time
    goal: 0.99
    objectiveMetricName: accuracy
    type: maximize
  parallelTrialCount: 1
  parameters:
    - feasibleSpace:
        min: "0.00"
        max: "0.05"
      name: alpha
      parameterType: double
    - feasibleSpace:
        min: "0.1"
        max: "0.4"
      name: eta
      parameterType: double
    - feasibleSpace:
        min: "0.6"
        max: "1.0"
      name: subsample
      parameterType: double
  trialTemplate:
    primaryContainerName: training-container
    trialParameters:
      - name: alpha
        description: L1 regularization term on weights
        reference: alpha
      - name: eta
        description: Step size shrinkage used in update to prevent overfitting
        reference: eta
      - name: subsample
        description: Subsample ratio of the training instances
        reference: subsample
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          metadata:
            labels:
              inaccel/fpga: enabled
            annotations:
              inaccel/cli: |
                bitstream install --mode others https://store.inaccel.com/artifactory/bitstreams/xilinx/aws-vu9p-f1/dynamic-shell/aws/com/inaccel/xgboost/0.1/2exact
          spec:
            containers:
              - name: training-container
                image: "docker.io/inaccel/jupyter:lab"
                command:
                  - python3
                  - XGBoost/parameter-tuning.py
                args:
                  - "--name=SVHN"
                  - "--test-size=0.35"
                  - "--tree-method=fpga_exact"
                  - "--max-depth=10"
                  - "--alpha=${trialParameters.alpha}"
                  - "--eta=${trialParameters.eta}"
                  - "--subsample=${trialParameters.subsample}"
                resources:
                  limits:
                    xilinx/aws-vu9p-f1: 1
            restartPolicy: Never



================================================
FILE: examples/v1beta1/hp-tuning/bayesian-optimization.yaml
================================================
---
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: bayesian-optimization
spec:
  objective:
    type: minimize
    goal: 0.001
    objectiveMetricName: loss
  algorithm:
    algorithmName: bayesianoptimization
    algorithmSettings:
      - name: "random_state"
        value: "10"
  parallelTrialCount: 3
  maxTrialCount: 12
  maxFailedTrialCount: 3
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.05"
    - name: momentum
      parameterType: double
      feasibleSpace:
        min: "0.5"
        max: "0.9"
  trialTemplate:
    primaryContainerName: training-container
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: momentum
        description: Momentum for the training model
        reference: momentum
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
                command:
                  - "python3"
                  - "/opt/pytorch-mnist/mnist.py"
                  - "--epochs=1"
                  - "--batch-size=16"
                  - "--lr=${trialParameters.learningRate}"
                  - "--momentum=${trialParameters.momentum}"
            restartPolicy: Never



================================================
FILE: examples/v1beta1/hp-tuning/cma-es.yaml
================================================
---
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: cmaes
spec:
  objective:
    type: minimize
    goal: 0.001
    objectiveMetricName: loss
  algorithm:
    algorithmName: cmaes
    algorithmSettings:
      - name: "restart_strategy"
        value: "ipop"
  parallelTrialCount: 3
  maxTrialCount: 12
  maxFailedTrialCount: 3
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.05"
    - name: momentum
      parameterType: double
      feasibleSpace:
        min: "0.5"
        max: "0.9"
  trialTemplate:
    primaryContainerName: training-container
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: momentum
        description: Momentum for the training model
        reference: momentum
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
                command:
                  - "python3"
                  - "/opt/pytorch-mnist/mnist.py"
                  - "--epochs=1"
                  - "--batch-size=16"
                  - "--lr=${trialParameters.learningRate}"
                  - "--momentum=${trialParameters.momentum}"
            restartPolicy: Never



================================================
FILE: examples/v1beta1/hp-tuning/grid.yaml
================================================
---
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: grid
spec:
  objective:
    type: minimize
    goal: 0.001
    objectiveMetricName: loss
  algorithm:
    algorithmName: grid
  parallelTrialCount: 3
  maxTrialCount: 12
  maxFailedTrialCount: 3
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        step: "0.005"
        max: "0.05"
    - name: momentum
      parameterType: double
      feasibleSpace:
        min: "0.5"
        step: "0.1"
        max: "0.9"
  trialTemplate:
    primaryContainerName: training-container
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: momentum
        description: Momentum for the training model
        reference: momentum
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
                command:
                  - "python3"
                  - "/opt/pytorch-mnist/mnist.py"
                  - "--epochs=1"
                  - "--batch-size=16"
                  - "--lr=${trialParameters.learningRate}"
                  - "--momentum=${trialParameters.momentum}"
            restartPolicy: Never



================================================
FILE: examples/v1beta1/hp-tuning/hyperband.yaml
================================================
---
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: hyperband
spec:
  parallelTrialCount: 2
  maxTrialCount: 2
  objective:
    type: minimize
    goal: 0.001
    objectiveMetricName: loss
  algorithm:
    algorithmName: hyperband
    algorithmSettings:
      - name: "resource_name"
        value: "num-epochs"
      - name: "eta"
        value: "2"
      - name: "r_l"
        value: "2"
  maxFailedTrialCount: 2
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.05"
    - name: momentum
      parameterType: double
      feasibleSpace:
        min: "0.5"
        max: "0.9"
    - name: num-epochs
      parameterType: int
      feasibleSpace:
        min: "1"
        max: "1"
  trialTemplate:
    primaryContainerName: training-container
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: momentum
        description: Momentum for the training model
        reference: momentum
      - name: numberEpochs
        description: Number of epochs to train the model
        reference: num-epochs
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
                command:
                  - "python3"
                  - "/opt/pytorch-mnist/mnist.py"
                  - "--epochs=${trialParameters.numberEpochs}"
                  - "--batch-size=16"
                  - "--lr=${trialParameters.learningRate}"
                  - "--momentum=${trialParameters.momentum}"
            restartPolicy: Never



================================================
FILE: examples/v1beta1/hp-tuning/hyperopt-distribution.yaml
================================================
---
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: hyperopt-distribution
spec:
  objective:
    type: minimize
    goal: 0.05
    objectiveMetricName: loss
  algorithm:
    algorithmName: random
  parallelTrialCount: 3
  maxTrialCount: 12
  maxFailedTrialCount: 3
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.05"
        step: "0.01"
        distribution: normal
    - name: momentum
      parameterType: double
      feasibleSpace:
        min: "0.001"
        max: "1"
        distribution: uniform
    - name: epochs
      parameterType: int
      feasibleSpace:
        min: "1"
        max: "3"
        distribution: logUniform
    - name: batch_size
      parameterType: int
      feasibleSpace:
        min: "32"
        max: "64"
        distribution: logNormal
  trialTemplate:
    primaryContainerName: training-container
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: momentum
        description: Momentum for the training model
        reference: momentum
      - name: epochs
        description: Epochs
        reference: epochs
      - name: batchSize
        description: Batch Size
        reference: batch_size
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
                command:
                  - "python3"
                  - "/opt/pytorch-mnist/mnist.py"
                  - "--epochs=${trialParameters.epochs}"
                  - "--batch-size=${trialParameters.batchSize}"
                  - "--lr=${trialParameters.learningRate}"
                  - "--momentum=${trialParameters.momentum}"
            restartPolicy: Never



================================================
FILE: examples/v1beta1/hp-tuning/multivariate-tpe.yaml
================================================
---
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: multivariate-tpe
spec:
  objective:
    type: minimize
    goal: 0.001
    objectiveMetricName: loss
  algorithm:
    algorithmName: multivariate-tpe
  parallelTrialCount: 3
  maxTrialCount: 12
  maxFailedTrialCount: 3
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.05"
    - name: momentum
      parameterType: double
      feasibleSpace:
        min: "0.5"
        max: "0.9"
  trialTemplate:
    primaryContainerName: training-container
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: momentum
        description: Momentum for the training model
        reference: momentum
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
                command:
                  - "python3"
                  - "/opt/pytorch-mnist/mnist.py"
                  - "--epochs=1"
                  - "--batch-size=16"
                  - "--lr=${trialParameters.learningRate}"
                  - "--momentum=${trialParameters.momentum}"
            restartPolicy: Never



================================================
FILE: examples/v1beta1/hp-tuning/optuna-distribution.yaml
================================================
---
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: optuna-distribution
spec:
  objective:
    type: minimize
    goal: 0.05
    objectiveMetricName: loss
  algorithm:
    algorithmName: tpe
  parallelTrialCount: 3
  maxTrialCount: 12
  maxFailedTrialCount: 3
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "1"
        max: "5"
        step: "0.1"
        distribution: uniform
    - name: momentum
      parameterType: double
      feasibleSpace:
        min: "0.001"
        max: "3"
        distribution: logUniform
    - name: epochs
      parameterType: int
      feasibleSpace:
        min: "1"
        max: "3"
        distribution: uniform
    - name: batch_size
      parameterType: int
      feasibleSpace:
        min: "32"
        max: "64"
        distribution: logUniform
  trialTemplate:
    primaryContainerName: training-container
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: momentum
        description: Momentum for the training model
        reference: momentum
      - name: epochs
        description: Epochs
        reference: epochs
      - name: batchSize
        description: Batch Size
        reference: batch_size
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
                command:
                  - "python3"
                  - "/opt/pytorch-mnist/mnist.py"
                  - "--epochs=${trialParameters.epochs}"
                  - "--batch-size=${trialParameters.batchSize}"
                  - "--lr=${trialParameters.learningRate}"
                  - "--momentum=${trialParameters.momentum}"
            restartPolicy: Never



================================================
FILE: examples/v1beta1/hp-tuning/random.yaml
================================================
---
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: random
spec:
  objective:
    type: minimize
    goal: 0.001
    objectiveMetricName: loss
  algorithm:
    algorithmName: random
  parallelTrialCount: 3
  maxTrialCount: 12
  maxFailedTrialCount: 3
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.05"
    - name: momentum
      parameterType: double
      feasibleSpace:
        min: "0.5"
        max: "0.9"
  trialTemplate:
    primaryContainerName: training-container
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: momentum
        description: Momentum for the training model
        reference: momentum
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
                command:
                  - "python3"
                  - "/opt/pytorch-mnist/mnist.py"
                  - "--epochs=1"
                  - "--batch-size=16"
                  - "--lr=${trialParameters.learningRate}"
                  - "--momentum=${trialParameters.momentum}"
                resources:
                  limits:
                    memory: "1Gi"
                    cpu: "0.5"
            restartPolicy: Never



================================================
FILE: examples/v1beta1/hp-tuning/simple-pbt.yaml
================================================
---
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: simple-pbt
spec:
  maxTrialCount: 2
  parallelTrialCount: 2
  maxFailedTrialCount: 3
  resumePolicy: FromVolume
  objective:
    type: maximize
    goal: 0.99
    objectiveMetricName: Validation-accuracy
  algorithm:
    algorithmName: pbt
    algorithmSettings:
      - name: suggestion_trial_dir
        value: /var/log/katib/checkpoints/
      - name: n_population
        value: '40'
      - name: truncation_threshold
        value: '0.2'
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: '0.0001'
        max: '0.02'
        step: '0.0001'
  trialTemplate:
    primaryContainerName: training-container
    trialParameters:
      - name: learningRate
        description: Learning rate for training the model
        reference: lr
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: ghcr.io/kubeflow/katib/simple-pbt:latest
                command:
                  - "python3"
                  - "/opt/pbt/pbt_test.py"
                  - "--epochs=20"
                  - "--lr=${trialParameters.learningRate}"
                  - "--checkpoint=/var/log/katib/checkpoints/"
            restartPolicy: Never



================================================
FILE: examples/v1beta1/hp-tuning/sobol.yaml
================================================
---
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: sobol
spec:
  objective:
    type: minimize
    goal: 0.001
    objectiveMetricName: loss
  algorithm:
    algorithmName: sobol
  parallelTrialCount: 3
  maxTrialCount: 12
  maxFailedTrialCount: 3
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.05"
    - name: momentum
      parameterType: double
      feasibleSpace:
        min: "0.5"
        max: "0.9"
  trialTemplate:
    primaryContainerName: training-container
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: momentum
        description: Momentum for the training model
        reference: momentum
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
                command:
                  - "python3"
                  - "/opt/pytorch-mnist/mnist.py"
                  - "--epochs=1"
                  - "--batch-size=16"
                  - "--lr=${trialParameters.learningRate}"
                  - "--momentum=${trialParameters.momentum}"
            restartPolicy: Never



================================================
FILE: examples/v1beta1/hp-tuning/tpe.yaml
================================================
---
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: tpe
spec:
  objective:
    type: minimize
    goal: 0.001
    objectiveMetricName: loss
  algorithm:
    algorithmName: tpe
  parallelTrialCount: 3
  maxTrialCount: 12
  maxFailedTrialCount: 3
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.05"
    - name: momentum
      parameterType: double
      feasibleSpace:
        min: "0.5"
        max: "0.9"
  trialTemplate:
    primaryContainerName: training-container
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: momentum
        description: Momentum for the training model
        reference: momentum
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
                command:
                  - "python3"
                  - "/opt/pytorch-mnist/mnist.py"
                  - "--epochs=1"
                  - "--batch-size=16"
                  - "--lr=${trialParameters.learningRate}"
                  - "--momentum=${trialParameters.momentum}"
            restartPolicy: Never



================================================
FILE: examples/v1beta1/kind-cluster/README.md
================================================
# Katib Example with Kind Cluster

Follow this example to run Katib Experiment on your **local laptop** with
[Kind](https://github.com/kubernetes-sigs/kind/) cluster. This example doesn't
require any public or private cloud to run Katib Experiments.

## Prerequisites

Install the following tools to run the example:

- [Docker](https://docs.docker.com/get-docker) >= 20.10
- [Kind](https://kind.sigs.k8s.io/docs/user/quick-start/#installation) >= 0.13
- [`kubectl`](https://kubernetes.io/docs/tasks/tools/#kubectl) >= 1.29

## Installation

Run the following command to create Kind cluster with the
[Katib components](https://www.kubeflow.org/docs/components/katib/hyperparameter/#katib-components):

```
./deploy.sh
```

If the above script was successful, Katib components will be running:

```
$ kubectl get pods -n kubeflow

NAME                                READY   STATUS      RESTARTS   AGE
katib-controller-566595bdd8-x7z6w   1/1     Running     0          67s
katib-db-manager-57cd769cdb-x4lnz   1/1     Running     0          67s
katib-mysql-7894994f88-7l8nd        1/1     Running     0          67s
katib-ui-5767cfccdc-nt6mz           1/1     Running     0          67s
```

## Run Katib Experiment

You can use various [Katib interfaces](https://www.kubeflow.org/docs/components/katib/overview/#katib-interfaces)
to run your first Katib Experiment.

For example, create Hyperparameter Tuning Katib Experiment with
[random search algorithm](https://www.kubeflow.org/docs/components/katib/experiment/#random-search)
using `kubectl`:

```
kubectl create -f https://raw.githubusercontent.com/kubeflow/katib/master/examples/v1beta1/hp-tuning/random.yaml
```

This example uses a PyTorch neural network to train an image classification model
using the MNIST dataset. You can check the training container source code
[here](../trial-images/pytorch-mnist).
The Experiment runs twelve training jobs (Trials) and tunes the following hyperparameters:

- Learning Rate (`lr`).
- Momentum (`momentum`).

After creating above example, check the
[Experiment](https://www.kubeflow.org/docs/components/katib/overview/#experiment) status:

```
$ kubectl get experiment random -n kubeflow

NAME     TYPE      STATUS   AGE
random   Running   True     6m19s
```

Check the [Suggestion](https://www.kubeflow.org/docs/components/katib/overview/#suggestion) status:

```
$ kubectl get suggestion -n kubeflow

NAME     TYPE      STATUS   REQUESTED   ASSIGNED   AGE
random   Running   True     4           4          6m21s
```

Check the [Trials](https://www.kubeflow.org/docs/components/katib/overview/#trial) statuses:

```
$ kubectl get trial -n kubeflow

NAME              TYPE        STATUS   AGE
random-9hmdjqk9   Running     True     99s
random-cf7tfss2   Succeeded   True     5m21s
random-fr5lfn2x   Running     True     5m21s
random-z9wqm7xh   Running     True     5m21s
```

You can get the best hyperparameters with the following command:

```
$ kubectl get experiment random -n kubeflow -o jsonpath='{range .status.currentOptimalTrial.parameterAssignments[*]}{.name}: {.value}{"\n"}{end}'

lr: 0.028162244250364066
momentum: 0.583672196492823
```

To view created Experiment in Katib UI, follow
[this guide](https://www.kubeflow.org/docs/components/katib/hyperparameter/#accessing-the-katib-ui).

## Cleanup

To cleanup Kind cluster run:

```
kind delete cluster
```



================================================
FILE: examples/v1beta1/kind-cluster/deploy.sh
================================================
#!/usr/bin/env bash

# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This script is used to deploy Kind cluster with Katib standalone components.
set -e

# Verify that appropriate tools are installed.
if [ -z "$(command -v docker)" ]; then
  echo "Unable to find Docker"
  echo "To install Docker, please follow this guide: https://docs.docker.com/get-docker"
  exit 1
fi

if [ -z "$(command -v kind)" ]; then
  echo "Unable to find Kind"
  echo "To install Kind, please follow this guide: https://kind.sigs.k8s.io/docs/user/quick-start/#installation"
  exit 1
fi

if [ -z "$(command -v kubectl)" ]; then
  echo "Unable to find kubectl"
  echo "To install kubectl, please follow this guide: https://kubernetes.io/docs/tasks/tools/#kubectl"
  exit 1
fi

# Step 1. Create Kind cluster with Kubernetes v1.29.2
kind create cluster --image kindest/node:v1.29.2
echo -e "\nKind cluster has been created\n"

# Step 2. Set context for kubectl
kubectl config use-context kind-kind

# Step 3. Wait until Kubernetes Nodes will be ready.
TIMEOUT=30m
kubectl wait --for=condition=ready --timeout=${TIMEOUT} node kind-control-plane

kubectl get nodes

# Step 4. Deploy Katib components.
echo -e "\nDeploying Katib components\n"
kubectl apply -k "github.com/kubeflow/katib.git/manifests/v1beta1/installs/katib-standalone?ref=master"

# If the local machine's CPU architecture is arm64, rewrite mysql image.
if [ "$(uname -m)" = "arm64" ]; then
  kubectl patch deployments -n kubeflow katib-mysql --type json -p \
    '[{"op": "replace", "path": "/spec/template/spec/containers/0/image", "value": "arm64v8/mysql:8.0.29-oracle"}]'
fi

# Wait until all Katib pods are running.
kubectl wait --for=condition=ready --timeout=${TIMEOUT} -l "katib.kubeflow.org/component in (controller,db-manager,mysql,ui)" -n kubeflow pod

echo -e "\nKatib has been deployed"
kubectl get pods -n kubeflow



================================================
FILE: examples/v1beta1/kubeflow-pipelines/README.md
================================================
# Using Katib with Kubeflow Pipelines

The following examples show how to use Katib with
[Kubeflow Pipelines](https://github.com/kubeflow/pipelines).

You can find the Katib Component source code for the Kubeflow Pipelines
[here](https://github.com/kubeflow/pipelines/tree/master/components/kubeflow/katib-launcher).

## Prerequisites

You have to install the following Python SDK to run these examples:

- [`kfp`](https://pypi.org/project/kfp/) >= 1.8.12
- [`kubeflow-katib`](https://pypi.org/project/kubeflow-katib/) >= 0.13.0

## Multi-User Pipelines Setup

The Notebooks examples run Pipelines in multi-user mode and your Kubeflow Notebook must authenticate the Pipeline SDK.

Please follow [this guide](https://www.kubeflow.org/docs/components/pipelines/user-guides/core-functions/connect-api/)
to give an access Kubeflow Notebook to run Kubeflow Pipelines.

## List of Examples

The following Pipelines are deployed from Kubeflow Notebook:

- [Kubeflow E2E MNIST](kubeflow-e2e-mnist.ipynb)

- [Katib Experiment with Early Stopping](early-stopping.ipynb)

The following Pipelines have to be compiled and uploaded to the Kubeflow Pipelines UI:

- [MPIJob Horovod](mpi-job-horovod.py)



================================================
FILE: examples/v1beta1/kubeflow-pipelines/early-stopping.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
# Kubeflow Pipelines with Katib component

In this notebook you will:
- Create Katib Experiment using random algorithm.
- Use median stopping rule as an early stopping algorithm.
- Use Kubernetes Job with pytorch mnist training container as a Trial template.
- Create Pipeline to get the optimal hyperparameters.

Reference documentation:
- https://kubeflow.org/docs/components/katib/experiment/#random-search
- https://kubeflow.org/docs/components/katib/early-stopping/
- https://kubeflow.org/docs/pipelines/overview/concepts/component/

**Note**: This Pipeline runs in the multi-user mode. Follow [this guide](https://github.com/kubeflow/katib/tree/master/examples/v1beta1/kubeflow-pipelines#multi-user-pipelines-setup) to give your Notebook access to Kubeflow Pipelines.
"""

# Install required packages (Kubeflow Pipelines and Katib SDK).
!pip install kfp==1.8.12
!pip install kubeflow-katib==0.13.0
# Output:
#   Requirement already satisfied: kfp==1.8.12 in /opt/conda/lib/python3.8/site-packages (1.8.12)

#   Requirement already satisfied: fire<1,>=0.3.1 in /opt/conda/lib/python3.8/site-packages (from kfp==1.8.12) (0.4.0)

#   Requirement already satisfied: absl-py<2,>=0.9 in /opt/conda/lib/python3.8/site-packages (from kfp==1.8.12) (0.11.0)

#   Requirement already satisfied: jsonschema<4,>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from kfp==1.8.12) (3.2.0)

#   Requirement already satisfied: typer<1.0,>=0.3.2 in /opt/conda/lib/python3.8/site-packages (from kfp==1.8.12) (0.4.1)

#   Requirement already satisfied: uritemplate<4,>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from kfp==1.8.12) (3.0.1)

#   Requirement already satisfied: typing-extensions<4,>=3.7.4 in /opt/conda/lib/python3.8/site-packages (from kfp==1.8.12) (3.10.0.2)

#   Requirement already satisfied: tabulate<1,>=0.8.6 in /opt/conda/lib/python3.8/site-packages (from kfp==1.8.12) (0.8.9)

#   Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.8/site-packages (from kfp==1.8.12) (2.7.1)

#   Requirement already satisfied: kfp-pipeline-spec<0.2.0,>=0.1.14 in /opt/conda/lib/python3.8/site-packages (from kfp==1.8.12) (0.1.14)

#   Requirement already satisfied: pydantic<2,>=1.8.2 in /opt/conda/lib/python3.8/site-packages (from kfp==1.8.12) (1.9.0)

#   Requirement already satisfied: cloudpickle<3,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from kfp==1.8.12) (2.0.0)

#   Requirement already satisfied: docstring-parser<1,>=0.7.3 in /opt/conda/lib/python3.8/site-packages (from kfp==1.8.12) (0.13)

#   Requirement already satisfied: kfp-server-api<2.0.0,>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from kfp==1.8.12) (1.6.0)

#   Requirement already satisfied: google-api-python-client<2,>=1.7.8 in /opt/conda/lib/python3.8/site-packages (from kfp==1.8.12) (1.12.10)

#   Requirement already satisfied: google-auth<2,>=1.6.1 in /opt/conda/lib/python3.8/site-packages (from kfp==1.8.12) (1.35.0)

#   Requirement already satisfied: strip-hints<1,>=0.1.8 in /opt/conda/lib/python3.8/site-packages (from kfp==1.8.12) (0.1.10)

#   Requirement already satisfied: Deprecated<2,>=1.2.7 in /opt/conda/lib/python3.8/site-packages (from kfp==1.8.12) (1.2.13)

#   Requirement already satisfied: click<9,>=7.1.2 in /opt/conda/lib/python3.8/site-packages (from kfp==1.8.12) (7.1.2)

#   Requirement already satisfied: PyYAML<6,>=5.3 in /opt/conda/lib/python3.8/site-packages (from kfp==1.8.12) (5.4.1)

#   Requirement already satisfied: kubernetes<19,>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from kfp==1.8.12) (12.0.1)

#   Requirement already satisfied: google-cloud-storage<2,>=1.20.0 in /opt/conda/lib/python3.8/site-packages (from kfp==1.8.12) (1.44.0)

#   Requirement already satisfied: protobuf<4,>=3.13.0 in /opt/conda/lib/python3.8/site-packages (from kfp==1.8.12) (3.17.3)

#   Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from kfp==1.8.12) (0.9.1)

#   Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from absl-py<2,>=0.9->kfp==1.8.12) (1.16.0)

#   Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.8/site-packages (from Deprecated<2,>=1.2.7->kfp==1.8.12) (1.13.3)

#   Requirement already satisfied: termcolor in /opt/conda/lib/python3.8/site-packages (from fire<1,>=0.3.1->kfp==1.8.12) (1.1.0)

#   Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /opt/conda/lib/python3.8/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp==1.8.12) (1.55.0)

#   Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.8/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp==1.8.12) (2.25.1)

#   Requirement already satisfied: httplib2<1dev,>=0.15.0 in /opt/conda/lib/python3.8/site-packages (from google-api-python-client<2,>=1.7.8->kfp==1.8.12) (0.20.4)

#   Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.8/site-packages (from google-api-python-client<2,>=1.7.8->kfp==1.8.12) (0.1.0)

#   Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.1->kfp==1.8.12) (49.6.0.post20210108)

#   Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.1->kfp==1.8.12) (4.2.4)

#   Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.1->kfp==1.8.12) (4.8)

#   Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<2,>=1.6.1->kfp==1.8.12) (0.2.8)

#   Requirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /opt/conda/lib/python3.8/site-packages (from google-cloud-storage<2,>=1.20.0->kfp==1.8.12) (2.3.2)

#   Requirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from google-cloud-storage<2,>=1.20.0->kfp==1.8.12) (2.2.3)

#   Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.8/site-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->kfp==1.8.12) (1.3.0)

#   Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.8/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client<2,>=1.7.8->kfp==1.8.12) (2.4.7)

#   Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema<4,>=3.0.1->kfp==1.8.12) (21.2.0)

#   Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema<4,>=3.0.1->kfp==1.8.12) (0.17.3)

#   Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.8/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp==1.8.12) (2.8.1)

#   Requirement already satisfied: urllib3>=1.15 in /opt/conda/lib/python3.8/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp==1.8.12) (1.26.5)

#   Requirement already satisfied: certifi in /opt/conda/lib/python3.8/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp==1.8.12) (2021.5.30)

#   Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.8/site-packages (from kubernetes<19,>=8.0.0->kfp==1.8.12) (1.3.1)

#   Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.8/site-packages (from kubernetes<19,>=8.0.0->kfp==1.8.12) (1.0.1)

#   Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.1->kfp==1.8.12) (0.4.8)

#   Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp==1.8.12) (2.10)

#   Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp==1.8.12) (4.0.0)

#   Requirement already satisfied: wheel in /opt/conda/lib/python3.8/site-packages (from strip-hints<1,>=0.1.8->kfp==1.8.12) (0.36.2)

#   Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib->kubernetes<19,>=8.0.0->kfp==1.8.12) (3.2.0)

#   Requirement already satisfied: kubeflow-katib==0.13.0 in /opt/conda/lib/python3.8/site-packages (0.13.0)

#   Requirement already satisfied: kubernetes>=12.0.0 in /opt/conda/lib/python3.8/site-packages (from kubeflow-katib==0.13.0) (12.0.1)

#   Requirement already satisfied: certifi>=14.05.14 in /opt/conda/lib/python3.8/site-packages (from kubeflow-katib==0.13.0) (2021.5.30)

#   Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.8/site-packages (from kubeflow-katib==0.13.0) (1.16.0)

#   Requirement already satisfied: urllib3>=1.15.1 in /opt/conda/lib/python3.8/site-packages (from kubeflow-katib==0.13.0) (1.26.5)

#   Requirement already satisfied: setuptools>=21.0.0 in /opt/conda/lib/python3.8/site-packages (from kubeflow-katib==0.13.0) (49.6.0.post20210108)

#   Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from kubernetes>=12.0.0->kubeflow-katib==0.13.0) (2.25.1)

#   Requirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.8/site-packages (from kubernetes>=12.0.0->kubeflow-katib==0.13.0) (2.8.1)

#   Requirement already satisfied: pyyaml>=3.12 in /opt/conda/lib/python3.8/site-packages (from kubernetes>=12.0.0->kubeflow-katib==0.13.0) (5.4.1)

#   Requirement already satisfied: google-auth>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from kubernetes>=12.0.0->kubeflow-katib==0.13.0) (1.35.0)

#   Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.8/site-packages (from kubernetes>=12.0.0->kubeflow-katib==0.13.0) (1.3.1)

#   Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.8/site-packages (from kubernetes>=12.0.0->kubeflow-katib==0.13.0) (1.0.1)

#   Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth>=1.0.1->kubernetes>=12.0.0->kubeflow-katib==0.13.0) (4.2.4)

#   Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth>=1.0.1->kubernetes>=12.0.0->kubeflow-katib==0.13.0) (0.2.8)

#   Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth>=1.0.1->kubernetes>=12.0.0->kubeflow-katib==0.13.0) (4.8)

#   Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=12.0.0->kubeflow-katib==0.13.0) (0.4.8)

#   Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->kubernetes>=12.0.0->kubeflow-katib==0.13.0) (4.0.0)

#   Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->kubernetes>=12.0.0->kubeflow-katib==0.13.0) (2.10)

#   Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib->kubernetes>=12.0.0->kubeflow-katib==0.13.0) (3.2.0)


import kfp
import kfp.dsl as dsl
from kfp import components

from kubeflow.katib import ApiClient
from kubeflow.katib import V1beta1ExperimentSpec
from kubeflow.katib import V1beta1AlgorithmSpec
from kubeflow.katib import V1beta1EarlyStoppingSpec
from kubeflow.katib import V1beta1EarlyStoppingSetting
from kubeflow.katib import V1beta1ObjectiveSpec
from kubeflow.katib import V1beta1ParameterSpec
from kubeflow.katib import V1beta1FeasibleSpace
from kubeflow.katib import V1beta1TrialTemplate
from kubeflow.katib import V1beta1TrialParameterSpec

"""
## Define an Experiment

You have to create an Experiment object before deploying it. This Experiment is similar to [this](https://github.com/kubeflow/katib/blob/master/examples/v1beta1/early-stopping/median-stop.yaml) YAML.
"""

# Experiment name and namespace.
experiment_name = "median-stop"
experiment_namespace = "kubeflow-user-example-com"

# Trial count specification.
max_trial_count = 18
max_failed_trial_count = 3
parallel_trial_count = 2

# Objective specification.
objective=V1beta1ObjectiveSpec(
    type="minimize",
    goal= 0.001,
    objective_metric_name="loss",
)

# Algorithm specification.
algorithm=V1beta1AlgorithmSpec(
    algorithm_name="random",
)

# Early Stopping specification.
early_stopping=V1beta1EarlyStoppingSpec(
    algorithm_name="medianstop",
    algorithm_settings=[
        V1beta1EarlyStoppingSetting(
            name="min_trials_required",
            value="2"
        )
    ]
)

# Experiment search space.
# In this example we tune learning rate, number of layer and optimizer.
# Learning rate has bad feasible space to show more early stopped Trials.
parameters=[
    V1beta1ParameterSpec(
        name="lr",
        parameter_type="double",
        feasible_space=V1beta1FeasibleSpace(
            min="0.01",
            max="0.3"
        ),
    ),
    V1beta1ParameterSpec(
        name="momentum",
        parameter_type="double",
        feasible_space=V1beta1FeasibleSpace(
            min="0.5",
            max="0.9"
        ),
    ),
]


"""
## Define a Trial template

In this example, the Trial's Worker is the Kubernetes Job.
"""

# JSON template specification for the Trial's Worker Kubernetes Job.
trial_spec={
    "apiVersion": "batch/v1",
    "kind": "Job",
    "spec": {
        "template": {
            "metadata": {
                "labels": {
                     "sidecar.istio.io/inject": "false"
                }
            },
            "spec": {
                "containers": [
                    {
                        "name": "training-container",
                        "image": "docker.io/kubeflowkatib/pytorch-mnist-cpu:v0.14.0",
                        "command": [
                            "python3",
                            "/opt/pytorch-mnist/mnist.py",
                            "--epochs=1",
                            "--batch-size=16",
                            "--lr=${trialParameters.learningRate}",
                            "--momentum=${trialParameters.momentum}",
                        ]
                    }
                ],
                "restartPolicy": "Never"
            }
        }
    }
}

# Configure parameters for the Trial template.
# We set the retain parameter to "True" to not clean-up the Trial Job's Kubernetes Pods.
trial_template=V1beta1TrialTemplate(
    retain=True,
    primary_container_name="training-container",
    trial_parameters=[
        V1beta1TrialParameterSpec(
            name="learningRate",
            description="Learning rate for the training model",
            reference="lr"
        ),
        V1beta1TrialParameterSpec(
            name="momentum",
            description="Momentum for the training model",
            reference="momentum"
        ),
    ],
    trial_spec=trial_spec
)

"""
## Define an Experiment specification

Create an Experiment specification from the above parameters.
"""

experiment_spec=V1beta1ExperimentSpec(
    max_trial_count=max_trial_count,
    max_failed_trial_count=max_failed_trial_count,
    parallel_trial_count=parallel_trial_count,
    objective=objective,
    algorithm=algorithm,
    early_stopping=early_stopping,
    parameters=parameters,
    trial_template=trial_template
)

"""
# Create a Pipeline using Katib component

The best hyperparameters are printed after Experiment is finished.
The Experiment is not deleted after the Pipeline is finished.
"""

# Get the Katib launcher.
katib_experiment_launcher_op = components.load_component_from_url(
    "https://raw.githubusercontent.com/kubeflow/pipelines/master/components/kubeflow/katib-launcher/component.yaml")

@dsl.pipeline(
    name="Launch Katib early stopping Experiment",
    description="An example to launch Katib Experiment with early stopping"
)

def median_stop():

    # Katib launcher component.
    # Experiment Spec should be serialized to a valid Kubernetes object.
    op = katib_experiment_launcher_op(
        experiment_name=experiment_name,
        experiment_namespace=experiment_namespace,
        experiment_spec=ApiClient().sanitize_for_serialization(experiment_spec),
        experiment_timeout_minutes=60,
        delete_finished_experiment=False)

    # Output container to print the results.
    op_out = dsl.ContainerOp(
        name="best-hp",
        image="library/bash:4.4.23",
        command=["sh", "-c"],
        arguments=["echo Best HyperParameters: %s" % op.output],
    )

"""
# Run the Kubeflow Pipeline

You can check the Katib Experiment info in the Katib UI.
"""

# Run the Kubeflow Pipeline in the user's namespace.
kfp.Client().create_run_from_pipeline_func(median_stop,  namespace=experiment_namespace, arguments={})
# Output:
#   /opt/conda/lib/python3.8/site-packages/kfp/dsl/_container_op.py:1257: FutureWarning: Please create reusable components instead of constructing ContainerOp instances directly. Reusable components are shareable, portable and have compatibility and support guarantees. Please see the documentation: https://www.kubeflow.org/docs/pipelines/sdk/component-development/#writing-your-component-definition-file The components can be created manually (or, in case of python, using kfp.components.create_component_from_func or func_to_container_op) and then loaded using kfp.components.load_component_from_file, load_component_from_uri or load_component_from_text: https://kubeflow-pipelines.readthedocs.io/en/stable/source/kfp.components.html#kfp.components.load_component_from_file

#     warnings.warn(

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   RunPipelineResult(run_id=bb6689a9-1efa-4fd7-bcb1-09f47bf1e932)



================================================
FILE: examples/v1beta1/kubeflow-pipelines/mpi-job-horovod.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Kubeflow Pipeline with Katib component.

# In this example you will create Katib Experiment using Bayesian optimization algorithm.
# As a Trial template you will use Kubeflow MPIJob with Horovod MNIST training container.
# After that, you will compile a Kubeflow Pipeline with your Katib Experiment.
# Use Kubeflow Pipelines UI to upload the Pipeline and create the Experiment and Run.

# This Experiment is similar to this:
# https://github.com/kubeflow/katib/blob/master/examples/v1beta1/kubeflow-training-operator/mpijob-horovod.yaml
# Check the training container source code here:
# https://github.com/kubeflow/mpi-operator/tree/master/examples/horovod.

# Note: To run this example, your Kubernetes cluster should run MPIJob operator.
# Follow this guide to install MPIJob on your cluster:
# https://www.kubeflow.org/docs/components/training/mpi/

import kfp
import kfp.dsl as dsl
from kfp import components
from kubeflow.katib import (
    ApiClient,
    V1beta1AlgorithmSetting,
    V1beta1AlgorithmSpec,
    V1beta1ExperimentSpec,
    V1beta1FeasibleSpace,
    V1beta1ObjectiveSpec,
    V1beta1ParameterSpec,
    V1beta1TrialParameterSpec,
    V1beta1TrialTemplate,
)


@dsl.pipeline(
    name="Launch Katib MPIJob Experiment",
    description="An example to launch Katib Experiment with MPIJob",
)
def horovod_mnist_hpo(
    experiment_name: str = "mpi-horovod-mnist",
    experiment_namespace: str = "kubeflow-user-example-com",
):
    # Trial count specification.
    max_trial_count = 6
    max_failed_trial_count = 3
    parallel_trial_count = 2

    # Objective specification.
    objective = V1beta1ObjectiveSpec(
        type="minimize",
        goal=0.01,
        objective_metric_name="loss",
    )

    # Algorithm specification.
    algorithm = V1beta1AlgorithmSpec(
        algorithm_name="bayesianoptimization",
        algorithm_settings=[V1beta1AlgorithmSetting(name="random_state", value="10")],
    )

    # Experiment search space.
    # In this example we tune learning rate and number of training steps.
    parameters = [
        V1beta1ParameterSpec(
            name="lr",
            parameter_type="double",
            feasible_space=V1beta1FeasibleSpace(min="0.001", max="0.003"),
        ),
        V1beta1ParameterSpec(
            name="num-steps",
            parameter_type="int",
            feasible_space=V1beta1FeasibleSpace(min="50", max="150", step="10"),
        ),
    ]

    # JSON template specification for the Trial's Worker Kubeflow MPIJob.
    trial_spec = {
        "apiVersion": "kubeflow.org/v1",
        "kind": "MPIJob",
        "spec": {
            "slotsPerWorker": 1,
            "cleanPodPolicy": "Running",
            "mpiReplicaSpecs": {
                "Launcher": {
                    "replicas": 1,
                    "template": {
                        "metadata": {"labels": {"sidecar.istio.io/inject": "false"}},
                        "spec": {
                            "containers": [
                                {
                                    "image": "docker.io/kubeflow/mpi-horovod-mnist",
                                    "name": "mpi-launcher",
                                    "command": ["mpirun"],
                                    "args": [
                                        "-np",
                                        "2",
                                        "--allow-run-as-root",
                                        "-bind-to",
                                        "none",
                                        "-map-by",
                                        "slot",
                                        "-x",
                                        "LD_LIBRARY_PATH",
                                        "-x",
                                        "PATH",
                                        "-mca",
                                        "pml",
                                        "ob1",
                                        "-mca",
                                        "btl",
                                        "^openib",
                                        "python",
                                        "/examples/tensorflow_mnist.py",
                                        "--lr",
                                        "${trialParameters.learningRate}",
                                        "--num-steps",
                                        "${trialParameters.numberSteps}",
                                    ],
                                    "resources": {
                                        "limits": {"cpu": "500m", "memory": "2Gi"}
                                    },
                                }
                            ]
                        },
                    },
                },
                "Worker": {
                    "replicas": 2,
                    "template": {
                        "metadata": {"labels": {"sidecar.istio.io/inject": "false"}},
                        "spec": {
                            "containers": [
                                {
                                    "image": "docker.io/kubeflow/mpi-horovod-mnist",
                                    "name": "mpi-worker",
                                    "resources": {
                                        "limits": {"cpu": "500m", "memory": "4Gi"}
                                    },
                                }
                            ]
                        },
                    },
                },
            },
        },
    }

    # Configure parameters for the Trial template.
    trial_template = V1beta1TrialTemplate(
        primary_pod_labels={"mpi-job-role": "launcher"},
        primary_container_name="mpi-launcher",
        success_condition='status.conditions.#(type=="Succeeded")#|#(status=="True")#',
        failure_condition='status.conditions.#(type=="Failed")#|#(status=="True")#',
        trial_parameters=[
            V1beta1TrialParameterSpec(
                name="learningRate",
                description="Learning rate for the training model",
                reference="lr",
            ),
            V1beta1TrialParameterSpec(
                name="numberSteps",
                description="Number of training steps",
                reference="num-steps",
            ),
        ],
        trial_spec=trial_spec,
    )

    # Create Experiment specification.
    experiment_spec = V1beta1ExperimentSpec(
        max_trial_count=max_trial_count,
        max_failed_trial_count=max_failed_trial_count,
        parallel_trial_count=parallel_trial_count,
        objective=objective,
        algorithm=algorithm,
        parameters=parameters,
        trial_template=trial_template,
    )

    # Get the Katib launcher.
    # Load component from the URL or from the file.
    katib_experiment_launcher_op = components.load_component_from_url(
        "https://raw.githubusercontent.com/kubeflow/pipelines/master/"
        "components/kubeflow/katib-launcher/component.yaml"
    )
    # katib_experiment_launcher_op = components.load_component_from_file(
    #     "../../../components/kubeflow/katib-launcher/component.yaml"
    # )

    # Katib launcher component.
    # Experiment Spec should be serialized to a valid Kubernetes object.
    # The Experiment is deleted after the Pipeline is finished.
    op = katib_experiment_launcher_op(
        experiment_name=experiment_name,
        experiment_namespace=experiment_namespace,
        experiment_spec=ApiClient().sanitize_for_serialization(experiment_spec),
        experiment_timeout_minutes=60,
    )

    # Output container to print the results.
    dsl.ContainerOp(
        name="best-hp",
        image="library/bash:4.4.23",
        command=["sh", "-c"],
        arguments=["echo Best HyperParameters: %s" % op.output],
    )


if __name__ == "__main__":
    kfp.compiler.Compiler().compile(horovod_mnist_hpo, __file__ + ".tar.gz")



================================================
FILE: examples/v1beta1/kubeflow-pipelines/images/9.bmp
================================================
[Binary file]


================================================
FILE: examples/v1beta1/kubeflow-trainer/trainjob-pytorch.yaml
================================================
---
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: torch-distributed-example
spec:
  parallelTrialCount: 3
  maxTrialCount: 12
  maxFailedTrialCount: 3
  objective:
    type: minimize
    goal: 0.001
    objectiveMetricName: loss
  algorithm:
    algorithmName: random
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.05"
    - name: momentum
      parameterType: double
      feasibleSpace:
        min: "0.5"
        max: "0.9"
  trialTemplate:
    primaryContainerName: node
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: momentum
        description: Momentum for the training model
        reference: momentum
    trialSpec:
      apiVersion: trainer.kubeflow.org/v1alpha1
      kind: TrainJob
      spec:
        runtimeRef:
          name: torch-distributed
        trainer:
          numNodes: 2
          image: docker.io/kubeflowkatib/pytorch-mnist:v1beta1-45c5727
          command:
            - "python3"
            - "/opt/pytorch-mnist/mnist.py"
            - "--epochs=1"
            - "--lr=${trialParameters.learningRate}"
            - "--momentum=${trialParameters.momentum}"



================================================
FILE: examples/v1beta1/kubeflow-training-operator/mpijob-horovod.yaml
================================================
---
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: mpijob-horovod
spec:
  objective:
    type: minimize
    goal: 0.01
    objectiveMetricName: loss
  algorithm:
    algorithmName: random
  parallelTrialCount: 2
  maxTrialCount: 6
  maxFailedTrialCount: 3
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.001"
        max: "0.003"
    - name: num-steps
      parameterType: int
      feasibleSpace:
        min: "50"
        max: "150"
        step: "10"
  trialTemplate:
    primaryPodLabels:
      mpi-job-role: launcher
    primaryContainerName: mpi-launcher
    successCondition: status.conditions.#(type=="Succeeded")#|#(status=="True")#
    failureCondition: status.conditions.#(type=="Failed")#|#(status=="True")#
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: numberSteps
        description: Number of training steps
        reference: num-steps
    trialSpec:
      apiVersion: kubeflow.org/v1
      kind: MPIJob
      spec:
        slotsPerWorker: 1
        cleanPodPolicy: Running
        mpiReplicaSpecs:
          Launcher:
            replicas: 1
            template:
              spec:
                containers:
                  - image: docker.io/kubeflow/mpi-horovod-mnist
                    name: mpi-launcher
                    command:
                      - mpirun
                    args:
                      - -np
                      - "2"
                      - --allow-run-as-root
                      - -bind-to
                      - none
                      - -map-by
                      - slot
                      - -x
                      - LD_LIBRARY_PATH
                      - -x
                      - PATH
                      - -mca
                      - pml
                      - ob1
                      - -mca
                      - btl
                      - ^openib
                      - python
                      - /examples/tensorflow_mnist.py
                      - --lr
                      - ${trialParameters.learningRate}
                      - --num-steps
                      - ${trialParameters.numberSteps}
                    resources:
                      limits:
                        cpu: 500m
                        memory: 2Gi
          Worker:
            replicas: 2
            template:
              spec:
                containers:
                  - image: docker.io/kubeflow/mpi-horovod-mnist
                    name: mpi-worker
                    resources:
                      limits:
                        cpu: 500m
                        memory: 4Gi



================================================
FILE: examples/v1beta1/kubeflow-training-operator/pytorchjob-mnist.yaml
================================================
---
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: pytorchjob-mnist
spec:
  parallelTrialCount: 3
  maxTrialCount: 12
  maxFailedTrialCount: 3
  objective:
    type: minimize
    goal: 0.001
    objectiveMetricName: loss
  algorithm:
    algorithmName: random
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.05"
    - name: momentum
      parameterType: double
      feasibleSpace:
        min: "0.5"
        max: "0.9"
  trialTemplate:
    primaryContainerName: pytorch
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: momentum
        description: Momentum for the training model
        reference: momentum
    trialSpec:
      apiVersion: kubeflow.org/v1
      kind: PyTorchJob
      spec:
        pytorchReplicaSpecs:
          Master:
            replicas: 1
            restartPolicy: OnFailure
            template:
              spec:
                containers:
                  - name: pytorch
                    image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
                    command:
                      - "python3"
                      - "/opt/pytorch-mnist/mnist.py"
                      - "--epochs=1"
                      - "--batch-size=16"
                      - "--lr=${trialParameters.learningRate}"
                      - "--momentum=${trialParameters.momentum}"
          Worker:
            replicas: 1
            restartPolicy: OnFailure
            template:
              spec:
                containers:
                  - name: pytorch
                    image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
                    command:
                      - "python3"
                      - "/opt/pytorch-mnist/mnist.py"
                      - "--epochs=1"
                      - "--batch-size=16"
                      - "--lr=${trialParameters.learningRate}"
                      - "--momentum=${trialParameters.momentum}"



================================================
FILE: examples/v1beta1/kubeflow-training-operator/tfjob-mnist-with-summaries.yaml
================================================
---
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: tfjob-mnist-with-summaries
spec:
  parallelTrialCount: 3
  maxTrialCount: 12
  maxFailedTrialCount: 3
  objective:
    type: maximize
    goal: 0.99
    objectiveMetricName: accuracy
  algorithm:
    algorithmName: random
  metricsCollectorSpec:
    source:
      fileSystemPath:
        path: /mnist-with-summaries-logs/test
        kind: Directory
    collector:
      kind: TensorFlowEvent
  parameters:
    - name: learning_rate
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.05"
    - name: batch_size
      parameterType: int
      feasibleSpace:
        min: "32"
        max: "64"
  trialTemplate:
    primaryContainerName: tensorflow
    # In this example we can collect metrics only from the Worker pods.
    primaryPodLabels:
      training.kubeflow.org/replica-type: worker
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: learning_rate
      - name: batchSize
        description: Batch Size
        reference: batch_size
    trialSpec:
      apiVersion: kubeflow.org/v1
      kind: TFJob
      spec:
        tfReplicaSpecs:
          Worker:
            replicas: 2
            restartPolicy: OnFailure
            template:
              spec:
                containers:
                  - name: tensorflow
                    image: ghcr.io/kubeflow/katib/tf-mnist-with-summaries:latest
                    command:
                      - "python"
                      - "/opt/tf-mnist-with-summaries/mnist.py"
                      - "--epochs=1"
                      - "--learning-rate=${trialParameters.learningRate}"
                      - "--batch-size=${trialParameters.batchSize}"
                      - "--log-path=/mnist-with-summaries-logs"



================================================
FILE: examples/v1beta1/kubeflow-training-operator/xgboostjob-lightgbm.yaml
================================================
---
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: xgboostjob-lightgbm
spec:
  objective:
    type: maximize
    goal: 0.99
    objectiveMetricName: valid_1 auc
    additionalMetricNames:
      - valid_1 binary_logloss
      - training auc
      - training binary_logloss
  metricsCollectorSpec:
    source:
      filter:
        metricsFormat:
          - "(\\w+\\s\\w+)\\s:\\s((-?\\d+)(\\.\\d+)?)"
  algorithm:
    algorithmName: random
  parallelTrialCount: 2
  maxTrialCount: 6
  maxFailedTrialCount: 3
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.1"
    - name: num-leaves
      parameterType: int
      feasibleSpace:
        min: "50"
        max: "60"
        step: "1"
  trialTemplate:
    primaryContainerName: xgboost
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: numberLeaves
        description: Number of leaves for one tree
        reference: num-leaves
    trialSpec:
      apiVersion: kubeflow.org/v1
      kind: XGBoostJob
      spec:
        xgbReplicaSpecs:
          Master:
            replicas: 1
            restartPolicy: Never
            template:
              spec:
                containers:
                  - name: xgboost
                    image: ghcr.io/kubeflow/katib/xgboost-lightgbm:1.0
                    ports:
                      - containerPort: 9991
                        name: xgboostjob-port
                    imagePullPolicy: Always
                    args:
                      - --job_type=Train
                      - --metric=binary_logloss,auc
                      - --learning_rate=${trialParameters.learningRate}
                      - --num_leaves=${trialParameters.numberLeaves}
                      - --num_trees=100
                      - --boosting_type=gbdt
                      - --objective=binary
                      - --metric_freq=1
                      - --is_training_metric=true
                      - --max_bin=255
                      - --data=data/binary.train
                      - --valid_data=data/binary.test
                      - --tree_learner=feature
                      - --feature_fraction=0.8
                      - --bagging_freq=5
                      - --bagging_fraction=0.8
                      - --min_data_in_leaf=50
                      - --min_sum_hessian_in_leaf=50
                      - --is_enable_sparse=true
                      - --use_two_round_loading=false
                      - --is_save_binary_file=false
          Worker:
            replicas: 2
            restartPolicy: ExitCode
            template:
              spec:
                containers:
                  - name: xgboost
                    image: ghcr.io/kubeflow/katib/xgboost-lightgbm:1.0
                    ports:
                      - containerPort: 9991
                        name: xgboostjob-port
                    imagePullPolicy: Always
                    args:
                      - --job_type=Train
                      - --metric=binary_logloss,auc
                      - --learning_rate=${trialParameters.learningRate}
                      - --num_leaves=${trialParameters.numberLeaves}
                      - --num_trees=100
                      - --boosting_type=gbdt
                      - --objective=binary
                      - --metric_freq=1
                      - --is_training_metric=true
                      - --max_bin=255
                      - --data=data/binary.train
                      - --valid_data=data/binary.test
                      - --tree_learner=feature
                      - --feature_fraction=0.8
                      - --bagging_freq=5
                      - --bagging_fraction=0.8
                      - --min_data_in_leaf=50
                      - --min_sum_hessian_in_leaf=50
                      - --is_enable_sparse=true
                      - --use_two_round_loading=false
                      - --is_save_binary_file=false



================================================
FILE: examples/v1beta1/metrics-collector/custom-metrics-collector.yaml
================================================
---
# TODO (andreyvelich) This metrics collector image (kubeflowkatib/custom-metrics-collector) doesn't work in v1beta1.
# It is currently using api.v1.alpha3.Manager instead of api.v1.beta1.Manager to report metrics.
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: custom-metrics-collector
spec:
  objective:
    type: maximize
    goal: 0.99
    objectiveMetricName: accuracy
  metricsCollectorSpec:
    source:
      fileSystemPath:
        path: "/katib/mnist.log"
        kind: File
    collector:
      kind: Custom
      customCollector:
        args:
          - -m
          - accuracy
          - -s
          - katib-db-manager.kubeflow:6789
          - -path
          - /katib/mnist.log
        image: ghcr.io/kubeflow/katib/custom-metrics-collector:latest
        imagePullPolicy: Always
        name: custom-metrics-logger-and-collector
        env:
          - name: TrialNamePrefix
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
  algorithm:
    algorithmName: random
  parallelTrialCount: 3
  maxTrialCount: 12
  maxFailedTrialCount: 3
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.03"
    - name: momentum
      parameterType: double
      feasibleSpace:
        min: "0.3"
        max: "0.7"
  trialTemplate:
    primaryContainerName: training-container
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: momentum
        description: Momentum for the training model
        reference: momentum
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
                command:
                  - "python3"
                  - "/opt/pytorch-mnist/mnist.py"
                  - "--epochs=1"
                  - "--log-path=/katib/mnist.log"
                  - "--lr=${trialParameters.learningRate}"
                  - "--momentum=${trialParameters.momentum}"
            restartPolicy: Never



================================================
FILE: examples/v1beta1/metrics-collector/file-metrics-collector-with-json-format.yaml
================================================
---
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: file-metrics-collector-with-json-format
spec:
  objective:
    type: maximize
    goal: 0.99
    objectiveMetricName: accuracy
    additionalMetricNames:
      - loss
  metricsCollectorSpec:
    source:
      fileSystemPath:
        path: "/katib/mnist.json"
        kind: File
        format: JSON
    collector:
      kind: File
  algorithm:
    algorithmName: random
  parallelTrialCount: 3
  maxTrialCount: 12
  maxFailedTrialCount: 3
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.03"
    - name: momentum
      parameterType: double
      feasibleSpace:
        min: "0.3"
        max: "0.7"
  trialTemplate:
    primaryContainerName: training-container
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: momentum
        description: Momentum for the training model
        reference: momentum
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
                command:
                  - "python3"
                  - "/opt/pytorch-mnist/mnist.py"
                  - "--epochs=1"
                  - "--log-path=/katib/mnist.json"
                  - "--lr=${trialParameters.learningRate}"
                  - "--momentum=${trialParameters.momentum}"
                  - "--logger=hypertune"
            restartPolicy: Never



================================================
FILE: examples/v1beta1/metrics-collector/file-metrics-collector.yaml
================================================
---
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: file-metrics-collector
spec:
  objective:
    type: maximize
    goal: 0.99
    objectiveMetricName: accuracy
    additionalMetricNames:
      - loss
  metricsCollectorSpec:
    source:
      filter:
        metricsFormat:
          - "{metricName: ([\\w|-]+), metricValue: ((-?\\d+)(\\.\\d+)?)}"
      fileSystemPath:
        path: "/katib/mnist.log"
        kind: File
    collector:
      kind: File
  algorithm:
    algorithmName: random
  parallelTrialCount: 3
  maxTrialCount: 12
  maxFailedTrialCount: 3
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.03"
    - name: momentum
      parameterType: double
      feasibleSpace:
        min: "0.3"
        max: "0.7"
  trialTemplate:
    primaryContainerName: training-container
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: momentum
        description: Momentum for the training model
        reference: momentum
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
                command:
                  - "python3"
                  - "/opt/pytorch-mnist/mnist.py"
                  - "--epochs=1"
                  - "--log-path=/katib/mnist.log"
                  - "--lr=${trialParameters.learningRate}"
                  - "--momentum=${trialParameters.momentum}"
            restartPolicy: Never



================================================
FILE: examples/v1beta1/metrics-collector/metrics-collection-strategy.yaml
================================================
---
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: metrics-collection-strategy
spec:
  objective:
    type: minimize
    goal: 0.001
    objectiveMetricName: loss
    additionalMetricNames:
      - accuracy
    metricStrategies:
      - name: accuracy
        value: "max"
      - name: loss
        value: "min"
  algorithm:
    algorithmName: tpe
  parallelTrialCount: 3
  maxTrialCount: 12
  maxFailedTrialCount: 3
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.05"
    - name: momentum
      parameterType: double
      feasibleSpace:
        min: "0.5"
        max: "0.9"
  trialTemplate:
    primaryContainerName: training-container
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: momentum
        description: Momentum for the training model
        reference: momentum
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
                command:
                  - "python3"
                  - "/opt/pytorch-mnist/mnist.py"
                  - "--epochs=1"
                  - "--batch-size=16"
                  - "--lr=${trialParameters.learningRate}"
                  - "--momentum=${trialParameters.momentum}"
            restartPolicy: Never



================================================
FILE: examples/v1beta1/nas/darts-cpu.yaml
================================================
---
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: darts-cpu
spec:
  parallelTrialCount: 1
  maxTrialCount: 1
  maxFailedTrialCount: 1
  objective:
    type: maximize
    objectiveMetricName: Best-Genotype
  metricsCollectorSpec:
    collector:
      kind: StdOut
    source:
      filter:
        metricsFormat:
          - "([\\w-]+)=(Genotype.*)"
  algorithm:
    algorithmName: darts
    algorithmSettings:
      - name: num_epochs
        value: "1"
      - name: num_nodes
        value: "1"
      - name: init_channels
        value: "1"
      - name: stem_multiplier
        value: "1"
  nasConfig:
    graphConfig:
      numLayers: 1
    operations:
      - operationType: max_pooling
        parameters:
          - name: filter_size
            parameterType: categorical
            feasibleSpace:
              list:
                - "3"
  trialTemplate:
    primaryContainerName: training-container
    trialParameters:
      - name: algorithmSettings
        description: Algorithm settings of DARTS Experiment
        reference: algorithm-settings
      - name: searchSpace
        description: Search Space of DARTS Experiment
        reference: search-space
      - name: numberLayers
        description: Number of Neural Network layers
        reference: num-layers
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: ghcr.io/kubeflow/katib/darts-cnn-cifar10-cpu:latest
                command:
                  - python3
                  - run_trial.py
                  - --algorithm-settings="${trialParameters.algorithmSettings}"
                  - --search-space="${trialParameters.searchSpace}"
                  - --num-layers="${trialParameters.numberLayers}"
            restartPolicy: Never



================================================
FILE: examples/v1beta1/nas/darts-gpu.yaml
================================================
---
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: darts-gpu
spec:
  parallelTrialCount: 1
  maxTrialCount: 1
  maxFailedTrialCount: 1
  objective:
    type: maximize
    objectiveMetricName: Best-Genotype
  metricsCollectorSpec:
    collector:
      kind: StdOut
    source:
      filter:
        metricsFormat:
          - "([\\w-]+)=(Genotype.*)"
  algorithm:
    algorithmName: darts
    algorithmSettings:
      - name: num_epochs
        value: "3"
  nasConfig:
    graphConfig:
      numLayers: 3
    operations:
      - operationType: separable_convolution
        parameters:
          - name: filter_size
            parameterType: categorical
            feasibleSpace:
              list:
                - "3"
      - operationType: dilated_convolution
        parameters:
          - name: filter_size
            parameterType: categorical
            feasibleSpace:
              list:
                - "3"
                - "5"
      - operationType: avg_pooling
        parameters:
          - name: filter_size
            parameterType: categorical
            feasibleSpace:
              list:
                - "3"
      - operationType: max_pooling
        parameters:
          - name: filter_size
            parameterType: categorical
            feasibleSpace:
              list:
                - "3"
      - operationType: skip_connection
  trialTemplate:
    primaryContainerName: training-container
    trialParameters:
      - name: algorithmSettings
        description: Algorithm settings of DARTS Experiment
        reference: algorithm-settings
      - name: searchSpace
        description: Search Space of DARTS Experiment
        reference: search-space
      - name: numberLayers
        description: Number of Neural Network layers
        reference: num-layers
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: ghcr.io/kubeflow/katib/darts-cnn-cifar10-gpu:latest
                command:
                  - python3
                  - run_trial.py
                  - --algorithm-settings="${trialParameters.algorithmSettings}"
                  - --search-space="${trialParameters.searchSpace}"
                  - --num-layers="${trialParameters.numberLayers}"
                resources:
                  limits:
                    nvidia.com/gpu: 1
            restartPolicy: Never



================================================
FILE: examples/v1beta1/nas/enas-cpu.yaml
================================================
---
# This CPU example aims to show all the possible operations
# is not very likely to get good result due to the extensive search space

# In practice, setting up a limited search space with more common operations is more likely to get better performance.
# For example, Efficient Neural Architecture Search via Parameter Sharing (https://arxiv.org/abs/1802.03268)
# uses only 6 operations, 3x3/5x5 convolution, 3x3/5x5 separable_convolution and 3x3 max_pooling/avg_pooling.

# It uses only 1 layer of CNN and 1 train epoch to show CPU support and it has very bad results.
# In practice, if you increase number of layers, training process on CPU will take more time.
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: enas-cpu
spec:
  parallelTrialCount: 2
  maxTrialCount: 3
  maxFailedTrialCount: 2
  objective:
    type: maximize
    goal: 0.99
    objectiveMetricName: Validation-Accuracy
  algorithm:
    algorithmName: enas
  nasConfig:
    graphConfig:
      numLayers: 1
      inputSizes:
        - 32
        - 32
        - 3
      outputSizes:
        - 10
    operations:
      - operationType: convolution
        parameters:
          - name: filter_size
            parameterType: categorical
            feasibleSpace:
              list:
                - "3"
                - "5"
                - "7"
          - name: num_filter
            parameterType: categorical
            feasibleSpace:
              list:
                - "32"
                - "48"
                - "64"
                - "96"
                - "128"
          - name: stride
            parameterType: categorical
            feasibleSpace:
              list:
                - "1"
                - "2"
      - operationType: separable_convolution
        parameters:
          - name: filter_size
            parameterType: categorical
            feasibleSpace:
              list:
                - "3"
                - "5"
                - "7"
          - name: num_filter
            parameterType: categorical
            feasibleSpace:
              list:
                - "32"
                - "48"
                - "64"
                - "96"
                - "128"
          - name: stride
            parameterType: categorical
            feasibleSpace:
              list:
                - "1"
                - "2"
          - name: depth_multiplier
            parameterType: categorical
            feasibleSpace:
              list:
                - "1"
                - "2"
      - operationType: depthwise_convolution
        parameters:
          - name: filter_size
            parameterType: categorical
            feasibleSpace:
              list:
                - "3"
                - "5"
                - "7"
          - name: stride
            parameterType: categorical
            feasibleSpace:
              list:
                - "1"
                - "2"
          - name: depth_multiplier
            parameterType: categorical
            feasibleSpace:
              list:
                - "1"
                - "2"
      - operationType: reduction
        parameters:
          - name: reduction_type
            parameterType: categorical
            feasibleSpace:
              list:
                - max_pooling
                - avg_pooling
          - name: pool_size
            parameterType: int
            feasibleSpace:
              min: "2"
              max: "3"
              step: "1"
  trialTemplate:
    primaryContainerName: training-container
    trialParameters:
      - name: neuralNetworkArchitecture
        description: NN architecture contains operations ID on each NN layer and skip connections between layers
        reference: architecture
      - name: neuralNetworkConfig
        description: Configuration contains NN number of layers, input and output sizes, description what each operation ID means
        reference: nn_config
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: ghcr.io/kubeflow/katib/enas-cnn-cifar10-cpu:latest
                command:
                  - python3
                  - -u
                  - RunTrial.py
                  - --num_epochs=1
                  - --architecture="${trialParameters.neuralNetworkArchitecture}"
                  - --nn_config="${trialParameters.neuralNetworkConfig}"
            restartPolicy: Never



================================================
FILE: examples/v1beta1/nas/enas-gpu.yaml
================================================
---
# This GPU example aims to show all the possible operations
# is not very likely to get good result due to the extensive search space

# In practice, setting up a limited search space with more common operations is more likely to get better performance.
# For example, Efficient Neural Architecture Search via Parameter Sharing (https://arxiv.org/abs/1802.03268)
# uses only 6 operations, 3x3/5x5 convolution, 3x3/5x5 separable_convolution and 3x3 max_pooling/avg_pooling
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: enas-gpu
spec:
  parallelTrialCount: 3
  maxTrialCount: 12
  maxFailedTrialCount: 3
  objective:
    type: maximize
    goal: 0.99
    objectiveMetricName: Validation-Accuracy
  algorithm:
    algorithmName: enas
  nasConfig:
    graphConfig:
      numLayers: 8
      inputSizes:
        - 32
        - 32
        - 3
      outputSizes:
        - 10
    operations:
      - operationType: convolution
        parameters:
          - name: filter_size
            parameterType: categorical
            feasibleSpace:
              list:
                - "3"
                - "5"
                - "7"
          - name: num_filter
            parameterType: categorical
            feasibleSpace:
              list:
                - "32"
                - "48"
                - "64"
                - "96"
                - "128"
          - name: stride
            parameterType: categorical
            feasibleSpace:
              list:
                - "1"
                - "2"
      - operationType: separable_convolution
        parameters:
          - name: filter_size
            parameterType: categorical
            feasibleSpace:
              list:
                - "3"
                - "5"
                - "7"
          - name: num_filter
            parameterType: categorical
            feasibleSpace:
              list:
                - "32"
                - "48"
                - "64"
                - "96"
                - "128"
          - name: stride
            parameterType: categorical
            feasibleSpace:
              list:
                - "1"
                - "2"
          - name: depth_multiplier
            parameterType: categorical
            feasibleSpace:
              list:
                - "1"
                - "2"
      - operationType: depthwise_convolution
        parameters:
          - name: filter_size
            parameterType: categorical
            feasibleSpace:
              list:
                - "3"
                - "5"
                - "7"
          - name: stride
            parameterType: categorical
            feasibleSpace:
              list:
                - "1"
                - "2"
          - name: depth_multiplier
            parameterType: categorical
            feasibleSpace:
              list:
                - "1"
                - "2"
      - operationType: reduction
        parameters:
          - name: reduction_type
            parameterType: categorical
            feasibleSpace:
              list:
                - max_pooling
                - avg_pooling
          - name: pool_size
            parameterType: int
            feasibleSpace:
              min: "2"
              max: "3"
              step: "1"
  trialTemplate:
    primaryContainerName: training-container
    trialParameters:
      - name: neuralNetworkArchitecture
        description: NN architecture contains operations ID on each NN layer and skip connections between layers
        reference: architecture
      - name: neuralNetworkConfig
        description: Configuration contains NN number of layers, input and output sizes, description what each operation ID means
        reference: nn_config
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: ghcr.io/kubeflow/katib/enas-cnn-cifar10-gpu:latest
                command:
                  - python3
                  - -u
                  - RunTrial.py
                  - --architecture="${trialParameters.neuralNetworkArchitecture}"
                  - --nn_config="${trialParameters.neuralNetworkConfig}"
                resources:
                  limits:
                    nvidia.com/gpu: 1
            restartPolicy: Never



================================================
FILE: examples/v1beta1/resume-experiment/from-volume-resume.yaml
================================================
---
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: from-volume-resume
spec:
  objective:
    type: minimize
    goal: 0.001
    objectiveMetricName: loss
  algorithm:
    algorithmName: random
  parallelTrialCount: 3
  maxTrialCount: 12
  maxFailedTrialCount: 3
  resumePolicy: FromVolume
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.05"
    - name: momentum
      parameterType: double
      feasibleSpace:
        min: "0.5"
        max: "0.9"
  trialTemplate:
    primaryContainerName: training-container
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: momentum
        description: Momentum for the training model
        reference: momentum
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
                command:
                  - "python3"
                  - "/opt/pytorch-mnist/mnist.py"
                  - "--epochs=1"
                  - "--batch-size=16"
                  - "--lr=${trialParameters.learningRate}"
                  - "--momentum=${trialParameters.momentum}"
            restartPolicy: Never



================================================
FILE: examples/v1beta1/resume-experiment/long-running-resume.yaml
================================================
---
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: long-running-resume
spec:
  objective:
    type: minimize
    goal: 0.001
    objectiveMetricName: loss
  algorithm:
    algorithmName: random
  parallelTrialCount: 3
  maxTrialCount: 12
  maxFailedTrialCount: 3
  resumePolicy: LongRunning
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.05"
    - name: momentum
      parameterType: double
      feasibleSpace:
        min: "0.5"
        max: "0.9"
  trialTemplate:
    primaryContainerName: training-container
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: momentum
        description: Momentum for the training model
        reference: momentum
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
                command:
                  - "python3"
                  - "/opt/pytorch-mnist/mnist.py"
                  - "--epochs=1"
                  - "--batch-size=16"
                  - "--lr=${trialParameters.learningRate}"
                  - "--momentum=${trialParameters.momentum}"
            restartPolicy: Never



================================================
FILE: examples/v1beta1/sdk/README.md
================================================
# Katib Python SDK examples.

Here you can find examples of using [Katib Python SDK](../../../sdk/python/v1beta1/).



================================================
FILE: examples/v1beta1/sdk/cmaes-and-resume-policies.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
# HyperParameter tunning using  CMA-ES

In this example you will deploy 3 Katib Experiments with Covariance Matrix Adaptation Evolution Strategy (CMA-ES) using Jupyter Notebook and Katib SDK. These Experiments have various resume policies.

Reference documentation:
- https://www.kubeflow.org/docs/components/katib/experiment/#cmaes
- https://www.kubeflow.org/docs/components/katib/resume-experiment/

The notebook shows how to create, get, check status and delete an Experiment.
"""

"""
## Install Katib SDK

You need to install Katib SDK to run this Notebook.
"""

# TODO (andreyvelich): Change to release version when SDK with the new APIs is published.
!pip install git+https://github.com/kubeflow/katib.git#subdirectory=sdk/python/v1beta1

"""
## Import required packages
"""

import copy

from kubeflow.katib import KatibClient
from kubernetes.client import V1ObjectMeta
from kubeflow.katib import V1beta1Experiment
from kubeflow.katib import V1beta1AlgorithmSpec
from kubeflow.katib import V1beta1ObjectiveSpec
from kubeflow.katib import V1beta1FeasibleSpace
from kubeflow.katib import V1beta1ExperimentSpec
from kubeflow.katib import V1beta1ObjectiveSpec
from kubeflow.katib import V1beta1ParameterSpec
from kubeflow.katib import V1beta1TrialTemplate
from kubeflow.katib import V1beta1TrialParameterSpec

"""
## Define your Experiment

You have to create your Experiment object before deploying it. This Experiment is similar to [this](https://github.com/kubeflow/katib/blob/master/examples/v1beta1/hp-tuning/cma-es.yaml) example.
"""

# Experiment name and namespace.
namespace = "kubeflow-user-example-com"
experiment_name = "cmaes-example"

metadata = V1ObjectMeta(
    name=experiment_name,
    namespace=namespace
)

# Algorithm specification.
algorithm_spec=V1beta1AlgorithmSpec(
    algorithm_name="cmaes"
)

# Objective specification.
objective_spec=V1beta1ObjectiveSpec(
    type="minimize",
    goal= 0.001,
    objective_metric_name="loss",
)

# Experiment search space. In this example we tune learning rate, number of layer and optimizer.
parameters=[
    V1beta1ParameterSpec(
        name="lr",
        parameter_type="double",
        feasible_space=V1beta1FeasibleSpace(
            min="0.01",
            max="0.06"
        ),
    ),
    V1beta1ParameterSpec(
        name="momentum",
        parameter_type="double",
        feasible_space=V1beta1FeasibleSpace(
            min="0.5",
            max="0.9"
        ),
    ),
]

# JSON template specification for the Trial's Worker Kubernetes Job.
trial_spec={
    "apiVersion": "batch/v1",
    "kind": "Job",
    "spec": {
        "template": {
            "metadata": {
                "labels": {
                    "sidecar.istio.io/inject": "false"
                }
            },
            "spec": {
                "containers": [
                    {
                        "name": "training-container",
                        "image": "docker.io/kubeflowkatib/pytorch-mnist-cpu:v0.14.0",
                        "command": [
                            "python3",
                            "/opt/pytorch-mnist/mnist.py",
                            "--epochs=1",
                            "--batch-size=64",
                            "--lr=${trialParameters.learningRate}",
                            "--momentum=${trialParameters.momentum}",
                        ]
                    }
                ],
                "restartPolicy": "Never"
            }
        }
    }
}

# Configure parameters for the Trial template.
trial_template=V1beta1TrialTemplate(
    primary_container_name="training-container",
    trial_parameters=[
        V1beta1TrialParameterSpec(
            name="learningRate",
            description="Learning rate for the training model",
            reference="lr"
        ),
        V1beta1TrialParameterSpec(
            name="momentum",
            description="Momentum for the training model",
            reference="momentum"
        ),
    ],
    trial_spec=trial_spec
)


# Experiment object.
experiment = V1beta1Experiment(
    api_version="kubeflow.org/v1beta1",
    kind="Experiment",
    metadata=metadata,
    spec=V1beta1ExperimentSpec(
        max_trial_count=3,
        parallel_trial_count=2,
        max_failed_trial_count=1,
        algorithm=algorithm_spec,
        objective=objective_spec,
        parameters=parameters,
        trial_template=trial_template,
    )
)

"""
## Define Experiments with resume policy

We will define another 2 Experiments with ResumePolicy = Never and ResumePolicy = FromVolume.

Experiment with _Never_ resume policy can't be resumed, the Suggestion resources will be deleted.

Experiment with _FromVolume_ resume policy can be resumed, volume is attached to the Suggestion. Suggestion's PVC be created for the Suggestion.
"""

experiment_never_resume_name = "never-resume-cmaes"
experiment_from_volume_resume_name = "from-volume-resume-cmaes"

# Create new Experiments from the previous Experiment info.
# Define Experiment with Never resume.
experiment_never_resume = copy.deepcopy(experiment)
experiment_never_resume.metadata.name = experiment_never_resume_name
experiment_never_resume.spec.resume_policy = "Never"
experiment_never_resume.spec.max_trial_count = 4

# Define Experiment with FromVolume resume.
experiment_from_volume_resume = copy.deepcopy(experiment)
experiment_from_volume_resume.metadata.name = experiment_from_volume_resume_name
experiment_from_volume_resume.spec.resume_policy = "FromVolume"
experiment_from_volume_resume.spec.max_trial_count = 4

"""
You can print the Experiment's info to verify it before submission.
"""

print(experiment.metadata.name)
print(experiment.spec.algorithm.algorithm_name)
print("-----------------")
print(experiment_never_resume.metadata.name)
print(experiment_never_resume.spec.resume_policy)
print("-----------------")
print(experiment_from_volume_resume.metadata.name)
print(experiment_from_volume_resume.spec.resume_policy)

# Output:
#   cmaes-example

#   cmaes

#   -----------------

#   never-resume-cmaes

#   Never

#   -----------------

#   from-volume-resume-cmaes

#   FromVolume


"""
## Create your Experiment

You have to create Katib client to use the SDK.
"""

# Create Katib client.
kclient = KatibClient()

# Create your Experiment.
kclient.create_experiment(experiment,namespace=namespace)
# Output:
#   Experiment kubeflow-user-example-com/cmaes-example has been created

#   <IPython.core.display.HTML object>

"""
### Create other Experiments
"""

# Create Experiment with never resume.
kclient.create_experiment(experiment_never_resume,namespace=namespace)
# Create Experiment with from volume resume.
kclient.create_experiment(experiment_from_volume_resume,namespace=namespace)
# Output:
#   Experiment kubeflow-user-example-com/never-resume-cmaes has been created

#   <IPython.core.display.HTML object>
#   Experiment kubeflow-user-example-com/from-volume-resume-cmaes has been created

#   <IPython.core.display.HTML object>

"""
## Get your Experiment

You can get your Experiment by name and receive required data.
"""

exp = kclient.get_experiment(name=experiment_name, namespace=namespace)
print(exp)
print("-----------------\n")

# Get the max trial count and latest status.
print(exp.spec.max_trial_count)
print(exp.status.conditions[-1])
# Output:
#   {'api_version': 'kubeflow.org/v1beta1',

#    'kind': 'Experiment',

#    'metadata': {'annotations': None,

#                 'creation_timestamp': datetime.datetime(2023, 1, 6, 14, 28, 28, tzinfo=tzlocal()),

#                 'deletion_grace_period_seconds': None,

#                 'deletion_timestamp': None,

#                 'finalizers': ['update-prometheus-metrics'],

#                 'generate_name': None,

#                 'generation': 1,

#                 'labels': None,

#                 'managed_fields': [{'api_version': 'kubeflow.org/v1beta1',

#                                     'fields_type': 'FieldsV1',

#                                     'fields_v1': {'f:spec': {'.': {},

#                                                              'f:algorithm': {'.': {},

#                                                                              'f:algorithmName': {}},

#                                                              'f:maxFailedTrialCount': {},

#                                                              'f:maxTrialCount': {},

#                                                              'f:objective': {'.': {},

#                                                                              'f:additionalMetricNames': {},

#                                                                              'f:goal': {},

#                                                                              'f:objectiveMetricName': {},

#                                                                              'f:type': {}},

#                                                              'f:parallelTrialCount': {},

#                                                              'f:parameters': {},

#                                                              'f:trialTemplate': {'.': {},

#                                                                                  'f:primaryContainerName': {},

#                                                                                  'f:trialParameters': {},

#                                                                                  'f:trialSpec': {'.': {},

#                                                                                                  'f:apiVersion': {},

#                                                                                                  'f:kind': {},

#                                                                                                  'f:spec': {'.': {},

#                                                                                                             'f:template': {'.': {},

#                                                                                                                            'f:metadata': {'.': {},

#                                                                                                                                           'f:annotations': {'.': {},

#                                                                                                                                                             'f:sidecar.istio.io/inject': {}}},

#                                                                                                                            'f:spec': {'.': {},

#                                                                                                                                       'f:containers': {},

#                                                                                                                                       'f:restartPolicy': {}}}}}}}},

#                                     'manager': 'OpenAPI-Generator',

#                                     'operation': 'Update',

#                                     'subresource': None,

#                                     'time': datetime.datetime(2023, 1, 6, 14, 28, 28, tzinfo=tzlocal())},

#                                    {'api_version': 'kubeflow.org/v1beta1',

#                                     'fields_type': 'FieldsV1',

#                                     'fields_v1': {'f:metadata': {'f:finalizers': {'.': {},

#                                                                                   'v:"update-prometheus-metrics"': {}}}},

#                                     'manager': 'katib-controller',

#                                     'operation': 'Update',

#                                     'subresource': None,

#                                     'time': datetime.datetime(2023, 1, 6, 14, 28, 28, tzinfo=tzlocal())},

#                                    {'api_version': 'kubeflow.org/v1beta1',

#                                     'fields_type': 'FieldsV1',

#                                     'fields_v1': {'f:status': {'.': {},

#                                                                'f:conditions': {},

#                                                                'f:currentOptimalTrial': {'.': {},

#                                                                                          'f:observation': {}},

#                                                                'f:runningTrialList': {},

#                                                                'f:startTime': {},

#                                                                'f:trials': {},

#                                                                'f:trialsRunning': {}}},

#                                     'manager': 'katib-controller',

#                                     'operation': 'Update',

#                                     'subresource': 'status',

#                                     'time': datetime.datetime(2023, 1, 6, 14, 28, 52, tzinfo=tzlocal())}],

#                 'name': 'cmaes-example',

#                 'namespace': 'kubeflow-user-example-com',

#                 'owner_references': None,

#                 'resource_version': '26516',

#                 'self_link': None,

#                 'uid': '1d59819e-4e5f-4adc-90cc-62c2ee867f72'},

#    'spec': {'algorithm': {'algorithm_name': 'cmaes', 'algorithm_settings': None},

#             'early_stopping': None,

#             'max_failed_trial_count': 1,

#             'max_trial_count': 3,

#             'metrics_collector_spec': {'collector': {'custom_collector': None,

#                                                      'kind': 'StdOut'},

#                                        'source': None},

#             'nas_config': None,

#             'objective': {'additional_metric_names': ['Train-accuracy'],

#                           'goal': 0.99,

#                           'metric_strategies': [{'name': 'Validation-accuracy',

#                                                  'value': 'max'},

#                                                 {'name': 'Train-accuracy',

#                                                  'value': 'max'}],

#                           'objective_metric_name': 'Validation-accuracy',

#                           'type': 'maximize'},

#             'parallel_trial_count': 2,

#             'parameters': [{'feasible_space': {'list': None,

#                                                'max': '0.06',

#                                                'min': '0.01',

#                                                'step': None},

#                             'name': 'lr',

#                             'parameter_type': 'double'},

#                            {'feasible_space': {'list': None,

#                                                'max': '5',

#                                                'min': '2',

#                                                'step': None},

#                             'name': 'num-layers',

#                             'parameter_type': 'int'},

#                            {'feasible_space': {'list': ['sgd', 'adam', 'ftrl'],

#                                                'max': None,

#                                                'min': None,

#                                                'step': None},

#                             'name': 'optimizer',

#                             'parameter_type': 'categorical'}],

#             'resume_policy': 'LongRunning',

#             'trial_template': {'config_map': None,

#                                'failure_condition': 'status.conditions.#(type=="Failed")#|#(status=="True")#',

#                                'primary_container_name': 'training-container',

#                                'primary_pod_labels': None,

#                                'retain': None,

#                                'success_condition': 'status.conditions.#(type=="Complete")#|#(status=="True")#',

#                                'trial_parameters': [{'description': 'Learning '

#                                                                     'rate for '

#                                                                     'the '

#                                                                     'training '

#                                                                     'model',

#                                                      'name': 'learningRate',

#                                                      'reference': 'lr'},

#                                                     {'description': 'Number of '

#                                                                     'training '

#                                                                     'model '

#                                                                     'layers',

#                                                      'name': 'numberLayers',

#                                                      'reference': 'num-layers'},

#                                                     {'description': 'Training '

#                                                                     'model '

#                                                                     'optimizer '

#                                                                     '(sdg, adam '

#                                                                     'or ftrl)',

#                                                      'name': 'optimizer',

#                                                      'reference': 'optimizer'}],

#                                'trial_spec': {'apiVersion': 'batch/v1',

#                                               'kind': 'Job',

#                                               'spec': {'template': {'metadata': {'annotations': {'sidecar.istio.io/inject': 'false'}},

#                                                                     'spec': {'containers': [{'command': ['python3',

#                                                                                                          '/opt/mxnet-mnist/mnist.py',

#                                                                                                          '--batch-size=64',

#                                                                                                          '--num-epochs=1',

#                                                                                                          '--lr=${trialParameters.learningRate}',

#                                                                                                          '--num-layers=${trialParameters.numberLayers}',

#                                                                                                          '--optimizer=${trialParameters.optimizer}'],

#                                                                                              'image': 'docker.io/kubeflowkatib/mxnet-mnist:v0.14.0',

#                                                                                              'name': 'training-container'}],

#                                                                              'restartPolicy': 'Never'}}}}}},

#    'status': {'completion_time': None,

#               'conditions': [{'last_transition_time': datetime.datetime(2023, 1, 6, 14, 28, 28, tzinfo=tzlocal()),

#                               'last_update_time': datetime.datetime(2023, 1, 6, 14, 28, 28, tzinfo=tzlocal()),

#                               'message': 'Experiment is created',

#                               'reason': 'ExperimentCreated',

#                               'status': 'True',

#                               'type': 'Created'},

#                              {'last_transition_time': datetime.datetime(2023, 1, 6, 14, 28, 52, tzinfo=tzlocal()),

#                               'last_update_time': datetime.datetime(2023, 1, 6, 14, 28, 52, tzinfo=tzlocal()),

#                               'message': 'Experiment is running',

#                               'reason': 'ExperimentRunning',

#                               'status': 'True',

#                               'type': 'Running'}],

#               'current_optimal_trial': {'best_trial_name': None,

#                                         'observation': {'metrics': None},

#                                         'parameter_assignments': None},

#               'early_stopped_trial_list': None,

#               'failed_trial_list': None,

#               'killed_trial_list': None,

#               'last_reconcile_time': None,

#               'metrics_unavailable_trial_list': None,

#               'pending_trial_list': None,

#               'running_trial_list': ['cmaes-example-f64n8vb5',

#                                      'cmaes-example-l6zkx5jx'],

#               'start_time': datetime.datetime(2023, 1, 6, 14, 28, 28, tzinfo=tzlocal()),

#               'succeeded_trial_list': None,

#               'trial_metrics_unavailable': None,

#               'trials': 2,

#               'trials_early_stopped': None,

#               'trials_failed': None,

#               'trials_killed': None,

#               'trials_pending': None,

#               'trials_running': 2,

#               'trials_succeeded': None}}

#   -----------------

#   

#   3

#   {'last_transition_time': datetime.datetime(2023, 1, 6, 14, 28, 52, tzinfo=tzlocal()),

#    'last_update_time': datetime.datetime(2023, 1, 6, 14, 28, 52, tzinfo=tzlocal()),

#    'message': 'Experiment is running',

#    'reason': 'ExperimentRunning',

#    'status': 'True',

#    'type': 'Running'}


"""
## Get all Experiments

You can get list of the current Experiments.
"""

# Get names from the running Experiments.
exp_list = kclient.list_experiments(namespace=namespace)

for exp in exp_list:
    print(exp.metadata.name)
# Output:
#   cmaes-example

#   from-volume-resume-cmaes

#   never-resume-cmaes


"""
## Get the current Experiment conditions

You can check the current Experiment conditions and check if Experiment is Succeeded.
"""

kclient.get_experiment_conditions(name=experiment_name, namespace=namespace)

# Output:
#   [{'last_transition_time': datetime.datetime(2023, 1, 6, 14, 28, 28, tzinfo=tzlocal()),

#     'last_update_time': datetime.datetime(2023, 1, 6, 14, 28, 28, tzinfo=tzlocal()),

#     'message': 'Experiment is created',

#     'reason': 'ExperimentCreated',

#     'status': 'True',

#     'type': 'Created'},

#    {'last_transition_time': datetime.datetime(2023, 1, 6, 14, 28, 52, tzinfo=tzlocal()),

#     'last_update_time': datetime.datetime(2023, 1, 6, 14, 28, 52, tzinfo=tzlocal()),

#     'message': 'Experiment is running',

#     'reason': 'ExperimentRunning',

#     'status': 'True',

#     'type': 'Running'}]

kclient.is_experiment_succeeded(name=experiment_name, namespace=namespace)
# Output:
#   False

"""
## List of the current Trials

You can get list of the current Trials with the latest status.
"""

# Trial list.
trial_list = kclient.list_trials(experiment_name=experiment_name, namespace=namespace)
for trial in trial_list:
    print(f"Trial Name: {trial.metadata.name}")
    print(f"Trial Status: {trial.status.conditions[-1]}\n")
# Output:
#   Trial Name: cmaes-example-dd4x6tsh

#   Trial Status: {'last_transition_time': datetime.datetime(2023, 1, 6, 14, 30, 43, tzinfo=tzlocal()),

#    'last_update_time': datetime.datetime(2023, 1, 6, 14, 30, 43, tzinfo=tzlocal()),

#    'message': 'Trial is running',

#    'reason': 'TrialRunning',

#    'status': 'True',

#    'type': 'Running'}

#   

#   Trial Name: cmaes-example-f64n8vb5

#   Trial Status: {'last_transition_time': datetime.datetime(2023, 1, 6, 14, 30, 43, tzinfo=tzlocal()),

#    'last_update_time': datetime.datetime(2023, 1, 6, 14, 30, 43, tzinfo=tzlocal()),

#    'message': 'Trial has succeeded',

#    'reason': 'TrialSucceeded',

#    'status': 'True',

#    'type': 'Succeeded'}

#   

#   Trial Name: cmaes-example-l6zkx5jx

#   Trial Status: {'last_transition_time': datetime.datetime(2023, 1, 6, 14, 30, 45, tzinfo=tzlocal()),

#    'last_update_time': datetime.datetime(2023, 1, 6, 14, 30, 45, tzinfo=tzlocal()),

#    'message': 'Trial has succeeded',

#    'reason': 'TrialSucceeded',

#    'status': 'True',

#    'type': 'Succeeded'}


"""
## Get the optimal HyperParameters

You can get the current optimal Trial from your Experiment. For the each metric you can see the max, min and latest value.
"""

# Optimal HPs.
kclient.get_optimal_hyperparameters(name=experiment_name, namespace=namespace)
# Output:
#   {'best_trial_name': 'cmaes-example-l6zkx5jx',

#    'observation': {'metrics': [{'latest': '0.955613',

#                                 'max': '0.955613',

#                                 'min': '0.955613',

#                                 'name': 'Validation-accuracy'},

#                                {'latest': '0.922775',

#                                 'max': '0.922775',

#                                 'min': '0.922775',

#                                 'name': 'Train-accuracy'}]},

#    'parameter_assignments': [{'name': 'lr', 'value': '0.04511033252270099'},

#                              {'name': 'num-layers', 'value': '3'},

#                              {'name': 'optimizer', 'value': 'sgd'}]}

"""
## Status for the Suggestion objects

Once Experiment is Succeeded, you can check the Suggestion object status for more information about resume status.

For Experiment with FromVolume you should be able to check created PVC.
"""

# Get the current Suggestion status for the never resume Experiment.
suggestion = kclient.get_suggestion(name=experiment_never_resume_name, namespace=namespace)

print(suggestion.status.conditions[-1].message)
print("-----------------")

# Get the current Suggestion status for the from volume Experiment.
suggestion = kclient.get_suggestion(name=experiment_from_volume_resume_name, namespace=namespace)

print(suggestion.status.conditions[-1].message)
# Output:
#   Suggestion is succeeded, can't be restarted

#   -----------------

#   Suggestion is succeeded, suggestion volume is not deleted, can be restarted


"""
## Delete your Experiments

You can delete your Experiments.
"""

kclient.delete_experiment(name=experiment_name, namespace=namespace)
kclient.delete_experiment(name=experiment_never_resume_name, namespace=namespace)
kclient.delete_experiment(name=experiment_from_volume_resume_name, namespace=namespace)
# Output:
#   Experiment kubeflow-user-example-com/cmaes-example has been deleted

#   Experiment kubeflow-user-example-com/never-resume-cmaes has been deleted

#   Experiment kubeflow-user-example-com/from-volume-resume-cmaes has been deleted




================================================
FILE: examples/v1beta1/sdk/mnist-with-push-metrics-collection.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
# Tune and Train with Push-based Metrics Collection Using MNIST

In this Notebook we are going to do the following:
- Train PyTorch MNIST image classification model(CNN).
- Improve the model HyperParameters with [Kubeflow Katib](https://www.kubeflow.org/docs/components/katib/overview/).
- Use Push-based Metrics Collection to efficiently collect metrics in the training containers.
"""

"""
## Install Kubeflow Python SDKs

You need to install Kubeflow SDKs to run this Notebook.
"""

# TODO (Electronic-Waste): Change to release version when SDK with the updated `tune()` is published.
%pip install git+https://github.com/kubeflow/katib.git#subdirectory=sdk/python/v1beta1

"""
## Create Train Script for CNN Model

This is simple **Convolutional Neural Network (CNN)** model for recognizing hand-written digits using [MNIST Dataset](https://yann.lecun.com/exdb/mnist/).
"""

def train_mnist_model(parameters):
    import torch
    import logging
    import kubeflow.katib as katib
    from torchvision import datasets, transforms

    logging.basicConfig(
        format="%(asctime)s %(levelname)-8s %(message)s",
        datefmt="%Y-%m-%dT%H:%M:%SZ",
        level=logging.INFO,
    )
    logging.info("--------------------------------------------------------------------------------------")
    logging.info(f"Input Parameters: {parameters}")
    logging.info("--------------------------------------------------------------------------------------\n\n")

    # Get HyperParameters from the input params dict.
    lr = float(parameters["lr"])
    momentum = float(parameters["momentum"])
    batch_size = int(parameters["batch_size"])
    num_epoch = int(parameters["num_epoch"])
    log_interval = int(parameters["log_interval"])

    # Prepare MNIST Dataset.
    def mnist_train_dataset(batch_size):
        return torch.utils.data.DataLoader(
            datasets.FashionMNIST(
                "./data",
                train=True,
                download=True,
                transform=transforms.Compose([transforms.ToTensor()]),
            ),
            batch_size=batch_size,
            shuffle=True,
        )

    def mnist_test_dataset(batch_size):
        return torch.utils.data.DataLoader(
            datasets.FashionMNIST(
                "./data", train=False, transform=transforms.Compose([transforms.ToTensor()])
            ),
            batch_size=batch_size,
            shuffle=False,
    )
    
    # Build CNN Model.
    def build_and_compile_cnn_model():
        return torch.nn.Sequential(
            torch.nn.Conv2d(1, 20, 5, 1),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(2, 2),
        
            torch.nn.Conv2d(20, 50, 5, 1),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(2, 2),
        
            torch.nn.Flatten(),
        
            torch.nn.Linear(4 * 4 * 50, 500),
            torch.nn.ReLU(),
        
            torch.nn.Linear(500, 10),
            torch.nn.LogSoftmax(dim=1)
        )
    
    # Train CNN Model.
    def train_cnn_model(model, train_loader, optimizer, epoch):
        model.train()
        for batch_idx, (data, target) in enumerate(train_loader):
            optimizer.zero_grad()
            output = model(data)
            loss = torch.nn.functional.nll_loss(output, target)
            loss.backward()
            optimizer.step()
            if batch_idx % log_interval == 0:
                msg = "Train Epoch: {} [{}/{} ({:.0f}%)]\tloss={:.4f}".format(
                    epoch,
                    batch_idx * len(data),
                    len(train_loader.dataset),
                    100.0 * batch_idx / len(train_loader),
                    loss.item(),
                )
                logging.info(msg)
    
    # Test CNN Model and report training metrics
    def test_cnn_model(model, test_loader):
        model.eval()
        test_loss = 0
        correct = 0
        with torch.no_grad():
            for data, target in test_loader:
                output = model(data)
                test_loss += torch.nn.functional.nll_loss(
                    output, target, reduction="sum"
                ).item()  # sum up batch loss
                pred = output.max(1, keepdim=True)[1]  # get the index of the max log-probability
                correct += pred.eq(target.view_as(pred)).sum().item()
        
        test_loss /= len(test_loader.dataset)
        test_accuracy = float(correct) / len(test_loader.dataset)
        katib.report_metrics({  # report metrics directly without outputing logs
            "accuracy": test_accuracy, 
            "loss": test_loss,
        })

    # Download dataset and construct loaders for training and testing
    train_loader = mnist_train_dataset(batch_size)
    test_loader = mnist_test_dataset(batch_size)

    # Build Model and Optimizer
    model = build_and_compile_cnn_model()
    optimizer = torch.optim.SGD(model.parameters(), lr, momentum)

    # Train Model and report metrics
    for epoch_idx in range(1, num_epoch + 1):
       train_cnn_model(model, train_loader, optimizer, epoch_idx)
       test_cnn_model(model, test_loader)



"""
## Start Model Tuning with Katib

If you want to improve your model, you can run HyperParameter tuning with Katib.

The following example uses **Random Search** algorithm to tune HyperParameters.

We are going to tune `learning rate` and `momentum`.
"""

import kubeflow.katib as katib

# Set parameters with their distribution for HyperParameter Tuning with Katib.
parameters = {
    "lr": katib.search.double(min=0.01, max=0.03),
    "momentum": katib.search.double(min=0.3, max=0.7),
    "num_epoch": 1,
    "batch_size": 64,
    "log_interval": 10
}

# Start the Katib Experiment.
# TODO (Electronic-Waste): 
# 1. Change `kubeflow-katib` to release version when `0.18.0` is ready.
# 2. Change `base_image` to official image when `kubeflow-katib` release version `0.18.0` is ready.
exp_name = "tune-mnist"
katib_client = katib.KatibClient(namespace="kubeflow")

katib_client.tune(
    name=exp_name,
    objective=train_mnist_model, # Objective function.
    base_image="docker.io/electronicwaste/pytorch:gitv1",
    parameters=parameters, # HyperParameters to tune.
    algorithm_name="random", # Alorithm to use.
    objective_metric_name="accuracy", # Katib is going to optimize "accuracy".
    additional_metric_names=["loss"], # Katib is going to collect these metrics in addition to the objective metric.
    max_trial_count=12, # Trial Threshold.
    parallel_trial_count=2,
    packages_to_install=["git+https://github.com/kubeflow/katib.git@master#subdirectory=sdk/python/v1beta1"],
    metrics_collector_config={"kind": "Push"},
)

"""
### Access to Katib UI

You can check created experiment in the Katib UI.


"""

"""
### Get the Best HyperParameters from the Katib Experiment

You can get the best HyperParameters from the most optimal Katib Trial.
"""

status = katib_client.is_experiment_succeeded(exp_name)
print(f"Katib Experiment is Succeeded: {status}\n")

best_hps = katib_client.get_optimal_hyperparameters(exp_name)
print(f"Current Optimal Trial:\n{best_hps}")
# Output:
#   Katib Experiment is Succeeded: True

#   

#   Current Optimal Trial:

#   {'best_trial_name': 'tune-mnist-xqwfhr9w',

#    'observation': {'metrics': [{'latest': '0.8276',

#                                 'max': '0.8276',

#                                 'min': '0.8276',

#                                 'name': 'accuracy'},

#                                {'latest': '0.48769191679954527',

#                                 'max': '0.48769191679954527',

#                                 'min': '0.48769191679954527',

#                                 'name': 'loss'}]},

#    'parameter_assignments': [{'name': 'lr', 'value': '0.024527727574297616'},

#                              {'name': 'momentum', 'value': '0.6490973329748595'}]}


"""
## Delete Katib Experiment

When jobs are finished, you can delete the resources.
"""

katib_client.delete_experiment(exp_name)



================================================
FILE: examples/v1beta1/sdk/nas-with-darts.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
# Neural Architecture Search with DARTS

In this example you will deploy Katib Experiment with Differentiable Architecture Search (DARTS) algorithm using Jupyter Notebook and Katib SDK. Your Kubernetes cluster must have at least one GPU for this example.

You can read more about how we use DARTS in Katib [here](https://github.com/kubeflow/katib/tree/master/pkg/suggestion/v1beta1/nas/darts).

The notebook shows how to create, get, check status and delete an Experiment.
"""

# Install required package (Katib SDK).
# TODO (andreyvelich): Update this example with the latest SDK.
!pip install kubeflow-katib==0.13.0
# Output:
#   Requirement already satisfied: kubeflow-katib==0.13.0 in /opt/conda/lib/python3.8/site-packages (0.13.0)

#   Requirement already satisfied: kubernetes>=12.0.0 in /opt/conda/lib/python3.8/site-packages (from kubeflow-katib==0.13.0) (12.0.1)

#   Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.8/site-packages (from kubeflow-katib==0.13.0) (1.16.0)

#   Requirement already satisfied: certifi>=14.05.14 in /opt/conda/lib/python3.8/site-packages (from kubeflow-katib==0.13.0) (2021.5.30)

#   Requirement already satisfied: urllib3>=1.15.1 in /opt/conda/lib/python3.8/site-packages (from kubeflow-katib==0.13.0) (1.26.5)

#   Requirement already satisfied: setuptools>=21.0.0 in /opt/conda/lib/python3.8/site-packages (from kubeflow-katib==0.13.0) (49.6.0.post20210108)

#   Requirement already satisfied: pyyaml>=3.12 in /opt/conda/lib/python3.8/site-packages (from kubernetes>=12.0.0->kubeflow-katib==0.13.0) (5.4.1)

#   Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from kubernetes>=12.0.0->kubeflow-katib==0.13.0) (2.25.1)

#   Requirement already satisfied: google-auth>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from kubernetes>=12.0.0->kubeflow-katib==0.13.0) (1.35.0)

#   Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.8/site-packages (from kubernetes>=12.0.0->kubeflow-katib==0.13.0) (1.0.1)

#   Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.8/site-packages (from kubernetes>=12.0.0->kubeflow-katib==0.13.0) (1.3.1)

#   Requirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.8/site-packages (from kubernetes>=12.0.0->kubeflow-katib==0.13.0) (2.8.1)

#   Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth>=1.0.1->kubernetes>=12.0.0->kubeflow-katib==0.13.0) (4.8)

#   Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth>=1.0.1->kubernetes>=12.0.0->kubeflow-katib==0.13.0) (0.2.8)

#   Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth>=1.0.1->kubernetes>=12.0.0->kubeflow-katib==0.13.0) (4.2.4)

#   Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=12.0.0->kubeflow-katib==0.13.0) (0.4.8)

#   Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->kubernetes>=12.0.0->kubeflow-katib==0.13.0) (4.0.0)

#   Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->kubernetes>=12.0.0->kubeflow-katib==0.13.0) (2.10)

#   Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib->kubernetes>=12.0.0->kubeflow-katib==0.13.0) (3.2.0)


"""
## Import required packages
"""

from kubeflow.katib import KatibClient
from kubernetes.client import V1ObjectMeta
from kubeflow.katib import V1beta1Experiment
from kubeflow.katib import V1beta1AlgorithmSpec
from kubeflow.katib import V1beta1AlgorithmSetting
from kubeflow.katib import V1beta1ObjectiveSpec
from kubeflow.katib import V1beta1MetricsCollectorSpec
from kubeflow.katib import V1beta1CollectorSpec
from kubeflow.katib import V1beta1SourceSpec
from kubeflow.katib import V1beta1FilterSpec
from kubeflow.katib import V1beta1FeasibleSpace
from kubeflow.katib import V1beta1ExperimentSpec
from kubeflow.katib import V1beta1NasConfig
from kubeflow.katib import V1beta1GraphConfig
from kubeflow.katib import V1beta1Operation
from kubeflow.katib import V1beta1ParameterSpec
from kubeflow.katib import V1beta1TrialTemplate
from kubeflow.katib import V1beta1TrialParameterSpec

"""
## Define your Experiment

You have to create your Experiment object before deploying it. This Experiment is similar to [this](https://github.com/kubeflow/katib/blob/master/examples/v1beta1/nas/darts-gpu.yaml) example.

You can read more about DARTS algorithm settings [here](https://www.kubeflow.org/docs/components/katib/experiment/#differentiable-architecture-search-darts).
"""

# Experiment name and namespace.
namespace = "kubeflow-user-example-com"
experiment_name = "darts-example"

metadata = V1ObjectMeta(
    name=experiment_name,
    namespace=namespace
)


# Algorithm specification.
algorithm_spec=V1beta1AlgorithmSpec(
    algorithm_name="darts",
    algorithm_settings=[
        V1beta1AlgorithmSetting(
            name="num_epochs",
            value="2"
        ),
        V1beta1AlgorithmSetting(
            name="stem_multiplier",
            value="1"
        ),
        V1beta1AlgorithmSetting(
            name="init_channels",
            value="4"
        ),
        V1beta1AlgorithmSetting(
            name="num_nodes",
            value="3"
        ),
        
    ]
)

# Objective specification. For DARTS Goal is omitted.
objective_spec=V1beta1ObjectiveSpec(
    type="maximize",
    objective_metric_name="Best-Genotype",
)

# Metrics collector specification.
# We should specify metrics format to get Genotype from training container.
metrics_collector_spec=V1beta1MetricsCollectorSpec(
    collector=V1beta1CollectorSpec(
        kind="StdOut"
    ),
    source=V1beta1SourceSpec(
        filter=V1beta1FilterSpec(
            metrics_format=[
                "([\\w-]+)=(Genotype.*)"
            ]
        )
    )
)

# Configuration for the Neural Network (NN).
# This NN contains 2 number of layers and 5 various operations with different parameters.
nas_config=V1beta1NasConfig(
    graph_config=V1beta1GraphConfig(
        num_layers=2
    ),
    operations=[
        V1beta1Operation(
            operation_type="separable_convolution",
            parameters=[
                V1beta1ParameterSpec(
                    name="filter_size",
                    parameter_type="categorical",
                    feasible_space=V1beta1FeasibleSpace(
                        list=["3"]
                    ),
                )
            ]
        ),
        V1beta1Operation(
            operation_type="dilated_convolution",
            parameters=[
                V1beta1ParameterSpec(
                    name="filter_size",
                    parameter_type="categorical",
                    feasible_space=V1beta1FeasibleSpace(
                        list=["3", "5"]
                    ),
                )
            ]
        ),
        V1beta1Operation(
            operation_type="avg_pooling",
            parameters=[
                V1beta1ParameterSpec(
                    name="filter_size",
                    parameter_type="categorical",
                    feasible_space=V1beta1FeasibleSpace(
                        list=["3"]
                    ),
                )
            ]
        ),
        V1beta1Operation(
            operation_type="max_pooling",
            parameters=[
                V1beta1ParameterSpec(
                    name="filter_size",
                    parameter_type="categorical",
                    feasible_space=V1beta1FeasibleSpace(
                        list=["3"]
                    ),
                )
            ]
        ),
        V1beta1Operation(
            operation_type="skip_connection",
        ),
    ]
)


# JSON template specification for the Trial's Worker Kubernetes Job.
trial_spec={
    "apiVersion": "batch/v1",
    "kind": "Job",
    "spec": {
        "template": {
            "metadata": {
                "labels": {
                    "sidecar.istio.io/inject": "false"
                }
            },
            "spec": {
                "containers": [
                    {
                        "name": "training-container",
                        "image": "docker.io/kubeflowkatib/darts-cnn-cifar10:v0.13.0",
                        "command": [
                            'python3',
                            'run_trial.py',
                            '--algorithm-settings="${trialParameters.algorithmSettings}"',
                            '--search-space="${trialParameters.searchSpace}"',
                            '--num-layers="${trialParameters.numberLayers}"'
                        ],
                        # Training container requires 1 GPU.
                        "resources": {
                            "limits": {
                                "nvidia.com/gpu": 1
                            }
                        }
                    }
                ],
                "restartPolicy": "Never"
            }
        }
    }
}

# Template with Trial parameters and Trial spec.
# Set retain to True to save trial resources after completion.
trial_template=V1beta1TrialTemplate(
    retain=True,
    primary_container_name="training-container",
    trial_parameters=[
        V1beta1TrialParameterSpec(
            name="algorithmSettings",
            description=" Algorithm settings of DARTS Experiment",
            reference="algorithm-settings"
        ),
        V1beta1TrialParameterSpec(
            name="searchSpace",
            description="Search Space of DARTS Experiment",
            reference="search-space"
        ),
        V1beta1TrialParameterSpec(
            name="numberLayers",
            description="Number of Neural Network layers",
            reference="num-layers"
        ),
    ],
    trial_spec=trial_spec
)


# Experiment object.
experiment = V1beta1Experiment(
    api_version="kubeflow.org/v1beta1",
    kind="Experiment",
    metadata=metadata,
    spec=V1beta1ExperimentSpec(
        max_trial_count=1,
        parallel_trial_count=1,
        max_failed_trial_count=1,
        algorithm=algorithm_spec,
        objective=objective_spec,
        metrics_collector_spec=metrics_collector_spec,
        nas_config=nas_config,
        trial_template=trial_template,
    )
)

"""
You can print the Experiment's info to verify it before submission.
"""

# Print the Trial template container info.
print(experiment.spec.trial_template.trial_spec["spec"]["template"]["spec"]["containers"][0])
# Output:
#   {'name': 'training-container', 'image': 'docker.io/kubeflowkatib/darts-cnn-cifar10:v0.13.0', 'command': ['python3', 'run_trial.py', '--algorithm-settings="${trialParameters.algorithmSettings}"', '--search-space="${trialParameters.searchSpace}"', '--num-layers="${trialParameters.numberLayers}"'], 'resources': {'limits': {'nvidia.com/gpu': 1}}}


"""
## Create your Experiment

You have to create Katib client to use the SDK

TODO (andreyvelich): Current Experiment link for NAS is incorrect.
"""

# Create client.
kclient = KatibClient()

# Create your Experiment.
kclient.create_experiment(experiment,namespace=namespace)
# Output:
#   <IPython.core.display.HTML object>
#   {'apiVersion': 'kubeflow.org/v1beta1',

#    'kind': 'Experiment',

#    'metadata': {'creationTimestamp': '2021-10-05T23:49:49Z',

#     'generation': 1,

#     'managedFields': [{'apiVersion': 'kubeflow.org/v1beta1',

#       'fieldsType': 'FieldsV1',

#       'fieldsV1': {'f:spec': {'.': {},

#         'f:algorithm': {'.': {},

#          'f:algorithmName': {},

#          'f:algorithmSettings': {}},

#         'f:maxFailedTrialCount': {},

#         'f:maxTrialCount': {},

#         'f:metricsCollectorSpec': {'.': {},

#          'f:collector': {'.': {}, 'f:kind': {}},

#          'f:source': {'.': {}, 'f:filter': {'.': {}, 'f:metricsFormat': {}}}},

#         'f:nasConfig': {'.': {},

#          'f:graphConfig': {'.': {}, 'f:numLayers': {}},

#          'f:operations': {}},

#         'f:objective': {'.': {}, 'f:objectiveMetricName': {}, 'f:type': {}},

#         'f:parallelTrialCount': {},

#         'f:trialTemplate': {'.': {},

#          'f:primaryContainerName': {},

#          'f:retain': {},

#          'f:trialParameters': {},

#          'f:trialSpec': {'.': {},

#           'f:apiVersion': {},

#           'f:kind': {},

#           'f:spec': {'.': {},

#            'f:template': {'.': {},

#             'f:metadata': {'.': {},

#              'f:annotations': {'.': {}, 'f:sidecar.istio.io/inject': {}}},

#             'f:spec': {'.': {}, 'f:containers': {}, 'f:restartPolicy': {}}}}}}}},

#       'manager': 'OpenAPI-Generator',

#       'operation': 'Update',

#       'time': '2021-10-05T23:49:49Z'}],

#     'name': 'darts-example',

#     'namespace': 'kubeflow-user-example-com',

#     'resourceVersion': '393947521',

#     'uid': '3fbda962-64c0-4474-b1de-03b390f96369'},

#    'spec': {'algorithm': {'algorithmName': 'darts',

#      'algorithmSettings': [{'name': 'num_epochs', 'value': '2'},

#       {'name': 'stem_multiplier', 'value': '1'},

#       {'name': 'init_channels', 'value': '4'},

#       {'name': 'num_nodes', 'value': '3'}]},

#     'maxFailedTrialCount': 1,

#     'maxTrialCount': 1,

#     'metricsCollectorSpec': {'collector': {'kind': 'StdOut'},

#      'source': {'filter': {'metricsFormat': ['([\\w-]+)=(Genotype.*)']}}},

#     'nasConfig': {'graphConfig': {'numLayers': 2},

#      'operations': [{'operationType': 'separable_convolution',

#        'parameters': [{'feasibleSpace': {'list': ['3']},

#          'name': 'filter_size',

#          'parameterType': 'categorical'}]},

#       {'operationType': 'dilated_convolution',

#        'parameters': [{'feasibleSpace': {'list': ['3', '5']},

#          'name': 'filter_size',

#          'parameterType': 'categorical'}]},

#       {'operationType': 'avg_pooling',

#        'parameters': [{'feasibleSpace': {'list': ['3']},

#          'name': 'filter_size',

#          'parameterType': 'categorical'}]},

#       {'operationType': 'max_pooling',

#        'parameters': [{'feasibleSpace': {'list': ['3']},

#          'name': 'filter_size',

#          'parameterType': 'categorical'}]},

#       {'operationType': 'skip_connection'}]},

#     'objective': {'metricStrategies': [{'name': 'Best-Genotype',

#        'value': 'max'}],

#      'objectiveMetricName': 'Best-Genotype',

#      'type': 'maximize'},

#     'parallelTrialCount': 1,

#     'resumePolicy': 'Never',

#     'trialTemplate': {'failureCondition': 'status.conditions.#(type=="Failed")#|#(status=="True")#',

#      'primaryContainerName': 'training-container',

#      'retain': True,

#      'successCondition': 'status.conditions.#(type=="Complete")#|#(status=="True")#',

#      'trialParameters': [{'description': ' Algorithm settings of DARTS Experiment',

#        'name': 'algorithmSettings',

#        'reference': 'algorithm-settings'},

#       {'description': 'Search Space of DARTS Experiment',

#        'name': 'searchSpace',

#        'reference': 'search-space'},

#       {'description': 'Number of Neural Network layers',

#        'name': 'numberLayers',

#        'reference': 'num-layers'}],

#      'trialSpec': {'apiVersion': 'batch/v1',

#       'kind': 'Job',

#       'spec': {'template': {'metadata': {'annotations': {'sidecar.istio.io/inject': 'false'}},

#         'spec': {'containers': [{'command': ['python3',

#             'run_trial.py',

#             '--algorithm-settings="${trialParameters.algorithmSettings}"',

#             '--search-space="${trialParameters.searchSpace}"',

#             '--num-layers="${trialParameters.numberLayers}"'],

#            'image': 'docker.io/kubeflowkatib/darts-cnn-cifar10:v0.13.0',

#            'name': 'training-container',

#            'resources': {'limits': {'nvidia.com/gpu': 1}}}],

#          'restartPolicy': 'Never'}}}}}}}

"""
## Get your Experiment

You can get your Experiment by name and receive required data.
"""

exp = kclient.get_experiment(name=experiment_name, namespace=namespace)
print(exp)
print("-----------------\n")

# Get the latest status.
print(exp["status"]["conditions"][-1])
# Output:
#   {'apiVersion': 'kubeflow.org/v1beta1', 'kind': 'Experiment', 'metadata': {'creationTimestamp': '2021-10-05T23:49:49Z', 'finalizers': ['update-prometheus-metrics'], 'generation': 1, 'managedFields': [{'apiVersion': 'kubeflow.org/v1beta1', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:spec': {'.': {}, 'f:algorithm': {'.': {}, 'f:algorithmName': {}, 'f:algorithmSettings': {}}, 'f:maxFailedTrialCount': {}, 'f:maxTrialCount': {}, 'f:metricsCollectorSpec': {'.': {}, 'f:collector': {'.': {}, 'f:kind': {}}, 'f:source': {'.': {}, 'f:filter': {'.': {}, 'f:metricsFormat': {}}}}, 'f:nasConfig': {'.': {}, 'f:graphConfig': {'.': {}, 'f:numLayers': {}}, 'f:operations': {}}, 'f:objective': {'.': {}, 'f:objectiveMetricName': {}, 'f:type': {}}, 'f:parallelTrialCount': {}, 'f:trialTemplate': {'.': {}, 'f:primaryContainerName': {}, 'f:retain': {}, 'f:trialParameters': {}, 'f:trialSpec': {'.': {}, 'f:apiVersion': {}, 'f:kind': {}, 'f:spec': {'.': {}, 'f:template': {'.': {}, 'f:metadata': {'.': {}, 'f:annotations': {'.': {}, 'f:sidecar.istio.io/inject': {}}}, 'f:spec': {'.': {}, 'f:containers': {}, 'f:restartPolicy': {}}}}}}}}, 'manager': 'OpenAPI-Generator', 'operation': 'Update', 'time': '2021-10-05T23:49:49Z'}, {'apiVersion': 'kubeflow.org/v1beta1', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:metadata': {'f:finalizers': {'.': {}, 'v:"update-prometheus-metrics"': {}}}, 'f:status': {'.': {}, 'f:conditions': {}, 'f:currentOptimalTrial': {'.': {}, 'f:bestTrialName': {}, 'f:observation': {'.': {}, 'f:metrics': {}}, 'f:parameterAssignments': {}}, 'f:runningTrialList': {}, 'f:startTime': {}, 'f:trials': {}, 'f:trialsRunning': {}}}, 'manager': 'katib-controller', 'operation': 'Update', 'time': '2021-10-05T23:50:31Z'}], 'name': 'darts-example', 'namespace': 'kubeflow-user-example-com', 'resourceVersion': '393948698', 'uid': '3fbda962-64c0-4474-b1de-03b390f96369'}, 'spec': {'algorithm': {'algorithmName': 'darts', 'algorithmSettings': [{'name': 'num_epochs', 'value': '2'}, {'name': 'stem_multiplier', 'value': '1'}, {'name': 'init_channels', 'value': '4'}, {'name': 'num_nodes', 'value': '3'}]}, 'maxFailedTrialCount': 1, 'maxTrialCount': 1, 'metricsCollectorSpec': {'collector': {'kind': 'StdOut'}, 'source': {'filter': {'metricsFormat': ['([\\w-]+)=(Genotype.*)']}}}, 'nasConfig': {'graphConfig': {'numLayers': 2}, 'operations': [{'operationType': 'separable_convolution', 'parameters': [{'feasibleSpace': {'list': ['3']}, 'name': 'filter_size', 'parameterType': 'categorical'}]}, {'operationType': 'dilated_convolution', 'parameters': [{'feasibleSpace': {'list': ['3', '5']}, 'name': 'filter_size', 'parameterType': 'categorical'}]}, {'operationType': 'avg_pooling', 'parameters': [{'feasibleSpace': {'list': ['3']}, 'name': 'filter_size', 'parameterType': 'categorical'}]}, {'operationType': 'max_pooling', 'parameters': [{'feasibleSpace': {'list': ['3']}, 'name': 'filter_size', 'parameterType': 'categorical'}]}, {'operationType': 'skip_connection'}]}, 'objective': {'metricStrategies': [{'name': 'Best-Genotype', 'value': 'max'}], 'objectiveMetricName': 'Best-Genotype', 'type': 'maximize'}, 'parallelTrialCount': 1, 'resumePolicy': 'Never', 'trialTemplate': {'failureCondition': 'status.conditions.#(type=="Failed")#|#(status=="True")#', 'primaryContainerName': 'training-container', 'retain': True, 'successCondition': 'status.conditions.#(type=="Complete")#|#(status=="True")#', 'trialParameters': [{'description': ' Algorithm settings of DARTS Experiment', 'name': 'algorithmSettings', 'reference': 'algorithm-settings'}, {'description': 'Search Space of DARTS Experiment', 'name': 'searchSpace', 'reference': 'search-space'}, {'description': 'Number of Neural Network layers', 'name': 'numberLayers', 'reference': 'num-layers'}], 'trialSpec': {'apiVersion': 'batch/v1', 'kind': 'Job', 'spec': {'template': {'metadata': {'annotations': {'sidecar.istio.io/inject': 'false'}}, 'spec': {'containers': [{'command': ['python3', 'run_trial.py', '--algorithm-settings="${trialParameters.algorithmSettings}"', '--search-space="${trialParameters.searchSpace}"', '--num-layers="${trialParameters.numberLayers}"'], 'image': 'docker.io/kubeflowkatib/darts-cnn-cifar10:v0.13.0', 'name': 'training-container', 'resources': {'limits': {'nvidia.com/gpu': 1}}}], 'restartPolicy': 'Never'}}}}}}, 'status': {'conditions': [{'lastTransitionTime': '2021-10-05T23:49:49Z', 'lastUpdateTime': '2021-10-05T23:49:49Z', 'message': 'Experiment is created', 'reason': 'ExperimentCreated', 'status': 'True', 'type': 'Created'}, {'lastTransitionTime': '2021-10-05T23:50:30Z', 'lastUpdateTime': '2021-10-05T23:50:30Z', 'message': 'Experiment is running', 'reason': 'ExperimentRunning', 'status': 'True', 'type': 'Running'}], 'currentOptimalTrial': {'bestTrialName': '', 'observation': {'metrics': None}, 'parameterAssignments': None}, 'runningTrialList': ['darts-example-n4fpnxlm'], 'startTime': '2021-10-05T23:49:49Z', 'trials': 1, 'trialsRunning': 1}}

#   -----------------

#   

#   {'lastTransitionTime': '2021-10-05T23:50:30Z', 'lastUpdateTime': '2021-10-05T23:50:30Z', 'message': 'Experiment is running', 'reason': 'ExperimentRunning', 'status': 'True', 'type': 'Running'}


"""
## Get the current Experiment status

You can check the current Experiment status.
"""

kclient.get_experiment_status(name=experiment_name, namespace=namespace)
# Output:
#   'Succeeded'

"""
You can check if your Experiment is succeeded.
"""

kclient.is_experiment_succeeded(name=experiment_name, namespace=namespace)
# Output:
#   True

"""
## Get the best Genotype

Best Genotype is located in the optimal Trial currently. The latest Genotype is the best.

Check your Trial logs to get more information about the training process.
"""

opt_trial = kclient.get_optimal_hyperparameters(name=experiment_name, namespace=namespace)

best_genotype = opt_trial["currentOptimalTrial"]["observation"]["metrics"][0]["latest"]
print(best_genotype)
# Output:
#   Genotype(normal=[[('separable_convolution_3x3',0),('dilated_convolution_3x3',1)],[('dilated_convolution_3x3',2),('dilated_convolution_5x5',1)],[('dilated_convolution_5x5',2),('separable_convolution_3x3',3)]],normal_concat=range(2,5),reduce=[[('separable_convolution_3x3',1),('separable_convolution_3x3',0)],[('max_pooling_3x3',2),('max_pooling_3x3',1)],[('max_pooling_3x3',2),('max_pooling_3x3',3)]],reduce_concat=range(2,5))


"""
## Delete your Experiments

You can delete your Experiments.
"""

kclient.delete_experiment(name=experiment_name, namespace=namespace)
# Output:
#   {'apiVersion': 'kubeflow.org/v1beta1',

#    'kind': 'Experiment',

#    'metadata': {'creationTimestamp': '2021-10-05T23:49:49Z',

#     'deletionGracePeriodSeconds': 0,

#     'deletionTimestamp': '2021-10-05T23:58:39Z',

#     'finalizers': ['update-prometheus-metrics'],

#     'generation': 2,

#     'managedFields': [{'apiVersion': 'kubeflow.org/v1beta1',

#       'fieldsType': 'FieldsV1',

#       'fieldsV1': {'f:spec': {'.': {},

#         'f:algorithm': {'.': {},

#          'f:algorithmName': {},

#          'f:algorithmSettings': {}},

#         'f:maxFailedTrialCount': {},

#         'f:maxTrialCount': {},

#         'f:metricsCollectorSpec': {'.': {},

#          'f:collector': {'.': {}, 'f:kind': {}},

#          'f:source': {'.': {}, 'f:filter': {'.': {}, 'f:metricsFormat': {}}}},

#         'f:nasConfig': {'.': {},

#          'f:graphConfig': {'.': {}, 'f:numLayers': {}},

#          'f:operations': {}},

#         'f:objective': {'.': {}, 'f:objectiveMetricName': {}, 'f:type': {}},

#         'f:parallelTrialCount': {},

#         'f:trialTemplate': {'.': {},

#          'f:primaryContainerName': {},

#          'f:retain': {},

#          'f:trialParameters': {},

#          'f:trialSpec': {'.': {},

#           'f:apiVersion': {},

#           'f:kind': {},

#           'f:spec': {'.': {},

#            'f:template': {'.': {},

#             'f:metadata': {'.': {},

#              'f:annotations': {'.': {}, 'f:sidecar.istio.io/inject': {}}},

#             'f:spec': {'.': {}, 'f:containers': {}, 'f:restartPolicy': {}}}}}}}},

#       'manager': 'OpenAPI-Generator',

#       'operation': 'Update',

#       'time': '2021-10-05T23:49:49Z'},

#      {'apiVersion': 'kubeflow.org/v1beta1',

#       'fieldsType': 'FieldsV1',

#       'fieldsV1': {'f:metadata': {'f:finalizers': {'.': {},

#          'v:"update-prometheus-metrics"': {}}},

#        'f:status': {'.': {},

#         'f:completionTime': {},

#         'f:conditions': {},

#         'f:currentOptimalTrial': {'.': {},

#          'f:bestTrialName': {},

#          'f:observation': {'.': {}, 'f:metrics': {}},

#          'f:parameterAssignments': {}},

#         'f:startTime': {},

#         'f:succeededTrialList': {},

#         'f:trials': {},

#         'f:trialsSucceeded': {}}},

#       'manager': 'katib-controller',

#       'operation': 'Update',

#       'time': '2021-10-05T23:54:31Z'}],

#     'name': 'darts-example',

#     'namespace': 'kubeflow-user-example-com',

#     'resourceVersion': '393962398',

#     'uid': '3fbda962-64c0-4474-b1de-03b390f96369'},

#    'spec': {'algorithm': {'algorithmName': 'darts',

#      'algorithmSettings': [{'name': 'num_epochs', 'value': '2'},

#       {'name': 'stem_multiplier', 'value': '1'},

#       {'name': 'init_channels', 'value': '4'},

#       {'name': 'num_nodes', 'value': '3'}]},

#     'maxFailedTrialCount': 1,

#     'maxTrialCount': 1,

#     'metricsCollectorSpec': {'collector': {'kind': 'StdOut'},

#      'source': {'filter': {'metricsFormat': ['([\\w-]+)=(Genotype.*)']}}},

#     'nasConfig': {'graphConfig': {'numLayers': 2},

#      'operations': [{'operationType': 'separable_convolution',

#        'parameters': [{'feasibleSpace': {'list': ['3']},

#          'name': 'filter_size',

#          'parameterType': 'categorical'}]},

#       {'operationType': 'dilated_convolution',

#        'parameters': [{'feasibleSpace': {'list': ['3', '5']},

#          'name': 'filter_size',

#          'parameterType': 'categorical'}]},

#       {'operationType': 'avg_pooling',

#        'parameters': [{'feasibleSpace': {'list': ['3']},

#          'name': 'filter_size',

#          'parameterType': 'categorical'}]},

#       {'operationType': 'max_pooling',

#        'parameters': [{'feasibleSpace': {'list': ['3']},

#          'name': 'filter_size',

#          'parameterType': 'categorical'}]},

#       {'operationType': 'skip_connection'}]},

#     'objective': {'metricStrategies': [{'name': 'Best-Genotype',

#        'value': 'max'}],

#      'objectiveMetricName': 'Best-Genotype',

#      'type': 'maximize'},

#     'parallelTrialCount': 1,

#     'resumePolicy': 'Never',

#     'trialTemplate': {'failureCondition': 'status.conditions.#(type=="Failed")#|#(status=="True")#',

#      'primaryContainerName': 'training-container',

#      'retain': True,

#      'successCondition': 'status.conditions.#(type=="Complete")#|#(status=="True")#',

#      'trialParameters': [{'description': ' Algorithm settings of DARTS Experiment',

#        'name': 'algorithmSettings',

#        'reference': 'algorithm-settings'},

#       {'description': 'Search Space of DARTS Experiment',

#        'name': 'searchSpace',

#        'reference': 'search-space'},

#       {'description': 'Number of Neural Network layers',

#        'name': 'numberLayers',

#        'reference': 'num-layers'}],

#      'trialSpec': {'apiVersion': 'batch/v1',

#       'kind': 'Job',

#       'spec': {'template': {'metadata': {'annotations': {'sidecar.istio.io/inject': 'false'}},

#         'spec': {'containers': [{'command': ['python3',

#             'run_trial.py',

#             '--algorithm-settings="${trialParameters.algorithmSettings}"',

#             '--search-space="${trialParameters.searchSpace}"',

#             '--num-layers="${trialParameters.numberLayers}"'],

#            'image': 'docker.io/kubeflowkatib/darts-cnn-cifar10:v0.13.0',

#            'name': 'training-container',

#            'resources': {'limits': {'nvidia.com/gpu': 1}}}],

#          'restartPolicy': 'Never'}}}}}},

#    'status': {'completionTime': '2021-10-05T23:54:31Z',

#     'conditions': [{'lastTransitionTime': '2021-10-05T23:49:49Z',

#       'lastUpdateTime': '2021-10-05T23:49:49Z',

#       'message': 'Experiment is created',

#       'reason': 'ExperimentCreated',

#       'status': 'True',

#       'type': 'Created'},

#      {'lastTransitionTime': '2021-10-05T23:54:31Z',

#       'lastUpdateTime': '2021-10-05T23:54:31Z',

#       'message': 'Experiment is running',

#       'reason': 'ExperimentRunning',

#       'status': 'False',

#       'type': 'Running'},

#      {'lastTransitionTime': '2021-10-05T23:54:31Z',

#       'lastUpdateTime': '2021-10-05T23:54:31Z',

#       'message': 'Experiment has succeeded because max trial count has reached',

#       'reason': 'ExperimentMaxTrialsReached',

#       'status': 'True',

#       'type': 'Succeeded'}],

#     'currentOptimalTrial': {'bestTrialName': 'darts-example-n4fpnxlm',

#      'observation': {'metrics': [{'latest': "Genotype(normal=[[('separable_convolution_3x3',0),('dilated_convolution_3x3',1)],[('dilated_convolution_3x3',2),('dilated_convolution_5x5',1)],[('dilated_convolution_5x5',2),('separable_convolution_3x3',3)]],normal_concat=range(2,5),reduce=[[('separable_convolution_3x3',1),('separable_convolution_3x3',0)],[('max_pooling_3x3',2),('max_pooling_3x3',1)],[('max_pooling_3x3',2),('max_pooling_3x3',3)]],reduce_concat=range(2,5))",

#         'max': 'unavailable',

#         'min': 'unavailable',

#         'name': 'Best-Genotype'}]},

#      'parameterAssignments': [{'name': 'algorithm-settings',

#        'value': "{'num_epochs': '2', 'w_lr': 0.025, 'w_lr_min': 0.001, 'w_momentum': 0.9, 'w_weight_decay': 0.0003, 'w_grad_clip': 5.0, 'alpha_lr': 0.0003, 'alpha_weight_decay': 0.001, 'batch_size': 128, 'num_workers': 4, 'init_channels': '4', 'print_step': 50, 'num_nodes': '3', 'stem_multiplier': '1'}"},

#       {'name': 'search-space',

#        'value': "['separable_convolution_3x3', 'dilated_convolution_3x3', 'dilated_convolution_5x5', 'avg_pooling_3x3', 'max_pooling_3x3', 'skip_connection']"},

#       {'name': 'num-layers', 'value': '2'}]},

#     'startTime': '2021-10-05T23:49:49Z',

#     'succeededTrialList': ['darts-example-n4fpnxlm'],

#     'trials': 1,

#     'trialsSucceeded': 1}}



================================================
FILE: examples/v1beta1/tekton/README.md
================================================
# Katib Examples with Tekton Pipelines Integration

Here you can find examples of using Katib with [Tekton](https://github.com/tektoncd/pipeline).

## Installation

### Tekton Pipelines

To deploy Tekton Pipelines `v0.26.0`, run the following command:

```bash
kubectl apply -f https://storage.googleapis.com/tekton-releases/pipeline/previous/v0.26.0/release.yaml
```

Check that Tekton Pipelines components are running:

```bash
$ kubectl get pods -n tekton-pipelines

NAME                                           READY   STATUS    RESTARTS   AGE
tekton-pipelines-controller-799cdc78fc-sm4vl   1/1     Running   0          50s
tekton-pipelines-webhook-79d8f4f9bc-qmk97      1/1     Running   0          50s
```

**Note:** You must modify Tekton [`nop`](https://github.com/tektoncd/pipeline/tree/master/cmd/nop)
image to run Tekton Pipelines. `Nop` image is used to stop sidecar containers after main container
is completed. Since Katib is using Metrics Collector sidecar container
and Tekton Pipelines Controller should not kill sidecar containers, you have to
set this `nop` image to Metrics Collector image.

For example, if you are using
[StdOut](https://www.kubeflow.org/docs/components/katib/experiment/#metrics-collector) Metrics Collector,
`nop` image must be equal to `ghcr.io/kubeflow/katib/file-metrics-collector`.

Run the following command to modify the `nop` image:

```bash
kubectl patch deploy tekton-pipelines-controller -n tekton-pipelines --type='json' \
  -p='[{"op": "replace", "path": "/spec/template/spec/containers/0/args/9", "value": "ghcr.io/kubeflow/katib/file-metrics-collector"}]'
```

Check that Tekton Pipelines Controller's pod was restarted:

```bash
$ kubectl get pods -n tekton-pipelines

NAME                                           READY   STATUS    RESTARTS   AGE
tekton-pipelines-controller-7fcb6c6cd4-p8zf2   1/1     Running   0          2m2s
tekton-pipelines-webhook-7f9888f9b-7d6mr       1/1     Running   0          3m
```

Verify that `nop` image was modified:

```bash
$ kubectl get $(kubectl get pods -o name -n tekton-pipelines | grep tekton-pipelines-controller) -n tekton-pipelines -o yaml | grep katib

   - ghcr.io/kubeflow/katib/file-metrics-collector
```

### Katib Controller

To run Tekton Pipelines within Katib Trials you have to update Katib
[ClusterRole's rules](https://github.com/kubeflow/katib/blob/master/manifests/v1beta1/components/controller/rbac.yaml#L5)
with the appropriate permission:

```yaml
- apiGroups:
    - tekton.dev
  resources:
    - pipelineruns
    - taskruns
  verbs:
    - "get"
    - "list"
    - "watch"
    - "create"
    - "delete"
```

Run the following command to update Katib ClusterRole:

```bash
kubectl patch ClusterRole katib-controller -n kubeflow --type=json \
  -p='[{"op": "add", "path": "/rules/-", "value": {"apiGroups":["tekton.dev"],"resources":["pipelineruns", "taskruns"],"verbs":["get", "list", "watch", "create", "delete"]}}]'
```

Modify Katib Config [controller parameters](https://github.com/kubeflow/katib/blob/fc858d15dd41ff69166a2020efa200199063f9ba/manifests/v1beta1/installs/katib-standalone/katib-config.yaml#L9-L15) with the new entity:

```
trialResources:
 - <object-kind>.<object-API-version>.<object-API-group>
```

For example, to support Tekton Pipelines:

```
trialResources:
  - PipelineRun.v1beta1.tekton.dev
```

After these changes, deploy Katib as described in the [install guide](https://www.kubeflow.org/docs/components/katib/installation/) and wait until the katib-controller Pod is created. You can check logs from the Katib controller to verify your resource integration:

```bash
$ kubectl logs $(kubectl get pods -n kubeflow -o name | grep katib-controller) -n kubeflow | grep '"CRD Kind":"PipelineRun"'

{"level":"info","ts":1628032648.6285546,"logger":"trial-controller","msg":"Job watch added successfully","CRD Group":"tekton.dev","CRD Version":"v1beta1","CRD Kind":"PipelineRun"}
```

If you ran the above steps successfully, you should be able to run Tekton Pipelines examples.

Learn more about using custom Kubernetes resource as a Trial template in the
[official Kubeflow guides](https://www.kubeflow.org/docs/components/katib/user-guides/trial-template/#use-crds-with-trial-template).



================================================
FILE: examples/v1beta1/tekton/pipeline-run.yaml
================================================
---
# This example shows how you can use Tekton Pipelines in Katib, transfer parameters from one Task to another and run HP job.
# It uses simple random algorithm and tunes only learning rate.
# Pipelines contains 2 Tasks, first is data-preprocessing second is model-training.
# First Task shows how you can prepare your training data (here: simply divide number of training examples) before running HP job.
# Number of training examples is transferred to the second Task.
# Second Task is the actual training which metrics collector sidecar is injected.
# Note that for this example Tekton controller's nop image must be equal to StdOut metrics collector image.
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: tekton-pipeline-run
spec:
  objective:
    type: minimize
    goal: 0.001
    objectiveMetricName: loss
  algorithm:
    algorithmName: random
  parallelTrialCount: 2
  maxTrialCount: 4
  maxFailedTrialCount: 3
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.03"
  trialTemplate:
    retain: true
    primaryPodLabels:
      tekton.dev/pipelineTask: model-training
    primaryContainerName: step-model-training
    successCondition: status.conditions.#(type=="Succeeded")#|#(status=="True")#
    failureCondition: status.conditions.#(type=="Succeeded")#|#(status=="False")#
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
    trialSpec:
      apiVersion: tekton.dev/v1beta1
      kind: PipelineRun
      spec:
        params:
          - name: learningRate
            description: Learning rate for the training model
            reference: lr
          - name: epochs-init
            value: "60000"
        pipelineSpec:
          params:
            - name: lr
              description: Learning rate for the training model
            - name: epochs-init
              description: Initial value for number of training examples
          tasks:
            - name: data-preprocessing
              params:
                - name: epochs-pre
                  value: $(params.epochs-init)
              taskSpec:
                params:
                  - name: epochs-pre
                    description: Number of training examples before optimization
                results:
                  - name: epochs-post
                    description: Number of training examples after optimization
                steps:
                  - name: epochs-optimize
                    image: python:alpine3.6
                    command:
                      - sh
                      - -c
                    args:
                      - python3 -c "import random; print($(params.epochs-pre)//random.randint(3000,30000),end='')" | tee $(results.epochs-post.path)
            - name: model-training
              params:
                - name: lr
                  value: $(params.lr)
                - name: epochs
                  value: $(tasks.data-preprocessing.results.epochs-post)
              taskSpec:
                params:
                  - name: lr
                    description: Learning rate for the training model
                  - name: epochs
                    description: Number of epochs
                steps:
                  - name: model-training
                    image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
                    command:
                      - "python3"
                      - "/opt/pytorch-mnist/mnist.py"
                      - "--epochs=$(params.epochs)"
                      - "--batch-size=16"
                      - "--lr=$(trialParameters.lr)"



================================================
FILE: examples/v1beta1/trial-images/darts-cnn-cifar10/README.md
================================================
# Differentiable Architecture Search (DARTS) Training Container

This is training container for the DARTS algorithm. It uses PyTorch convolutional neural
network and CIFAR-10 dataset to train the model.

To know more about using DARTS in Katib, check
[this guide](../../../../pkg/suggestion/v1beta1/nas/darts/).

Katib uses this training container in the [DARTS Experiments](../../nas/darts-gpu.yaml#L78-L89).



================================================
FILE: examples/v1beta1/trial-images/darts-cnn-cifar10/architect.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import copy

import torch


class Architect:
    """ " Architect controls architecture of cell by computing gradients of alphas"""

    def __init__(self, model, w_momentum, w_weight_decay, device):
        self.model = model
        self.v_model = copy.deepcopy(model)
        self.w_momentum = w_momentum
        self.w_weight_decay = w_weight_decay
        self.device = device

    def virtual_step(self, train_x, train_y, xi, w_optim):
        """
        Compute unrolled weight w' (virtual step)
        Step process:
        1) forward
        2) calculate loss
        3) compute gradient (by backprop)
        4) update gradient

        Args:
            xi: learning rate for virtual gradient step (same as weights lr)
            w_optim: weights optimizer
        """

        # Forward and calculate loss
        # Loss for train with w. L_train(w)
        loss = self.model.loss(train_x, train_y)

        # Compute gradient
        gradients = torch.autograd.grad(loss, self.model.getWeights())

        # Do virtual step (Update gradient)
        # Below operations do not need gradient tracking
        with torch.no_grad():
            # dict key is not the value, but the pointer. So original network weight have to
            # be iterated also.
            for w, vw, g in zip(
                self.model.getWeights(), self.v_model.getWeights(), gradients
            ):
                m = w_optim.state[w].get("momentum_buffer", 0.0) * self.w_momentum
                if self.device == "cuda":
                    vw.copy_(
                        w
                        - torch.cuda.FloatTensor(xi) * (m + g + self.w_weight_decay * w)
                    )
                elif self.device == "cpu":
                    vw.copy_(
                        w - torch.FloatTensor(xi) * (m + g + self.w_weight_decay * w)
                    )

            # Sync alphas
            for a, va in zip(self.model.getAlphas(), self.v_model.getAlphas()):
                va.copy_(a)

    def unrolled_backward(self, train_x, train_y, valid_x, valid_y, xi, w_optim):
        """Compute unrolled loss and backward its gradients
        Args:
            xi: learning rate for virtual gradient step (same as model lr)
            w_optim: weights optimizer - for virtual step
        """
        # Do virtual step (calc w')
        self.virtual_step(train_x, train_y, xi, w_optim)

        # Calculate unrolled loss
        # Loss for validation with w'. L_valid(w')
        loss = self.v_model.loss(valid_x, valid_y)

        # Calculate gradient
        v_alphas = tuple(self.v_model.getAlphas())
        v_weights = tuple(self.v_model.getWeights())
        v_grads = torch.autograd.grad(loss, v_alphas + v_weights)

        dalpha = v_grads[: len(v_alphas)]
        dws = v_grads[len(v_alphas) :]

        hessian = self.compute_hessian(dws, train_x, train_y)

        # Update final gradient = dalpha - xi * hessian
        with torch.no_grad():
            for alpha, da, h in zip(self.model.getAlphas(), dalpha, hessian):
                if self.device == "cuda":
                    alpha.grad = da - torch.cuda.FloatTensor(xi) * h
                elif self.device == "cpu":
                    alpha.grad = da - torch.cpu.FloatTensor(xi) * h

    def compute_hessian(self, dws, train_x, train_y):
        """
        dw = dw' { L_valid(w', alpha) }
        w+ = w + eps * dw
        w- = w - eps * dw
        hessian = (dalpha{ L_train(w+, alpha) } - dalpha{ L_train(w-, alpha) }) / (2*eps)
        eps = 0.01 / ||dw||
        """

        norm = torch.cat([dw.view(-1) for dw in dws]).norm()
        eps = 0.01 / norm

        # w+ = w + eps * dw
        with torch.no_grad():
            for p, dw in zip(self.model.getWeights(), dws):
                p += eps * dw

        loss = self.model.loss(train_x, train_y)
        # dalpha { L_train(w+, alpha) }
        dalpha_positive = torch.autograd.grad(loss, self.model.getAlphas())

        # w- = w - eps * dw
        with torch.no_grad():
            for p, dw in zip(self.model.getWeights(), dws):
                # TODO (andreyvelich): Do we need this * 2.0 ?
                p -= 2.0 * eps * dw

        loss = self.model.loss(train_x, train_y)
        # dalpha { L_train(w-, alpha) }
        dalpha_negative = torch.autograd.grad(loss, self.model.getAlphas())

        # recover w
        with torch.no_grad():
            for p, dw in zip(self.model.getWeights(), dws):
                p += eps * dw

        hessian = [
            (p - n) / (2.0 * eps) for p, n in zip(dalpha_positive, dalpha_negative)
        ]
        return hessian



================================================
FILE: examples/v1beta1/trial-images/darts-cnn-cifar10/Dockerfile.cpu
================================================
FROM python:3.11-slim

ENV TARGET_DIR /opt/darts-cnn-cifar10

ADD examples/v1beta1/trial-images/darts-cnn-cifar10 ${TARGET_DIR}

WORKDIR ${TARGET_DIR}

# TODO (andreyvelich): This is required since torchvision==0.17.1 is incompatible with numpy 2.0
RUN pip install numpy==1.26.0
RUN pip install --prefer-binary --no-cache-dir torch==2.2.1 torchvision==0.17.1

RUN chgrp -R 0 ${TARGET_DIR} \
  && chmod -R g+rwX ${TARGET_DIR}

ENTRYPOINT ["python3", "-u", "run_trial.py"]



================================================
FILE: examples/v1beta1/trial-images/darts-cnn-cifar10/Dockerfile.gpu
================================================
# We need to use the nvcr.io/nvidia/pytorch image as a base image to support both linux/amd64 and linux_arm64 platforms.
# PyTorch=2.2.0, cuda=12.3.2
# Ref: https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/rel-24-01.html#rel-24-01
FROM nvcr.io/nvidia/pytorch:24.01-py3

ENV TARGET_DIR /opt/darts-cnn-cifar10

ADD examples/v1beta1/trial-images/darts-cnn-cifar10 ${TARGET_DIR}

WORKDIR  ${TARGET_DIR}

RUN chgrp -R 0 ${TARGET_DIR} \
  && chmod -R g+rwX ${TARGET_DIR}

ENTRYPOINT ["python3", "-u", "run_trial.py"]



================================================
FILE: examples/v1beta1/trial-images/darts-cnn-cifar10/model.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import torch
import torch.nn as nn
import torch.nn.functional as F
from operations import FactorizedReduce, MixedOp, StdConv


class Cell(nn.Module):
    """Cell for search
    Each edge is mixed and continuous relaxed.
    """

    def __init__(
        self,
        num_nodes,
        c_prev_prev,
        c_prev,
        c_cur,
        reduction_prev,
        reduction_cur,
        search_space,
    ):
        """
        Args:
            num_nodes: Number of intermediate cell nodes
            c_prev_prev: channels_out[k-2]
            c_prev : Channels_out[k-1]
            c_cur   : Channels_in[k] (current)
            reduction_prev: flag for whether the previous cell is reduction cell or not
            reduction_cur: flag for whether the current cell is reduction cell or not
        """

        super(Cell, self).__init__()
        self.reduction_cur = reduction_cur
        self.num_nodes = num_nodes

        # If previous cell is reduction cell, current input size does not match with
        # output size of cell[k-2]. So the output[k-2] should be reduced by preprocessing
        if reduction_prev:
            self.preprocess0 = FactorizedReduce(c_prev_prev, c_cur)
        else:
            self.preprocess0 = StdConv(
                c_prev_prev, c_cur, kernel_size=1, stride=1, padding=0
            )
        self.preprocess1 = StdConv(c_prev, c_cur, kernel_size=1, stride=1, padding=0)

        # Generate dag from mixed operations
        self.dag_ops = nn.ModuleList()

        for i in range(self.num_nodes):
            self.dag_ops.append(nn.ModuleList())
            # Include 2 input nodes
            for j in range(2 + i):
                # Reduction with stride = 2 must be only for the input node
                stride = 2 if reduction_cur and j < 2 else 1
                op = MixedOp(c_cur, stride, search_space)
                self.dag_ops[i].append(op)

    def forward(self, s0, s1, w_dag):
        s0 = self.preprocess0(s0)
        s1 = self.preprocess1(s1)

        states = [s0, s1]
        for edges, w_list in zip(self.dag_ops, w_dag):
            state_cur = sum(
                edges[i](s, w) for i, (s, w) in enumerate((zip(states, w_list)))
            )
            states.append(state_cur)

        state_out = torch.cat(states[2:], dim=1)
        return state_out


class NetworkCNN(nn.Module):

    def __init__(
        self,
        init_channels,
        input_channels,
        num_classes,
        num_layers,
        criterion,
        search_space,
        num_nodes,
        stem_multiplier,
    ):
        super(NetworkCNN, self).__init__()

        self.init_channels = init_channels
        self.num_classes = num_classes
        self.num_layers = num_layers
        self.criterion = criterion

        self.num_nodes = num_nodes
        self.stem_multiplier = stem_multiplier

        c_cur = self.stem_multiplier * self.init_channels

        self.stem = nn.Sequential(
            nn.Conv2d(input_channels, c_cur, 3, padding=1, bias=False),
            nn.BatchNorm2d(c_cur),
        )

        # In first Cell stem is used for s0 and s1
        # c_prev_prev and c_prev - output channels size
        # c_cur - init channels size
        c_prev_prev, c_prev, c_cur = c_cur, c_cur, self.init_channels

        self.cells = nn.ModuleList()

        reduction_prev = False
        for i in range(self.num_layers):
            # For Network with 1 layer: Only Normal Cell
            if self.num_layers == 1:
                reduction_cur = False
            else:
                # For Network with two layers: First layer - Normal, Second - Reduction
                # For Other Networks: [1/3, 2/3] Layers - Reduction cell with double channels
                # Others - Normal cell
                if (self.num_layers == 2 and i == 1) or (
                    self.num_layers > 2
                    and i in [self.num_layers // 3, 2 * self.num_layers // 3]
                ):
                    c_cur *= 2
                    reduction_cur = True
                else:
                    reduction_cur = False

            cell = Cell(
                self.num_nodes,
                c_prev_prev,
                c_prev,
                c_cur,
                reduction_prev,
                reduction_cur,
                search_space,
            )
            reduction_prev = reduction_cur
            self.cells.append(cell)

            c_cur_out = c_cur * self.num_nodes
            c_prev_prev, c_prev = c_prev, c_cur_out

        self.global_pooling = nn.AdaptiveAvgPool2d(1)
        self.classifier = nn.Linear(c_prev, self.num_classes)

        # Initialize alphas parameters
        num_ops = len(search_space.primitives)

        self.alpha_normal = nn.ParameterList()
        self.alpha_reduce = nn.ParameterList()

        for i in range(self.num_nodes):
            self.alpha_normal.append(nn.Parameter(1e-3 * torch.randn(i + 2, num_ops)))
            if self.num_layers > 1:
                self.alpha_reduce.append(
                    nn.Parameter(1e-3 * torch.randn(i + 2, num_ops))
                )

        # Setup alphas list
        self.alphas = []
        for name, parameter in self.named_parameters():
            if "alpha" in name:
                self.alphas.append((name, parameter))

    def forward(self, x):

        weights_normal = [F.softmax(alpha, dim=-1) for alpha in self.alpha_normal]
        weights_reduce = [F.softmax(alpha, dim=-1) for alpha in self.alpha_reduce]

        s0 = s1 = self.stem(x)

        for cell in self.cells:
            weights = weights_reduce if cell.reduction_cur else weights_normal
            s0, s1 = s1, cell(s0, s1, weights)

        out = self.global_pooling(s1)

        # Make out flatten
        out = out.view(out.size(0), -1)

        logits = self.classifier(out)
        return logits

    def print_alphas(self):

        print("\n>>> Alphas Normal <<<")
        for alpha in self.alpha_normal:
            print(F.softmax(alpha, dim=-1))

        if self.num_layers > 1:
            print("\n>>> Alpha Reduce <<<")
            for alpha in self.alpha_reduce:
                print(F.softmax(alpha, dim=-1))
        print("\n")

    def getWeights(self):
        return self.parameters()

    def getAlphas(self):
        for _, parameter in self.alphas:
            yield parameter

    def loss(self, x, y):
        logits = self.forward(x)
        return self.criterion(logits, y)

    def genotype(self, search_space):
        gene_normal = search_space.parse(self.alpha_normal, k=2)
        gene_reduce = search_space.parse(self.alpha_reduce, k=2)
        # concat all intermediate nodes
        concat = range(2, 2 + self.num_nodes)

        return search_space.genotype(
            normal=gene_normal,
            normal_concat=concat,
            reduce=gene_reduce,
            reduce_concat=concat,
        )



================================================
FILE: examples/v1beta1/trial-images/darts-cnn-cifar10/operations.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import torch
import torch.nn as nn

OPS = {
    "none": lambda channels, stride: Zero(stride),
    "avg_pooling_3x3": lambda channels, stride: PoolBN(
        "avg", channels, kernel_size=3, stride=stride, padding=1
    ),
    "max_pooling_3x3": lambda channels, stride: PoolBN(
        "max", channels, kernel_size=3, stride=stride, padding=1
    ),
    "skip_connection": lambda channels, stride: (
        Identity() if stride == 1 else FactorizedReduce(channels, channels)
    ),
    "separable_convolution_3x3": lambda channels, stride: SepConv(
        channels, kernel_size=3, stride=stride, padding=1
    ),
    "separable_convolution_5x5": lambda channels, stride: SepConv(
        channels, kernel_size=5, stride=stride, padding=2
    ),
    # 3x3 -> 5x5
    "dilated_convolution_3x3": lambda channels, stride: DilConv(
        channels, kernel_size=3, stride=stride, padding=2, dilation=2
    ),
    # 5x5 -> 9x9
    "dilated_convolution_5x5": lambda channels, stride: DilConv(
        channels, kernel_size=5, stride=stride, padding=4, dilation=2
    ),
}


class Zero(nn.Module):
    """
    Zero operation
    """

    def __init__(self, stride):
        super(Zero, self).__init__()
        self.stride = stride

    def forward(self, x):
        if self.stride == 1:
            return x * 0.0
        # Resize by stride
        return x[:, :, :: self.stride, :: self.stride] * 0.0


class PoolBN(nn.Module):
    """
    Avg or Max pooling - BN
    """

    def __init__(self, pool_type, channels, kernel_size, stride, padding):
        super(PoolBN, self).__init__()
        if pool_type == "avg":
            self.pool = nn.AvgPool2d(
                kernel_size, stride, padding, count_include_pad=False
            )
        elif pool_type == "max":
            self.pool = nn.MaxPool2d(kernel_size, stride, padding)

        self.bn = nn.BatchNorm2d(channels, affine=False)
        self.net = nn.Sequential(self.pool, self.bn)

    def forward(self, x):
        # out = self.pool(x),
        # print(out)
        # out = self.bn(out)
        # print(out)
        return self.net(x)


class Identity(nn.Module):

    def __init__(self):
        super(Identity, self).__init__()

    def forward(self, x):
        return x


class FactorizedReduce(nn.Module):
    """
    Reduce feature map size by factorized pointwise (stride=2)
    ReLU - Conv1 - Conv2 - BN
    """

    def __init__(self, c_in, c_out):
        super(FactorizedReduce, self).__init__()
        self.relu = nn.ReLU()
        self.conv1 = nn.Conv2d(
            c_in, c_out // 2, kernel_size=1, stride=2, padding=0, bias=False
        )
        self.conv2 = nn.Conv2d(
            c_in, c_out // 2, kernel_size=1, stride=2, padding=0, bias=False
        )
        self.bn = nn.BatchNorm2d(c_out, affine=False)

    def forward(self, x):

        x = self.relu(x)
        out = torch.cat([self.conv1(x), self.conv2(x[:, :, 1:, 1:])], dim=1)
        out = self.bn(out)

        return out


class StdConv(nn.Module):
    """Standard convolition
    ReLU - Conv - BN
    """

    def __init__(self, c_in, c_out, kernel_size, stride, padding):
        super(StdConv, self).__init__()
        self.net = nn.Sequential(
            nn.ReLU(),
            nn.Conv2d(
                c_in,
                c_out,
                kernel_size=kernel_size,
                stride=stride,
                padding=padding,
                bias=False,
            ),
            nn.BatchNorm2d(c_out, affine=False),
        )

    def forward(self, x):
        return self.net(x)


class DilConv(nn.Module):
    """(Dilated) depthwise separable conv
    ReLU - (Dilated) depthwise separable - Pointwise - BN

    If dilation == 2, 3x3 conv => 5x5 receptive field
                      5x5 conv => 9x9 receptive field
    """

    def __init__(self, channels, kernel_size, stride, padding, dilation):
        super(DilConv, self).__init__()

        self.net = nn.Sequential(
            nn.ReLU(),
            nn.Conv2d(
                channels,
                channels,
                kernel_size,
                stride,
                padding,
                dilation=dilation,
                groups=channels,
                bias=False,
            ),
            nn.Conv2d(
                channels, channels, kernel_size=1, stride=1, padding=0, bias=False
            ),
            nn.BatchNorm2d(channels, affine=False),
        )

    def forward(self, x):
        return self.net(x)


class SepConv(nn.Module):
    """Depthwise separable conv
    DilConv (dilation=1) * 2
    """

    def __init__(self, channels, kernel_size, stride, padding):
        super(SepConv, self).__init__()
        self.net = nn.Sequential(
            DilConv(channels, kernel_size, stride=stride, padding=padding, dilation=1),
            DilConv(channels, kernel_size, stride=1, padding=padding, dilation=1),
        )

    def forward(self, x):
        return self.net(x)


class MixedOp(nn.Module):
    """Mixed operation"""

    def __init__(self, channels, stride, search_space):
        super(MixedOp, self).__init__()
        self.ops = nn.ModuleList()

        for primitive in search_space.primitives:
            op = OPS[primitive](channels, stride)
            self.ops.append(op)

    def forward(self, x, weights):
        """
        Args:
            x: input
            weights: weight for each operation
        """
        return sum(w * op(x) for w, op in zip(weights, self.ops))



================================================
FILE: examples/v1beta1/trial-images/darts-cnn-cifar10/run_trial.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import argparse
import json

import numpy as np
import torch
import torch.nn as nn
import utils
from architect import Architect
from model import NetworkCNN
from search_space import SearchSpace


def main():

    parser = argparse.ArgumentParser(description="TrainingContainer")
    parser.add_argument(
        "--algorithm-settings", type=str, default="", help="algorithm settings"
    )
    parser.add_argument(
        "--search-space",
        type=str,
        default="",
        help="search space for the neural architecture search",
    )
    parser.add_argument(
        "--num-layers",
        type=str,
        default="",
        help="number of layers of the neural network",
    )

    args = parser.parse_args()

    # Get Algorithm Settings
    algorithm_settings = args.algorithm_settings.replace("'", '"')
    algorithm_settings = json.loads(algorithm_settings)
    print(">>> Algorithm settings")
    for key, value in algorithm_settings.items():
        if len(key) > 13:
            print("{}\t{}".format(key, value))
        elif len(key) < 5:
            print("{}\t\t\t{}".format(key, value))
        else:
            print("{}\t\t{}".format(key, value))
    print()

    num_epochs = int(algorithm_settings["num_epochs"])

    w_lr = float(algorithm_settings["w_lr"])
    w_lr_min = float(algorithm_settings["w_lr_min"])
    w_momentum = float(algorithm_settings["w_momentum"])
    w_weight_decay = float(algorithm_settings["w_weight_decay"])
    w_grad_clip = float(algorithm_settings["w_grad_clip"])

    alpha_lr = float(algorithm_settings["alpha_lr"])
    alpha_weight_decay = float(algorithm_settings["alpha_weight_decay"])

    batch_size = int(algorithm_settings["batch_size"])
    num_workers = int(algorithm_settings["num_workers"])

    init_channels = int(algorithm_settings["init_channels"])

    print_step = int(algorithm_settings["print_step"])

    num_nodes = int(algorithm_settings["num_nodes"])
    stem_multiplier = int(algorithm_settings["stem_multiplier"])

    # Get Search Space
    search_space = args.search_space.replace("'", '"')
    search_space = json.loads(search_space)
    search_space = SearchSpace(search_space)

    # Get Num Layers
    num_layers = int(args.num_layers)
    print("Number of layers {}\n".format(num_layers))

    # Set GPU Device
    # Currently use only first available GPU
    # TODO: Add multi GPU support
    # TODO: Add functionality to select GPU
    all_gpus = list(range(torch.cuda.device_count()))
    if len(all_gpus) > 0:
        device = torch.device("cuda")
        torch.cuda.set_device(all_gpus[0])
        np.random.seed(2)
        torch.manual_seed(2)
        torch.cuda.manual_seed_all(2)
        torch.backends.cudnn.benchmark = True
        print(">>> Use GPU for Training <<<")
        print("Device ID: {}".format(torch.cuda.current_device()))
        print("Device name: {}".format(torch.cuda.get_device_name(0)))
        print("Device availability: {}\n".format(torch.cuda.is_available()))
    else:
        device = torch.device("cpu")
        print(">>> Use CPU for Training <<<")

    # Get dataset with meta information
    # TODO: Add support for more dataset
    input_channels, num_classes, train_data = utils.get_dataset()

    criterion = nn.CrossEntropyLoss().to(device)

    model = NetworkCNN(
        init_channels,
        input_channels,
        num_classes,
        num_layers,
        criterion,
        search_space,
        num_nodes,
        stem_multiplier,
    )

    model = model.to(device)

    # Weights optimizer
    w_optim = torch.optim.SGD(
        model.getWeights(), w_lr, momentum=w_momentum, weight_decay=w_weight_decay
    )

    # Alphas optimizer
    alpha_optim = torch.optim.Adam(
        model.getAlphas(), alpha_lr, betas=(0.5, 0.999), weight_decay=alpha_weight_decay
    )

    # Split data to train/validation
    num_train = len(train_data)
    split = num_train // 2
    indices = list(range(num_train))

    train_sampler = torch.utils.data.sampler.SubsetRandomSampler(indices[:split])
    valid_sampler = torch.utils.data.sampler.SubsetRandomSampler(indices[split:])

    train_loader = torch.utils.data.DataLoader(
        train_data,
        batch_size=batch_size,
        sampler=train_sampler,
        num_workers=num_workers,
        pin_memory=True,
    )

    valid_loader = torch.utils.data.DataLoader(
        train_data,
        batch_size=batch_size,
        sampler=valid_sampler,
        num_workers=num_workers,
        pin_memory=True,
    )

    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        w_optim, num_epochs, eta_min=w_lr_min
    )

    architect = Architect(model, w_momentum, w_weight_decay, device)

    # Start training
    best_top1 = 0.0

    for epoch in range(num_epochs):
        lr = lr_scheduler.get_last_lr()

        model.print_alphas()

        # Training
        print(">>> Training")
        train(
            train_loader,
            valid_loader,
            model,
            architect,
            w_optim,
            alpha_optim,
            lr,
            epoch,
            num_epochs,
            device,
            w_grad_clip,
            print_step,
        )
        lr_scheduler.step()

        # Validation
        print("\n>>> Validation")
        cur_step = (epoch + 1) * len(train_loader)
        top1 = validate(
            valid_loader, model, epoch, cur_step, num_epochs, device, print_step
        )

        # Print genotype
        genotype = model.genotype(search_space)
        print("\nModel genotype = {}".format(genotype))

        # Modify best top1
        if top1 > best_top1:
            best_top1 = top1
            best_genotype = genotype

    print("Final best Prec@1 = {:.4%}".format(best_top1))
    print("\nBest-Genotype={}".format(str(best_genotype).replace(" ", "")))


def train(
    train_loader,
    valid_loader,
    model,
    architect,
    w_optim,
    alpha_optim,
    lr,
    epoch,
    num_epochs,
    device,
    w_grad_clip,
    print_step,
):
    top1 = utils.AverageMeter()
    top5 = utils.AverageMeter()
    losses = utils.AverageMeter()
    cur_step = epoch * len(train_loader)

    model.train()
    for step, ((train_x, train_y), (valid_x, valid_y)) in enumerate(
        zip(train_loader, valid_loader)
    ):

        train_x, train_y = train_x.to(device, non_blocking=True), train_y.to(
            device, non_blocking=True
        )
        valid_x, valid_y = valid_x.to(device, non_blocking=True), valid_y.to(
            device, non_blocking=True
        )

        train_size = train_x.size(0)

        # Phase 1. Architect step (Alpha)
        alpha_optim.zero_grad()
        architect.unrolled_backward(train_x, train_y, valid_x, valid_y, lr, w_optim)
        alpha_optim.step()

        # Phase 2. Child network step (W)
        w_optim.zero_grad()
        logits = model(train_x)
        loss = model.criterion(logits, train_y)
        loss.backward()

        # Gradient clipping
        nn.utils.clip_grad_norm_(model.getWeights(), w_grad_clip)
        w_optim.step()

        prec1, prec5 = utils.accuracy(logits, train_y, topk=(1, 5))

        losses.update(loss.item(), train_size)
        top1.update(prec1.item(), train_size)
        top5.update(prec5.item(), train_size)

        if step % print_step == 0 or step == len(train_loader) - 1:
            print(
                "Train: [{:2d}/{}] Step {:03d}/{:03d} Loss {losses.avg:.3f} "
                "Prec@(1,5) ({top1.avg:.1%}, {top5.avg:.1%})".format(
                    epoch + 1,
                    num_epochs,
                    step,
                    len(train_loader) - 1,
                    losses=losses,
                    top1=top1,
                    top5=top5,
                )
            )

        cur_step += 1

    print(
        "Train: [{:2d}/{}] Final Prec@1 {:.4%}".format(epoch + 1, num_epochs, top1.avg)
    )


def validate(valid_loader, model, epoch, cur_step, num_epochs, device, print_step):
    top1 = utils.AverageMeter()
    top5 = utils.AverageMeter()
    losses = utils.AverageMeter()

    model.eval()

    with torch.no_grad():
        for step, (valid_x, valid_y) in enumerate(valid_loader):
            valid_x, valid_y = valid_x.to(device, non_blocking=True), valid_y.to(
                device, non_blocking=True
            )

            valid_size = valid_x.size(0)

            logits = model(valid_x)
            loss = model.criterion(logits, valid_y)

            prec1, prec5 = utils.accuracy(logits, valid_y, topk=(1, 5))
            losses.update(loss.item(), valid_size)
            top1.update(prec1.item(), valid_size)
            top5.update(prec5.item(), valid_size)

            if step % print_step == 0 or step == len(valid_loader) - 1:
                print(
                    "Validation: [{:2d}/{}] Step {:03d}/{:03d} Loss {losses.avg:.3f} "
                    "Prec@(1,5) ({top1.avg:.1%}, {top5.avg:.1%})".format(
                        epoch + 1,
                        num_epochs,
                        step,
                        len(valid_loader) - 1,
                        losses=losses,
                        top1=top1,
                        top5=top5,
                    )
                )

    print(
        "Valid: [{:2d}/{}] Final Prec@1 {:.4%}".format(epoch + 1, num_epochs, top1.avg)
    )

    return top1.avg


if __name__ == "__main__":
    main()



================================================
FILE: examples/v1beta1/trial-images/darts-cnn-cifar10/search_space.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from collections import namedtuple

import torch


class SearchSpace:
    def __init__(self, search_space):
        self.primitives = search_space
        self.primitives.append("none")

        print(">>> All Primitives")
        print("{}\n".format(self.primitives))
        self.genotype = namedtuple(
            "Genotype", "normal normal_concat reduce reduce_concat"
        )

    def parse(self, alpha, k):
        """
        Parse continuous alpha to discrete gene.
        alpha is ParameterList:
        ParameterList [
            Parameter(n_edges1, n_ops),
            Parameter(n_edges2, n_ops),
            ...
        ]

        gene is list:
        [
            [('node1_ops_1', node_idx), ..., ('node1_ops_k', node_idx)],
            [('node2_ops_1', node_idx), ..., ('node2_ops_k', node_idx)],
            ...
        ]
        each node has two edges (k=2) in CNN.
        """

        gene = []
        assert self.primitives[-1] == "none"  # assume last PRIMITIVE is 'none'

        # 1) Convert the mixed op to discrete edge (single op) by choosing top-1 weight edge
        # 2) Choose top-k edges per node by edge score (top-1 weight in edge)
        for edges in alpha:
            # edges: Tensor(n_edges, n_ops)
            edge_max, primitive_indices = torch.topk(edges[:, :-1], 1)  # ignore 'none'
            topk_edge_values, topk_edge_indices = torch.topk(edge_max.view(-1), k)
            node_gene = []
            for edge_idx in topk_edge_indices:
                prim_idx = primitive_indices[edge_idx]
                prim = self.primitives[prim_idx]
                node_gene.append((prim, edge_idx.item()))

            gene.append(node_gene)

        return gene



================================================
FILE: examples/v1beta1/trial-images/darts-cnn-cifar10/utils.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import torchvision.datasets as dset
import torchvision.transforms as transforms


class AverageMeter:
    """Computes and stores the average and current value"""

    def __init__(self):
        self.reset()

    def reset(self):
        """Reset all statistics"""
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0

    def update(self, val, n=1):
        """Update statistics"""
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count


def accuracy(output, target, topk=(1,)):
    """Computes the precision@k for the specified values of k"""
    maxk = max(topk)
    batch_size = target.size(0)

    _, pred = output.topk(maxk, 1, True, True)

    pred = pred.t()
    # one-hot case
    if target.ndimension() > 1:
        target = target.max(1)[1]

    correct = pred.eq(target.view(1, -1).expand_as(pred))

    res = []
    for k in topk:
        correct_k = correct[:k].contiguous().view(-1).float().sum(0)
        res.append(correct_k.mul_(1.0 / batch_size))

    return res


def get_dataset():
    dataset_cls = dset.CIFAR10
    num_classes = 10
    input_channels = 3

    # Do preprocessing
    MEAN = [0.49139968, 0.48215827, 0.44653124]
    STD = [0.24703233, 0.24348505, 0.26158768]
    transf = [transforms.RandomCrop(32, padding=4), transforms.RandomHorizontalFlip()]

    normalize = [transforms.ToTensor(), transforms.Normalize(MEAN, STD)]

    train_transform = transforms.Compose(transf + normalize)

    train_data = dataset_cls(
        root="./data", train=True, download=True, transform=train_transform
    )

    return input_channels, num_classes, train_data



================================================
FILE: examples/v1beta1/trial-images/enas-cnn-cifar10/README.md
================================================
# Efficient Neural Architecture Search (ENAS) Training Container

This is training container for the ENAS algorithm. It uses Keras convolutional neural
network and CIFAR-10 dataset to train the model.

To know more about using ENAS in Katib, check
[this guide](../../../../pkg/suggestion/v1beta1/nas/enas/).

Katib uses this training container in the [ENAS Experiments](../../nas/enas-gpu.yaml#L137-L148).



================================================
FILE: examples/v1beta1/trial-images/enas-cnn-cifar10/Dockerfile.cpu
================================================
FROM python:3.11-slim

ARG TARGETARCH
ENV TARGET_DIR /opt/enas-cnn-cifar10
ENV PYTHONPATH ${TARGET_DIR}

ADD examples/v1beta1/trial-images/enas-cnn-cifar10 ${TARGET_DIR}

WORKDIR  ${TARGET_DIR}

RUN if [ "${TARGETARCH}" = "arm64" ]; then \
    apt-get -y update && \
    apt-get -y install gfortran libpcre2-dev && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*; \
    fi

RUN pip install --prefer-binary --no-cache-dir -r requirements.txt
RUN chgrp -R 0 ${TARGET_DIR} \
  && chmod -R g+rwX ${TARGET_DIR}

ENTRYPOINT ["python3", "-u", "RunTrial.py"]



================================================
FILE: examples/v1beta1/trial-images/enas-cnn-cifar10/Dockerfile.gpu
================================================
# We need to use the nvcr.io/nvidia/tensorflow image as a base image to support both linux/amd64 and linux_arm64 platforms.
# tensorflow-gpu=2.10.1, cuda=11.8.0
# Ref: https://docs.nvidia.com/deeplearning/frameworks/tensorflow-release-notes/rel-22-12.html#rel-22-12
FROM nvcr.io/nvidia/tensorflow:22.12-tf2-py3

ENV TARGET_DIR /opt/enas-cnn-cifar10
ENV PYTHONPATH ${TARGET_DIR}

ADD examples/v1beta1/trial-images/enas-cnn-cifar10 ${TARGET_DIR}

WORKDIR  ${TARGET_DIR}

RUN pip install --prefer-binary --no-cache-dir scipy==1.8.1
RUN chgrp -R 0 ${TARGET_DIR} \
  && chmod -R g+rwX ${TARGET_DIR}

ENTRYPOINT ["python3", "-u", "RunTrial.py"]



================================================
FILE: examples/v1beta1/trial-images/enas-cnn-cifar10/ModelConstructor.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import json

from keras.layers import Dense, GlobalAveragePooling2D, Input
from keras.models import Model
from op_library import concat, conv, dw_conv, reduction, sp_conv


class ModelConstructor(object):
    def __init__(self, arc_json, nn_json):
        self.arch = json.loads(arc_json)
        nn_config = json.loads(nn_json)
        self.num_layers = nn_config["num_layers"]
        self.input_sizes = nn_config["input_sizes"]
        self.output_size = nn_config["output_sizes"][-1]
        self.embedding = nn_config["embedding"]

    def build_model(self):
        # a list of the data all layers
        all_layers = [0 for _ in range(self.num_layers + 1)]

        # ================= Stacking layers =================
        # Input Layer. Layer 0
        input_layer = Input(shape=self.input_sizes)
        all_layers[0] = input_layer

        # Intermediate Layers. Starting from layer 1.
        for l_index in range(1, self.num_layers + 1):
            input_layers = list()
            opt = self.arch[l_index - 1][0]
            opt_config = self.embedding[str(opt)]
            skip = self.arch[l_index - 1][1 : l_index + 1]

            # set up the connection to the previous layer first
            input_layers.append(all_layers[l_index - 1])

            # then add skip connections
            for i in range(l_index - 1):
                if l_index > 1 and skip[i] == 1:
                    input_layers.append(all_layers[i])

            layer_input = concat(input_layers)
            if opt_config["opt_type"] == "convolution":
                layer_output = conv(layer_input, opt_config)
            if opt_config["opt_type"] == "separable_convolution":
                layer_output = sp_conv(layer_input, opt_config)
            if opt_config["opt_type"] == "depthwise_convolution":
                layer_output = dw_conv(layer_input, opt_config)
            elif opt_config["opt_type"] == "reduction":
                layer_output = reduction(layer_input, opt_config)

            all_layers[l_index] = layer_output

        # Final Layer
        # Global Average Pooling, then Fully connected with softmax.
        avgpooled = GlobalAveragePooling2D()(all_layers[self.num_layers])

        # TODO (andreyvelich): Currently, Dropout layer fails in distributed training.
        # Error: creating distributed tf.Variable with aggregation=MEAN
        # and a non-floating dtype is not supported, please use a different aggregation or dtype
        # dropped = Dropout(0.4)(avgpooled)

        logits = Dense(units=self.output_size, activation="softmax")(avgpooled)

        # Encapsulate the model
        self.model = Model(inputs=input_layer, outputs=logits)

        return self.model



================================================
FILE: examples/v1beta1/trial-images/enas-cnn-cifar10/op_library.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import numpy as np
from keras import backend as K
from keras.layers import (
    Activation,
    AveragePooling2D,
    BatchNormalization,
    Conv2D,
    DepthwiseConv2D,
    MaxPooling2D,
    SeparableConv2D,
    ZeroPadding2D,
    concatenate,
)


def concat(inputs):
    n = len(inputs)
    if n == 1:
        return inputs[0]

    total_dim = list()
    for x in inputs:
        total_dim.append(K.int_shape(x))
    total_dim = np.asarray(total_dim)
    max_dim = max(total_dim[:, 1])

    padded_input = [0 for _ in range(n)]

    for i in range(n):
        if total_dim[i][1] < max_dim:
            diff = max_dim - total_dim[i][1]
            half_diff = int(diff / 2)
            if diff % 2 == 0:
                padded_input[i] = ZeroPadding2D(padding=(half_diff, half_diff))(
                    inputs[i]
                )
            else:
                padded_input[i] = ZeroPadding2D(
                    padding=((half_diff, half_diff + 1), (half_diff, half_diff + 1))
                )(inputs[i])
        else:
            padded_input[i] = inputs[i]

    result = concatenate(inputs=padded_input, axis=-1)
    return result


def conv(x, config):
    parameters = {
        "num_filter": 64,
        "filter_size": 3,
        "stride": 1,
    }
    for k in parameters.keys():
        if k in config:
            parameters[k] = int(config[k])

    activated = Activation("relu")(x)

    conved = Conv2D(
        filters=parameters["num_filter"],
        kernel_size=parameters["filter_size"],
        strides=parameters["stride"],
        padding="same",
    )(activated)

    result = BatchNormalization()(conved)

    return result


def sp_conv(x, config):
    parameters = {
        "num_filter": 64,
        "filter_size": 3,
        "stride": 1,
        "depth_multiplier": 1,
    }

    for k in parameters.keys():
        if k in config:
            parameters[k] = int(config[k])

    activated = Activation("relu")(x)

    conved = SeparableConv2D(
        filters=parameters["num_filter"],
        kernel_size=parameters["filter_size"],
        strides=parameters["stride"],
        depth_multiplier=parameters["depth_multiplier"],
        padding="same",
    )(activated)

    result = BatchNormalization()(conved)

    return result


def dw_conv(x, config):
    parameters = {
        "filter_size": 3,
        "stride": 1,
        "depth_multiplier": 1,
    }
    for k in parameters.keys():
        if k in config:
            parameters[k] = int(config[k])

    activated = Activation("relu")(x)

    conved = DepthwiseConv2D(
        kernel_size=parameters["filter_size"],
        strides=parameters["stride"],
        depth_multiplier=parameters["depth_multiplier"],
        padding="same",
    )(activated)

    result = BatchNormalization()(conved)

    return result


def reduction(x, config):
    # handle the exteme case where the input has the dimension 1 by 1 and is not reductible
    # we will just change the reduction layer to identity layer
    # such situation is very likely to appear though
    dim = K.int_shape(x)
    if dim[1] == 1 or dim[2] == 1:
        print(
            "WARNING: One or more dimensions of the input of the reduction layer is 1. "
            "It cannot be further reduced. A identity layer will be used instead."
        )
        return x

    parameters = {
        "reduction_type": "max_pooling",
        "pool_size": 2,
        "stride": None,
    }

    if "reduction_type" in config:
        parameters["reduction_type"] = config["reduction_type"]
    if "pool_size" in config:
        parameters["pool_size"] = int(config["pool_size"])
    if "stride" in config:
        parameters["stride"] = int(config["stride"])

    if parameters["reduction_type"] == "max_pooling":
        result = MaxPooling2D(
            pool_size=parameters["pool_size"], strides=parameters["stride"]
        )(x)
    elif parameters["reduction_type"] == "avg_pooling":
        result = AveragePooling2D(
            pool_size=parameters["pool_size"], strides=parameters["stride"]
        )(x)

    return result



================================================
FILE: examples/v1beta1/trial-images/enas-cnn-cifar10/requirements.txt
================================================
scipy>=1.7.2
tensorflow==2.16.1



================================================
FILE: examples/v1beta1/trial-images/enas-cnn-cifar10/RunTrial.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import argparse

import tensorflow as tf
from keras.datasets import cifar10
from ModelConstructor import ModelConstructor
from tensorflow import keras
from tensorflow.keras.layers import RandomFlip, RandomTranslation, Rescaling
from tensorflow.keras.utils import to_categorical

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="TrainingContainer")
    parser.add_argument(
        "--architecture",
        type=str,
        default="",
        metavar="N",
        help="architecture of the neural network",
    )
    parser.add_argument(
        "--nn_config",
        type=str,
        default="",
        metavar="N",
        help="configurations and search space embeddings",
    )
    parser.add_argument(
        "--num_epochs",
        type=int,
        default=10,
        metavar="N",
        help="number of epoches that each child will be trained",
    )
    parser.add_argument(
        "--num_gpus",
        type=int,
        default=1,
        metavar="N",
        help="number of GPU that used for training",
    )
    args = parser.parse_args()

    arch = args.architecture.replace("'", '"')
    print(">>> arch received by trial")
    print(arch)

    nn_config = args.nn_config.replace("'", '"')
    print(">>> nn_config received by trial")
    print(nn_config)

    num_epochs = args.num_epochs
    print(">>> num_epochs received by trial")
    print(num_epochs)

    num_gpus = args.num_gpus
    print(">>> num_gpus received by trial:")
    print(num_gpus)

    print("\n>>> Constructing Model...")
    constructor = ModelConstructor(arch, nn_config)

    num_physical_gpus = len(tf.config.experimental.list_physical_devices("GPU"))
    if 1 <= num_gpus <= num_physical_gpus:
        devices = ["/gpu:" + str(i) for i in range(num_physical_gpus)]
    else:
        num_physical_cpu = len(tf.config.experimental.list_physical_devices("CPU"))
        devices = ["/cpu:" + str(j) for j in range(num_physical_cpu)]

    print(f">>> Using devices: {devices}")

    strategy = tf.distribute.MirroredStrategy(devices)
    with strategy.scope():
        print("Setup TensorFlow distributed training")
        test_model = constructor.build_model()
        test_model.summary()
        test_model.compile(
            loss=keras.losses.categorical_crossentropy,
            optimizer=keras.optimizers.Adam(learning_rate=1e-3),
            metrics=["accuracy"],
        )

    print(">>> Model Constructed Successfully\n")

    (x_train, y_train), (x_test, y_test) = cifar10.load_data()
    x_train = x_train.astype("float32")
    x_test = x_test.astype("float32")
    x_train /= 255
    x_test /= 255
    y_train = to_categorical(y_train)
    y_test = to_categorical(y_test)

    augmentation = tf.keras.Sequential(
        [
            Rescaling(1.0 / 255),
            RandomFlip("horizontal"),
            RandomTranslation(height_factor=0.1, width_factor=0.1),
        ]
    )

    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
    train_dataset = train_dataset.map(lambda x, y: (augmentation(x, training=True), y))
    # TODO: Add batch size to args
    train_dataset = train_dataset.batch(128)

    print(">>> Data Loaded. Training starts.")
    for e in range(num_epochs):
        print("\nTotal Epoch {}/{}".format(e + 1, num_epochs))
        history = test_model.fit(
            train_dataset,
            steps_per_epoch=int(len(x_train) / 128) + 1,
            epochs=1,
            verbose=1,
            validation_data=(x_test, y_test),
        )
        print("Training-Accuracy={}".format(history.history["accuracy"][-1]))
        print("Training-Loss={}".format(history.history["loss"][-1]))
        print("Validation-Accuracy={}".format(history.history["val_accuracy"][-1]))
        print("Validation-Loss={}".format(history.history["val_loss"][-1]))



================================================
FILE: examples/v1beta1/trial-images/pytorch-mnist/README.md
================================================
# PyTorch MNIST Image Classification Example

This is PyTorch MNIST image classification training container with saving metrics
to the file or printing to the StdOut. It uses convolutional neural network to
train the model.

Katib uses this training container in some Experiments, for instance in the
[file Metrics Collector example](../../metrics-collector/file-metrics-collector.yaml#L55-L64),
the [file Metrics Collector with logs in JSON format example](../../metrics-collector/file-metrics-collector-with-json-format.yaml#L52-L62),
the [median stopping early stopping rule with logs in JSON format example](../../early-stopping/median-stop-with-json-format.yaml#L62-L71)
and the [PyTorchJob example](../../kubeflow-training-operator/pytorchjob-mnist.yaml#L47-L54).



================================================
FILE: examples/v1beta1/trial-images/pytorch-mnist/Dockerfile.cpu
================================================
FROM python:3.11-slim

ADD examples/v1beta1/trial-images/pytorch-mnist /opt/pytorch-mnist

WORKDIR /opt/pytorch-mnist

# Add folder for the logs.
RUN mkdir /katib

# TODO (andreyvelich): This is required since torchvision==0.17.1 is incompatible with numpy 2.0
RUN pip install numpy==1.26.0
RUN pip install --prefer-binary --no-cache-dir torch==2.2.1 torchvision==0.17.1
RUN pip install --prefer-binary --no-cache-dir -r requirements.txt

RUN chgrp -R 0 /opt/pytorch-mnist \
  && chmod -R g+rwX /opt/pytorch-mnist \
  && chgrp -R 0 /katib \
  && chmod -R g+rwX /katib

ENTRYPOINT ["python3", "/opt/pytorch-mnist/mnist.py"]



================================================
FILE: examples/v1beta1/trial-images/pytorch-mnist/Dockerfile.gpu
================================================
# We need to use the nvcr.io/nvidia/pytorch image as a base image to support both linux/amd64 and linux_arm64 platforms.
# PyTorch=2.2.0, cuda=12.3.2
# Ref: https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/rel-24-01.html#rel-24-01
FROM nvcr.io/nvidia/pytorch:24.01-py3

ADD examples/v1beta1/trial-images/pytorch-mnist /opt/pytorch-mnist

WORKDIR /opt/pytorch-mnist

# Add folder for the logs.
RUN mkdir /katib
RUN pip install --prefer-binary --no-cache-dir -r requirements.txt

RUN chgrp -R 0 /opt/pytorch-mnist \
  && chmod -R g+rwX /opt/pytorch-mnist \
  && chgrp -R 0 /katib \
  && chmod -R g+rwX /katib

ENTRYPOINT ["python3", "/opt/pytorch-mnist/mnist.py"]



================================================
FILE: examples/v1beta1/trial-images/pytorch-mnist/mnist.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import print_function

import argparse
import logging
import os

import hypertune
import torch
import torch.distributed as dist
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms

WORLD_SIZE = int(os.environ.get("WORLD_SIZE", 1))


class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5, 1)
        self.conv2 = nn.Conv2d(20, 50, 5, 1)
        self.fc1 = nn.Linear(4 * 4 * 50, 500)
        self.fc2 = nn.Linear(500, 10)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.max_pool2d(x, 2, 2)
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, 2, 2)
        x = x.view(-1, 4 * 4 * 50)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)


def train(args, model, device, train_loader, optimizer, epoch):
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = F.nll_loss(output, target)
        loss.backward()
        optimizer.step()
        if batch_idx % args.log_interval == 0:
            msg = "Train Epoch: {} [{}/{} ({:.0f}%)]\tloss={:.4f}".format(
                epoch,
                batch_idx * len(data),
                len(train_loader.dataset),
                100.0 * batch_idx / len(train_loader),
                loss.item(),
            )
            logging.info(msg)
            niter = epoch * len(train_loader) + batch_idx  # noqa: F841


def test(args, model, device, test_loader, epoch, hpt):
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += F.nll_loss(
                output, target, reduction="sum"
            ).item()  # sum up batch loss
            pred = output.max(1, keepdim=True)[
                1
            ]  # get the index of the max log-probability
            correct += pred.eq(target.view_as(pred)).sum().item()

    test_loss /= len(test_loader.dataset)
    test_accuracy = float(correct) / len(test_loader.dataset)

    logging.info(
        "{{metricName: accuracy, metricValue: {:.4f}}};"
        "{{metricName: loss, metricValue: {:.4f}}}\n".format(test_accuracy, test_loss)
    )

    if args.logger == "hypertune":
        hpt.report_hyperparameter_tuning_metric(
            hyperparameter_metric_tag="loss", metric_value=test_loss, global_step=epoch
        )
        hpt.report_hyperparameter_tuning_metric(
            hyperparameter_metric_tag="accuracy",
            metric_value=test_accuracy,
            global_step=epoch,
        )


def should_distribute():
    return dist.is_available() and WORLD_SIZE > 1


def is_distributed():
    return dist.is_available() and dist.is_initialized()


def main():
    # Training settings
    parser = argparse.ArgumentParser(description="PyTorch MNIST Example")
    parser.add_argument(
        "--batch-size",
        type=int,
        default=64,
        metavar="N",
        help="input batch size for training (default: 64)",
    )
    parser.add_argument(
        "--test-batch-size",
        type=int,
        default=1000,
        metavar="N",
        help="input batch size for testing (default: 1000)",
    )
    parser.add_argument(
        "--epochs",
        type=int,
        default=10,
        metavar="N",
        help="number of epochs to train (default: 10)",
    )
    parser.add_argument(
        "--lr",
        type=float,
        default=0.01,
        metavar="LR",
        help="learning rate (default: 0.01)",
    )
    parser.add_argument(
        "--momentum",
        type=float,
        default=0.5,
        metavar="M",
        help="SGD momentum (default: 0.5)",
    )
    parser.add_argument(
        "--no-cuda", action="store_true", default=False, help="disables CUDA training"
    )
    parser.add_argument(
        "--seed", type=int, default=1, metavar="S", help="random seed (default: 1)"
    )
    parser.add_argument(
        "--log-interval",
        type=int,
        default=10,
        metavar="N",
        help="how many batches to wait before logging training status",
    )
    parser.add_argument(
        "--log-path",
        type=str,
        default="",
        help="Path to save logs. Print to StdOut if log-path is not set",
    )
    parser.add_argument(
        "--save-model",
        action="store_true",
        default=False,
        help="For Saving the current Model",
    )
    parser.add_argument(
        "--logger",
        type=str,
        choices=["standard", "hypertune"],
        help="Logger",
        default="standard",
    )

    if dist.is_available():
        parser.add_argument(
            "--backend",
            type=str,
            help="Distributed backend",
            choices=[dist.Backend.GLOO, dist.Backend.NCCL, dist.Backend.MPI],
            default=dist.Backend.GLOO,
        )
    args = parser.parse_args()

    # Use this format (%Y-%m-%dT%H:%M:%SZ) to record timestamp of the metrics.
    # If log_path is empty print log to StdOut, otherwise print log to the file.
    if args.log_path == "" or args.logger == "hypertune":
        logging.basicConfig(
            format="%(asctime)s %(levelname)-8s %(message)s",
            datefmt="%Y-%m-%dT%H:%M:%SZ",
            level=logging.DEBUG,
        )
    else:
        logging.basicConfig(
            format="%(asctime)s %(levelname)-8s %(message)s",
            datefmt="%Y-%m-%dT%H:%M:%SZ",
            level=logging.DEBUG,
            filename=args.log_path,
        )

    if args.logger == "hypertune" and args.log_path != "":
        os.environ["CLOUD_ML_HP_METRIC_FILE"] = args.log_path

    # For JSON logging
    hpt = hypertune.HyperTune()

    use_cuda = not args.no_cuda and torch.cuda.is_available()
    if use_cuda:
        print("Using CUDA")

    torch.manual_seed(args.seed)

    device = torch.device("cuda" if use_cuda else "cpu")

    if should_distribute():
        print("Using distributed PyTorch with {} backend".format(args.backend))
        dist.init_process_group(backend=args.backend)

    kwargs = {"num_workers": 1, "pin_memory": True} if use_cuda else {}

    train_loader = torch.utils.data.DataLoader(
        datasets.FashionMNIST(
            "./data",
            train=True,
            download=True,
            transform=transforms.Compose([transforms.ToTensor()]),
        ),
        batch_size=args.batch_size,
        shuffle=True,
        **kwargs,
    )

    test_loader = torch.utils.data.DataLoader(
        datasets.FashionMNIST(
            "./data", train=False, transform=transforms.Compose([transforms.ToTensor()])
        ),
        batch_size=args.test_batch_size,
        shuffle=False,
        **kwargs,
    )

    model = Net().to(device)

    if is_distributed():
        Distributor = (
            nn.parallel.DistributedDataParallel
            if use_cuda
            else nn.parallel.DistributedDataParallelCPU
        )
        model = Distributor(model)

    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)

    for epoch in range(1, args.epochs + 1):
        train(args, model, device, train_loader, optimizer, epoch)
        test(args, model, device, test_loader, epoch, hpt)

    if args.save_model:
        torch.save(model.state_dict(), "mnist_cnn.pt")


if __name__ == "__main__":
    main()



================================================
FILE: examples/v1beta1/trial-images/pytorch-mnist/requirements.txt
================================================
cloudml-hypertune==0.1.0.dev6



================================================
FILE: examples/v1beta1/trial-images/simple-pbt/README.md
================================================
# Toy PBT problem for benchmarking adaptive learning rate

The goal is to optimize this trainable's accuracy. The accuracy increases
fastest at the optimal lr, which is a function of the current accuracy.
The optimal lr schedule for this problem is the triangle wave as follows.
Note that many lr schedules for real models also follow this shape:

```
 best lr
  ^
  |    /\
  |   /  \
  |  /    \
  | /      \
  ------------> accuracy
```

In this problem, using PBT with a population of 2-4 is sufficient to
roughly approximate this lr schedule. Higher population sizes will yield
faster convergence. Training will not converge without PBT.

If you want to read more about this example, vist the 
[ray](https://github.com/ray-project/ray/blob/7f1bacc7dc9caf6d0ec042e39499bbf1d9a7d065/python/ray/tune/examples/README.rst) 
documentation.

Katib uses this training container in some Experiments, for instance in the
[PBT example](../../hp-tuning/simple-pbt.yaml#L44-L52).



================================================
FILE: examples/v1beta1/trial-images/simple-pbt/Dockerfile
================================================
FROM python:3.11-slim

ADD examples/v1beta1/trial-images/simple-pbt /opt/pbt

WORKDIR /opt/pbt

RUN python3 -m pip install --prefer-binary -r requirements.txt
RUN chgrp -R 0 /opt/pbt \
  && chmod -R g+rwX /opt/pbt

ENTRYPOINT ["python3", "/opt/pbt/pbt_test.py"]



================================================
FILE: examples/v1beta1/trial-images/simple-pbt/pbt_test.py
================================================
#!/usr/bin/env python
# Implementation based on:
#   https://github.com/ray-project/ray/blob/7f1bacc7dc9caf6d0ec042e39499bbf1d9a7d065/python/ray/tune/examples/pbt_example.py

# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import argparse
import os
import pickle
import random
import time

import numpy as np

# Ensure job runs for at least this long (secs) to allow metrics collector to
# read PID correctly before cleanup
_METRICS_COLLECTOR_SPAWN_LATENCY = 7


class PBTBenchmarkExample:
    """Toy PBT problem for benchmarking adaptive learning rate.
    The goal is to optimize this trainable's accuracy. The accuracy increases
    fastest at the optimal lr, which is a function of the current accuracy.
    The optimal lr schedule for this problem is the triangle wave as follows.
    Note that many lr schedules for real models also follow this shape:
     best lr
      ^
      |    /\
      |   /  \
      |  /    \
      | /      \
      ------------> accuracy
    In this problem, using PBT with a population of 2-4 is sufficient to
    roughly approximate this lr schedule. Higher population sizes will yield
    faster convergence. Training will not converge without PBT.
    """

    def __init__(self, lr, checkpoint: str):
        self._lr = lr

        self._checkpoint_file = os.path.join(checkpoint, "training.ckpt")
        if os.path.exists(self._checkpoint_file):
            with open(self._checkpoint_file, "rb") as fin:
                checkpoint_data = pickle.load(fin)
            self._accuracy = checkpoint_data["accuracy"]
            self._step = checkpoint_data["step"]
        else:
            os.makedirs(checkpoint, exist_ok=True)
            self._step = 1
            self._accuracy = 0.0

    def save_checkpoint(self):
        with open(self._checkpoint_file, "wb") as fout:
            pickle.dump({"step": self._step, "accuracy": self._accuracy}, fout)

    def step(self):
        midpoint = 50  # lr starts decreasing after acc > midpoint
        q_tolerance = 3  # penalize exceeding lr by more than this multiple
        noise_level = 2  # add gaussian noise to the acc increase
        # triangle wave:
        #  - start at 0.001 @ t=0,
        #  - peak at 0.01 @ t=midpoint,
        #  - end at 0.001 @ t=midpoint * 2,
        if self._accuracy < midpoint:
            optimal_lr = 0.01 * self._accuracy / midpoint
        else:
            optimal_lr = 0.01 - 0.01 * (self._accuracy - midpoint) / midpoint
        optimal_lr = min(0.01, max(0.001, optimal_lr))

        # compute accuracy increase
        q_err = max(self._lr, optimal_lr) / (
            min(self._lr, optimal_lr) + np.finfo(float).eps
        )
        if q_err < q_tolerance:
            self._accuracy += (1.0 / q_err) * random.random()
        elif self._lr > optimal_lr:
            self._accuracy -= (q_err - q_tolerance) * random.random()
        self._accuracy += noise_level * np.random.normal()
        self._accuracy = max(0, min(100, self._accuracy))

        self._step += 1

    def __repr__(self):
        return "epoch {}:\nlr={:0.4f}\nValidation-accuracy={:0.4f}".format(
            self._step, self._lr, self._accuracy / 100
        )


if __name__ == "__main__":
    # Parse CLI arguments
    parser = argparse.ArgumentParser(description="PBT Basic Test")
    parser.add_argument(
        "--lr", type=float, default=0.0001, help="learning rate (default: 0.0001)"
    )
    parser.add_argument(
        "--epochs", type=int, default=20, help="number of epochs to train (default: 20)"
    )
    parser.add_argument(
        "--checkpoint",
        type=str,
        default="/var/log/katib/checkpoints/",
        help="checkpoint directory (resume and save)",
    )
    opt = parser.parse_args()

    benchmark = PBTBenchmarkExample(opt.lr, opt.checkpoint)

    start_time = time.time()
    for i in range(opt.epochs):
        benchmark.step()
    exec_time_thresh = time.time() - start_time - _METRICS_COLLECTOR_SPAWN_LATENCY
    if exec_time_thresh < 0:
        time.sleep(abs(exec_time_thresh))
    benchmark.save_checkpoint()

    print(benchmark)



================================================
FILE: examples/v1beta1/trial-images/simple-pbt/requirements.txt
================================================
numpy==1.25.2



================================================
FILE: examples/v1beta1/trial-images/tf-mnist-with-summaries/README.md
================================================
# Tensorflow MNIST Classification With Summaries Example

This is Tensorflow MNIST image classification training container that outputs TF summaries.
It uses convolutional neural network to train the model.

If you want to read more about this example, visit the official
[tensorflow](https://www.tensorflow.org/tutorials/quickstart/advanced)
documentation.

Katib uses this training container in some Experiments, for instance in the
[TFJob example](../../kubeflow-training-operator/tfjob-mnist-with-summaries.yaml#L54-L62).



================================================
FILE: examples/v1beta1/trial-images/tf-mnist-with-summaries/Dockerfile
================================================
FROM python:3.11-slim

ARG TARGETARCH

ADD examples/v1beta1/trial-images/tf-mnist-with-summaries /opt/tf-mnist-with-summaries

WORKDIR /opt/tf-mnist-with-summaries

RUN if [ "${TARGETARCH}" = "arm64" ]; then \
    apt-get -y update && \
    apt-get -y install gfortran libpcre2-dev && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*; \
    fi

RUN pip install --prefer-binary --no-cache-dir -r requirements.txt
RUN chgrp -R 0 /opt/tf-mnist-with-summaries \
  && chmod -R g+rwX /opt/tf-mnist-with-summaries

ENTRYPOINT ["python3", "/opt/tf-mnist-with-summaries/mnist.py"]



================================================
FILE: examples/v1beta1/trial-images/tf-mnist-with-summaries/mnist.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import argparse
import os

import tensorflow as tf
from tensorflow.keras import Model
from tensorflow.keras.layers import Conv2D, Dense, Flatten


class MyModel(Model):
    def __init__(self):
        super(MyModel, self).__init__()
        self.conv1 = Conv2D(32, 3, activation="relu")
        self.flatten = Flatten()
        self.d1 = Dense(128, activation="relu")
        self.d2 = Dense(10)

    def call(self, x):
        x = self.conv1(x)
        x = self.flatten(x)
        x = self.d1(x)
        return self.d2(x)


def train_step(
    args,
    model,
    optimizer,
    train_ds,
    epoch,
    loss_object,
    train_summary_writer,
    train_loss,
    train_accuracy,
):
    for step, (images, labels) in enumerate(train_ds):
        with tf.GradientTape() as tape:
            # training=True is only needed if there are layers with different
            # behavior during training versus inference (e.g. Dropout).
            predictions = model(images, training=True)
            loss = loss_object(labels, predictions)
            gradients = tape.gradient(loss, model.trainable_variables)
            optimizer.apply_gradients(zip(gradients, model.trainable_variables))

            train_loss(loss)
            train_accuracy(labels, predictions)

        if step % args.log_interval == 0:
            print(
                "Train Epoch: {} [{}/60000 ({:.0f}%)]\tloss={:.4f}, accuracy={:.4f}".format(
                    epoch + 1,
                    step * args.batch_size,
                    100.0 * step * args.batch_size / 60000,
                    train_loss.result(),
                    train_accuracy.result() * 100,
                )
            )

    with train_summary_writer.as_default():
        tf.summary.scalar("loss", train_loss.result(), step=epoch)
        tf.summary.scalar("accuracy", train_accuracy.result(), step=epoch)


def test_step(
    model, test_ds, epoch, loss_object, test_summary_writer, test_loss, test_accuracy
):
    for images, labels in test_ds:
        # training=False is only needed if there are layers with different
        # behavior during training versus inference (e.g. Dropout).
        predictions = model(images, training=False)
        t_loss = loss_object(labels, predictions)

        test_loss(t_loss)
        test_accuracy(labels, predictions)

    with test_summary_writer.as_default():
        tf.summary.scalar("loss", test_loss.result(), step=epoch)
        tf.summary.scalar("accuracy", test_accuracy.result(), step=epoch)

    print(
        "Test Loss: {:.4f}, Test Accuracy: {:.4f}\n".format(
            test_loss.result(), test_accuracy.result() * 100
        )
    )


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--batch-size",
        type=int,
        default=64,
        help="input batch size for training (default: 64)",
    )
    parser.add_argument(
        "--learning-rate",
        type=float,
        default=0.001,
        help="learning rate (default: 0.001)",
    )
    parser.add_argument(
        "--epochs",
        type=int,
        default=10,
        metavar="N",
        help="number of epochs to train (default: 10)",
    )
    parser.add_argument(
        "--log-interval",
        type=int,
        default=100,
        metavar="N",
        help="how many batches to wait before logging training status (default: 100)",
    )
    parser.add_argument(
        "--log-path",
        type=str,
        default=os.path.join(
            os.getenv("TEST_TMPDIR", "/tmp"),
            "tensorflow/mnist/logs/mnist_with_summaries",
        ),
        help="Summaries log PATH",
    )
    args = parser.parse_args()

    # Setup dataset
    mnist = tf.keras.datasets.mnist
    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    x_train, x_test = x_train / 255.0, x_test / 255.0
    # Add a channels dimension
    x_train = x_train[..., tf.newaxis].astype("float32")
    x_test = x_test[..., tf.newaxis].astype("float32")
    train_ds = (
        tf.data.Dataset.from_tensor_slices((x_train, y_train))
        .shuffle(10000)
        .batch(args.batch_size)
    )
    test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(
        args.batch_size
    )

    # Setup tensorflow summaries
    train_log_dir = os.path.join(args.log_path, "train")
    test_log_dir = os.path.join(args.log_path, "test")
    train_summary_writer = tf.summary.create_file_writer(train_log_dir)
    test_summary_writer = tf.summary.create_file_writer(test_log_dir)

    # Create an instance of the model
    model = MyModel()
    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
    optimizer = tf.keras.optimizers.Adam(learning_rate=args.learning_rate)

    train_loss = tf.keras.metrics.Mean(name="train_loss")
    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name="train_accuracy")

    test_loss = tf.keras.metrics.Mean(name="test_loss")
    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name="test_accuracy")

    for epoch in range(args.epochs):
        # Reset the metrics at the start of the next epoch
        train_summary_writer.flush()
        test_summary_writer.flush()

        train_step(
            args,
            model,
            optimizer,
            train_ds,
            epoch,
            loss_object,
            train_summary_writer,
            train_loss,
            train_accuracy,
        )
        test_step(
            model,
            test_ds,
            epoch,
            loss_object,
            test_summary_writer,
            test_loss,
            test_accuracy,
        )


if __name__ == "__main__":
    main()



================================================
FILE: examples/v1beta1/trial-images/tf-mnist-with-summaries/requirements.txt
================================================
tensorflow==2.16.1



================================================
FILE: examples/v1beta1/trial-template/trial-configmap-source.yaml
================================================
---
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: trial-configmap-source
spec:
  objective:
    type: maximize
    goal: 0.99
    objectiveMetricName: Validation-accuracy
    additionalMetricNames:
      - Train-accuracy
  algorithm:
    algorithmName: cmaes
  parallelTrialCount: 2
  maxTrialCount: 10
  maxFailedTrialCount: 3
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.03"
    - name: num-layers
      parameterType: int
      feasibleSpace:
        min: "2"
        max: "5"
    - name: optimizer
      parameterType: categorical
      feasibleSpace:
        list:
          - sgd
          - adam
          - ftrl
  trialTemplate:
    primaryContainerName: training-container
    successCondition: status.conditions.#(type=="Complete")#|#(status=="True")#
    failureCondition: status.conditions.#(type=="Failed")#|#(status=="True")#
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: numberLayers
        description: Number of training model layers
        reference: num-layers
      - name: optimizer
        description: Training model optimizer (sdg, adam or ftrl)
        reference: optimizer
    configMap:
      configMapName: trial-templates
      configMapNamespace: kubeflow
      templatePath: defaultTrialTemplate.yaml



================================================
FILE: examples/v1beta1/trial-template/trial-metadata-substitution.yaml
================================================
---
# This example shows how you can use trial metadata in template substitution
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: trial-metadata-substitution
spec:
  objective:
    type: minimize
    goal: 0.001
    objectiveMetricName: loss
  algorithm:
    algorithmName: random
  parallelTrialCount: 3
  maxTrialCount: 12
  maxFailedTrialCount: 3
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.05"
    - name: momentum
      parameterType: double
      feasibleSpace:
        min: "0.5"
        max: "0.9"
  trialTemplate:
    primaryContainerName: training-container
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: momentum
        description: Momentum for the training model
        reference: momentum
      - name: trialName
        description: Name of the current trial's job
        reference: ${trialSpec.Name}
      - name: trialNamespace
        description: Namespace of the current trial's job
        reference: ${trialSpec.Namespace}
      - name: trialKind
        description: Kind of the current trial's job
        reference: ${trialSpec.Kind}
      - name: trialAPIVersion
        description: API version of the current trial's job
        reference: ${trialSpec.APIVersion}
      - name: trialLabelCustom
        description: Trial's job label with custom value
        reference: ${trialSpec.Labels[custom-key]}
      - name: trialAnnotationCustom
        description: Trial's job annotation with custom value
        reference: ${trialSpec.Annotations[custom-key]}
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      metadata:
        annotations:
          "custom-key": "custom-annotation"
        labels:
          "custom-key": "custom-label"
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
                command:
                  - "python3"
                  - "/opt/pytorch-mnist/mnist.py"
                  - "--epochs=1"
                  - "--batch-size=16"
                  - "--lr=${trialParameters.learningRate}"
                  - "--momentum=${trialParameters.momentum}"
                env:
                  - name: TRIAL_NAME
                    value: ${trialParameters.trialName}
                  - name: TRIAL_NAMESPACE
                    value: ${trialParameters.trialNamespace}
                  - name: TRIAL_KIND
                    value: ${trialParameters.trialKind}
                  - name: TRIAL_API_VERSION
                    value: ${trialParameters.trialAPIVersion}
                  - name: TRIAL_LABEL_CUSTOM
                    value: ${trialParameters.trialLabelCustom}
                  - name: TRIAL_ANNOTATION_CUSTOM
                    value: ${trialParameters.trialAnnotationCustom}
            restartPolicy: Never



================================================
FILE: hack/install-shellcheck.sh
================================================
#!/usr/bin/env bash

# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

set -o errexit
set -o pipefail
set -o nounset
cd "$(dirname "$0")"

ARCH=$(uname -m)
OS=$(uname)
SHELLCHECK_VERSION=v0.8.0

if [ "$ARCH" = "arm64" ] && [ "$OS" = "Darwin" ]; then
  echo "Please install the shellcheck via Homebrew."
  exit 1
fi

curl -sSL "https://github.com/koalaman/shellcheck/releases/download/${SHELLCHECK_VERSION}/shellcheck-${SHELLCHECK_VERSION}.${OS,,}.${ARCH}.tar.xz" \
  | tar Jxf - -C /tmp
mv /tmp/shellcheck-$SHELLCHECK_VERSION/shellcheck /usr/local/bin/shellcheck
chmod +x /usr/local/bin/shellcheck

rm -rf /tmp/shellcheck-$SHELLCHECK_VERSION



================================================
FILE: hack/tools.go
================================================
//go:build tools

/*
Copyright 2022 The Kubeflow Authors.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

// This package contains code generation required by build scripts.
// https://github.com/golang/go/wiki/Modules#how-can-i-track-tool-dependencies-for-a-module
package test

import (
	_ "k8s.io/code-generator"
	_ "k8s.io/kube-openapi/cmd/openapi-gen"
)



================================================
FILE: hack/update-codegen.sh
================================================
#!/usr/bin/env bash

# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

set -o errexit
set -o nounset
set -o pipefail

echo "Generate deepcopy, clientset, listers, informers for the APIs"

CURRENT_DIR=$(dirname "${BASH_SOURCE[0]}")
KATIB_ROOT=$(realpath "${CURRENT_DIR}/..")
KATIB_PKG="github.com/kubeflow/katib"
CODEGEN_PKG=$(go list -m -mod=readonly -f "{{.Dir}}" k8s.io/code-generator)

cd "$CURRENT_DIR/.."

# shellcheck source=/dev/null
source "${CODEGEN_PKG}/kube_codegen.sh"

echo "Generating deepcopy and defaults for config.kubeflow.org ..."
kube::codegen::gen_helpers \
    --boilerplate "${KATIB_ROOT}/hack/boilerplate/boilerplate.go.txt" \
    "${KATIB_ROOT}/pkg/apis/config"

echo "Generating clients for v1beta1 ..."
kube::codegen::gen_client \
    --boilerplate "${KATIB_ROOT}/hack/boilerplate/boilerplate.go.txt" \
    --output-dir "${KATIB_ROOT}/pkg/client/controller" \
    --output-pkg "${KATIB_PKG}/pkg/client/controller" \
    --with-watch \
    --with-applyconfig \
    "${KATIB_ROOT}/pkg/apis/controller"



================================================
FILE: hack/update-gofmt.sh
================================================
#!/usr/bin/env bash

# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

set -o errexit
set -o nounset
set -o pipefail

find . -name "*.go" | grep -v "\.pb\.go$" | xargs gofmt -s -w



================================================
FILE: hack/update-mockgen.sh
================================================
#!/usr/bin/env bash

# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This script generates files using mockgen.
# Usage: `hack/update-mockgen.sh`.

set -o errexit
set -o nounset
set -o pipefail

SCRIPT_ROOT="$(dirname "${BASH_SOURCE[0]}")/.."

cd "${SCRIPT_ROOT}"

# Grab mockgen version from go.mod
MOCKGEN_VERSION=$(grep 'go.uber.org/mock' go.mod | awk '{print $2}')

if [[ ! $(mockgen -version) == "${MOCKGEN_VERSION}" ]]; then
  echo "You must use ${MOCKGEN_VERSION} mockgen version to run this script"
  echo "To install mockgen follow this doc: https://github.com/uber-go/mock#installation"
  echo "Run 'mockgen -version' to check the installed version"
  exit 1
fi

echo "Generating v1beta1 Suggestion RPC Client..."
mockgen -package mock -destination pkg/mock/v1beta1/api/suggestion.go github.com/kubeflow/katib/pkg/apis/manager/v1beta1 SuggestionClient
echo "Generating v1beta1 EarlyStopping RPC Client..."
mockgen -package mock -destination pkg/mock/v1beta1/api/earlystopping.go github.com/kubeflow/katib/pkg/apis/manager/v1beta1 EarlyStoppingClient
echo "Generating v1beta1 KatibDBInterface..."
mockgen -package mock -destination pkg/mock/v1beta1/db/db.go github.com/kubeflow/katib/pkg/db/v1beta1/common KatibDBInterface
echo "Generating v1beta1 Generator..."
mockgen -package mock -destination pkg/mock/v1beta1/experiment/manifest/generator.go github.com/kubeflow/katib/pkg/controller.v1beta1/experiment/manifest Generator
echo "Generating v1beta1 KatibClient..."
mockgen -package mock -destination pkg/mock/v1beta1/util/katibclient/katibclient.go github.com/kubeflow/katib/pkg/util/v1beta1/katibclient Client
echo "Generating v1beta1 ManagerClient in Trial Controller..."
mockgen -package mock -destination pkg/mock/v1beta1/trial/managerclient/katibmanager.go github.com/kubeflow/katib/pkg/controller.v1beta1/trial/managerclient ManagerClient
echo "Generating v1beta1 Suggestion in Experiment Controller..."
mockgen -package mock -destination pkg/mock/v1beta1/experiment/suggestion/suggestion.go github.com/kubeflow/katib/pkg/controller.v1beta1/experiment/suggestion Suggestion
echo "Generating v1beta1 SuggestionClient in Suggestion Controller..."
mockgen -package mock -destination pkg/mock/v1beta1/suggestion/suggestionclient/suggestionclient.go github.com/kubeflow/katib/pkg/controller.v1beta1/suggestion/suggestionclient SuggestionClient



================================================
FILE: hack/update-openapigen.sh
================================================
#!/usr/bin/env bash

# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

set -o errexit
set -o nounset
set -o pipefail

echo "Generate open-api for the APIs"

CURRENT_DIR=$(dirname "${BASH_SOURCE[0]}")
KATIB_ROOT=$(realpath "${CURRENT_DIR}/..")
KATIB_PKG="github.com/kubeflow/katib"

cd "$CURRENT_DIR/.."

# Get the kube-openapi binary.
OPENAPI_PKG=$(go list -m -mod=readonly -f "{{.Dir}}" k8s.io/kube-openapi)
echo ">> Using ${OPENAPI_PKG}"

VERSION_LIST=(v1beta1)
SWAGGER_VERSION="0.1"

for VERSION in "${VERSION_LIST[@]}"; do
  SWAGGER_CODEGEN_FILE=${KATIB_ROOT}/pkg/apis/${VERSION}/swagger.json

  echo "Generating OpenAPI specification for ${VERSION} ..."
  
  go run "${OPENAPI_PKG}/cmd/openapi-gen" \
    --go-header-file "${KATIB_ROOT}/hack/boilerplate/boilerplate.go.txt" \
    --output-pkg "${KATIB_PKG}/pkg/apis/${VERSION}" \
    --output-dir "${KATIB_ROOT}/pkg/apis/${VERSION}" \
    --output-file "zz_generated.openapi.go" \
    --report-filename "${KATIB_ROOT}/hack/violation_exception_${VERSION}.list" \
    "${KATIB_ROOT}/pkg/apis/controller/common/${VERSION}" \
    "${KATIB_ROOT}/pkg/apis/controller/experiments/${VERSION}" \
    "${KATIB_ROOT}/pkg/apis/controller/suggestions/${VERSION}" \
    "${KATIB_ROOT}/pkg/apis/controller/trials/${VERSION}"
  
  echo "Generating OpenAPI Swagger for ${VERSION} ..."
  go run "${KATIB_ROOT}/hack/swagger/main.go" "${VERSION}-${SWAGGER_VERSION}" "${VERSION}" >"${SWAGGER_CODEGEN_FILE}"
done



================================================
FILE: hack/update-proto.sh
================================================
#!/usr/bin/env bash

# Copyright 2024 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

set -e

SOURCE="${BASH_SOURCE[0]}"
while [ -h "$SOURCE" ]; do # resolve $SOURCE until the file is no longer a symlink
  DIR="$( cd -P "$( dirname "$SOURCE" )" && pwd )"
  SOURCE="$(readlink "$SOURCE")"
  [[ $SOURCE != /* ]] && SOURCE="$DIR/$SOURCE" # if $SOURCE was a relative symlink, we need to resolve it relative to the path where the symlink file was located
done
ROOT_DIR="$( cd -P "$( dirname "$SOURCE" )/.." && pwd )"

mkdir -p "${ROOT_DIR}/bin"
export GOBIN=$ROOT_DIR/bin

if [ ! -f "${GOBIN}/buf" ]; then
  go install github.com/bufbuild/buf/cmd/buf@v1.32.2
fi

pushd "${ROOT_DIR}/pkg/apis/manager/health"
  "${GOBIN}/buf" generate
popd

pushd "${ROOT_DIR}/pkg/apis/manager/v1beta1"
  "${GOBIN}/buf" generate
popd



================================================
FILE: hack/verify-generated-codes.sh
================================================
#!/usr/bin/env bash

# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

set -o errexit
set -o nounset
set -o pipefail

PATHS=( "${@}" )
cd "$(dirname "$0")/.."

git diff --exit-code -- "${PATHS[@]}" > /dev/null



================================================
FILE: hack/verify-gofmt.sh
================================================
#!/usr/bin/env bash

# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

set -o errexit
set -o nounset
set -o pipefail

if [ -z "$(command -v gofmt)" ]; then
  echo "Can not find gofmt"
  exit 1
fi

diff=$(find . -name "*.go" | grep -v "\.pb\.go$" | xargs gofmt -s -d 2>&1)
if [[ -n "${diff}" ]]; then
  echo "${diff}"
  echo
  echo "Please run hack/update-gofmt.sh"
  exit 1
fi



================================================
FILE: hack/verify-golangci-lint.sh
================================================
#!/usr/bin/env bash

# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

set -o errexit
set -o pipefail

cd "$(dirname "$0")/.."

if [ -z "$(command -v golangci-lint)" ]; then
	echo 'Can not find golangci-lint, install with: make lint'
	exit 1
fi

echo 'Running golangci-lint'
golangci-lint run --timeout 5m --go 1.23



================================================
FILE: hack/verify-shellcheck.sh
================================================
#!/usr/bin/env bash

# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

set -o errexit
set -o pipefail

cd "$(dirname "$0")/.."

if [ -z "$(command -v shellcheck)" ]; then
	echo 'Can not find shellcheck, install with: make shellcheck'
	exit 1
fi

shell_scripts=()
while IFS='' read -r script;
  do git check-ignore -q "$script" || shell_scripts+=("$script");
done < <(find . -name "*.sh" \
  ! -path "./_*" \
  ! -path "./.git/*"
)

echo 'Running shellcheck'
shellcheck "${shell_scripts[@]}"



================================================
FILE: hack/verify-yamllint.sh
================================================
#!/usr/bin/env bash

# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

set -o errexit
set -o pipefail

cd "$(dirname "$0")/.."

if [ -z "$(command -v yamllint)" ]; then
	echo 'Can not find yamllint, install with: make yamllint'
	exit 1
fi

echo 'Running yamllint'
yamllint -d "{extends: default, rules: {line-length: disable}}" examples/* manifests/*



================================================
FILE: hack/violation_exception_v1beta1.list
================================================
[Empty file]


================================================
FILE: hack/boilerplate/boilerplate.go.txt
================================================
/*
Copyright 2022 The Kubeflow Authors.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/




================================================
FILE: hack/boilerplate/boilerplate.py.txt
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.




================================================
FILE: hack/boilerplate/boilerplate.sh.txt
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.




================================================
FILE: hack/boilerplate/update-boilerplate.sh
================================================
#!/usr/bin/env bash

# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This script is used to update or add the boilerplate.

# ------------------ Go files ------------------
# Exclude client, gRPC manager, swagger, deepcopy and mock from the search.
find_go_files=$(
  find ./cmd ./pkg ./hack ./test -name "*.go" \
    ! -path "./pkg/client/*" \
    ! -path "./pkg/apis/manager/*" \
    ! -path "./pkg/apis/v1beta1/*" \
    ! -path "./pkg/apis/controller/*.deepcopy.go" \
    ! -path "./pkg/mock/*"
)

for i in ${find_go_files}; do
  # If the 2nd line starts with "Copyright", remove the current boilerplate.
  if [[ $(sed -n 2p "$i") =~ "Copyright" ]]; then
    echo "Remove the current boilerplate and add the new boilerplate to $i"
    tail -n +17 "$i" >"$i.tmp"
  # If the 1st line starts with "//go:build" and the 4th line starts with "Copyright", remove the current boilerplate and copy the marker.
  elif [[ $(sed -n 1p "$i") =~ "//go:build" ]] && [[ $(sed -n 4p "$i") =~ "Copyright" ]]; then
    echo "Remove the current boilerplate, copy the marker for Go, and add the new boilerplate to $i"
    sed -e "2,17d" "$i" > "$i.tmp"
  # Otherwise, copy the whole file.
  else
    echo "Add the new boilerplate to $i"
    cat "$i" >"$i.tmp"
  fi

  # If the 1st line starts with "//go:build", copy the marker and add the new boilerplate to the file.
  if [[ $(sed -n 1p "$i.tmp") =~ "//go:build" ]]; then
    (head -2 "$i.tmp" && cat ./hack/boilerplate/boilerplate.go.txt && tail -n +3 "$i.tmp") >"$i" && rm "$i.tmp"
  # Otherwise, add the new boilerplate to the file.
  else
    cat ./hack/boilerplate/boilerplate.go.txt "$i.tmp" >"$i" && rm "$i.tmp"
  fi
done

# ------------------ Python files ------------------
# Exclude gRPC manager and __init__.py files from the search.
find_python_files=$(
  find ./cmd ./pkg ./hack ./test ./examples -name "*.py" \
    ! -path "./pkg/apis/manager/*" \
    ! -path "*__init__.py" \
)

for i in ${find_python_files}; do
  # If the 1st line starts with "# Copyright", remove the boilerplate.
  if [[ $(sed -n 1p "$i") =~ "# Copyright" ]]; then
    echo "Remove the current boilerplate and add the new boilerplate to $i"
    tail -n +15 "$i" >"$i.tmp"
  # Otherwise, copy the whole file.
  else
    echo "Add the new boilerplate to $i"
    cat "$i" >"$i.tmp"
  fi
  # Add the new boilerplate to the file.
  cat ./hack/boilerplate/boilerplate.py.txt "$i.tmp" >"$i" && rm "$i.tmp"
done

# ------------------ Shell files ------------------
find_shell_files=$(find ./pkg ./hack ./scripts ./test ./examples -name "*.sh")

for i in ${find_shell_files}; do
  # If the 3rd line starts with "# Copyright", remove the boilerplate.
  # In the shell files we should save the first line.
  if [[ $(sed -n 3p "$i") =~ "# Copyright" ]]; then
    echo "Remove the current boilerplate and add the new boilerplate to $i"
    sed -e "2,15d" "$i" >"$i.tmp"
  # Otherwise, copy the whole file.
  else
    echo "Add the new boilerplate to $i"
    cat "$i" >"$i.tmp"
  fi
  # Add the new boilerplate to the file.
  (head -2 "$i.tmp" && cat ./hack/boilerplate/boilerplate.sh.txt && tail -n +3 "$i.tmp") >"$i" && rm "$i.tmp"
done



================================================
FILE: hack/gen-python-sdk/gen-sdk.sh
================================================
#!/usr/bin/env bash

# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

set -o errexit
set -o nounset
set -o pipefail

SWAGGER_JAR_URL="https://repo1.maven.org/maven2/org/openapitools/openapi-generator-cli/4.3.1/openapi-generator-cli-4.3.1.jar"
SWAGGER_CODEGEN_JAR="hack/gen-python-sdk/openapi-generator-cli.jar"

SWAGGER_CODEGEN_CONF="hack/gen-python-sdk/swagger_config.json"
SWAGGER_CODEGEN_FILE="pkg/apis/KATIB_VERSION/swagger.json"

TMP_CODEGEN_PATH="sdk/tmp/KATIB_VERSION"
SDK_OUTPUT_PATH="sdk/python"
POST_GEN_PYTHON_HANDLER="hack/gen-python-sdk/post_gen.py"
KATIB_VERSIONS=(v1beta1)

# Download JAR package if file doesn't exist.
if ! test -f "${SWAGGER_CODEGEN_JAR}"; then
    echo "Downloading the openapi generator JAR package ..."
    wget -O "${SWAGGER_CODEGEN_JAR}" "${SWAGGER_JAR_URL}"
fi

for VERSION in "${KATIB_VERSIONS[@]}"; do
    echo "Generating Python SDK for Kubeflow Katib ${VERSION} ..."
    SWAGGER_FILE="${SWAGGER_CODEGEN_FILE/KATIB_VERSION/$VERSION}"
    TMP_PATH="${TMP_CODEGEN_PATH/KATIB_VERSION/$VERSION}"
    java -jar "${SWAGGER_CODEGEN_JAR}" generate -i "${SWAGGER_FILE}" -g python -o "${TMP_PATH}" -c "${SWAGGER_CODEGEN_CONF}"

    # Run post gen script.
    python "${POST_GEN_PYTHON_HANDLER}" "${TMP_PATH}" "${SDK_OUTPUT_PATH}/${VERSION}"
done



================================================
FILE: hack/gen-python-sdk/post_gen.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import shutil
import sys

IGNORE_LINES = [
    "from kubeflow.katib.models.v1_unstructured_unstructured import V1UnstructuredUnstructured",
    "from kubeflow.katib.models.v1_time import V1Time",
]


def _rewrite_helper(input_file, output_file, rewrite_rules):
    rules = rewrite_rules or []
    lines = []
    with open(input_file, "r") as f:
        while True:
            line = f.readline()
            if not line:
                break
            # Apply rewrite rules to the line.
            for rule in rules:
                line = rule(line)
            # Remove ignored lines.
            if not any(li in line for li in IGNORE_LINES):
                lines.append(line)

    # Add Katib APIs to the init file.
    if output_file == "sdk/python/v1beta1/kubeflow/katib/__init__.py":
        lines.append("# Import Katib API client.\n")
        lines.append("from kubeflow.katib.api.katib_client import KatibClient\n")
        lines.append("# Import Katib TrainerResources class.\n")
        lines.append("from kubeflow.katib.types.types import TrainerResources\n")
        lines.append("# Import Katib report metrics functions\n")
        lines.append("from kubeflow.katib.api.report_metrics import report_metrics\n")
        lines.append("# Import Katib helper functions.\n")
        lines.append("import kubeflow.katib.api.search as search\n")
        lines.append("# Import Katib helper constants.\n")
        lines.append(
            "from kubeflow.katib.constants.constants import BASE_IMAGE_TENSORFLOW\n"
        )
        lines.append(
            "from kubeflow.katib.constants.constants import BASE_IMAGE_TENSORFLOW_GPU\n"
        )
        lines.append(
            "from kubeflow.katib.constants.constants import BASE_IMAGE_PYTORCH\n"
        )

    # Add Kubernetes models to proper deserialization of Katib models.
    if output_file == "sdk/python/v1beta1/kubeflow/katib/models/__init__.py":
        lines.append("\n")
        lines.append("# Import Kubernetes models.\n")
        lines.append("from kubernetes.client import *\n")

    with open(output_file, "w") as f:
        f.writelines(lines)


def update_python_sdk(src, dest, versions=("v1beta1")):
    # tiny transformers to refine generated codes
    rewrite_rules = [
        # Models rules.
        lambda line: line.replace("import katib", "import kubeflow.katib"),
        lambda line: line.replace("from katib", "from kubeflow.katib"),
        # For the api_client.py.
        lambda line: line.replace(
            "klass = getattr(katib.models, klass)",
            "klass = getattr(kubeflow.katib.models, klass)",
        ),
        # Doc rules.
        lambda line: line.replace("[**datetime**](V1Time.md)", "**datetime**"),
        lambda line: line.replace(
            "[**object**](V1UnstructuredUnstructured.md)", "**object**"
        ),
        lambda line: line.replace(
            "[**V1Container**](V1Container.md)",
            "[**V1Container**](https://github.com/kubernetes-client/"
            "python/blob/master/kubernetes/docs/V1Container.md)",
        ),
        lambda line: line.replace(
            "[**V1ObjectMeta**](V1ObjectMeta.md)",
            "[**V1ObjectMeta**](https://github.com/kubernetes-client/"
            "python/blob/master/kubernetes/docs/V1ObjectMeta.md)",
        ),
        lambda line: line.replace(
            "[**V1ListMeta**](V1ListMeta.md)",
            "[**V1ListMeta**](https://github.com/kubernetes-client/"
            "python/blob/master/kubernetes/docs/V1ListMeta.md)",
        ),
        lambda line: line.replace(
            "[**V1HTTPGetAction**](V1HTTPGetAction.md)",
            "[**V1HTTPGetAction**](https://github.com/kubernetes-client/"
            "python/blob/master/kubernetes/docs/V1HTTPGetAction.md)",
        ),
    ]

    # TODO (andreyvelich): Currently test can't be generated properly.
    src_dirs = [
        os.path.join(src, "katib"),
        os.path.join(src, "katib", "models"),
        # os.path.join(src, 'test'),
        os.path.join(src, "docs"),
    ]
    dest_dirs = [
        os.path.join(dest, "kubeflow", "katib"),
        os.path.join(dest, "kubeflow", "katib", "models"),
        # os.path.join(dest, 'test'),
        os.path.join(dest, "docs"),
    ]

    for src_dir, dest_dir in zip(src_dirs, dest_dirs):
        # Remove previous generated files explicitly, in case of deprecated instances.
        for file in os.listdir(dest_dir):
            path = os.path.join(dest_dir, file)
            # We should not remove KatibClient doc.
            if not os.path.isfile(path) or "/docs/KatibClient.md" in path:
                continue
            for v in versions:
                if v in file.lower():
                    os.remove(path)
                    break
        # fill latest generated files
        for file in os.listdir(src_dir):
            in_file = os.path.join(src_dir, file)
            out_file = os.path.join(dest_dir, file)
            if not os.path.isfile(in_file):
                continue
            _rewrite_helper(in_file, out_file, rewrite_rules)

    # Update doc for Models README.md
    buffer = []
    update_buffer = []

    # Get data from generated doc
    with open(os.path.join(src, "README.md"), "r") as src_f:
        anchor = 0
        for line in src_f.readlines():
            if line.startswith("## Documentation For Models"):
                if anchor == 0:
                    anchor = 1
            elif line.startswith("##") and anchor == 1:
                anchor = 2
            if anchor == 0:
                continue
            if anchor == 2:
                break
            # Remove leading space from the list
            if len(line) > 0:
                line = line.lstrip(" ")
            update_buffer.append(line)
    # Remove latest redundant newline
    update_buffer = update_buffer[:-1]

    # Update README with new models
    with open(os.path.join(dest, "README.md"), "r") as dest_f:
        anchor = 0
        for line in dest_f.readlines():
            if line.startswith("## Documentation For Models"):
                if anchor == 0:
                    buffer.extend(update_buffer)
                    anchor = 1
            elif line.startswith("##") and anchor == 1:
                anchor = 2
            if anchor == 1:
                continue
            buffer.append(line)
    with open(os.path.join(dest, "README.md"), "w") as dest_f:
        dest_f.writelines(buffer)

    # Clear working dictionary
    shutil.rmtree(src)


if __name__ == "__main__":
    update_python_sdk(src=sys.argv[1], dest=sys.argv[2])



================================================
FILE: hack/gen-python-sdk/swagger_config.json
================================================
{
  "packageName": "katib",
  "projectName": "katib",
  "packageVersion": "0.1",
  "importMappings": {
    "V1Container": "from kubernetes.client import V1Container",
    "V1ListMeta": "from kubernetes.client import V1ListMeta",
    "V1ObjectMeta": "from kubernetes.client import V1ObjectMeta",
    "V1HTTPGetAction": "from kubernetes.client import V1HTTPGetAction",
    "V1ManagedFieldsEntry": "from kubernetes.client import V1ManagedFieldsEntry",
    "V1OwnerReference": "from kubernetes.client import V1OwnerReference"
  },
  "typeMappings": {
    "V1Time": "datetime",
    "V1UnstructuredUnstructured": "object"
  }
}



================================================
FILE: hack/swagger/main.go
================================================
/*
Copyright 2022 The Kubeflow Authors.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package main

import (
	"encoding/json"
	"fmt"
	"os"
	"strings"

	"github.com/kubeflow/katib/pkg/apis/v1beta1"
	"k8s.io/klog/v2"
	"k8s.io/kube-openapi/pkg/common"
	"k8s.io/kube-openapi/pkg/validation/spec"
)

// Generate OpenAPI spec definitions for Katib Resource
func main() {
	if len(os.Args) <= 2 {
		klog.Fatal("Supply Swagger version and Katib Version")
	}
	version := os.Args[1]
	if !strings.HasPrefix(version, "v") {
		version = "v" + version
	}
	refCallback := func(name string) spec.Ref {
		return spec.MustCreateRef("#/definitions/" + common.EscapeJsonPointer(swaggify(name)))
	}

	katibVersion := os.Args[2]
	if katibVersion != "v1beta1" {
		klog.Fatalf("Katib version %v is not supported", katibVersion)
	}

	oAPIDefs := v1beta1.GetOpenAPIDefinitions(refCallback)
	defs := spec.Definitions{}
	for defName, val := range oAPIDefs {
		defs[swaggify(defName)] = val.Schema
	}
	swagger := spec.Swagger{
		SwaggerProps: spec.SwaggerProps{
			Swagger:     "2.0",
			Definitions: defs,
			Paths:       &spec.Paths{Paths: map[string]spec.PathItem{}},
			Info: &spec.Info{
				InfoProps: spec.InfoProps{
					Title:       "Katib",
					Description: "Swagger description for Katib",
					Version:     version,
				},
			},
		},
	}
	jsonBytes, err := json.MarshalIndent(swagger, "", "  ")
	if err != nil {
		klog.Fatal(err.Error())
	}
	fmt.Println(string(jsonBytes))
}

func swaggify(name string) string {
	name = strings.Replace(name, "github.com/kubeflow/katib/pkg/apis/controller/common/", "", -1)
	name = strings.Replace(name, "github.com/kubeflow/katib/pkg/apis/controller/experiments/", "", -1)
	name = strings.Replace(name, "github.com/kubeflow/katib/pkg/apis/controller/suggestions", "", -1)
	name = strings.Replace(name, "github.com/kubeflow/katib/pkg/apis/controller/trials", "", -1)
	name = strings.Replace(name, "k8s.io/api/core/", "", -1)
	name = strings.Replace(name, "k8s.io/apimachinery/pkg/apis/meta/", "", -1)
	name = strings.Replace(name, "/", ".", -1)
	return name
}



================================================
FILE: manifests/v1beta1/components/controller/controller.yaml
================================================
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: katib-controller
  namespace: kubeflow
  labels:
    katib.kubeflow.org/component: controller
spec:
  replicas: 1
  selector:
    matchLabels:
      katib.kubeflow.org/component: controller
  template:
    metadata:
      labels:
        katib.kubeflow.org/component: controller
        sidecar.istio.io/inject: "false"
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
    spec:
      serviceAccountName: katib-controller
      containers:
        - name: katib-controller
          image: ghcr.io/kubeflow/katib/katib-controller
          command: ["./katib-controller"]
          args:
            - --katib-config=/katib-config.yaml
          ports:
            - containerPort: 8443
              name: webhook
              protocol: TCP
            - containerPort: 8080
              name: metrics
              protocol: TCP
            - containerPort: 18080
              name: healthz
              protocol: TCP
          readinessProbe:
            httpGet:
              path: /readyz
              port: healthz
          livenessProbe:
            httpGet:
              path: /healthz
              port: healthz
          env:
            - name: KATIB_CORE_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          volumeMounts:
            - mountPath: /tmp/cert
              name: cert
              readOnly: true
            - mountPath: /katib-config.yaml
              name: katib-config
              subPath: katib-config.yaml
              readOnly: true
          securityContext:
            runAsNonRoot: true
            allowPrivilegeEscalation: false
            runAsUser: 1000
            seccompProfile:
              type: RuntimeDefault
            capabilities:
              drop:
              - ALL
      volumes:
        - name: cert
          secret:
            defaultMode: 420
            secretName: katib-webhook-cert
        - name: katib-config
          configMap:
            name: katib-config



================================================
FILE: manifests/v1beta1/components/controller/kustomization.yaml
================================================
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
  - controller.yaml
  - rbac.yaml
  - service.yaml
  - trial-templates.yaml



================================================
FILE: manifests/v1beta1/components/controller/rbac.yaml
================================================
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: katib-controller
rules:
  - apiGroups:
      - ""
    resources:
      - services
    verbs:
      - "get"
      - "list"
      - "watch"
      - "create"
      - "delete"
  - apiGroups:
      - ""
    resources:
      - events
    verbs:
      - "create"
      - "patch"
      - "update"
  - apiGroups:
      - ""
    resources:
      - serviceaccounts
      - persistentvolumes
      - persistentvolumeclaims
    verbs:
      - "get"
      - "list"
      - "watch"
      - "create"
  - apiGroups:
      - ""
    resources:
      - namespaces
      - configmaps
    verbs:
      - "get"
      - "list"
      - "watch"
  - apiGroups:
      - ""
    resources:
      - pods
      - pods/status
    verbs:
      - "get"
  - apiGroups:
      - ""
    resources:
      - secrets
    verbs:
      - "get"
      - "list"
      - "watch"
      - "patch"
      - "update"
  - apiGroups:
      - apps
    resources:
      - deployments
    verbs:
      - "get"
      - "list"
      - "watch"
      - "create"
      - "delete"
  - apiGroups:
      - rbac.authorization.k8s.io
    resources:
      - roles
      - rolebindings
    verbs:
      - "get"
      - "create"
      - "list"
      - "watch"
  - apiGroups:
      - batch
    resources:
      - jobs
      - cronjobs
    verbs:
      - "get"
      - "list"
      - "watch"
      - "create"
      - "delete"
  - apiGroups:
      - jobset.x-k8s.io
    resources:
      - jobsets
    verbs:
      - "get"
      - "list"
      - "watch"
  - apiGroups:
      - trainer.kubeflow.org
    resources:
      - trainjobs
    verbs:
      - "get"
      - "list"
      - "watch"
  - apiGroups:
      - kubeflow.org
    resources:
      - tfjobs
      - pytorchjobs
      - mpijobs
      - xgboostjobs
    verbs:
      - "get"
      - "list"
      - "watch"
      - "create"
      - "delete"
  - apiGroups:
      - kubeflow.org
    resources:
      - experiments
      - experiments/status
      - experiments/finalizers
      - trials
      - trials/status
      - trials/finalizers
      - suggestions
      - suggestions/status
      - suggestions/finalizers
    verbs:
      - "*"
  - apiGroups:
      - admissionregistration.k8s.io
    resources:
      - validatingwebhookconfigurations
      - mutatingwebhookconfigurations
    verbs:
      - "get"
      - "watch"
      - "list"
      - "patch"
      - "update"
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: katib-controller
  namespace: kubeflow
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: katib-controller
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: katib-controller
subjects:
  - kind: ServiceAccount
    name: katib-controller
    namespace: kubeflow



================================================
FILE: manifests/v1beta1/components/controller/service.yaml
================================================
---
apiVersion: v1
kind: Service
metadata:
  name: katib-controller
  namespace: kubeflow
  labels:
    katib.kubeflow.org/component: controller
  annotations:
    prometheus.io/port: "8080"
    prometheus.io/scheme: http
    prometheus.io/scrape: "true"
spec:
  ports:
    - port: 443
      protocol: TCP
      targetPort: 8443
      name: webhook
    - name: metrics
      port: 8080
      targetPort: 8080
    - name: healthz
      port: 18080
      targetPort: 18080
  selector:
    katib.kubeflow.org/component: controller



================================================
FILE: manifests/v1beta1/components/controller/trial-templates.yaml
================================================
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: trial-templates
  namespace: kubeflow
  labels:
    katib.kubeflow.org/component: trial-templates
data:
  defaultTrialTemplate.yaml: |-
    apiVersion: batch/v1
    kind: Job
    spec:
      template:
        spec:
          containers:
            - name: training-container
              image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
              command:
                - "python3"
                - "/opt/pytorch-mnist/mnist.py"
                - "--epochs=1"
                - "--batch-size=16"
                - "--lr=${trialParameters.learningRate}"
                - "--momentum=${trialParameters.momentum}"
          restartPolicy: Never
  # For ConfigMap templates double quotes must set in commands to correct parse JSON parameters in Trial Template (e.g nn_config, architecture)
  enasCPUTemplate: |-
    apiVersion: batch/v1
    kind: Job
    spec:
      template:
        spec:
          containers:
            - name: training-container
              image: ghcr.io/kubeflow/katib/enas-cnn-cifar10-cpu:latest
              command:
                - python3
                - -u
                - RunTrial.py
                - --num_epochs=1
                - "--architecture=\"${trialParameters.neuralNetworkArchitecture}\""
                - "--nn_config=\"${trialParameters.neuralNetworkConfig}\""
          restartPolicy: Never
  pytorchJobTemplate: |-
    apiVersion: kubeflow.org/v1
    kind: PyTorchJob
    spec:
      pytorchReplicaSpecs:
        Master:
          replicas: 1
          restartPolicy: OnFailure
          template:
            spec:
              containers:
                - name: pytorch
                  image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
                  command:
                    - "python3"
                    - "/opt/pytorch-mnist/mnist.py"
                    - "--epochs=1"
                    - "--lr=${trialParameters.learningRate}"
                    - "--momentum=${trialParameters.momentum}"
        Worker:
          replicas: 2
          restartPolicy: OnFailure
          template:
            spec:
              containers:
                - name: pytorch
                  image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
                  command:
                    - "python3"
                    - "/opt/pytorch-mnist/mnist.py"
                    - "--epochs=1"
                    - "--lr=${trialParameters.learningRate}"
                    - "--momentum=${trialParameters.momentum}"



================================================
FILE: manifests/v1beta1/components/crd/experiment.yaml
================================================
---
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: experiments.kubeflow.org
spec:
  group: kubeflow.org
  scope: Namespaced
  versions:
    - name: v1beta1
      served: true
      storage: true
      additionalPrinterColumns:
        - name: Type
          type: string
          jsonPath: .status.conditions[-1:].type
        - name: Status
          type: string
          jsonPath: .status.conditions[-1:].status
        - name: Age
          type: date
          jsonPath: .metadata.creationTimestamp
      subresources:
        status: {}
      schema:
        openAPIV3Schema:
          type: object
          x-kubernetes-preserve-unknown-fields: true
  names:
    kind: Experiment
    singular: experiment
    plural: experiments
    categories:
      - all
      - kubeflow
      - katib



================================================
FILE: manifests/v1beta1/components/crd/kustomization.yaml
================================================
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
  - experiment.yaml
  - suggestion.yaml
  - trial.yaml



================================================
FILE: manifests/v1beta1/components/crd/suggestion.yaml
================================================
---
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: suggestions.kubeflow.org
spec:
  group: kubeflow.org
  scope: Namespaced
  versions:
    - name: v1beta1
      served: true
      storage: true
      additionalPrinterColumns:
        - name: Type
          type: string
          jsonPath: .status.conditions[-1:].type
        - name: Status
          type: string
          jsonPath: .status.conditions[-1:].status
        - name: Requested
          type: string
          jsonPath: .spec.requests
        - name: Assigned
          type: string
          jsonPath: .status.suggestionCount
        - name: Age
          type: date
          jsonPath: .metadata.creationTimestamp
      subresources:
        status: {}
      schema:
        openAPIV3Schema:
          type: object
          x-kubernetes-preserve-unknown-fields: true
  names:
    kind: Suggestion
    singular: suggestion
    plural: suggestions
    categories:
      - all
      - kubeflow
      - katib



================================================
FILE: manifests/v1beta1/components/crd/trial.yaml
================================================
---
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: trials.kubeflow.org
spec:
  group: kubeflow.org
  scope: Namespaced
  versions:
    - name: v1beta1
      served: true
      storage: true
      additionalPrinterColumns:
        - name: Type
          type: string
          jsonPath: .status.conditions[-1:].type
        - name: Status
          type: string
          jsonPath: .status.conditions[-1:].status
        - name: Age
          type: date
          jsonPath: .metadata.creationTimestamp
      subresources:
        status: {}
      schema:
        openAPIV3Schema:
          type: object
          x-kubernetes-preserve-unknown-fields: true
  names:
    kind: Trial
    singular: trial
    plural: trials
    categories:
      - all
      - kubeflow
      - katib



================================================
FILE: manifests/v1beta1/components/db-manager/db-manager.yaml
================================================
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: katib-db-manager
  namespace: kubeflow
  labels:
    katib.kubeflow.org/component: db-manager
spec:
  replicas: 1
  selector:
    matchLabels:
      katib.kubeflow.org/component: db-manager
  template:
    metadata:
      labels:
        katib.kubeflow.org/component: db-manager
        sidecar.istio.io/inject: "false"
    spec:
      containers:
        - name: katib-db-manager
          image: ghcr.io/kubeflow/katib/katib-db-manager
          env:
            - name: DB_NAME
              value: "mysql"
            - name: DB_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: katib-mysql-secrets
                  key: MYSQL_ROOT_PASSWORD
          command:
            - "./katib-db-manager"
          ports:
            - name: api
              containerPort: 6789
          livenessProbe:
            grpc:
              port: 6789
            initialDelaySeconds: 10
            periodSeconds: 60
            failureThreshold: 5
          securityContext:
            runAsNonRoot: true
            allowPrivilegeEscalation: false
            runAsUser: 1000
            seccompProfile:
              type: RuntimeDefault
            capabilities:
              drop:
              - ALL



================================================
FILE: manifests/v1beta1/components/db-manager/kustomization.yaml
================================================
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
  - db-manager.yaml
  - service.yaml



================================================
FILE: manifests/v1beta1/components/db-manager/service.yaml
================================================
---
apiVersion: v1
kind: Service
metadata:
  name: katib-db-manager
  namespace: kubeflow
  labels:
    katib.kubeflow.org/component: db-manager
spec:
  type: ClusterIP
  ports:
    - port: 6789
      protocol: TCP
      name: api
  selector:
    katib.kubeflow.org/component: db-manager



================================================
FILE: manifests/v1beta1/components/mysql/kustomization.yaml
================================================
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
  - mysql.yaml
  - pvc.yaml
  - secret.yaml
  - service.yaml



================================================
FILE: manifests/v1beta1/components/mysql/mysql.yaml
================================================
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: katib-mysql
  namespace: kubeflow
  labels:
    katib.kubeflow.org/component: mysql
spec:
  replicas: 1
  selector:
    matchLabels:
      katib.kubeflow.org/component: mysql
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        katib.kubeflow.org/component: mysql
        sidecar.istio.io/inject: "false"
    spec:
      securityContext:
        fsGroup: 999
        fsGroupChangePolicy: OnRootMismatch
      containers:
        - name: katib-mysql
          image: mysql:8.0.29
          args:
            - --datadir
            - /var/lib/mysql/datadir
          env:
            - name: MYSQL_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: katib-mysql-secrets
                  key: MYSQL_ROOT_PASSWORD
            - name: MYSQL_ALLOW_EMPTY_PASSWORD
              value: "true"
            - name: MYSQL_DATABASE
              value: "katib"
          ports:
            - name: dbapi
              containerPort: 3306
          readinessProbe:
            exec:
              command:
                - "/bin/bash"
                - "-c"
                - "mysql -D ${MYSQL_DATABASE} -u root -p${MYSQL_ROOT_PASSWORD} -e 'SELECT 1'"
            initialDelaySeconds: 10
            periodSeconds: 5
            failureThreshold: 10
          livenessProbe:
            exec:
              command:
                - "/bin/bash"
                - "-c"
                - "mysqladmin ping -u root -p${MYSQL_ROOT_PASSWORD}"
            initialDelaySeconds: 10
            periodSeconds: 5
            failureThreshold: 10
          startupProbe:
            exec:
              command:
                - "/bin/bash"
                - "-c"
                - "mysqladmin ping -u root -p${MYSQL_ROOT_PASSWORD}"
            periodSeconds: 15
            failureThreshold: 60
          volumeMounts:
            - name: katib-mysql
              mountPath: /var/lib/mysql
          securityContext:
            allowPrivilegeEscalation: false
            seccompProfile:
              type: RuntimeDefault
            runAsNonRoot: true
            runAsUser: 999
            runAsGroup: 999
            capabilities:
              drop:
              - ALL
      volumes:
        - name: katib-mysql
          persistentVolumeClaim:
            claimName: katib-mysql



================================================
FILE: manifests/v1beta1/components/mysql/pvc.yaml
================================================
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: katib-mysql
  namespace: kubeflow
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi



================================================
FILE: manifests/v1beta1/components/mysql/secret.yaml
================================================
---
apiVersion: v1
kind: Secret
type: Opaque
metadata:
  name: katib-mysql-secrets
data:
  MYSQL_ROOT_PASSWORD: dGVzdA==  # "test"



================================================
FILE: manifests/v1beta1/components/mysql/service.yaml
================================================
---
apiVersion: v1
kind: Service
metadata:
  name: katib-mysql
  namespace: kubeflow
  labels:
    katib.kubeflow.org/component: mysql
spec:
  type: ClusterIP
  ports:
    - port: 3306
      protocol: TCP
      name: dbapi
  selector:
    katib.kubeflow.org/component: mysql



================================================
FILE: manifests/v1beta1/components/namespace/kustomization.yaml
================================================
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
namespace: kubeflow
resources:
  # Namespace.
  - namespace.yaml



================================================
FILE: manifests/v1beta1/components/namespace/namespace.yaml
================================================
---
apiVersion: v1
kind: Namespace
metadata:
  name: kubeflow
  labels:
    katib.kubeflow.org/metrics-collector-injection: enabled



================================================
FILE: manifests/v1beta1/components/postgres/kustomization.yaml
================================================
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
  - postgres.yaml
  - pvc.yaml
  - secret.yaml
  - service.yaml



================================================
FILE: manifests/v1beta1/components/postgres/postgres.yaml
================================================
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: katib-postgres
  namespace: kubeflow
  labels:
    katib.kubeflow.org/component: postgres
spec:
  replicas: 1
  selector:
    matchLabels:
      katib.kubeflow.org/component: postgres
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        katib.kubeflow.org/component: postgres
        sidecar.istio.io/inject: "false"
      annotations:
    spec:
      containers:
        - name: katib-postgres
          image: postgres:14.5-alpine
          envFrom:
            - secretRef:
                name: katib-postgres-secrets
          env:
            - name: PGDATA
              value: /var/lib/postgresql/data/pgdata
          ports:
            - name: postgres
              containerPort: 5432
              protocol: TCP
          volumeMounts:
            - name: katib-postgres
              mountPath: /var/lib/postgresql/data
      volumes:
        - name: katib-postgres
          persistentVolumeClaim:
            claimName: katib-postgres



================================================
FILE: manifests/v1beta1/components/postgres/pvc.yaml
================================================
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: katib-postgres
  namespace: kubeflow
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 3Gi



================================================
FILE: manifests/v1beta1/components/postgres/secret.yaml
================================================
---
apiVersion: v1
kind: Secret
type: Opaque
metadata:
  name: katib-postgres-secrets
data:
  POSTGRES_USER: a2F0aWI=  # katib
  POSTGRES_PASSWORD: a2F0aWI=  # katib
  POSTGRES_DB: a2F0aWI=  # katib



================================================
FILE: manifests/v1beta1/components/postgres/service.yaml
================================================
---
apiVersion: v1
kind: Service
metadata:
  name: katib-postgres
  namespace: kubeflow
  labels:
    katib.kubeflow.org/component: postgres
spec:
  type: ClusterIP
  ports:
    - port: 5432
      protocol: TCP
      name: dbapi
  selector:
    katib.kubeflow.org/component: postgres



================================================
FILE: manifests/v1beta1/components/ui/kustomization.yaml
================================================
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
  - rbac.yaml
  - service.yaml
  - ui.yaml



================================================
FILE: manifests/v1beta1/components/ui/rbac.yaml
================================================
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: katib-ui
rules:
  - apiGroups:
      - ""
    resources:
      - configmaps
      - namespaces
    verbs:
      - "*"
  - apiGroups:
      - kubeflow.org
    resources:
      - experiments
      - trials
      - suggestions
    verbs:
      - "*"
  - apiGroups:
      - ""
    resources:
      - pods
    verbs:
      - list
  - apiGroups:
      - ""
    resources:
      - pods/log
    verbs:
      - get
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: katib-ui
  namespace: kubeflow
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: katib-ui
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: katib-ui
subjects:
  - kind: ServiceAccount
    name: katib-ui
    namespace: kubeflow



================================================
FILE: manifests/v1beta1/components/ui/service.yaml
================================================
---
apiVersion: v1
kind: Service
metadata:
  name: katib-ui
  namespace: kubeflow
  labels:
    katib.kubeflow.org/component: ui
spec:
  type: ClusterIP
  ports:
    - port: 80
      protocol: TCP
      name: ui
      targetPort: 8080
  selector:
    katib.kubeflow.org/component: ui



================================================
FILE: manifests/v1beta1/components/ui/ui.yaml
================================================
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: katib-ui
  namespace: kubeflow
  labels:
    katib.kubeflow.org/component: ui
spec:
  replicas: 1
  selector:
    matchLabels:
      katib.kubeflow.org/component: ui
  template:
    metadata:
      labels:
        katib.kubeflow.org/component: ui
        sidecar.istio.io/inject: "false"
    spec:
      containers:
        - name: katib-ui
          image: ghcr.io/kubeflow/katib/katib-ui
          command:
            - "./katib-ui"
          args:
            - "--port=8080"
          env:
            - name: KATIB_CORE_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          ports:
            - name: ui
              containerPort: 8080
          securityContext:
            runAsNonRoot: true
            allowPrivilegeEscalation: false
            runAsUser: 1000
            seccompProfile:
              type: RuntimeDefault
            capabilities:
              drop:
              - ALL
      serviceAccountName: katib-ui



================================================
FILE: manifests/v1beta1/components/webhook/kustomization.yaml
================================================
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
  - webhooks.yaml



================================================
FILE: manifests/v1beta1/components/webhook/webhooks.yaml
================================================
---
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  name: katib.kubeflow.org
webhooks:
  - name: validator.experiment.katib.kubeflow.org
    sideEffects: None
    admissionReviewVersions:
      - v1
    clientConfig:
      service:
        name: katib-controller
        namespace: kubeflow
        path: /validate-experiment
    rules:
      - apiGroups:
          - kubeflow.org
        apiVersions:
          - v1beta1
        operations:
          - CREATE
          - UPDATE
        resources:
          - experiments
---
apiVersion: admissionregistration.k8s.io/v1
kind: MutatingWebhookConfiguration
metadata:
  name: katib.kubeflow.org
webhooks:
  - name: defaulter.experiment.katib.kubeflow.org
    sideEffects: None
    admissionReviewVersions:
      - v1
    clientConfig:
      service:
        name: katib-controller
        namespace: kubeflow
        path: /mutate-experiment
    rules:
      - apiGroups:
          - kubeflow.org
        apiVersions:
          - v1beta1
        operations:
          - CREATE
          - UPDATE
        resources:
          - experiments
  - name: mutator.pod.katib.kubeflow.org
    sideEffects: None
    admissionReviewVersions:
      - v1
    clientConfig:
      service:
        name: katib-controller
        namespace: kubeflow
        path: /mutate-pod
    namespaceSelector:
      matchLabels:
        katib.kubeflow.org/metrics-collector-injection: enabled
    matchConditions:
      - name: 'exclude-katib-controller'
        expression: 'request.userInfo.username != "system:serviceaccount:kubeflow:katib-controller"'
    rules:
      - apiGroups:
          - ""
        apiVersions:
          - v1
        operations:
          - CREATE
        resources:
          - pods



================================================
FILE: manifests/v1beta1/installs/katib-cert-manager/certificate.yaml
================================================
---
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: katib-webhook-cert
spec:
  isCA: true
  commonName: KATIB_SERVICE_NAME_PLACEHOLDER.KATIB_NAMESPACE_PLACEHOLDER.svc
  dnsNames:
    - KATIB_SERVICE_NAME_PLACEHOLDER.KATIB_NAMESPACE_PLACEHOLDER.svc
    - KATIB_SERVICE_NAME_PLACEHOLDER.KATIB_NAMESPACE_PLACEHOLDER.svc.cluster.local
  issuerRef:
    kind: Issuer
    name: katib-selfsigned-issuer
  secretName: katib-webhook-cert
---
apiVersion: cert-manager.io/v1
kind: Issuer
metadata:
  name: katib-selfsigned-issuer
spec:
  selfSigned: {}



================================================
FILE: manifests/v1beta1/installs/katib-cert-manager/katib-config.yaml
================================================
---
apiVersion: config.kubeflow.org/v1beta1
kind: KatibConfig
init:
  controller:
    webhookPort: 8443
    trialResources:
      - TrainJob.v1alpha1.trainer.kubeflow.org
      - Job.v1.batch
      - TFJob.v1.kubeflow.org
      - PyTorchJob.v1.kubeflow.org
      - MPIJob.v1.kubeflow.org
      - XGBoostJob.v1.kubeflow.org
runtime:
  metricsCollectors:
    - kind: StdOut
      image: ghcr.io/kubeflow/katib/file-metrics-collector:latest
    - kind: File
      image: ghcr.io/kubeflow/katib/file-metrics-collector:latest
    - kind: TensorFlowEvent
      image: ghcr.io/kubeflow/katib/tfevent-metrics-collector:latest
      resources:
        limits:
          memory: 1Gi
  suggestions:
    - algorithmName: random
      image: ghcr.io/kubeflow/katib/suggestion-hyperopt:latest
    - algorithmName: tpe
      image: ghcr.io/kubeflow/katib/suggestion-hyperopt:latest
    - algorithmName: grid
      image: ghcr.io/kubeflow/katib/suggestion-optuna:latest
    - algorithmName: hyperband
      image: ghcr.io/kubeflow/katib/suggestion-hyperband:latest
    - algorithmName: bayesianoptimization
      image: ghcr.io/kubeflow/katib/suggestion-skopt:latest
    - algorithmName: cmaes
      image: ghcr.io/kubeflow/katib/suggestion-goptuna:latest
    - algorithmName: sobol
      image: ghcr.io/kubeflow/katib/suggestion-goptuna:latest
    - algorithmName: multivariate-tpe
      image: ghcr.io/kubeflow/katib/suggestion-optuna:latest
    - algorithmName: enas
      image: ghcr.io/kubeflow/katib/suggestion-enas:latest
      resources:
        limits:
          memory: 400Mi
    - algorithmName: darts
      image: ghcr.io/kubeflow/katib/suggestion-darts:latest
    - algorithmName: pbt
      image: ghcr.io/kubeflow/katib/suggestion-pbt:latest
      persistentVolumeClaimSpec:
        accessModes:
          - ReadWriteMany
        resources:
          requests:
            storage: 5Gi
  earlyStoppings:
    - algorithmName: medianstop
      image: ghcr.io/kubeflow/katib/earlystopping-medianstop:latest



================================================
FILE: manifests/v1beta1/installs/katib-cert-manager/kustomization.yaml
================================================
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
namespace: kubeflow
resources:
# Namespace.
- ../../components/namespace
# Katib controller.
- ../../components/controller/
# Katib CRDs.
- ../../components/crd/
# Katib DB manager.
- ../../components/db-manager/
# Katib DB mysql.
- ../../components/mysql/
# Katib UI.
- ../../components/ui/
 # Katib webhooks.
- ../../components/webhook/
# Cert-manager certificate for webhooks
- certificate.yaml
images:
- name: ghcr.io/kubeflow/katib/katib-controller
  newName: ghcr.io/kubeflow/katib/katib-controller
  newTag: latest
- name: ghcr.io/kubeflow/katib/katib-db-manager
  newName: ghcr.io/kubeflow/katib/katib-db-manager
  newTag: latest
- name: ghcr.io/kubeflow/katib/katib-ui
  newName: ghcr.io/kubeflow/katib/katib-ui
  newTag: latest



configurations:
- params.yaml

configMapGenerator:
- behavior: create
  files:
  - katib-config.yaml
  name: katib-config
  options:
    disableNameSuffixHash: true
patches:
- path: patches/katib-cert-injection.yaml
replacements:
- source:
    fieldPath: metadata.namespace
    kind: Service
    name: katib-controller
    version: v1
  targets:
  - fieldPaths:
    - spec.commonName
    options:
      delimiter: .
      index: 1
    select:
      group: cert-manager.io
      kind: Certificate
      name: katib-webhook-cert
      version: v1
  - fieldPaths:
    - spec.dnsNames.0
    options:
      delimiter: .
      index: 1
    select:
      group: cert-manager.io
      kind: Certificate
      name: katib-webhook-cert
      version: v1
  - fieldPaths:
    - spec.dnsNames.1
    options:
      delimiter: .
      index: 1
    select:
      group: cert-manager.io
      kind: Certificate
      name: katib-webhook-cert
      version: v1
  - fieldPaths:
    - metadata.annotations.[cert-manager.io/inject-ca-from]
    options:
      delimiter: /
      create: true
    select: 
      group: admissionregistration.k8s.io
      kind: ValidatingWebhookConfiguration
      version: v1
  - fieldPaths:
    - metadata.annotations.[cert-manager.io/inject-ca-from]
    options:
      delimiter: /
      create: true
    select:
      group: admissionregistration.k8s.io
      kind: MutatingWebhookConfiguration
      version: v1
- source:
    fieldPath: metadata.name
    kind: Service
    name: katib-controller
    version: v1
  targets:
  - fieldPaths:
    - spec.commonName
    options:
      delimiter: .
    select:
      group: cert-manager.io
      kind: Certificate
      name: katib-webhook-cert
      version: v1
  - fieldPaths:
    - spec.dnsNames.0
    options:
      delimiter: .
    select:
      group: cert-manager.io
      kind: Certificate
      name: katib-webhook-cert
      version: v1
  - fieldPaths:
    - spec.dnsNames.1
    options:
      delimiter: .
    select:
      group: cert-manager.io
      kind: Certificate
      name: katib-webhook-cert
      version: v1
- source:
    fieldPath: metadata.name
    kind: Certificate
    name: katib-webhook-cert
  targets:
  - fieldPaths:
    - metadata.annotations.[cert-manager.io/inject-ca-from]
    options:
      delimiter: /
      index: 1
      create: true
    select:
      group: admissionregistration.k8s.io
      kind: ValidatingWebhookConfiguration
      version: v1
  - fieldPaths:
    - metadata.annotations.[cert-manager.io/inject-ca-from]
    options:
      delimiter: /
      index: 1
      create: true
    select:
      group: admissionregistration.k8s.io
      kind: MutatingWebhookConfiguration
      version: v1



================================================
FILE: manifests/v1beta1/installs/katib-cert-manager/params.yaml
================================================
---
varReference:
  - path: spec/commonName
    kind: Certificate
  - path: spec/dnsNames
    kind: Certificate
  - path: spec/issuerRef/name
    kind: Certificate
  - path: metadata/annotations
    kind: MutatingWebhookConfiguration
  - path: metadata/annotations
    kind: ValidatingWebhookConfiguration
nameReference:
  - kind: Issuer
    group: cert-manager.io
    fieldSpecs:
      - kind: Certificate
        group: cert-manager.io
        path: spec/issuerRef/name



================================================
FILE: manifests/v1beta1/installs/katib-cert-manager/patches/katib-cert-injection.yaml
================================================
---
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  name: katib.kubeflow.org
  annotations:
    cert-manager.io/inject-ca-from: KATIB_NAMESPACE_PLACEHOLDER/KATIB_CERT_NAME_PLACEHOLDER
---
apiVersion: admissionregistration.k8s.io/v1
kind: MutatingWebhookConfiguration
metadata:
  name: katib.kubeflow.org
  annotations:
    cert-manager.io/inject-ca-from: KATIB_NAMESPACE_PLACEHOLDER/KATIB_CERT_NAME_PLACEHOLDER



================================================
FILE: manifests/v1beta1/installs/katib-external-db/katib-config.yaml
================================================
---
apiVersion: config.kubeflow.org/v1beta1
kind: KatibConfig
init:
  certGenerator:
    enable: true
  controller:
    webhookPort: 8443
    trialResources:
      - Job.v1.batch
      - TFJob.v1.kubeflow.org
      - PyTorchJob.v1.kubeflow.org
      - MPIJob.v1.kubeflow.org
      - XGBoostJob.v1.kubeflow.org
runtime:
  metricsCollectors:
    - kind: StdOut
      image: ghcr.io/kubeflow/katib/file-metrics-collector:latest
    - kind: File
      image: ghcr.io/kubeflow/katib/file-metrics-collector:latest
    - kind: TensorFlowEvent
      image: ghcr.io/kubeflow/katib/tfevent-metrics-collector:latest
      resources:
        limits:
          memory: 1Gi
  suggestions:
    - algorithmName: random
      image: ghcr.io/kubeflow/katib/suggestion-hyperopt:latest
    - algorithmName: tpe
      image: ghcr.io/kubeflow/katib/suggestion-hyperopt:latest
    - algorithmName: grid
      image: ghcr.io/kubeflow/katib/suggestion-optuna:latest
    - algorithmName: hyperband
      image: ghcr.io/kubeflow/katib/suggestion-hyperband:latest
    - algorithmName: bayesianoptimization
      image: ghcr.io/kubeflow/katib/suggestion-skopt:latest
    - algorithmName: cmaes
      image: ghcr.io/kubeflow/katib/suggestion-goptuna:latest
    - algorithmName: sobol
      image: ghcr.io/kubeflow/katib/suggestion-goptuna:latest
    - algorithmName: multivariate-tpe
      image: ghcr.io/kubeflow/katib/suggestion-optuna:latest
    - algorithmName: enas
      image: ghcr.io/kubeflow/katib/suggestion-enas:latest
      resources:
        limits:
          memory: 400Mi
    - algorithmName: darts
      image: ghcr.io/kubeflow/katib/suggestion-darts:latest
    - algorithmName: pbt
      image: ghcr.io/kubeflow/katib/suggestion-pbt:latest
      persistentVolumeClaimSpec:
        accessModes:
          - ReadWriteMany
        resources:
          requests:
            storage: 5Gi
  earlyStoppings:
    - algorithmName: medianstop
      image: ghcr.io/kubeflow/katib/earlystopping-medianstop:latest



================================================
FILE: manifests/v1beta1/installs/katib-external-db/kustomization.yaml
================================================
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
namespace: kubeflow
resources:
# Namespace.
- ../../components/namespace/
# Katib controller.
- ../../components/controller/
# Katib CRDs.
- ../../components/crd/
# Katib DB manager.
- ../../components/db-manager/
# Katib UI.
- ../../components/ui/
# Katib webhooks.
- ../../components/webhook/
images:
- name: ghcr.io/kubeflow/katib/katib-controller
  newName: ghcr.io/kubeflow/katib/katib-controller
  newTag: latest
- name: ghcr.io/kubeflow/katib/katib-db-manager
  newName: ghcr.io/kubeflow/katib/katib-db-manager
  newTag: latest
- name: ghcr.io/kubeflow/katib/katib-ui
  newName: ghcr.io/kubeflow/katib/katib-ui
  newTag: latest
# Modify katib-mysql-secrets with parameters for the DB.
  # Secret for webhooks certs.
secretGenerator:
- envs:
  - secrets.env
  name: katib-mysql-secrets
- name: katib-webhook-cert
  options:
    disableNameSuffixHash: true
configMapGenerator:
- behavior: create
  files:
  - katib-config.yaml
  name: katib-config
  options:
    disableNameSuffixHash: true
patches:
- path: patches/db-manager.yaml



================================================
FILE: manifests/v1beta1/installs/katib-external-db/secrets.env
================================================
KATIB_MYSQL_DB_DATABASE=
KATIB_MYSQL_DB_HOST=
KATIB_MYSQL_DB_PORT=
DB_USER=
DB_PASSWORD=



================================================
FILE: manifests/v1beta1/installs/katib-external-db/patches/db-manager.yaml
================================================
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: katib-db-manager
  namespace: kubeflow
spec:
  template:
    spec:
      containers:
        - name: katib-db-manager
          env:
            - name: DB_NAME
              value: mysql
            - name: DB_USER
              valueFrom:
                secretKeyRef:
                  name: katib-mysql-secrets
                  key: DB_USER
            - name: DB_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: katib-mysql-secrets
                  key: DB_PASSWORD
            - name: KATIB_MYSQL_DB_DATABASE
              valueFrom:
                secretKeyRef:
                  name: katib-mysql-secrets
                  key: KATIB_MYSQL_DB_DATABASE
            - name: KATIB_MYSQL_DB_HOST
              valueFrom:
                secretKeyRef:
                  name: katib-mysql-secrets
                  key: KATIB_MYSQL_DB_HOST
            - name: KATIB_MYSQL_DB_PORT
              valueFrom:
                secretKeyRef:
                  name: katib-mysql-secrets
                  key: KATIB_MYSQL_DB_PORT



================================================
FILE: manifests/v1beta1/installs/katib-leader-election/katib-config.yaml
================================================
---
apiVersion: config.kubeflow.org/v1beta1
kind: KatibConfig
init:
  certGenerator:
    enable: true
  controller:
    webhookPort: 8443
    enableLeaderElection: true
    trialResources:
      - Job.v1.batch
      - TFJob.v1.kubeflow.org
      - PyTorchJob.v1.kubeflow.org
      - MPIJob.v1.kubeflow.org
      - XGBoostJob.v1.kubeflow.org
runtime:
  metricsCollectors:
    - kind: StdOut
      image: ghcr.io/kubeflow/katib/file-metrics-collector:latest
    - kind: File
      image: ghcr.io/kubeflow/katib/file-metrics-collector:latest
    - kind: TensorFlowEvent
      image: ghcr.io/kubeflow/katib/tfevent-metrics-collector:latest
      resources:
        limits:
          memory: 1Gi
  suggestions:
    - algorithmName: random
      image: ghcr.io/kubeflow/katib/suggestion-hyperopt:latest
    - algorithmName: tpe
      image: ghcr.io/kubeflow/katib/suggestion-hyperopt:latest
    - algorithmName: grid
      image: ghcr.io/kubeflow/katib/suggestion-optuna:latest
    - algorithmName: hyperband
      image: ghcr.io/kubeflow/katib/suggestion-hyperband:latest
    - algorithmName: bayesianoptimization
      image: ghcr.io/kubeflow/katib/suggestion-skopt:latest
    - algorithmName: cmaes
      image: ghcr.io/kubeflow/katib/suggestion-goptuna:latest
    - algorithmName: sobol
      image: ghcr.io/kubeflow/katib/suggestion-goptuna:latest
    - algorithmName: multivariate-tpe
      image: ghcr.io/kubeflow/katib/suggestion-optuna:latest
    - algorithmName: enas
      image: ghcr.io/kubeflow/katib/suggestion-enas:latest
      resources:
        limits:
          memory: 400Mi
    - algorithmName: darts
      image: ghcr.io/kubeflow/katib/suggestion-darts:latest
    - algorithmName: pbt
      image: ghcr.io/kubeflow/katib/suggestion-pbt:latest
      persistentVolumeClaimSpec:
        accessModes:
          - ReadWriteMany
        resources:
          requests:
            storage: 5Gi
  earlyStoppings:
    - algorithmName: medianstop
      image: ghcr.io/kubeflow/katib/earlystopping-medianstop:latest



================================================
FILE: manifests/v1beta1/installs/katib-leader-election/kustomization.yaml
================================================
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
namespace: kubeflow
  # rbac for leader-election
resources:
- ../katib-standalone
- leader-election-rbac.yaml
replicas:
- count: 2
  name: katib-controller
configMapGenerator:
- behavior: replace
  files:
  - katib-config.yaml
  name: katib-config
  options:
    disableNameSuffixHash: true



================================================
FILE: manifests/v1beta1/installs/katib-leader-election/leader-election-rbac.yaml
================================================
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: leader-election
  namespace: kubeflow
rules:
  - apiGroups:
      - coordination.k8s.io
    resources:
      - leases
    verbs:
      - "*"
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: leader-election
  namespace: kubeflow
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: leader-election
subjects:
  - kind: ServiceAccount
    name: katib-controller
    namespace: kubeflow



================================================
FILE: manifests/v1beta1/installs/katib-openshift/katib-config.yaml
================================================
---
apiVersion: config.kubeflow.org/v1beta1
kind: KatibConfig
init:
  controller:
    webhookPort: 8443
    trialResources:
      - Job.v1.batch
      - TFJob.v1.kubeflow.org
      - PyTorchJob.v1.kubeflow.org
      - MPIJob.v1.kubeflow.org
      - XGBoostJob.v1.kubeflow.org
runtime:
  metricsCollectors:
    - kind: StdOut
      image: ghcr.io/kubeflow/katib/file-metrics-collector:latest
    - kind: File
      image: ghcr.io/kubeflow/katib/file-metrics-collector:latest
    - kind: TensorFlowEvent
      image: ghcr.io/kubeflow/katib/tfevent-metrics-collector:latest
      resources:
        limits:
          memory: 1Gi
  suggestions:
    - algorithmName: random
      image: ghcr.io/kubeflow/katib/suggestion-hyperopt:latest
    - algorithmName: tpe
      image: ghcr.io/kubeflow/katib/suggestion-hyperopt:latest
    - algorithmName: grid
      image: ghcr.io/kubeflow/katib/suggestion-optuna:latest
    - algorithmName: hyperband
      image: ghcr.io/kubeflow/katib/suggestion-hyperband:latest
    - algorithmName: bayesianoptimization
      image: ghcr.io/kubeflow/katib/suggestion-skopt:latest
    - algorithmName: cmaes
      image: ghcr.io/kubeflow/katib/suggestion-goptuna:latest
    - algorithmName: sobol
      image: ghcr.io/kubeflow/katib/suggestion-goptuna:latest
    - algorithmName: multivariate-tpe
      image: ghcr.io/kubeflow/katib/suggestion-optuna:latest
    - algorithmName: enas
      image: ghcr.io/kubeflow/katib/suggestion-enas:latest
      resources:
        limits:
          memory: 400Mi
    - algorithmName: darts
      image: ghcr.io/kubeflow/katib/suggestion-darts:latest
    - algorithmName: pbt
      image: ghcr.io/kubeflow/katib/suggestion-pbt:latest
      persistentVolumeClaimSpec:
        accessModes:
          - ReadWriteMany
        resources:
          requests:
            storage: 5Gi
  earlyStoppings:
    - algorithmName: medianstop
      image: ghcr.io/kubeflow/katib/earlystopping-medianstop:latest



================================================
FILE: manifests/v1beta1/installs/katib-openshift/kustomization.yaml
================================================
# This kustomization copies the `katib-standalone` one with following exclusions:
#  - No Job is spawned to generate TLS key for `katib-controller` Service
#  - Instead, the Service and WebhookConfigurations linked to it are annotated
#    for OpenShift service controller to handle TLS certification.
#
# Requires OpenShift version: 4.4+
#
# To achieve this, run:
#
# `kustomize build ./manifests/v1beta1/installs/katib-openshift | oc apply -f - -l type!=local`
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
namespace: kubeflow
resources:
# Namespace.
- ../../components/namespace/
# Katib controller.
- ../../components/controller/
# Katib CRDs.
- ../../components/crd/
# Katib DB manager.
- ../../components/db-manager/
# Katib DB mysql.
- ../../components/mysql/
# Katib UI.
- ../../components/ui/
# Katib webhooks.
- ../../components/webhook/
images:
- name: ghcr.io/kubeflow/katib/katib-controller
  newName: ghcr.io/kubeflow/katib/katib-controller
  newTag: latest
- name: ghcr.io/kubeflow/katib/katib-db-manager
  newName: ghcr.io/kubeflow/katib/katib-db-manager
  newTag: latest
- name: ghcr.io/kubeflow/katib/katib-ui
  newName: ghcr.io/kubeflow/katib/katib-ui
  newTag: latest

configMapGenerator:
- behavior: create
  files:
  - katib-config.yaml
  name: katib-config
  options:
    disableNameSuffixHash: true
patches:
# Annotate Service to delegate TLS-secret generation to OpenShift service controller
# https://docs.openshift.com/container-platform/4.6/security/certificates/service-serving-certificate.html#add-service-certificate_service-serving-certificate
- path: patches/service-serving-cert.yaml
  target:
    kind: Service
    name: katib-controller
    namespace: kubeflow
    version: v1
 # Annotate WebhookConfigurations to delegate `caBundle` population to OpenShift service controller
# https://docs.openshift.com/container-platform/4.6/security/certificates/service-serving-certificate.html#add-service-certificate-mutating-webhook_service-serving-certificate
- path: patches/webhook-inject-cabundle.yaml
  target:
    group: admissionregistration.k8s.io
    kind: ValidatingWebhookConfiguration
    name: katib.kubeflow.org
    version: v1
- path: patches/webhook-inject-cabundle.yaml
  target:
    group: admissionregistration.k8s.io
    kind: MutatingWebhookConfiguration
    name: katib.kubeflow.org
    version: v1



================================================
FILE: manifests/v1beta1/installs/katib-openshift/patches/service-serving-cert.yaml
================================================
---
- op: "add"
  path: "/metadata/annotations/service.beta.openshift.io~1serving-cert-secret-name"
  value: katib-webhook-cert



================================================
FILE: manifests/v1beta1/installs/katib-openshift/patches/webhook-inject-cabundle.yaml
================================================
---
- op: "add"
  path: "/metadata/annotations"
  value:
    service.beta.openshift.io/inject-cabundle: "true"



================================================
FILE: manifests/v1beta1/installs/katib-standalone/katib-config.yaml
================================================
apiVersion: config.kubeflow.org/v1beta1
kind: KatibConfig
init:
  certGenerator:
    enable: true
  controller:
    webhookPort: 8443
    trialResources:
      - TrainJob.v1alpha1.trainer.kubeflow.org
      - Job.v1.batch
      - TFJob.v1.kubeflow.org
      - PyTorchJob.v1.kubeflow.org
      - MPIJob.v1.kubeflow.org
      - XGBoostJob.v1.kubeflow.org
runtime:
  metricsCollectors:
    - kind: StdOut
      image: ghcr.io/kubeflow/katib/file-metrics-collector:latest
    - kind: File
      image: ghcr.io/kubeflow/katib/file-metrics-collector:latest
    - kind: TensorFlowEvent
      image: ghcr.io/kubeflow/katib/tfevent-metrics-collector:latest
      resources:
        limits:
          memory: 1Gi
  suggestions:
    - algorithmName: random
      image: ghcr.io/kubeflow/katib/suggestion-hyperopt:latest
    - algorithmName: tpe
      image: ghcr.io/kubeflow/katib/suggestion-hyperopt:latest
    - algorithmName: grid
      image: ghcr.io/kubeflow/katib/suggestion-optuna:latest
    - algorithmName: hyperband
      image: ghcr.io/kubeflow/katib/suggestion-hyperband:latest
    - algorithmName: bayesianoptimization
      image: ghcr.io/kubeflow/katib/suggestion-skopt:latest
    - algorithmName: cmaes
      image: ghcr.io/kubeflow/katib/suggestion-goptuna:latest
    - algorithmName: sobol
      image: ghcr.io/kubeflow/katib/suggestion-goptuna:latest
    - algorithmName: multivariate-tpe
      image: ghcr.io/kubeflow/katib/suggestion-optuna:latest
    - algorithmName: enas
      image: ghcr.io/kubeflow/katib/suggestion-enas:latest
      resources:
        limits:
          memory: 400Mi
    - algorithmName: darts
      image: ghcr.io/kubeflow/katib/suggestion-darts:latest
    - algorithmName: pbt
      image: ghcr.io/kubeflow/katib/suggestion-pbt:latest
      persistentVolumeClaimSpec:
        accessModes:
          - ReadWriteMany
        resources:
          requests:
            storage: 5Gi
  earlyStoppings:
    - algorithmName: medianstop
      image: ghcr.io/kubeflow/katib/earlystopping-medianstop:latest



================================================
FILE: manifests/v1beta1/installs/katib-standalone/kustomization.yaml
================================================
---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
namespace: kubeflow
resources:
  # Namespace.
  - ../../components/namespace/
  # Katib controller.
  - ../../components/controller/
  # Katib CRDs.
  - ../../components/crd/
  # Katib DB manager.
  - ../../components/db-manager/
  # Katib DB mysql.
  - ../../components/mysql/
  # Katib UI.
  - ../../components/ui/
  # Katib webhooks.
  - ../../components/webhook/
images:
  - name: ghcr.io/kubeflow/katib/katib-controller
    newName: ghcr.io/kubeflow/katib/katib-controller
    newTag: latest
  - name: ghcr.io/kubeflow/katib/katib-db-manager
    newName: ghcr.io/kubeflow/katib/katib-db-manager
    newTag: latest
  - name: ghcr.io/kubeflow/katib/katib-ui
    newName: ghcr.io/kubeflow/katib/katib-ui
    newTag: latest
configMapGenerator:
  - name: katib-config
    behavior: create
    files:
      - katib-config.yaml
    options:
      disableNameSuffixHash: true
# Secret for webhooks certs.
secretGenerator:
  - name: katib-webhook-cert
    options:
      disableNameSuffixHash: true



================================================
FILE: manifests/v1beta1/installs/katib-standalone-postgres/katib-config.yaml
================================================
---
apiVersion: config.kubeflow.org/v1beta1
kind: KatibConfig
init:
  certGenerator:
    enable: true
  controller:
    webhookPort: 8443
    trialResources:
      - Job.v1.batch
      - TFJob.v1.kubeflow.org
      - PyTorchJob.v1.kubeflow.org
      - MPIJob.v1.kubeflow.org
      - XGBoostJob.v1.kubeflow.org
runtime:
  metricsCollectors:
    - kind: StdOut
      image: ghcr.io/kubeflow/katib/file-metrics-collector:latest
    - kind: File
      image: ghcr.io/kubeflow/katib/file-metrics-collector:latest
    - kind: TensorFlowEvent
      image: ghcr.io/kubeflow/katib/tfevent-metrics-collector:latest
      resources:
        limits:
          memory: 1Gi
  suggestions:
    - algorithmName: random
      image: ghcr.io/kubeflow/katib/suggestion-hyperopt:latest
    - algorithmName: tpe
      image: ghcr.io/kubeflow/katib/suggestion-hyperopt:latest
    - algorithmName: grid
      image: ghcr.io/kubeflow/katib/suggestion-optuna:latest
    - algorithmName: hyperband
      image: ghcr.io/kubeflow/katib/suggestion-hyperband:latest
    - algorithmName: bayesianoptimization
      image: ghcr.io/kubeflow/katib/suggestion-skopt:latest
    - algorithmName: cmaes
      image: ghcr.io/kubeflow/katib/suggestion-goptuna:latest
    - algorithmName: sobol
      image: ghcr.io/kubeflow/katib/suggestion-goptuna:latest
    - algorithmName: multivariate-tpe
      image: ghcr.io/kubeflow/katib/suggestion-optuna:latest
    - algorithmName: enas
      image: ghcr.io/kubeflow/katib/suggestion-enas:latest
      resources:
        limits:
          memory: 400Mi
    - algorithmName: darts
      image: ghcr.io/kubeflow/katib/suggestion-darts:latest
    - algorithmName: pbt
      image: ghcr.io/kubeflow/katib/suggestion-pbt:latest
      persistentVolumeClaimSpec:
        accessModes:
          - ReadWriteMany
        resources:
          requests:
            storage: 5Gi
  earlyStoppings:
    - algorithmName: medianstop
      image: ghcr.io/kubeflow/katib/earlystopping-medianstop:latest



================================================
FILE: manifests/v1beta1/installs/katib-standalone-postgres/kustomization.yaml
================================================
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
namespace: kubeflow 
resources:
# Namespace.
- ../../components/namespace/
# Katib controller.
- ../../components/controller/
# Katib CRDs.
- ../../components/crd/
# Katib DB manager.
- ../../components/db-manager/
# Katib DB postgres.
- ../../components/postgres/
# Katib UI.
- ../../components/ui/
# Katib webhooks.
- ../../components/webhook/
images:
- name: ghcr.io/kubeflow/katib/katib-controller
  newName: ghcr.io/kubeflow/katib/katib-controller
  newTag: latest
- name: ghcr.io/kubeflow/katib/katib-db-manager
  newName: ghcr.io/kubeflow/katib/katib-db-manager
  newTag: latest
- name: ghcr.io/kubeflow/katib/katib-ui
  newName: ghcr.io/kubeflow/katib/katib-ui
  newTag: latest
configMapGenerator:
- behavior: create
  files:
  - katib-config.yaml
  name: katib-config
  options:
    disableNameSuffixHash: true
# Secret for webhooks certs.
secretGenerator:
- name: katib-webhook-cert
  options:
    disableNameSuffixHash: true
patches:
- path: ./patches/db-manager.yaml
  target:
    group: apps
    kind: Deployment
    name: katib-db-manager
    version: v1



================================================
FILE: manifests/v1beta1/installs/katib-standalone-postgres/patches/db-manager.yaml
================================================
---
- op: replace
  path: /spec/template/spec/containers/0/env
  value:
    - name: DB_NAME
      value: "postgres"
    - name: DB_PASSWORD
      value: "katib"



================================================
FILE: manifests/v1beta1/installs/katib-with-kubeflow/istio-authorizationpolicy.yaml
================================================
---
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: katib-ui
  namespace: kubeflow
spec:
  action: ALLOW
  selector:
    matchLabels:
      katib.kubeflow.org/component: ui
  rules:
    - from:
        - source:
            principals: ["cluster.local/ns/istio-system/sa/istio-ingressgateway-service-account"]



================================================
FILE: manifests/v1beta1/installs/katib-with-kubeflow/kubeflow-katib-roles.yaml
================================================
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: kubeflow-katib-admin
  labels:
    rbac.authorization.kubeflow.org/aggregate-to-kubeflow-admin: "true"
aggregationRule:
  clusterRoleSelectors:
    - matchLabels:
        rbac.authorization.kubeflow.org/aggregate-to-kubeflow-katib-admin: "true"
rules: []
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: kubeflow-katib-edit
  labels:
    rbac.authorization.kubeflow.org/aggregate-to-kubeflow-edit: "true"
    rbac.authorization.kubeflow.org/aggregate-to-kubeflow-katib-admin: "true"
rules:
  - apiGroups:
      - kubeflow.org
    resources:
      - experiments
      - trials
      - suggestions
    verbs:
      - get
      - list
      - watch
      - create
      - delete
      - deletecollection
      - patch
      - update
  - apiGroups:
      - ""
    resources:
      - pods
    verbs:
      - list
  - apiGroups:
      - ""
    resources:
      - pods/log
    verbs:
      - get
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: kubeflow-katib-view
  labels:
    rbac.authorization.kubeflow.org/aggregate-to-kubeflow-view: "true"
rules:
  - apiGroups:
      - kubeflow.org
    resources:
      - experiments
      - trials
      - suggestions
    verbs:
      - get
      - list
      - watch



================================================
FILE: manifests/v1beta1/installs/katib-with-kubeflow/kustomization.yaml
================================================
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
namespace: kubeflow
resources:
- ../katib-cert-manager
# Kubeflow Katib components.
- kubeflow-katib-roles.yaml
- ui-virtual-service.yaml
- istio-authorizationpolicy.yaml
images:
- name: ghcr.io/kubeflow/katib/katib-controller
  newName: ghcr.io/kubeflow/katib/katib-controller
  newTag: latest
- name: ghcr.io/kubeflow/katib/katib-db-manager
  newName: ghcr.io/kubeflow/katib/katib-db-manager
  newTag: latest
- name: ghcr.io/kubeflow/katib/katib-ui
  newName: ghcr.io/kubeflow/katib/katib-ui
  newTag: latest
  
patches:
# Extend RBAC permission list of katib-ui so it can
# create SubjectAccessReview resources.
- path: patches/ui-rbac.yaml
  target:
    group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: katib-ui
    version: v1
# Enable RBAC authz checks in UI's backend.
- path: patches/enable-ui-authz-checks.yaml
  target:
    kind: Deployment
    name: katib-ui
    version: v1
# Allow istio sidecar injection in katib-UI Pod.
- path: patches/istio-sidecar-injection.yaml
  target:
    kind: Deployment
    name: katib-ui
- path: patches/remove-namespace.yaml


configurations:
- params.yaml
replacements:
- source:
    fieldPath: metadata.namespace
    group: apps
    kind: Deployment
    name: katib-ui
    version: v1
  targets:
  - fieldPaths:
    - spec.http.0.route.0.destination.host
    options:
      delimiter: .
      index: 1
    select:
      group: networking.istio.io
      kind: VirtualService
      name: katib-ui
      version: v1alpha3



================================================
FILE: manifests/v1beta1/installs/katib-with-kubeflow/params.yaml
================================================
---
varReference:
  - path: spec/http/route/destination/host
    kind: VirtualService



================================================
FILE: manifests/v1beta1/installs/katib-with-kubeflow/ui-virtual-service.yaml
================================================
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: katib-ui
spec:
  gateways:
    - kubeflow-gateway
  hosts:
    - "*"
  http:
    - match:
        - uri:
            prefix: /katib/
      rewrite:
        uri: /katib/
      route:
        - destination:
            host: katib-ui.KATIB_UI_NAMESPACE_PLACEHOLDER.svc.cluster.local
            port:
              number: 80



================================================
FILE: manifests/v1beta1/installs/katib-with-kubeflow/patches/enable-ui-authz-checks.yaml
================================================
---
- op: add
  path: /spec/template/spec/containers/0/env/-
  value:
    name: APP_DISABLE_AUTH
    value: "false"



================================================
FILE: manifests/v1beta1/installs/katib-with-kubeflow/patches/istio-sidecar-injection.yaml
================================================
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: "katib-ui"
spec:
  template:
    metadata:
      labels:
        sidecar.istio.io/inject: "true"



================================================
FILE: manifests/v1beta1/installs/katib-with-kubeflow/patches/remove-namespace.yaml
================================================
---
$patch: delete
apiVersion: v1
kind: Namespace
metadata:
  name: kubeflow



================================================
FILE: manifests/v1beta1/installs/katib-with-kubeflow/patches/ui-rbac.yaml
================================================
---
- op: add
  path: /rules/-
  value:
    apiGroups: [authorization.k8s.io]
    resources: [subjectaccessreviews]
    verbs: [create]



================================================
FILE: scripts/v1beta1/build.sh
================================================
#!/usr/bin/env bash

# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This script is used to build all Katib images.
# Run ./scripts/v1beta1/build.sh <IMAGE_REGISTRY> <TAG> to execute it.

set -e

REGISTRY=$1
TAG=$2
ARCH=$3

if [[ -z "${REGISTRY}" || -z "${TAG}" || -z "${ARCH}" ]]; then
  echo "Image registry, tag and cpu-architecture must be set"
  echo "Usage: $0 <image-registry> <image-tag> <cpu-architecture>" 1>&2
  exit 1
fi

SUPPORTED_CPU_ARCHS=(linux/amd64 linux/arm64 linux/ppc64le)
function check_specified_cpu_arch() {
  for SUPPORTED_ARCH in "${SUPPORTED_CPU_ARCHS[@]}"; do
    if [ "$1" = "${SUPPORTED_ARCH}" ]; then
      return 0
    fi
  done
  echo "CPU architecture '${1}' is not supported"
  echo "You can use '${SUPPORTED_CPU_ARCHS[*]}'"
  echo "To get machine architecture run: uname -m"
  return 1
}

# Verify that arch is supported.
IFS=',' read -ra archs <<< "$ARCH"
  for arch in "${archs[@]}"; do
    check_specified_cpu_arch "$arch"
done

VERSION="v1beta1"
CMD_PREFIX="cmd"

echo "Building images for Katib ${VERSION}..."
echo "Image registry: ${REGISTRY}"
echo "Image tag: ${TAG}"
echo "CPU architecture: ${ARCH}"

SCRIPT_ROOT=$(dirname "$0")/../..
cd "${SCRIPT_ROOT}"

# Katib core images
echo -e "\nBuilding Katib controller image...\n"
docker buildx build --platform "${ARCH}" -t "${REGISTRY}/katib-controller:${TAG}" -f ${CMD_PREFIX}/katib-controller/${VERSION}/Dockerfile .

echo -e "\nBuilding Katib DB manager image...\n"
docker buildx build --platform "${ARCH}" -t "${REGISTRY}/katib-db-manager:${TAG}" -f ${CMD_PREFIX}/db-manager/${VERSION}/Dockerfile .

echo -e "\nBuilding Katib UI image...\n"
docker buildx build --platform "${ARCH}" -t "${REGISTRY}/katib-ui:${TAG}" -f ${CMD_PREFIX}/ui/${VERSION}/Dockerfile .

echo -e "\nBuilding file metrics collector image...\n"
docker buildx build --platform "${ARCH}" -t "${REGISTRY}/file-metrics-collector:${TAG}" -f ${CMD_PREFIX}/metricscollector/${VERSION}/file-metricscollector/Dockerfile .

echo -e "\nBuilding TF Event metrics collector image...\n"
if [ "${ARCH}" == "ppc64le" ]; then
  docker buildx build --platform "${ARCH}" -t "${REGISTRY}/tfevent-metrics-collector:${TAG}" -f ${CMD_PREFIX}/metricscollector/${VERSION}/tfevent-metricscollector/Dockerfile.ppc64le .
else
  docker buildx build --platform "${ARCH}" -t "${REGISTRY}/tfevent-metrics-collector:${TAG}" -f ${CMD_PREFIX}/metricscollector/${VERSION}/tfevent-metricscollector/Dockerfile .
fi

# Suggestion images
echo -e "\nBuilding suggestion images..."

echo -e "\nBuilding hyperopt suggestion...\n"
docker buildx build --platform "${ARCH}" -t "${REGISTRY}/suggestion-hyperopt:${TAG}" -f ${CMD_PREFIX}/suggestion/hyperopt/${VERSION}/Dockerfile .

echo -e "\nBuilding hyperband suggestion...\n"
docker buildx build --platform "${ARCH}" -t "${REGISTRY}/suggestion-hyperband:${TAG}" -f ${CMD_PREFIX}/suggestion/hyperband/${VERSION}/Dockerfile .

echo -e "\nBuilding skopt suggestion...\n"
docker buildx build --platform "${ARCH}" -t "${REGISTRY}/suggestion-skopt:${TAG}" -f ${CMD_PREFIX}/suggestion/skopt/${VERSION}/Dockerfile .

echo -e "\nBuilding goptuna suggestion...\n"
docker buildx build --platform "${ARCH}" -t "${REGISTRY}/suggestion-goptuna:${TAG}" -f ${CMD_PREFIX}/suggestion/goptuna/${VERSION}/Dockerfile .

echo -e "\nBuilding optuna suggestion...\n"
docker buildx build --platform "${ARCH}" -t "${REGISTRY}/suggestion-optuna:${TAG}" -f ${CMD_PREFIX}/suggestion/optuna/${VERSION}/Dockerfile .

echo -e "\nBuilding ENAS suggestion...\n"
docker buildx build --platform "${ARCH}" -t "${REGISTRY}/suggestion-enas:${TAG}" -f ${CMD_PREFIX}/suggestion/nas/enas/${VERSION}/Dockerfile .

echo -e "\nBuilding DARTS suggestion...\n"
docker buildx build --platform "${ARCH}" -t "${REGISTRY}/suggestion-darts:${TAG}" -f ${CMD_PREFIX}/suggestion/nas/darts/${VERSION}/Dockerfile .

echo -e "\nBuilding PBT suggestion...\n"
docker buildx build --platform "${ARCH}" -t "${REGISTRY}/suggestion-pbt:${TAG}" -f ${CMD_PREFIX}/suggestion/pbt/${VERSION}/Dockerfile .

# Early stopping images
echo -e "\nBuilding early stopping images...\n"

echo -e "\nBuilding median stopping rule...\n"
docker buildx build --platform "${ARCH}" -t "${REGISTRY}/earlystopping-medianstop:${TAG}" -f ${CMD_PREFIX}/earlystopping/medianstop/${VERSION}/Dockerfile .

# Training container images
echo -e "\nBuilding training container images..."

echo -e "\nBuilding dynamic learning rate training container example for PBT...\n"
docker buildx build --platform "${ARCH}" -t "${REGISTRY}/simple-pbt:${TAG}" -f examples/${VERSION}/trial-images/simple-pbt/Dockerfile .

echo -e "\nBuilding PyTorch CIFAR-10 CNN training container example for DARTS with CPU support...\n"
docker buildx build --platform "${ARCH}" -t "${REGISTRY}/darts-cnn-cifar10-cpu:${TAG}" -f examples/${VERSION}/trial-images/darts-cnn-cifar10/Dockerfile.cpu .

echo -e "\nBuilding PyTorch CIFAR-10 CNN training container example for DARTS with GPU support...\n"
docker buildx build --platform "${ARCH}" -t "${REGISTRY}/darts-cnn-cifar10-gpu:${TAG}" -f examples/${VERSION}/trial-images/darts-cnn-cifar10/Dockerfile.gpu .

echo -e "\nBuilding PyTorch mnist training container example with CPU support...\n"
docker buildx build --platform "${ARCH}" -t "${REGISTRY}/pytorch-mnist-cpu:${TAG}" -f examples/${VERSION}/trial-images/pytorch-mnist/Dockerfile.cpu .

echo -e "\nBuilding PyTorch mnist training container example with GPU support...\n"
docker buildx build --platform "${ARCH}" -t "${REGISTRY}/pytorch-mnist-gpu:${TAG}" -f examples/${VERSION}/trial-images/pytorch-mnist/Dockerfile.gpu .

echo -e "\nBuilding Tensorflow with summaries mnist training container example...\n"
docker buildx build --platform "${ARCH}" -t "${REGISTRY}/tf-mnist-with-summaries:${TAG}" -f examples/${VERSION}/trial-images/tf-mnist-with-summaries/Dockerfile .

echo -e "\nBuilding Keras CIFAR-10 CNN training container example for ENAS with CPU support...\n"
docker buildx build --platform "${ARCH}" -t "${REGISTRY}/enas-cnn-cifar10-cpu:${TAG}" -f examples/${VERSION}/trial-images/enas-cnn-cifar10/Dockerfile.cpu .

echo -e "\nBuilding Keras CIFAR-10 CNN training container example for ENAS with GPU support...\n"
docker buildx build --platform "${ARCH}" -t "${REGISTRY}/enas-cnn-cifar10-gpu:${TAG}" -f examples/${VERSION}/trial-images/enas-cnn-cifar10/Dockerfile.gpu .

echo -e "\nAll Katib images with ${TAG} tag have been built successfully!\n"



================================================
FILE: scripts/v1beta1/deploy.sh
================================================
#!/usr/bin/env bash

# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

set -o xtrace
set -o errexit

SCRIPT_ROOT="$(dirname "${BASH_SOURCE[0]}")/../.."

cd "${SCRIPT_ROOT}"

WITH_DATABASE_TYPE=${1:-mysql}

# if mysql, use below kustomize, else use postgres
if [ "$WITH_DATABASE_TYPE" == "mysql" ]; then
    kustomize build manifests/v1beta1/installs/katib-standalone | kubectl apply -f -
elif [ "$WITH_DATABASE_TYPE" == "postgres" ]; then
    kustomize build manifests/v1beta1/installs/katib-standalone-postgres | kubectl apply -f -
else
    echo "Unknown database type: $WITH_DATABASE_TYPE"
    exit 1
fi



================================================
FILE: scripts/v1beta1/push.sh
================================================
#!/usr/bin/env bash

# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This script is used to push all Katib images.
# Run ./scripts/v1beta1/push.sh <IMAGE_REGISTRY> <TAG>

set -e

REGISTRY=$1
TAG=$2

if [[ -z "$REGISTRY" || -z "$TAG" ]]; then
  echo "Image registry and tag must be set"
  echo "Usage: $0 <image-registry> <image-tag>" 1>&2
  exit 1
fi

VERSION="v1beta1"

echo "Pushing images for Katib ${VERSION}..."
echo "Image registry: ${REGISTRY}"
echo "Image tag: ${TAG}"

# Katib core images
echo -e "\nPushing Katib controller image...\n"
docker push "${REGISTRY}/katib-controller:${TAG}"

echo -e "\nPushing Katib DB manager image...\n"
docker push "${REGISTRY}/katib-db-manager:${TAG}"

echo -e "\nPushing Katib UI image...\n"
docker push "${REGISTRY}/katib-ui:${TAG}"

echo -e "\nPushing file metrics collector image...\n"
docker push "${REGISTRY}/file-metrics-collector:${TAG}"

echo -e "\nPushing TF Event metrics collector image...\n"
docker push "${REGISTRY}/tfevent-metrics-collector:${TAG}"

# Suggestion images
echo -e "\nPushing suggestion images..."

echo -e "\nPushing hyperopt suggestion...\n"
docker push "${REGISTRY}/suggestion-hyperopt:${TAG}"

echo -e "\nPushing hyperband suggestion...\n"
docker push "${REGISTRY}/suggestion-hyperband:${TAG}"

echo -e "\nPushing skopt suggestion...\n"
docker push "${REGISTRY}/suggestion-skopt:${TAG}"

echo -e "\nPushing goptuna suggestion...\n"
docker push "${REGISTRY}/suggestion-goptuna:${TAG}"

echo -e "\nPushing optuna suggestion...\n"
docker push "${REGISTRY}/suggestion-optuna:${TAG}"

echo -e "\nPushing ENAS suggestion...\n"
docker push "${REGISTRY}/suggestion-enas:${TAG}"

echo -e "\nPushing DARTS suggestion...\n"
docker push "${REGISTRY}/suggestion-darts:${TAG}"

echo -e "\nPushing PBT suggestion...\n"
docker push "${REGISTRY}/suggestion-pbt:${TAG}"

# Early stopping images
echo -e "\nPushing early stopping images...\n"

echo -e "\nPushing median stopping rule...\n"
docker push "${REGISTRY}/earlystopping-medianstop:${TAG}"

# Training container images
echo -e "\nPushing training container images..."

echo -e "\nPushing Tensorflow with summaries mnist training container example...\n"
docker push "${REGISTRY}/tf-mnist-with-summaries:${TAG}"

echo -e "\nPushing PyTorch mnist training container example with CPU support...\n"
docker push "${REGISTRY}/pytorch-mnist-cpu:${TAG}"

echo -e "\nPushing PyTorch mnist training container example with GPU support...\n"
docker push "${REGISTRY}/pytorch-mnist-gpu:${TAG}"

echo -e "\nPushing Keras CIFAR-10 CNN training container example for ENAS with GPU support...\n"
docker push "${REGISTRY}/enas-cnn-cifar10-gpu:${TAG}"

echo -e "\nPushing Keras CIFAR-10 CNN training container example for ENAS with CPU support...\n"
docker push "${REGISTRY}/enas-cnn-cifar10-cpu:${TAG}"

echo -e "\nPushing PyTorch CIFAR-10 CNN training container example for DARTS with CPU support...\n"
docker push "${REGISTRY}/darts-cnn-cifar10-cpu:${TAG}"

echo -e "\nPushing PyTorch CIFAR-10 CNN training container example for DARTS with GPU support...\n"
docker push "${REGISTRY}/darts-cnn-cifar10-gpu:${TAG}"

echo -e "\nPushing dynamic learning rate training container example for PBT...\n"
docker push "${REGISTRY}/simple-pbt:${TAG}"

echo -e "\nAll Katib images with ${TAG} tag have been pushed successfully!\n"



================================================
FILE: scripts/v1beta1/release.sh
================================================
#!/usr/bin/env bash

# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This script is used to release Katib project.
# Run ./scripts/v1beta1/release.sh <BRANCH> <TAG> to execute it.
# For example: ./scripts/v1beta1/release.sh release-0.11 v0.11.1 or
# ./scripts/v1beta1/release.sh release-0.11 v0.11.0-rc.0
# You must follow this format, Branch: release-X.Y, Tag: vX.Y.Z.

set -e

BRANCH=$1
TAG=$2

if [[ -z "$BRANCH" || -z "$TAG" ]]; then
  echo "Branch and Tag must be set"
  echo "Usage: $0 <BRANCH> <TAG>" 1>&2
  echo "You must follow this format, Branch: release-X.Y, Tag: vX.Y.Z or Tag: vX.Y.Z-rc.N"
  exit 1
fi

# Check that Branch and Tag is in correct format.
if [[ ! "$BRANCH" =~ release-[0-9]+\.[0-9]+ || ! "$TAG" =~ v[0-9]+\.[0-9]+\.([0-9]+$|[0-9]+-rc\.[0-9]+$) ]]; then
  echo "Branch or Tag format is invalid"
  echo "Usage: $0 <BRANCH> <TAG>" 1>&2
  echo "You must follow this format, Branch: release-X.Y, Tag: vX.Y.Z or Tag: vX.Y.Z-rc.N"
  exit 1
fi

# Clone Katib repo to the temp dir.
temp_dir=$(mktemp -d)
git clone "git@github.com:kubeflow/katib.git" "${temp_dir}"
cd "$temp_dir"

# Check if tag exists.
if [[ -n $(git tag --list "${TAG}") ]]; then
  echo "Tag: ${TAG} exists. Release can't be published"
  exit 1
fi

echo -e "\nCreating a new release. Branch: ${BRANCH}, Tag: ${TAG}\n"

# Create or use the branch.
if [[ -z $(git branch -r -l "origin/${BRANCH}") ]]; then
  echo "Branch: ${BRANCH} does not exist. Creating a new minor release"
  git checkout -b "${BRANCH}"
else
  echo "Branch: ${BRANCH} exists. Creating a new patch release"
  git checkout "${BRANCH}"
  read -rp "Did you cherry pick all commits from the master to the ${BRANCH} branch? [y|n] "
  if [ "$REPLY" != "y" ]; then
    exit 1
  fi
fi

# ------------------ Change image tag ------------------
# Change Katib image tags to the new release tag.
make update-images OLD_PREFIX="ghcr.io/kubeflow/katib/" NEW_PREFIX="ghcr.io/kubeflow/katib/" TAG="${TAG}"

# ------------------ Publish Katib SDK ------------------
# Remove first "v" for the SDK version.
sdk_version=${TAG:1}
# Check if this is pre-release.
if [[ ${sdk_version} == *"-rc."* ]]; then
  # Replace "-rc." with "rc" for the SDK version.
  sdk_version=${sdk_version//-rc./rc}
fi
echo -e "\nPublishing Katib Python SDK, version: ${sdk_version}\n"

# Change version in setup.py
cd sdk/python/v1beta1
if [[ $(uname) == "Darwin" ]]; then
  sed -i '' -e "s@version=\".*\"@version=\"${sdk_version}\"@" setup.py
else
  sed -i -e "s@version=\".*\"@version=\"${sdk_version}\"@" setup.py
fi
# Generate SDK and upload new version to PyPi.
python3 setup.py sdist bdist_wheel
twine upload dist/*
rm -r dist/ build/
cd ../../..
echo -e "\nKatib Python SDK ${sdk_version} has been published\n"

# ------------------ Commit changes ------------------
git commit -a -m "Katib official release ${TAG}"
# Create a new tag.
git tag "${TAG}"

# ------------------ Publish Katib images ------------------
# Publish images to the registry with 2 tags: ${TAG} and v1beta1-<commit-sha>
echo -e "\nPublishing Katib images\n"
make push-tag TAG="${TAG}"
echo -e "Katib images have been published\n"

# ------------------ Push to upstream ------------------
read -rp "Do you want to push Katib ${TAG} version to the upstream? [y|n] "
if [ "$REPLY" != "y" ]; then
  exit 1
fi
# Push a new Branch and Tag.
git push -u origin "${BRANCH}"
git push -u origin "${TAG}"

echo -e "\nKatib ${TAG} release has been published"
echo "To finish the release process, follow these steps: https://github.com/kubeflow/katib/tree/master/docs/release#create-a-new-katib-release"



================================================
FILE: scripts/v1beta1/undeploy.sh
================================================
#!/usr/bin/env bash

# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

set -o xtrace
set -o errexit

# Delete all Katib Experiment in all namespaces.
kubectl delete experiment --all --all-namespaces
sleep 10

SCRIPT_ROOT="$(dirname "${BASH_SOURCE[0]}")/../.."

cd "${SCRIPT_ROOT}"
kustomize build manifests/v1beta1/installs/katib-standalone | kubectl delete -f -



================================================
FILE: scripts/v1beta1/update-images.sh
================================================
#!/usr/bin/env bash

# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This script is used to update images and tags which are hosted by Katib community.
#
# The image names postfix must be equal to Katib format.
# Please check the images format here: https://github.com/kubeflow/katib/blob/master/docs/images-location.md
# For example, for Katib controller the image postfix is "katib-controller".
#
# This script updates the following images:
# 1. Katib Core Components.
# 2. Katib Metrics Collectors
# 3. Katib Suggestions
# 4. Katib Early Stopping
# 5. Katib Trial training containers
#
# Run ./scripts/v1beta1/update-images.sh <OLD_PREFIX> <NEW_PREFIX> <TAG> to execute it.
# For example, to update images from: ghcr.io/kubeflow/katib/ to: ghcr.io/private/ registry with tag: v0.12.0, run:
# ./scripts/v1beta1/update-images.sh ghcr.io/kubeflow/katib/ ghcr.io/private/ v0.12.0

set -o errexit
set -o pipefail
set -o nounset

OLD_PREFIX=${1:-""}
NEW_PREFIX=${2:-""}
TAG=${3:-""}

if [[ -z "$OLD_PREFIX" || -z "$NEW_PREFIX" || -z "$TAG" ]]; then
  echo "Image old prefix, new prefix, and tag must be set"
  echo -e "Usage: $0 <OLD_PREFIX> <NEW_PREFIX> <TAG>\n" 1>&2
  echo "For example, to update images from: ghcr.io/kubeflow/katib/ to: ghcr.io/private/ registry with tag: v0.12.0, run:"
  echo "$0 ghcr.io/kubeflow/katib/ ghcr.io/private/ v0.12.0"
  exit 1
fi

# This function edits YAML files data for a given path.
# $1 argument - path for files to search.
# $2 argument - old string regex to be replaced.
# $3 argument - new string.
update_yaml_files() {
  # For MacOS we should set -i '' to avoid temp files from sed.
  if [[ $(uname) == "Darwin" ]]; then
    find "$1" -regex ".*\.yaml" -exec sed -i '' -e "s@$2@$3@" {} \;
  else
    find "$1" -regex ".*\.yaml" -exec sed -i -e "s@$2@$3@" {} \;
  fi
}

echo "Updating Katib images..."
echo "Image old prefix: ${OLD_PREFIX}"
echo "Image new prefix: ${NEW_PREFIX}"
echo -e "Image tag: ${TAG}\n"

# Katib Core images.
INSTALLS_PATH="manifests/v1beta1/installs/"

echo -e "Updating Katib Core images\n"
update_yaml_files "${INSTALLS_PATH}" "newName: ${OLD_PREFIX}" "newName: ${NEW_PREFIX}"
update_yaml_files "${INSTALLS_PATH}" "newTag: .*" "newTag: ${TAG}"

# Katib Config images.
echo -e "Update Katib Metrics Collectors, Suggestions and EarlyStopping images\n"
for config in manifests/v1beta1/installs/**/katib-config.yaml; do
  update_yaml_files "${config}" "${OLD_PREFIX}" "${NEW_PREFIX}"
  update_yaml_files "${config}" ":[^[:space:]].*" ":${TAG}"
done

# Katib Trial training container images.

# Postfixes for the each Trial image.
PYTORCH_MNIST_CPU="pytorch-mnist-cpu"
PYTORCH_MNIST_GPU="pytorch-mnist-gpu"
TF_MNIST_WITH_SUMMARIES="tf-mnist-with-summaries"
ENAS_GPU="enas-cnn-cifar10-gpu"
ENAS_CPU="enas-cnn-cifar10-cpu"
DARTS_GPU="darts-cnn-cifar10-gpu"
DARTS_CPU="darts-cnn-cifar10-cpu"
SIMPLE_PBT="simple-pbt"

echo -e "Update Katib Trial training container images\n"
update_yaml_files "./" "${OLD_PREFIX}${PYTORCH_MNIST_CPU}:.*" "${NEW_PREFIX}${PYTORCH_MNIST_CPU}:${TAG}"
update_yaml_files "./" "${OLD_PREFIX}${PYTORCH_MNIST_GPU}:.*" "${NEW_PREFIX}${PYTORCH_MNIST_GPU}:${TAG}"
update_yaml_files "./" "${OLD_PREFIX}${TF_MNIST_WITH_SUMMARIES}:.*" "${NEW_PREFIX}${TF_MNIST_WITH_SUMMARIES}:${TAG}"
update_yaml_files "./" "${OLD_PREFIX}${ENAS_GPU}:.*" "${NEW_PREFIX}${ENAS_GPU}:${TAG}"
update_yaml_files "./" "${OLD_PREFIX}${ENAS_CPU}:.*" "${NEW_PREFIX}${ENAS_CPU}:${TAG}"
update_yaml_files "./" "${OLD_PREFIX}${DARTS_GPU}:.*" "${NEW_PREFIX}${DARTS_GPU}:${TAG}"
update_yaml_files "./" "${OLD_PREFIX}${DARTS_CPU}:.*" "${NEW_PREFIX}${DARTS_CPU}:${TAG}"
update_yaml_files "./" "${OLD_PREFIX}${SIMPLE_PBT}:.*" "${NEW_PREFIX}${SIMPLE_PBT}:${TAG}"

echo "Katib images have been updated"



================================================
FILE: sdk/python/v1beta1/README.md
================================================
# Kubeflow Katib SDK

Python SDK for Kubeflow Katib

## Requirements.

Python >= 3.8

Katib Python SDK follows [Python release cycle](https://devguide.python.org/versions/#python-release-cycle)
for supported Python versions.

## Installation & Usage

### pip install

```sh
pip install kubeflow-katib
```

Then import package:

```python
from kubeflow import katib
```

### Setuptools

Install via [Setuptools](http://pypi.python.org/pypi/setuptools).

```sh
python setup.py install --user
```

(or `sudo python setup.py install` to install the package for all users)

### Publish new SDK version to PyPi

Our SDK is located in [`kubeflow-katib` PyPi package](https://pypi.org/project/kubeflow-katib/).
Katib Python SDK is published as part of the Katib patch releases.
You can check the release process [here](../../../scripts/v1beta1/release.sh).
For each Katib patch release, we upload a new SDK version to the PyPi.
The SDK version is equal to the Katib version.

## Getting Started

Please follow the [examples](../../../examples/v1beta1/sdk) to learn more about Katib SDK.

## Documentation for API Endpoints

| Class                 | Method                                 | Description                                                 |
| --------------------- | -------------------------------------- | ----------------------------------------------------------- |
| [KatibClient][client] | [create_experiment][create]            | Create the Katib Experiment                                 |
| [KatibClient][client] | [get_experiment][get_e]                | Get the Katib Experiment                                    |
| [KatibClient][client] | [get_suggestion][get_s]                | Get the Katib Suggestion                                    |
| [KatibClient][client] | [delete_experiment][delete]            | Delete the Katib Experiment                                 |
| [KatibClient][client] | [list_experiments][list_e]             | List all Katib Experiments                                  |
| [KatibClient][client] | [get_experiment_status][get_status]    | Get the Experiment current status                           |
| [KatibClient][client] | [is_experiment_succeeded][is_suc]      | Check if Experiment has succeeded                           |
| [KatibClient][client] | [list_trials][list_t]                  | List all Experiment's Trials                                |
| [KatibClient][client] | [get_success_trial_details][get_suc_t] | Get the Trial details that have succeeded for an Experiment |
| [KatibClient][client] | [get_optimal_hyperparameters][opt_hp]  | Get the current optimal Trial from the Experiment           |

[client]: docs/KatibClient.md
[create]: docs/KatibClient.md#create_experiment
[get_e]: docs/KatibClient.md#get_experiment
[get_s]: docs/KatibClient.md#get_suggestion
[delete]: docs/KatibClient.md#delete_experiment
[list_e]: docs/KatibClient.md#list_experiments
[get_status]: docs/KatibClient.md#get_experiment_status
[is_suc]: docs/KatibClient.md#is_experiment_succeeded
[list_t]: docs/KatibClient.md#list_trials
[get_suc_t]: docs/KatibClient.md#get_success_trial_details
[opt_hp]: docs/KatibClient.md#get_optimal_hyperparameters

## Documentation For Models

- [V1beta1AlgorithmSetting](docs/V1beta1AlgorithmSetting.md)
- [V1beta1AlgorithmSpec](docs/V1beta1AlgorithmSpec.md)
- [V1beta1CollectorSpec](docs/V1beta1CollectorSpec.md)
- [V1beta1ConfigMapSource](docs/V1beta1ConfigMapSource.md)
- [V1beta1EarlyStoppingRule](docs/V1beta1EarlyStoppingRule.md)
- [V1beta1EarlyStoppingSetting](docs/V1beta1EarlyStoppingSetting.md)
- [V1beta1EarlyStoppingSpec](docs/V1beta1EarlyStoppingSpec.md)
- [V1beta1Experiment](docs/V1beta1Experiment.md)
- [V1beta1ExperimentCondition](docs/V1beta1ExperimentCondition.md)
- [V1beta1ExperimentList](docs/V1beta1ExperimentList.md)
- [V1beta1ExperimentSpec](docs/V1beta1ExperimentSpec.md)
- [V1beta1ExperimentStatus](docs/V1beta1ExperimentStatus.md)
- [V1beta1FeasibleSpace](docs/V1beta1FeasibleSpace.md)
- [V1beta1FileSystemPath](docs/V1beta1FileSystemPath.md)
- [V1beta1FilterSpec](docs/V1beta1FilterSpec.md)
- [V1beta1GraphConfig](docs/V1beta1GraphConfig.md)
- [V1beta1Metric](docs/V1beta1Metric.md)
- [V1beta1MetricStrategy](docs/V1beta1MetricStrategy.md)
- [V1beta1MetricsCollectorSpec](docs/V1beta1MetricsCollectorSpec.md)
- [V1beta1NasConfig](docs/V1beta1NasConfig.md)
- [V1beta1ObjectiveSpec](docs/V1beta1ObjectiveSpec.md)
- [V1beta1Observation](docs/V1beta1Observation.md)
- [V1beta1Operation](docs/V1beta1Operation.md)
- [V1beta1OptimalTrial](docs/V1beta1OptimalTrial.md)
- [V1beta1ParameterAssignment](docs/V1beta1ParameterAssignment.md)
- [V1beta1ParameterSpec](docs/V1beta1ParameterSpec.md)
- [V1beta1SourceSpec](docs/V1beta1SourceSpec.md)
- [V1beta1Suggestion](docs/V1beta1Suggestion.md)
- [V1beta1SuggestionCondition](docs/V1beta1SuggestionCondition.md)
- [V1beta1SuggestionList](docs/V1beta1SuggestionList.md)
- [V1beta1SuggestionSpec](docs/V1beta1SuggestionSpec.md)
- [V1beta1SuggestionStatus](docs/V1beta1SuggestionStatus.md)
- [V1beta1Trial](docs/V1beta1Trial.md)
- [V1beta1TrialAssignment](docs/V1beta1TrialAssignment.md)
- [V1beta1TrialCondition](docs/V1beta1TrialCondition.md)
- [V1beta1TrialList](docs/V1beta1TrialList.md)
- [V1beta1TrialParameterSpec](docs/V1beta1TrialParameterSpec.md)
- [V1beta1TrialSource](docs/V1beta1TrialSource.md)
- [V1beta1TrialSpec](docs/V1beta1TrialSpec.md)
- [V1beta1TrialStatus](docs/V1beta1TrialStatus.md)
- [V1beta1TrialTemplate](docs/V1beta1TrialTemplate.md)

## Documentation For Authorization

All endpoints do not require authorization.

## Author

prem0912



================================================
FILE: sdk/python/v1beta1/OWNERS
================================================
reviewers:
  - helenxie-bit



================================================
FILE: sdk/python/v1beta1/setup.py
================================================
# Copyright 2021 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import shutil

import setuptools

REQUIRES = [
    "certifi>=14.05.14",
    "six>=1.10",
    "setuptools>=21.0.0",
    "urllib3>=1.15.1",
    "kubernetes>=27.2.0",
    "grpcio>=1.64.1",
    "protobuf>=4.21.12,<5",
    "kubeflow-training==1.9.0",
]

katib_grpc_api_file = "../../../pkg/apis/manager/v1beta1/python/api_pb2.py"
katib_grpc_svc_file = "../../../pkg/apis/manager/v1beta1/python/api_pb2_grpc.py"

# Copy Katib gRPC Python APIs to use it in the Katib SDK Client.
# We need to always copy this file only on the SDK building stage, not on SDK installation stage.
if os.path.exists(katib_grpc_api_file):
    shutil.copy(
        katib_grpc_api_file,
        "kubeflow/katib/katib_api_pb2.py",
    )

# TODO(Electronic-Waste): Remove the import rewrite when protobuf supports `python_package` option.
# REF: https://github.com/protocolbuffers/protobuf/issues/7061
if os.path.exists(katib_grpc_svc_file):
    shutil.copy(
        katib_grpc_svc_file,
        "kubeflow/katib/katib_api_pb2_grpc.py",
    )

    with open("kubeflow/katib/katib_api_pb2_grpc.py", "r+") as file:
        content = file.read()
        new_content = content.replace("api_pb2", "kubeflow.katib.katib_api_pb2")
        file.seek(0)
        file.write(new_content)
        file.truncate()

setuptools.setup(
    name="kubeflow-katib",
    version="0.18.0rc0",
    author="Kubeflow Authors",
    author_email="premnath.vel@gmail.com",
    license="Apache License Version 2.0",
    url="https://github.com/kubeflow/katib/tree/master/sdk/python/v1beta1",
    description="Katib Python SDK for APIVersion v1beta1",
    long_description="Katib Python SDK for APIVersion v1beta1",
    packages=setuptools.find_packages(include=("kubeflow*")),
    package_data={},
    include_package_data=False,
    zip_safe=False,
    classifiers=[
        "Intended Audience :: Developers",
        "Intended Audience :: Education",
        "Intended Audience :: Science/Research",
        "Programming Language :: Python :: 3",
        "Programming Language :: Python :: 3 :: Only",
        "Programming Language :: Python :: 3.8",
        "Programming Language :: Python :: 3.9",
        "Programming Language :: Python :: 3.10",
        "Programming Language :: Python :: 3.11",
        "License :: OSI Approved :: Apache Software License",
        "Operating System :: OS Independent",
        "Topic :: Scientific/Engineering",
        "Topic :: Scientific/Engineering :: Artificial Intelligence",
        "Topic :: Software Development",
        "Topic :: Software Development :: Libraries",
        "Topic :: Software Development :: Libraries :: Python Modules",
    ],
    install_requires=REQUIRES,
    extras_require={
        "huggingface": ["kubeflow-training[huggingface]==1.9.0"],
    },
)



================================================
FILE: sdk/python/v1beta1/docs/KatibClient.md
================================================
# KatibClient

> KatibClient(config_file=None, context=None, client_configuration=None, persist_config=True)

User can load authentication and cluster information from kube-config file and
stores them in kubernetes.client.configuration. Parameters are as following:

| Parameter            | Description                                                               |
| -------------------- | ------------------------------------------------------------------------- |
| config_file          | Name of the kube-config file. Defaults to ~/.kube/config.                 |
| context              | Set the active context. Defaults to current_context from the kube-config. |
| client_configuration | The kubernetes.client.Configuration to set configs to.                    |
| persist_config       | If True, config file will be updated when changed.                        |

The APIs for KatibClient are as following:

| Class       | Method                                                      | Description                                                 |
| ----------- | ----------------------------------------------------------- | ----------------------------------------------------------- |
| KatibClient | [create_experiment](#create_experiment)                     | Create the Katib Experiment                                 |
| KatibClient | [get_experiment](#get_experiment)                           | Get the Katib Experiment                                    |
| KatibClient | [get_suggestion](#get_suggestion)                           | Get the Katib Suggestion                                    |
| KatibClient | [delete_experiment](#delete_experiment)                     | Delete the Katib Experiment                                 |
| KatibClient | [list_experiments](#list_experiments)                       | List all Katib Experiments                                  |
| KatibClient | [get_experiment_status](#get_experiment_status)             | Get the Experiment current status                           |
| KatibClient | [is_experiment_succeeded](#is_experiment_succeeded)         | Check if Experiment has succeeded                           |
| KatibClient | [list_trials](#list_trials)                                 | List all Experiment's Trials                                |
| KatibClient | [get_success_trial_details](#get_success_trial_details)     | Get the Trial details that have succeeded for an Experiment |
| KatibClient | [get_optimal_hyperparameters](#get_optimal_hyperparameters) | Get the current optimal Trial from the Experiment           |

## create_experiment

> create_experiment(exp_object, namespace=None)

Create the Katib Experiment.
If the namespace is `None`, it takes namespace from the Experiment or "default".

Return the created Experiment.

### Parameters

| Name       | Type                                      | Description           | Notes    |
| ---------- | ----------------------------------------- | --------------------- | -------- |
| exp_object | [V1beta1Experiment](V1beta1Experiment.md) | Experiment object.    | Required |
| namespace  | str                                       | Experiment namespace. | Optional |

### Return type

dict

## get_experiment

> get_experiment(name=None, namespace=None)

Get the Katib Experiment.
If the name is `None` returns all Experiments in the namespace.
If the namespace is `None`, it takes namespace from the Experiment object or "default".

Return the Experiment object.

### Parameters

| Name      | Type | Description           | Notes    |
| --------- | ---- | --------------------- | -------- |
| name      | str  | Experiment name.      | Optional |
| namespace | str  | Experiment namespace. | Optional |

### Return type

dict

## get_suggestion

> get_suggestion(name=None, namespace=None)

Get the Katib Suggestion.
If the name is `None` returns all Suggestion in the namespace.
If the namespace is `None`, it takes namespace from the Suggestion object or "default".

Return the Suggestion object.

### Parameters

| Name      | Type | Description           | Notes    |
| --------- | ---- | --------------------- | -------- |
| name      | str  | Suggestion name.      | Optional |
| namespace | str  | Suggestion namespace. | Optional |

### Return type

dict

## delete_experiment

> delete_experiment(name, namespace=None)

Delete the Katib Experiment
If the namespace is `None`, it takes namespace from the Experiment object or "default".

Return the deleted Experiment object.

### Parameters

| Name      | Type | Description           | Notes    |
| --------- | ---- | --------------------- | -------- |
| name      | str  | Experiment name.      | Required |
| namespace | str  | Experiment namespace. | Optional |

### Return type

dict

## list_experiments

> list_experiments(namespace=None)

List all Katib Experiments.
If the namespace is `None`, it takes "default" namespace.

Return list of Experiment objects.

### Parameters

| Name      | Type | Description           | Notes    |
| --------- | ---- | --------------------- | -------- |
| namespace | str  | Experiment namespace. | Optional |

### Return type

list[V1beta1Experiment]

## get_experiment_status

> get_experiment_status(name, namespace=None)

Get the Experiment current status.
If the namespace is `None`, it takes "default" namespace.

Return the current Experiment status.

### Parameters

| Name      | Type | Description           | Notes    |
| --------- | ---- | --------------------- | -------- |
| name      | str  | Experiment name.      | Required |
| namespace | str  | Experiment namespace. | Optional |

### Return type

str

## is_experiment_succeeded

> is_experiment_succeeded(name, namespace=None)

Check if Experiment has succeeded.
If the namespace is `None`, it takes "default" namespace.

Return whether Experiment has succeeded or not.

### Parameters

| Name      | Type | Description           | Notes    |
| --------- | ---- | --------------------- | -------- |
| name      | str  | Experiment name.      | Required |
| namespace | str  | Experiment namespace. | Optional |

### Return type

bool

## list_trials

> list_trials(name, namespace=None)

List all Experiment's Trials.
If the namespace is `None`, it takes "default" namespace.

Return list of Trial objects

### Parameters

| Name      | Type | Description           | Notes    |
| --------- | ---- | --------------------- | -------- |
| name      | str  | Experiment name.      | Required |
| namespace | str  | Experiment namespace. | Optional |

### Return type

list[V1beta1Trial]

## get_success_trial_details

> get_success_trial_details(name, namespace=None)

Get the Trial details that have succeeded for an Experiment.
If the namespace is `None`, it takes namespace from the Experiment or "default".

Return Trial names with the hyperparameters and metrics.

### Parameters

| Name      | Type | Description           | Notes    |
| --------- | ---- | --------------------- | -------- |
| name      | str  | Experiment name.      | Required |
| namespace | str  | Experiment namespace. | Optional |

### Return type

list[dict]

## get_optimal_hyperparameters

> get_optimal_hyperparameters(name, namespace=None)

Get the current optimal Trial from the Experiment.
If the namespace is `None`, it takes namespace from the Experiment or "default".

Return current optimal Trial for the Experiment.

### Parameters

| Name      | Type | Description           | Notes    |
| --------- | ---- | --------------------- | -------- |
| name      | str  | Experiment name.      | Required |
| namespace | str  | Experiment namespace. | Optional |

### Return type

dict



================================================
FILE: sdk/python/v1beta1/docs/V1beta1AlgorithmSetting.md
================================================
# V1beta1AlgorithmSetting

AlgorithmSetting represents key-value pair for HP or NAS algorithm settings.
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**name** | **str** | Name is setting name. | [optional] 
**value** | **str** | Value is the setting value. | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1AlgorithmSpec.md
================================================
# V1beta1AlgorithmSpec

AlgorithmSpec is the specification for a HP or NAS algorithm.
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**algorithm_name** | **str** | HP or NAS algorithm name. | [optional] 
**algorithm_settings** | [**list[V1beta1AlgorithmSetting]**](V1beta1AlgorithmSetting.md) | Key-value pairs representing settings for suggestion algorithms. | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1CollectorSpec.md
================================================
# V1beta1CollectorSpec

## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**custom_collector** | [**V1Container**](https://github.com/kubernetes-client/python/blob/master/kubernetes/docs/V1Container.md) |  | [optional] 
**kind** | **str** |  | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1ConfigMapSource.md
================================================
# V1beta1ConfigMapSource

ConfigMapSource references the config map where trial template is located
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**config_map_name** | **str** | Name of config map where trial template is located | [optional] 
**config_map_namespace** | **str** | Namespace of config map where trial template is located | [optional] 
**template_path** | **str** | Path in config map where trial template is located | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1EarlyStoppingRule.md
================================================
# V1beta1EarlyStoppingRule

EarlyStoppingRule represents each rule for early stopping.
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**comparison** | **str** | Comparison defines correlation between name and value. | [optional] 
**name** | **str** | Name contains metric name for the rule. | [optional] 
**start_step** | **int** | StartStep defines quantity of intermediate results that should be received before applying the rule. If start step is empty, rule is applied from the first recorded metric. | [optional] 
**value** | **str** | Value contains metric value for the rule. | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1EarlyStoppingSetting.md
================================================
# V1beta1EarlyStoppingSetting

EarlyStoppingSetting represents key-value pair for early stopping algorithm settings.
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**name** | **str** | Name is the setting name. | [optional] 
**value** | **str** | Value is the setting value. | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1EarlyStoppingSpec.md
================================================
# V1beta1EarlyStoppingSpec

EarlyStoppingSpec is the specification for a early stopping algorithm.
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**algorithm_name** | **str** | Early stopping algorithm name. | [optional] 
**algorithm_settings** | [**list[V1beta1EarlyStoppingSetting]**](V1beta1EarlyStoppingSetting.md) | Key-value pairs representing settings for early stopping algorithm. | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1Experiment.md
================================================
# V1beta1Experiment

Structure of the Experiment custom resource.
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**api_version** | **str** | APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources | [optional] 
**kind** | **str** | Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds | [optional] 
**metadata** | [**V1ObjectMeta**](https://github.com/kubernetes-client/python/blob/master/kubernetes/docs/V1ObjectMeta.md) |  | [optional] 
**spec** | [**V1beta1ExperimentSpec**](V1beta1ExperimentSpec.md) |  | [optional] 
**status** | [**V1beta1ExperimentStatus**](V1beta1ExperimentStatus.md) |  | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1ExperimentCondition.md
================================================
# V1beta1ExperimentCondition

ExperimentCondition describes the state of the experiment at a certain point.
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**last_transition_time** | **datetime** |  | [optional] 
**last_update_time** | **datetime** |  | [optional] 
**message** | **str** | A human readable message indicating details about the transition. | [optional] 
**reason** | **str** | The reason for the condition&#39;s last transition. | [optional] 
**status** | **str** | Status of the condition, one of True, False, Unknown. | [default to '']
**type** | **str** | Type of experiment condition. | [default to '']

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1ExperimentList.md
================================================
# V1beta1ExperimentList

ExperimentList contains a list of Experiments
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**api_version** | **str** | APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources | [optional] 
**items** | [**list[V1beta1Experiment]**](V1beta1Experiment.md) |  | 
**kind** | **str** | Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds | [optional] 
**metadata** | [**V1ListMeta**](https://github.com/kubernetes-client/python/blob/master/kubernetes/docs/V1ListMeta.md) |  | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1ExperimentSpec.md
================================================
# V1beta1ExperimentSpec

ExperimentSpec is the specification of an Experiment.
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**algorithm** | [**V1beta1AlgorithmSpec**](V1beta1AlgorithmSpec.md) |  | [optional] 
**early_stopping** | [**V1beta1EarlyStoppingSpec**](V1beta1EarlyStoppingSpec.md) |  | [optional] 
**max_failed_trial_count** | **int** | Max failed trials to mark experiment as failed. | [optional] 
**max_trial_count** | **int** | Max completed trials to mark experiment as succeeded | [optional] 
**metrics_collector_spec** | [**V1beta1MetricsCollectorSpec**](V1beta1MetricsCollectorSpec.md) |  | [optional] 
**nas_config** | [**V1beta1NasConfig**](V1beta1NasConfig.md) |  | [optional] 
**objective** | [**V1beta1ObjectiveSpec**](V1beta1ObjectiveSpec.md) |  | [optional] 
**parallel_trial_count** | **int** | How many trials can be processed in parallel. Defaults to 3 | [optional] 
**parameters** | [**list[V1beta1ParameterSpec]**](V1beta1ParameterSpec.md) | List of hyperparameter configurations. | [optional] 
**resume_policy** | **str** | Describes resuming policy which usually take effect after experiment terminated. Default value is Never. | [optional] 
**trial_template** | [**V1beta1TrialTemplate**](V1beta1TrialTemplate.md) |  | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1ExperimentStatus.md
================================================
# V1beta1ExperimentStatus

ExperimentStatus is the current status of an Experiment.
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**completion_time** | **datetime** |  | [optional] 
**conditions** | [**list[V1beta1ExperimentCondition]**](V1beta1ExperimentCondition.md) | List of observed runtime conditions for this Experiment. | [optional] 
**current_optimal_trial** | [**V1beta1OptimalTrial**](V1beta1OptimalTrial.md) |  | [optional] 
**early_stopped_trial_list** | **list[str]** | List of trial names which have been early stopped. | [optional] 
**failed_trial_list** | **list[str]** | List of trial names which have already failed. | [optional] 
**killed_trial_list** | **list[str]** | List of trial names which have been killed. | [optional] 
**last_reconcile_time** | **datetime** |  | [optional] 
**metrics_unavailable_trial_list** | **list[str]** | List of trial names which have been metrics unavailable | [optional] 
**pending_trial_list** | **list[str]** | List of trial names which are pending. | [optional] 
**running_trial_list** | **list[str]** | List of trial names which are running. | [optional] 
**start_time** | **datetime** |  | [optional] 
**succeeded_trial_list** | **list[str]** | List of trial names which have already succeeded. | [optional] 
**trial_metrics_unavailable** | **int** | How many trials are currently metrics unavailable. | [optional] 
**trials** | **int** | Trials is the total number of trials owned by the experiment. | [optional] 
**trials_early_stopped** | **int** | How many trials are currently early stopped. | [optional] 
**trials_failed** | **int** | How many trials have failed. | [optional] 
**trials_killed** | **int** | How many trials have been killed. | [optional] 
**trials_pending** | **int** | How many trials are currently pending. | [optional] 
**trials_running** | **int** | How many trials are currently running. | [optional] 
**trials_succeeded** | **int** | How many trials have succeeded. | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1FeasibleSpace.md
================================================
# V1beta1FeasibleSpace

## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**distribution** | **str** |  | [optional] 
**list** | **list[str]** |  | [optional] 
**max** | **str** |  | [optional] 
**min** | **str** |  | [optional] 
**step** | **str** |  | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1FileSystemPath.md
================================================
# V1beta1FileSystemPath

## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**format** | **str** |  | [optional] 
**kind** | **str** |  | [optional] 
**path** | **str** |  | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1FilterSpec.md
================================================
# V1beta1FilterSpec

## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**metrics_format** | **list[str]** | When the metrics output follows format as this field specified, metricsCollector collects it and reports to metrics server, it can be \&quot;&lt;metric_name&gt;: &lt;float&gt;\&quot; or else | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1GraphConfig.md
================================================
# V1beta1GraphConfig

GraphConfig contains a config of DAG
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**input_sizes** | **list[int]** |  | [optional] 
**num_layers** | **int** |  | [optional] 
**output_sizes** | **list[int]** |  | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1Metric.md
================================================
# V1beta1Metric

## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**latest** | **str** |  | [optional] 
**max** | **str** |  | [optional] 
**min** | **str** |  | [optional] 
**name** | **str** |  | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1MetricsCollectorSpec.md
================================================
# V1beta1MetricsCollectorSpec

## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**collector** | [**V1beta1CollectorSpec**](V1beta1CollectorSpec.md) |  | [optional] 
**source** | [**V1beta1SourceSpec**](V1beta1SourceSpec.md) |  | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1MetricStrategy.md
================================================
# V1beta1MetricStrategy

## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**name** | **str** |  | [optional] 
**value** | **str** |  | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1NasConfig.md
================================================
# V1beta1NasConfig

NasConfig contains config for NAS job
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**graph_config** | [**V1beta1GraphConfig**](V1beta1GraphConfig.md) |  | [optional] 
**operations** | [**list[V1beta1Operation]**](V1beta1Operation.md) |  | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1ObjectiveSpec.md
================================================
# V1beta1ObjectiveSpec

ObjectiveSpec represents Experiment's objective specification.
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**additional_metric_names** | **list[str]** | AdditionalMetricNames represents metrics that should be collected from Trials. This can be empty if we only care about the objective metric. Note: If we adopt a push instead of pull mechanism, this can be omitted completely. | [optional] 
**goal** | **float** | Goal is the Experiment&#39;s objective goal that should be reached. In case of empty goal, Experiment is running until MaxTrialCount &#x3D; TrialsSucceeded. | [optional] 
**metric_strategies** | [**list[V1beta1MetricStrategy]**](V1beta1MetricStrategy.md) | MetricStrategies defines various rules (min, max or latest) to extract metrics values. This field is allowed to missing, experiment defaulter (webhook) will fill it. | [optional] 
**objective_metric_name** | **str** | ObjectiveMetricName represents primary Experiment&#39;s metric to optimize. | [optional] 
**type** | **str** | Type for Experiment optimization. | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1Observation.md
================================================
# V1beta1Observation

## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**metrics** | [**list[V1beta1Metric]**](V1beta1Metric.md) | Key-value pairs for metric names and values | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1Operation.md
================================================
# V1beta1Operation

Operation contains type of operation in DAG
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**operation_type** | **str** |  | [optional] 
**parameters** | [**list[V1beta1ParameterSpec]**](V1beta1ParameterSpec.md) |  | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1OptimalTrial.md
================================================
# V1beta1OptimalTrial

OptimalTrial is the metrics and assignments of the best trial.
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**best_trial_name** | **str** | BestTrialName is the name of the best trial. | [optional] 
**observation** | [**V1beta1Observation**](V1beta1Observation.md) |  | [optional] 
**parameter_assignments** | [**list[V1beta1ParameterAssignment]**](V1beta1ParameterAssignment.md) | Key-value pairs for hyperparameters and assignment values. | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1ParameterAssignment.md
================================================
# V1beta1ParameterAssignment

## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**name** | **str** |  | [optional] 
**value** | **str** |  | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1ParameterSpec.md
================================================
# V1beta1ParameterSpec

## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**feasible_space** | [**V1beta1FeasibleSpace**](V1beta1FeasibleSpace.md) |  | [optional] 
**name** | **str** |  | [optional] 
**parameter_type** | **str** |  | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1SourceSpec.md
================================================
# V1beta1SourceSpec

## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**file_system_path** | [**V1beta1FileSystemPath**](V1beta1FileSystemPath.md) |  | [optional] 
**filter** | [**V1beta1FilterSpec**](V1beta1FilterSpec.md) |  | [optional] 
**http_get** | [**V1HTTPGetAction**](https://github.com/kubernetes-client/python/blob/master/kubernetes/docs/V1HTTPGetAction.md) |  | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1Suggestion.md
================================================
# V1beta1Suggestion

Suggestion represents the structure of a Suggestion resource.
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**api_version** | **str** | APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources | [optional] 
**kind** | **str** | Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds | [optional] 
**metadata** | [**V1ObjectMeta**](https://github.com/kubernetes-client/python/blob/master/kubernetes/docs/V1ObjectMeta.md) |  | [optional] 
**spec** | [**V1beta1SuggestionSpec**](V1beta1SuggestionSpec.md) |  | [optional] 
**status** | [**V1beta1SuggestionStatus**](V1beta1SuggestionStatus.md) |  | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1SuggestionCondition.md
================================================
# V1beta1SuggestionCondition

SuggestionCondition describes the state of the Suggestion at a certain point.
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**last_transition_time** | **datetime** |  | [optional] 
**last_update_time** | **datetime** |  | [optional] 
**message** | **str** | A human readable message indicating details about the transition. | [optional] 
**reason** | **str** | The reason for the condition&#39;s last transition. | [optional] 
**status** | **str** | Status of the condition, one of True, False, Unknown. | [default to '']
**type** | **str** | Type of Suggestion condition. | [default to '']

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1SuggestionList.md
================================================
# V1beta1SuggestionList

SuggestionList contains a list of Suggestion
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**api_version** | **str** | APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources | [optional] 
**items** | [**list[V1beta1Suggestion]**](V1beta1Suggestion.md) |  | 
**kind** | **str** | Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds | [optional] 
**metadata** | [**V1ListMeta**](https://github.com/kubernetes-client/python/blob/master/kubernetes/docs/V1ListMeta.md) |  | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1SuggestionSpec.md
================================================
# V1beta1SuggestionSpec

SuggestionSpec is the specification of a Suggestion.
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**algorithm** | [**V1beta1AlgorithmSpec**](V1beta1AlgorithmSpec.md) |  | [optional] 
**early_stopping** | [**V1beta1EarlyStoppingSpec**](V1beta1EarlyStoppingSpec.md) |  | [optional] 
**requests** | **int** | Number of suggestions requested. | [optional] 
**resume_policy** | **str** | ResumePolicy describes resuming policy which usually take effect after experiment terminated. Default value is Never. | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1SuggestionStatus.md
================================================
# V1beta1SuggestionStatus

SuggestionStatus is the current status of a Suggestion.
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**algorithm_settings** | [**list[V1beta1AlgorithmSetting]**](V1beta1AlgorithmSetting.md) | AlgorithmSettings defines HP or NAS algorithm settings which suggestion gRPC service returns. These settings overwrites Experiment&#39;s settings before the gRPC request. It can be empty if settings haven&#39;t been changed. | [optional] 
**completion_time** | **datetime** |  | [optional] 
**conditions** | [**list[V1beta1SuggestionCondition]**](V1beta1SuggestionCondition.md) | List of observed runtime conditions for this Suggestion. | [optional] 
**last_reconcile_time** | **datetime** |  | [optional] 
**start_time** | **datetime** |  | [optional] 
**suggestion_count** | **int** | Number of suggestion results | [optional] 
**suggestions** | [**list[V1beta1TrialAssignment]**](V1beta1TrialAssignment.md) | Suggestion results | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1Trial.md
================================================
# V1beta1Trial

Represents the structure of a Trial resource.
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**api_version** | **str** | APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources | [optional] 
**kind** | **str** | Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds | [optional] 
**metadata** | [**V1ObjectMeta**](https://github.com/kubernetes-client/python/blob/master/kubernetes/docs/V1ObjectMeta.md) |  | [optional] 
**spec** | [**V1beta1TrialSpec**](V1beta1TrialSpec.md) |  | [optional] 
**status** | [**V1beta1TrialStatus**](V1beta1TrialStatus.md) |  | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1TrialAssignment.md
================================================
# V1beta1TrialAssignment

TrialAssignment is the assignment for one trial.
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**early_stopping_rules** | [**list[V1beta1EarlyStoppingRule]**](V1beta1EarlyStoppingRule.md) | Rules for early stopping techniques Contains rule name, value and comparison type | [optional] 
**labels** | **dict(str, str)** | Suggestion label metadata to attach to Trial job | [optional] 
**name** | **str** | Name of the suggestion | [optional] 
**parameter_assignments** | [**list[V1beta1ParameterAssignment]**](V1beta1ParameterAssignment.md) | Suggestion results with Trial parameters | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1TrialCondition.md
================================================
# V1beta1TrialCondition

TrialCondition describes the state of the trial at a certain point.
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**last_transition_time** | **datetime** |  | [optional] 
**last_update_time** | **datetime** |  | [optional] 
**message** | **str** | A human readable message indicating details about the transition. | [optional] 
**reason** | **str** | The reason for the condition&#39;s last transition. | [optional] 
**status** | **str** | Status of the condition, one of True, False, Unknown. | [default to '']
**type** | **str** | Type of trial condition. | [default to '']

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1TrialList.md
================================================
# V1beta1TrialList

TrialList contains a list of Trials
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**api_version** | **str** | APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources | [optional] 
**items** | [**list[V1beta1Trial]**](V1beta1Trial.md) |  | 
**kind** | **str** | Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds | [optional] 
**metadata** | [**V1ListMeta**](https://github.com/kubernetes-client/python/blob/master/kubernetes/docs/V1ListMeta.md) |  | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1TrialParameterSpec.md
================================================
# V1beta1TrialParameterSpec

TrialParameterSpec describes parameters that must be replaced in trial template
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**description** | **str** | Description of the parameter | [optional] 
**name** | **str** | Name of the parameter that must be replaced in trial template | [optional] 
**reference** | **str** | Reference to the parameter in search space | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1TrialSource.md
================================================
# V1beta1TrialSource

TrialSource represent the source for trial template Only one source can be specified
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**config_map** | [**V1beta1ConfigMapSource**](V1beta1ConfigMapSource.md) |  | [optional] 
**trial_spec** | **object** |  | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1TrialSpec.md
================================================
# V1beta1TrialSpec

TrialSpec is the specification of a Trial.
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**early_stopping_rules** | [**list[V1beta1EarlyStoppingRule]**](V1beta1EarlyStoppingRule.md) | Rules for early stopping techniques. Each rule should be met to early stop Trial. | [optional] 
**failure_condition** | **str** | Condition when trial custom resource is failed. Condition must be in GJSON format, ref https://github.com/tidwall/gjson. For example for BatchJob: status.conditions.#(type&#x3D;&#x3D;\&quot;Failed\&quot;)#|#(status&#x3D;&#x3D;\&quot;True\&quot;)# | [optional] 
**labels** | **dict(str, str)** | Labels that provide additional metadata for services (e.g. Suggestions tracking) | [optional] 
**metrics_collector** | [**V1beta1MetricsCollectorSpec**](V1beta1MetricsCollectorSpec.md) |  | [optional] 
**objective** | [**V1beta1ObjectiveSpec**](V1beta1ObjectiveSpec.md) |  | [optional] 
**parameter_assignments** | [**list[V1beta1ParameterAssignment]**](V1beta1ParameterAssignment.md) | Key-value pairs for hyperparameters and assignment values. | [optional] 
**primary_container_name** | **str** | Name of training container where actual model training is running | [optional] 
**primary_pod_labels** | **dict(str, str)** | Label that determines if pod needs to be injected by Katib sidecar container | [optional] 
**retain_run** | **bool** | Whether to retain the trial run object after completed. | [optional] 
**run_spec** | **object** |  | [optional] 
**success_condition** | **str** | Condition when trial custom resource is succeeded. Condition must be in GJSON format, ref https://github.com/tidwall/gjson. For example for BatchJob: status.conditions.#(type&#x3D;&#x3D;\&quot;Complete\&quot;)#|#(status&#x3D;&#x3D;\&quot;True\&quot;)# | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1TrialStatus.md
================================================
# V1beta1TrialStatus

TrialStatus is the current status of a Trial.
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**completion_time** | **datetime** |  | [optional] 
**conditions** | [**list[V1beta1TrialCondition]**](V1beta1TrialCondition.md) | List of observed runtime conditions for this Trial. | [optional] 
**last_reconcile_time** | **datetime** |  | [optional] 
**observation** | [**V1beta1Observation**](V1beta1Observation.md) |  | [optional] 
**start_time** | **datetime** |  | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/docs/V1beta1TrialTemplate.md
================================================
# V1beta1TrialTemplate

TrialTemplate describes structure of trial template
## Properties
Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**config_map** | [**V1beta1ConfigMapSource**](V1beta1ConfigMapSource.md) |  | [optional] 
**failure_condition** | **str** | Condition when trial custom resource is failed. Condition must be in GJSON format, ref https://github.com/tidwall/gjson. For example for BatchJob: status.conditions.#(type&#x3D;&#x3D;\&quot;Failed\&quot;)#|#(status&#x3D;&#x3D;\&quot;True\&quot;)# | [optional] 
**primary_container_name** | **str** | Name of training container where actual model training is running | [optional] 
**primary_pod_labels** | **dict(str, str)** | Labels that determines if pod needs to be injected by Katib sidecar container. If PrimaryPodLabels is omitted, metrics collector wraps all Trial&#39;s pods. | [optional] 
**retain** | **bool** | Retain indicates that trial resources must be not cleanup | [optional] 
**success_condition** | **str** | Condition when trial custom resource is succeeded. Condition must be in GJSON format, ref https://github.com/tidwall/gjson. For example for BatchJob: status.conditions.#(type&#x3D;&#x3D;\&quot;Complete\&quot;)#|#(status&#x3D;&#x3D;\&quot;True\&quot;)# | [optional] 
**trial_parameters** | [**list[V1beta1TrialParameterSpec]**](V1beta1TrialParameterSpec.md) | List of parameters that are used in trial template | [optional] 
**trial_spec** | **object** |  | [optional] 

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)





================================================
FILE: sdk/python/v1beta1/kubeflow/__init__.py
================================================
__path__ = __import__("pkgutil").extend_path(__path__, __name__)



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/__init__.py
================================================
# coding: utf-8

# flake8: noqa

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


from __future__ import absolute_import

__version__ = "0.1"

# import apis into sdk package

# import ApiClient
from kubeflow.katib.api_client import ApiClient
from kubeflow.katib.configuration import Configuration
from kubeflow.katib.exceptions import OpenApiException
from kubeflow.katib.exceptions import ApiTypeError
from kubeflow.katib.exceptions import ApiValueError
from kubeflow.katib.exceptions import ApiKeyError
from kubeflow.katib.exceptions import ApiException
# import models into sdk package
from kubeflow.katib.models.v1beta1_algorithm_setting import V1beta1AlgorithmSetting
from kubeflow.katib.models.v1beta1_algorithm_spec import V1beta1AlgorithmSpec
from kubeflow.katib.models.v1beta1_collector_spec import V1beta1CollectorSpec
from kubeflow.katib.models.v1beta1_config_map_source import V1beta1ConfigMapSource
from kubeflow.katib.models.v1beta1_early_stopping_rule import V1beta1EarlyStoppingRule
from kubeflow.katib.models.v1beta1_early_stopping_setting import V1beta1EarlyStoppingSetting
from kubeflow.katib.models.v1beta1_early_stopping_spec import V1beta1EarlyStoppingSpec
from kubeflow.katib.models.v1beta1_experiment import V1beta1Experiment
from kubeflow.katib.models.v1beta1_experiment_condition import V1beta1ExperimentCondition
from kubeflow.katib.models.v1beta1_experiment_list import V1beta1ExperimentList
from kubeflow.katib.models.v1beta1_experiment_spec import V1beta1ExperimentSpec
from kubeflow.katib.models.v1beta1_experiment_status import V1beta1ExperimentStatus
from kubeflow.katib.models.v1beta1_feasible_space import V1beta1FeasibleSpace
from kubeflow.katib.models.v1beta1_file_system_path import V1beta1FileSystemPath
from kubeflow.katib.models.v1beta1_filter_spec import V1beta1FilterSpec
from kubeflow.katib.models.v1beta1_graph_config import V1beta1GraphConfig
from kubeflow.katib.models.v1beta1_metric import V1beta1Metric
from kubeflow.katib.models.v1beta1_metric_strategy import V1beta1MetricStrategy
from kubeflow.katib.models.v1beta1_metrics_collector_spec import V1beta1MetricsCollectorSpec
from kubeflow.katib.models.v1beta1_nas_config import V1beta1NasConfig
from kubeflow.katib.models.v1beta1_objective_spec import V1beta1ObjectiveSpec
from kubeflow.katib.models.v1beta1_observation import V1beta1Observation
from kubeflow.katib.models.v1beta1_operation import V1beta1Operation
from kubeflow.katib.models.v1beta1_optimal_trial import V1beta1OptimalTrial
from kubeflow.katib.models.v1beta1_parameter_assignment import V1beta1ParameterAssignment
from kubeflow.katib.models.v1beta1_parameter_spec import V1beta1ParameterSpec
from kubeflow.katib.models.v1beta1_source_spec import V1beta1SourceSpec
from kubeflow.katib.models.v1beta1_suggestion import V1beta1Suggestion
from kubeflow.katib.models.v1beta1_suggestion_condition import V1beta1SuggestionCondition
from kubeflow.katib.models.v1beta1_suggestion_list import V1beta1SuggestionList
from kubeflow.katib.models.v1beta1_suggestion_spec import V1beta1SuggestionSpec
from kubeflow.katib.models.v1beta1_suggestion_status import V1beta1SuggestionStatus
from kubeflow.katib.models.v1beta1_trial import V1beta1Trial
from kubeflow.katib.models.v1beta1_trial_assignment import V1beta1TrialAssignment
from kubeflow.katib.models.v1beta1_trial_condition import V1beta1TrialCondition
from kubeflow.katib.models.v1beta1_trial_list import V1beta1TrialList
from kubeflow.katib.models.v1beta1_trial_parameter_spec import V1beta1TrialParameterSpec
from kubeflow.katib.models.v1beta1_trial_source import V1beta1TrialSource
from kubeflow.katib.models.v1beta1_trial_spec import V1beta1TrialSpec
from kubeflow.katib.models.v1beta1_trial_status import V1beta1TrialStatus
from kubeflow.katib.models.v1beta1_trial_template import V1beta1TrialTemplate

# Import Katib API client.
from kubeflow.katib.api.katib_client import KatibClient
# Import Katib TrainerResources class.
from kubeflow.katib.types.types import TrainerResources
# Import Katib report metrics functions
from kubeflow.katib.api.report_metrics import report_metrics
# Import Katib helper functions.
import kubeflow.katib.api.search as search
# Import Katib helper constants.
from kubeflow.katib.constants.constants import BASE_IMAGE_TENSORFLOW
from kubeflow.katib.constants.constants import BASE_IMAGE_TENSORFLOW_GPU
from kubeflow.katib.constants.constants import BASE_IMAGE_PYTORCH



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/api_client.py
================================================
# coding: utf-8
"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""

from __future__ import absolute_import

import atexit
import datetime
from dateutil.parser import parse
import json
import mimetypes
from multiprocessing.pool import ThreadPool
import os
import re
import tempfile

# python 2 and python 3 compatibility library
import six
from six.moves.urllib.parse import quote

from kubeflow.katib.configuration import Configuration
import kubeflow.katib.models
from kubeflow.katib import rest
from kubeflow.katib.exceptions import ApiValueError, ApiException


class ApiClient(object):
    """Generic API client for OpenAPI client library builds.

    OpenAPI generic API client. This client handles the client-
    server communication, and is invariant across implementations. Specifics of
    the methods and models for each application are generated from the OpenAPI
    templates.

    NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech
    Do not edit the class manually.

    :param configuration: .Configuration object for this client
    :param header_name: a header to pass when making calls to the API.
    :param header_value: a header value to pass when making calls to
        the API.
    :param cookie: a cookie to include in the header when making calls
        to the API
    :param pool_threads: The number of threads to use for async requests
        to the API. More threads means more concurrent API requests.
    """

    PRIMITIVE_TYPES = (float, bool, bytes, six.text_type) + six.integer_types
    NATIVE_TYPES_MAPPING = {
        'int': int,
        'long': int if six.PY3 else long,  # noqa: F821
        'float': float,
        'str': str,
        'bool': bool,
        'date': datetime.date,
        'datetime': datetime.datetime,
        'object': object,
    }
    _pool = None

    def __init__(self, configuration=None, header_name=None, header_value=None,
                 cookie=None, pool_threads=1):
        if configuration is None:
            configuration = Configuration.get_default_copy()
        self.configuration = configuration
        self.pool_threads = pool_threads

        self.rest_client = rest.RESTClientObject(configuration)
        self.default_headers = {}
        if header_name is not None:
            self.default_headers[header_name] = header_value
        self.cookie = cookie
        # Set default User-Agent.
        self.user_agent = 'OpenAPI-Generator/0.1/python'
        self.client_side_validation = configuration.client_side_validation

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_value, traceback):
        self.close()

    def close(self):
        if self._pool:
            self._pool.close()
            self._pool.join()
            self._pool = None
            if hasattr(atexit, 'unregister'):
                atexit.unregister(self.close)

    @property
    def pool(self):
        """Create thread pool on first request
         avoids instantiating unused threadpool for blocking clients.
        """
        if self._pool is None:
            atexit.register(self.close)
            self._pool = ThreadPool(self.pool_threads)
        return self._pool

    @property
    def user_agent(self):
        """User agent for this API client"""
        return self.default_headers['User-Agent']

    @user_agent.setter
    def user_agent(self, value):
        self.default_headers['User-Agent'] = value

    def set_default_header(self, header_name, header_value):
        self.default_headers[header_name] = header_value

    def __call_api(
            self, resource_path, method, path_params=None,
            query_params=None, header_params=None, body=None, post_params=None,
            files=None, response_type=None, auth_settings=None,
            _return_http_data_only=None, collection_formats=None,
            _preload_content=True, _request_timeout=None, _host=None):

        config = self.configuration

        # header parameters
        header_params = header_params or {}
        header_params.update(self.default_headers)
        if self.cookie:
            header_params['Cookie'] = self.cookie
        if header_params:
            header_params = self.sanitize_for_serialization(header_params)
            header_params = dict(self.parameters_to_tuples(header_params,
                                                           collection_formats))

        # path parameters
        if path_params:
            path_params = self.sanitize_for_serialization(path_params)
            path_params = self.parameters_to_tuples(path_params,
                                                    collection_formats)
            for k, v in path_params:
                # specified safe chars, encode everything
                resource_path = resource_path.replace(
                    '{%s}' % k,
                    quote(str(v), safe=config.safe_chars_for_path_param)
                )

        # query parameters
        if query_params:
            query_params = self.sanitize_for_serialization(query_params)
            query_params = self.parameters_to_tuples(query_params,
                                                     collection_formats)

        # post parameters
        if post_params or files:
            post_params = post_params if post_params else []
            post_params = self.sanitize_for_serialization(post_params)
            post_params = self.parameters_to_tuples(post_params,
                                                    collection_formats)
            post_params.extend(self.files_parameters(files))

        # auth setting
        self.update_params_for_auth(header_params, query_params, auth_settings)

        # body
        if body:
            body = self.sanitize_for_serialization(body)

        # request url
        if _host is None:
            url = self.configuration.host + resource_path
        else:
            # use server/host defined in path or operation instead
            url = _host + resource_path

        try:
            # perform request and return response
            response_data = self.request(
                method, url, query_params=query_params, headers=header_params,
                post_params=post_params, body=body,
                _preload_content=_preload_content,
                _request_timeout=_request_timeout)
        except ApiException as e:
            e.body = e.body.decode('utf-8') if six.PY3 else e.body
            raise e

        content_type = response_data.getheader('content-type')

        self.last_response = response_data

        return_data = response_data

        if not _preload_content:
            return return_data

        if six.PY3 and response_type not in ["file", "bytes"]:
            match = None
            if content_type is not None:
                match = re.search(r"charset=([a-zA-Z\-\d]+)[\s\;]?", content_type)
            encoding = match.group(1) if match else "utf-8"
            response_data.data = response_data.data.decode(encoding)

        # deserialize response data
        if response_type:
            return_data = self.deserialize(response_data, response_type)
        else:
            return_data = None

        if _return_http_data_only:
            return (return_data)
        else:
            return (return_data, response_data.status,
                    response_data.getheaders())

    def sanitize_for_serialization(self, obj):
        """Builds a JSON POST object.

        If obj is None, return None.
        If obj is str, int, long, float, bool, return directly.
        If obj is datetime.datetime, datetime.date
            convert to string in iso8601 format.
        If obj is list, sanitize each element in the list.
        If obj is dict, return the dict.
        If obj is OpenAPI model, return the properties dict.

        :param obj: The data to serialize.
        :return: The serialized form of data.
        """
        if obj is None:
            return None
        elif isinstance(obj, self.PRIMITIVE_TYPES):
            return obj
        elif isinstance(obj, list):
            return [self.sanitize_for_serialization(sub_obj)
                    for sub_obj in obj]
        elif isinstance(obj, tuple):
            return tuple(self.sanitize_for_serialization(sub_obj)
                         for sub_obj in obj)
        elif isinstance(obj, (datetime.datetime, datetime.date)):
            return obj.isoformat()

        if isinstance(obj, dict):
            obj_dict = obj
        else:
            # Convert model obj to dict except
            # attributes `openapi_types`, `attribute_map`
            # and attributes which value is not None.
            # Convert attribute name to json key in
            # model definition for request.
            obj_dict = {obj.attribute_map[attr]: getattr(obj, attr)
                        for attr, _ in six.iteritems(obj.openapi_types)
                        if getattr(obj, attr) is not None}

        return {key: self.sanitize_for_serialization(val)
                for key, val in six.iteritems(obj_dict)}

    def deserialize(self, response, response_type):
        """Deserializes response into an object.

        :param response: RESTResponse object to be deserialized.
        :param response_type: class literal for
            deserialized object, or string of class name.

        :return: deserialized object.
        """
        # handle file downloading
        # save response body into a tmp file and return the instance
        if response_type == "file":
            return self.__deserialize_file(response)

        # fetch data from response object
        try:
            data = json.loads(response.data)
        except ValueError:
            data = response.data

        return self.__deserialize(data, response_type)

    def __deserialize(self, data, klass):
        """Deserializes dict, list, str into an object.

        :param data: dict, list or str.
        :param klass: class literal, or string of class name.

        :return: object.
        """
        if data is None:
            return None

        if type(klass) == str:
            if klass.startswith('list['):
                sub_kls = re.match(r'list\[(.*)\]', klass).group(1)
                return [self.__deserialize(sub_data, sub_kls)
                        for sub_data in data]

            if klass.startswith('dict('):
                sub_kls = re.match(r'dict\(([^,]*), (.*)\)', klass).group(2)
                return {k: self.__deserialize(v, sub_kls)
                        for k, v in six.iteritems(data)}

            # convert str to class
            if klass in self.NATIVE_TYPES_MAPPING:
                klass = self.NATIVE_TYPES_MAPPING[klass]
            else:
                klass = getattr(kubeflow.katib.models, klass)

        if klass in self.PRIMITIVE_TYPES:
            return self.__deserialize_primitive(data, klass)
        elif klass == object:
            return self.__deserialize_object(data)
        elif klass == datetime.date:
            return self.__deserialize_date(data)
        elif klass == datetime.datetime:
            return self.__deserialize_datetime(data)
        else:
            return self.__deserialize_model(data, klass)

    def call_api(self, resource_path, method,
                 path_params=None, query_params=None, header_params=None,
                 body=None, post_params=None, files=None,
                 response_type=None, auth_settings=None, async_req=None,
                 _return_http_data_only=None, collection_formats=None,
                 _preload_content=True, _request_timeout=None, _host=None):
        """Makes the HTTP request (synchronous) and returns deserialized data.

        To make an async_req request, set the async_req parameter.

        :param resource_path: Path to method endpoint.
        :param method: Method to call.
        :param path_params: Path parameters in the url.
        :param query_params: Query parameters in the url.
        :param header_params: Header parameters to be
            placed in the request header.
        :param body: Request body.
        :param post_params dict: Request post form parameters,
            for `application/x-www-form-urlencoded`, `multipart/form-data`.
        :param auth_settings list: Auth Settings names for the request.
        :param response: Response data type.
        :param files dict: key -> filename, value -> filepath,
            for `multipart/form-data`.
        :param async_req bool: execute request asynchronously
        :param _return_http_data_only: response data without head status code
                                       and headers
        :param collection_formats: dict of collection formats for path, query,
            header, and post parameters.
        :param _preload_content: if False, the urllib3.HTTPResponse object will
                                 be returned without reading/decoding response
                                 data. Default is True.
        :param _request_timeout: timeout setting for this request. If one
                                 number provided, it will be total request
                                 timeout. It can also be a pair (tuple) of
                                 (connection, read) timeouts.
        :return:
            If async_req parameter is True,
            the request will be called asynchronously.
            The method will return the request thread.
            If parameter async_req is False or missing,
            then the method will return the response directly.
        """
        if not async_req:
            return self.__call_api(resource_path, method,
                                   path_params, query_params, header_params,
                                   body, post_params, files,
                                   response_type, auth_settings,
                                   _return_http_data_only, collection_formats,
                                   _preload_content, _request_timeout, _host)

        return self.pool.apply_async(self.__call_api, (resource_path,
                                                       method, path_params,
                                                       query_params,
                                                       header_params, body,
                                                       post_params, files,
                                                       response_type,
                                                       auth_settings,
                                                       _return_http_data_only,
                                                       collection_formats,
                                                       _preload_content,
                                                       _request_timeout,
                                                       _host))

    def request(self, method, url, query_params=None, headers=None,
                post_params=None, body=None, _preload_content=True,
                _request_timeout=None):
        """Makes the HTTP request using RESTClient."""
        if method == "GET":
            return self.rest_client.GET(url,
                                        query_params=query_params,
                                        _preload_content=_preload_content,
                                        _request_timeout=_request_timeout,
                                        headers=headers)
        elif method == "HEAD":
            return self.rest_client.HEAD(url,
                                         query_params=query_params,
                                         _preload_content=_preload_content,
                                         _request_timeout=_request_timeout,
                                         headers=headers)
        elif method == "OPTIONS":
            return self.rest_client.OPTIONS(url,
                                            query_params=query_params,
                                            headers=headers,
                                            _preload_content=_preload_content,
                                            _request_timeout=_request_timeout)
        elif method == "POST":
            return self.rest_client.POST(url,
                                         query_params=query_params,
                                         headers=headers,
                                         post_params=post_params,
                                         _preload_content=_preload_content,
                                         _request_timeout=_request_timeout,
                                         body=body)
        elif method == "PUT":
            return self.rest_client.PUT(url,
                                        query_params=query_params,
                                        headers=headers,
                                        post_params=post_params,
                                        _preload_content=_preload_content,
                                        _request_timeout=_request_timeout,
                                        body=body)
        elif method == "PATCH":
            return self.rest_client.PATCH(url,
                                          query_params=query_params,
                                          headers=headers,
                                          post_params=post_params,
                                          _preload_content=_preload_content,
                                          _request_timeout=_request_timeout,
                                          body=body)
        elif method == "DELETE":
            return self.rest_client.DELETE(url,
                                           query_params=query_params,
                                           headers=headers,
                                           _preload_content=_preload_content,
                                           _request_timeout=_request_timeout,
                                           body=body)
        else:
            raise ApiValueError(
                "http method must be `GET`, `HEAD`, `OPTIONS`,"
                " `POST`, `PATCH`, `PUT` or `DELETE`."
            )

    def parameters_to_tuples(self, params, collection_formats):
        """Get parameters as list of tuples, formatting collections.

        :param params: Parameters as dict or list of two-tuples
        :param dict collection_formats: Parameter collection formats
        :return: Parameters as list of tuples, collections formatted
        """
        new_params = []
        if collection_formats is None:
            collection_formats = {}
        for k, v in six.iteritems(params) if isinstance(params, dict) else params:  # noqa: E501
            if k in collection_formats:
                collection_format = collection_formats[k]
                if collection_format == 'multi':
                    new_params.extend((k, value) for value in v)
                else:
                    if collection_format == 'ssv':
                        delimiter = ' '
                    elif collection_format == 'tsv':
                        delimiter = '\t'
                    elif collection_format == 'pipes':
                        delimiter = '|'
                    else:  # csv is the default
                        delimiter = ','
                    new_params.append(
                        (k, delimiter.join(str(value) for value in v)))
            else:
                new_params.append((k, v))
        return new_params

    def files_parameters(self, files=None):
        """Builds form parameters.

        :param files: File parameters.
        :return: Form parameters with files.
        """
        params = []

        if files:
            for k, v in six.iteritems(files):
                if not v:
                    continue
                file_names = v if type(v) is list else [v]
                for n in file_names:
                    with open(n, 'rb') as f:
                        filename = os.path.basename(f.name)
                        filedata = f.read()
                        mimetype = (mimetypes.guess_type(filename)[0] or
                                    'application/octet-stream')
                        params.append(
                            tuple([k, tuple([filename, filedata, mimetype])]))

        return params

    def select_header_accept(self, accepts):
        """Returns `Accept` based on an array of accepts provided.

        :param accepts: List of headers.
        :return: Accept (e.g. application/json).
        """
        if not accepts:
            return

        accepts = [x.lower() for x in accepts]

        if 'application/json' in accepts:
            return 'application/json'
        else:
            return ', '.join(accepts)

    def select_header_content_type(self, content_types):
        """Returns `Content-Type` based on an array of content_types provided.

        :param content_types: List of content-types.
        :return: Content-Type (e.g. application/json).
        """
        if not content_types:
            return 'application/json'

        content_types = [x.lower() for x in content_types]

        if 'application/json' in content_types or '*/*' in content_types:
            return 'application/json'
        else:
            return content_types[0]

    def update_params_for_auth(self, headers, querys, auth_settings):
        """Updates header and query params based on authentication setting.

        :param headers: Header parameters dict to be updated.
        :param querys: Query parameters tuple list to be updated.
        :param auth_settings: Authentication setting identifiers list.
        """
        if not auth_settings:
            return

        for auth in auth_settings:
            auth_setting = self.configuration.auth_settings().get(auth)
            if auth_setting:
                if auth_setting['in'] == 'cookie':
                    headers['Cookie'] = auth_setting['value']
                elif auth_setting['in'] == 'header':
                    headers[auth_setting['key']] = auth_setting['value']
                elif auth_setting['in'] == 'query':
                    querys.append((auth_setting['key'], auth_setting['value']))
                else:
                    raise ApiValueError(
                        'Authentication token must be in `query` or `header`'
                    )

    def __deserialize_file(self, response):
        """Deserializes body to file

        Saves response body into a file in a temporary folder,
        using the filename from the `Content-Disposition` header if provided.

        :param response:  RESTResponse.
        :return: file path.
        """
        fd, path = tempfile.mkstemp(dir=self.configuration.temp_folder_path)
        os.close(fd)
        os.remove(path)

        content_disposition = response.getheader("Content-Disposition")
        if content_disposition:
            filename = re.search(r'filename=[\'"]?([^\'"\s]+)[\'"]?',
                                 content_disposition).group(1)
            path = os.path.join(os.path.dirname(path), filename)

        with open(path, "wb") as f:
            f.write(response.data)

        return path

    def __deserialize_primitive(self, data, klass):
        """Deserializes string to primitive type.

        :param data: str.
        :param klass: class literal.

        :return: int, long, float, str, bool.
        """
        try:
            return klass(data)
        except UnicodeEncodeError:
            return six.text_type(data)
        except TypeError:
            return data

    def __deserialize_object(self, value):
        """Return an original value.

        :return: object.
        """
        return value

    def __deserialize_date(self, string):
        """Deserializes string to date.

        :param string: str.
        :return: date.
        """
        try:
            return parse(string).date()
        except ImportError:
            return string
        except ValueError:
            raise rest.ApiException(
                status=0,
                reason="Failed to parse `{0}` as date object".format(string)
            )

    def __deserialize_datetime(self, string):
        """Deserializes string to datetime.

        The string should be in iso8601 datetime format.

        :param string: str.
        :return: datetime.
        """
        try:
            return parse(string)
        except ImportError:
            return string
        except ValueError:
            raise rest.ApiException(
                status=0,
                reason=(
                    "Failed to parse `{0}` as datetime object"
                    .format(string)
                )
            )

    def __deserialize_model(self, data, klass):
        """Deserializes list or dict to model.

        :param data: dict, list.
        :param klass: class literal.
        :return: model object.
        """
        has_discriminator = False
        if (hasattr(klass, 'get_real_child_model')
                and klass.discriminator_value_class_map):
            has_discriminator = True

        if not klass.openapi_types and has_discriminator is False:
            return data

        kwargs = {}
        if (data is not None and
                klass.openapi_types is not None and
                isinstance(data, (list, dict))):
            for attr, attr_type in six.iteritems(klass.openapi_types):
                if klass.attribute_map[attr] in data:
                    value = data[klass.attribute_map[attr]]
                    kwargs[attr] = self.__deserialize(value, attr_type)

        instance = klass(**kwargs)

        if has_discriminator:
            klass_name = instance.get_real_child_model(data)
            if klass_name:
                instance = self.__deserialize(data, klass_name)
        return instance



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/configuration.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


from __future__ import absolute_import

import copy
import logging
import multiprocessing
import sys
import urllib3

import six
from six.moves import http_client as httplib


class Configuration(object):
    """NOTE: This class is auto generated by OpenAPI Generator

    Ref: https://openapi-generator.tech
    Do not edit the class manually.

    :param host: Base url
    :param api_key: Dict to store API key(s).
      Each entry in the dict specifies an API key.
      The dict key is the name of the security scheme in the OAS specification.
      The dict value is the API key secret.
    :param api_key_prefix: Dict to store API prefix (e.g. Bearer)
      The dict key is the name of the security scheme in the OAS specification.
      The dict value is an API key prefix when generating the auth data.
    :param username: Username for HTTP basic authentication
    :param password: Password for HTTP basic authentication
    :param discard_unknown_keys: Boolean value indicating whether to discard
      unknown properties. A server may send a response that includes additional
      properties that are not known by the client in the following scenarios:
      1. The OpenAPI document is incomplete, i.e. it does not match the server
         implementation.
      2. The client was generated using an older version of the OpenAPI document
         and the server has been upgraded since then.
      If a schema in the OpenAPI document defines the additionalProperties attribute,
      then all undeclared properties received by the server are injected into the
      additional properties map. In that case, there are undeclared properties, and
      nothing to discard.

    """

    _default = None

    def __init__(self, host="http://localhost",
                 api_key=None, api_key_prefix=None,
                 username=None, password=None,
                 discard_unknown_keys=False,
                 ):
        """Constructor
        """
        self.host = host
        """Default Base url
        """
        self.temp_folder_path = None
        """Temp file folder for downloading files
        """
        # Authentication Settings
        self.api_key = {}
        if api_key:
            self.api_key = api_key
        """dict to store API key(s)
        """
        self.api_key_prefix = {}
        if api_key_prefix:
            self.api_key_prefix = api_key_prefix
        """dict to store API prefix (e.g. Bearer)
        """
        self.refresh_api_key_hook = None
        """function hook to refresh API key if expired
        """
        self.username = username
        """Username for HTTP basic authentication
        """
        self.password = password
        """Password for HTTP basic authentication
        """
        self.discard_unknown_keys = discard_unknown_keys
        self.logger = {}
        """Logging Settings
        """
        self.logger["package_logger"] = logging.getLogger("katib")
        self.logger["urllib3_logger"] = logging.getLogger("urllib3")
        self.logger_format = '%(asctime)s %(levelname)s %(message)s'
        """Log format
        """
        self.logger_stream_handler = None
        """Log stream handler
        """
        self.logger_file_handler = None
        """Log file handler
        """
        self.logger_file = None
        """Debug file location
        """
        self.debug = False
        """Debug switch
        """

        self.verify_ssl = True
        """SSL/TLS verification
           Set this to false to skip verifying SSL certificate when calling API
           from https server.
        """
        self.ssl_ca_cert = None
        """Set this to customize the certificate file to verify the peer.
        """
        self.cert_file = None
        """client certificate file
        """
        self.key_file = None
        """client key file
        """
        self.assert_hostname = None
        """Set this to True/False to enable/disable SSL hostname verification.
        """

        self.connection_pool_maxsize = multiprocessing.cpu_count() * 5
        """urllib3 connection pool's maximum number of connections saved
           per pool. urllib3 uses 1 connection as default value, but this is
           not the best value when you are making a lot of possibly parallel
           requests to the same host, which is often the case here.
           cpu_count * 5 is used as default value to increase performance.
        """

        self.proxy = None
        """Proxy URL
        """
        self.proxy_headers = None
        """Proxy headers
        """
        self.safe_chars_for_path_param = ''
        """Safe chars for path_param
        """
        self.retries = None
        """Adding retries to override urllib3 default value 3
        """
        # Disable client side validation
        self.client_side_validation = True

    def __deepcopy__(self, memo):
        cls = self.__class__
        result = cls.__new__(cls)
        memo[id(self)] = result
        for k, v in self.__dict__.items():
            if k not in ('logger', 'logger_file_handler'):
                setattr(result, k, copy.deepcopy(v, memo))
        # shallow copy of loggers
        result.logger = copy.copy(self.logger)
        # use setters to configure loggers
        result.logger_file = self.logger_file
        result.debug = self.debug
        return result

    def __setattr__(self, name, value):
        object.__setattr__(self, name, value)

    @classmethod
    def set_default(cls, default):
        """Set default instance of configuration.

        It stores default configuration, which can be
        returned by get_default_copy method.

        :param default: object of Configuration
        """
        cls._default = copy.deepcopy(default)

    @classmethod
    def get_default_copy(cls):
        """Return new instance of configuration.

        This method returns newly created, based on default constructor,
        object of Configuration class or returns a copy of default
        configuration passed by the set_default method.

        :return: The configuration object.
        """
        if cls._default is not None:
            return copy.deepcopy(cls._default)
        return Configuration()

    @property
    def logger_file(self):
        """The logger file.

        If the logger_file is None, then add stream handler and remove file
        handler. Otherwise, add file handler and remove stream handler.

        :param value: The logger_file path.
        :type: str
        """
        return self.__logger_file

    @logger_file.setter
    def logger_file(self, value):
        """The logger file.

        If the logger_file is None, then add stream handler and remove file
        handler. Otherwise, add file handler and remove stream handler.

        :param value: The logger_file path.
        :type: str
        """
        self.__logger_file = value
        if self.__logger_file:
            # If set logging file,
            # then add file handler and remove stream handler.
            self.logger_file_handler = logging.FileHandler(self.__logger_file)
            self.logger_file_handler.setFormatter(self.logger_formatter)
            for _, logger in six.iteritems(self.logger):
                logger.addHandler(self.logger_file_handler)

    @property
    def debug(self):
        """Debug status

        :param value: The debug status, True or False.
        :type: bool
        """
        return self.__debug

    @debug.setter
    def debug(self, value):
        """Debug status

        :param value: The debug status, True or False.
        :type: bool
        """
        self.__debug = value
        if self.__debug:
            # if debug status is True, turn on debug logging
            for _, logger in six.iteritems(self.logger):
                logger.setLevel(logging.DEBUG)
            # turn on httplib debug
            httplib.HTTPConnection.debuglevel = 1
        else:
            # if debug status is False, turn off debug logging,
            # setting log level to default `logging.WARNING`
            for _, logger in six.iteritems(self.logger):
                logger.setLevel(logging.WARNING)
            # turn off httplib debug
            httplib.HTTPConnection.debuglevel = 0

    @property
    def logger_format(self):
        """The logger format.

        The logger_formatter will be updated when sets logger_format.

        :param value: The format string.
        :type: str
        """
        return self.__logger_format

    @logger_format.setter
    def logger_format(self, value):
        """The logger format.

        The logger_formatter will be updated when sets logger_format.

        :param value: The format string.
        :type: str
        """
        self.__logger_format = value
        self.logger_formatter = logging.Formatter(self.__logger_format)

    def get_api_key_with_prefix(self, identifier):
        """Gets API key (with prefix if set).

        :param identifier: The identifier of apiKey.
        :return: The token for api key authentication.
        """
        if self.refresh_api_key_hook is not None:
            self.refresh_api_key_hook(self)
        key = self.api_key.get(identifier)
        if key:
            prefix = self.api_key_prefix.get(identifier)
            if prefix:
                return "%s %s" % (prefix, key)
            else:
                return key

    def get_basic_auth_token(self):
        """Gets HTTP basic authentication header (string).

        :return: The token for basic HTTP authentication.
        """
        username = ""
        if self.username is not None:
            username = self.username
        password = ""
        if self.password is not None:
            password = self.password
        return urllib3.util.make_headers(
            basic_auth=username + ':' + password
        ).get('authorization')

    def auth_settings(self):
        """Gets Auth Settings dict for api client.

        :return: The Auth Settings information dict.
        """
        auth = {}
        return auth

    def to_debug_report(self):
        """Gets the essential information for debugging.

        :return: The report for debugging.
        """
        return "Python SDK Debug Report:\n"\
               "OS: {env}\n"\
               "Python Version: {pyversion}\n"\
               "Version of the API: v1beta1-0.1\n"\
               "SDK Package Version: 0.1".\
               format(env=sys.platform, pyversion=sys.version)

    def get_host_settings(self):
        """Gets an array of host settings

        :return: An array of host settings
        """
        return [
            {
                'url': "/",
                'description': "No description provided",
            }
        ]

    def get_host_from_settings(self, index, variables=None):
        """Gets host URL based on the index and variables
        :param index: array index of the host settings
        :param variables: hash of variable and the corresponding value
        :return: URL based on host settings
        """
        variables = {} if variables is None else variables
        servers = self.get_host_settings()

        try:
            server = servers[index]
        except IndexError:
            raise ValueError(
                "Invalid index {0} when selecting the host settings. "
                "Must be less than {1}".format(index, len(servers)))

        url = server['url']

        # go through variables and replace placeholders
        for variable_name, variable in server['variables'].items():
            used_value = variables.get(
                variable_name, variable['default_value'])

            if 'enum_values' in variable \
                    and used_value not in variable['enum_values']:
                raise ValueError(
                    "The variable `{0}` in the host URL has invalid value "
                    "{1}. Must be {2}.".format(
                        variable_name, variables[variable_name],
                        variable['enum_values']))

            url = url.replace("{" + variable_name + "}", used_value)

        return url



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/exceptions.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import six


class OpenApiException(Exception):
    """The base exception class for all OpenAPIExceptions"""


class ApiTypeError(OpenApiException, TypeError):
    def __init__(self, msg, path_to_item=None, valid_classes=None,
                 key_type=None):
        """ Raises an exception for TypeErrors

        Args:
            msg (str): the exception message

        Keyword Args:
            path_to_item (list): a list of keys an indices to get to the
                                 current_item
                                 None if unset
            valid_classes (tuple): the primitive classes that current item
                                   should be an instance of
                                   None if unset
            key_type (bool): False if our value is a value in a dict
                             True if it is a key in a dict
                             False if our item is an item in a list
                             None if unset
        """
        self.path_to_item = path_to_item
        self.valid_classes = valid_classes
        self.key_type = key_type
        full_msg = msg
        if path_to_item:
            full_msg = "{0} at {1}".format(msg, render_path(path_to_item))
        super(ApiTypeError, self).__init__(full_msg)


class ApiValueError(OpenApiException, ValueError):
    def __init__(self, msg, path_to_item=None):
        """
        Args:
            msg (str): the exception message

        Keyword Args:
            path_to_item (list) the path to the exception in the
                received_data dict. None if unset
        """

        self.path_to_item = path_to_item
        full_msg = msg
        if path_to_item:
            full_msg = "{0} at {1}".format(msg, render_path(path_to_item))
        super(ApiValueError, self).__init__(full_msg)


class ApiKeyError(OpenApiException, KeyError):
    def __init__(self, msg, path_to_item=None):
        """
        Args:
            msg (str): the exception message

        Keyword Args:
            path_to_item (None/list) the path to the exception in the
                received_data dict
        """
        self.path_to_item = path_to_item
        full_msg = msg
        if path_to_item:
            full_msg = "{0} at {1}".format(msg, render_path(path_to_item))
        super(ApiKeyError, self).__init__(full_msg)


class ApiException(OpenApiException):

    def __init__(self, status=None, reason=None, http_resp=None):
        if http_resp:
            self.status = http_resp.status
            self.reason = http_resp.reason
            self.body = http_resp.data
            self.headers = http_resp.getheaders()
        else:
            self.status = status
            self.reason = reason
            self.body = None
            self.headers = None

    def __str__(self):
        """Custom error messages for exception"""
        error_message = "({0})\n"\
                        "Reason: {1}\n".format(self.status, self.reason)
        if self.headers:
            error_message += "HTTP response headers: {0}\n".format(
                self.headers)

        if self.body:
            error_message += "HTTP response body: {0}\n".format(self.body)

        return error_message


def render_path(path_to_item):
    """Returns a string representation of a path"""
    result = ""
    for pth in path_to_item:
        if isinstance(pth, six.integer_types):
            result += "[{0}]".format(pth)
        else:
            result += "['{0}']".format(pth)
    return result



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/rest.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


from __future__ import absolute_import

import io
import json
import logging
import re
import ssl

import certifi
# python 2 and python 3 compatibility library
import six
from six.moves.urllib.parse import urlencode
import urllib3

from kubeflow.katib.exceptions import ApiException, ApiValueError


logger = logging.getLogger(__name__)


class RESTResponse(io.IOBase):

    def __init__(self, resp):
        self.urllib3_response = resp
        self.status = resp.status
        self.reason = resp.reason
        self.data = resp.data

    def getheaders(self):
        """Returns a dictionary of the response headers."""
        return self.urllib3_response.getheaders()

    def getheader(self, name, default=None):
        """Returns a given response header."""
        return self.urllib3_response.getheader(name, default)


class RESTClientObject(object):

    def __init__(self, configuration, pools_size=4, maxsize=None):
        # urllib3.PoolManager will pass all kw parameters to connectionpool
        # https://github.com/shazow/urllib3/blob/f9409436f83aeb79fbaf090181cd81b784f1b8ce/urllib3/poolmanager.py#L75  # noqa: E501
        # https://github.com/shazow/urllib3/blob/f9409436f83aeb79fbaf090181cd81b784f1b8ce/urllib3/connectionpool.py#L680  # noqa: E501
        # maxsize is the number of requests to host that are allowed in parallel  # noqa: E501
        # Custom SSL certificates and client certificates: http://urllib3.readthedocs.io/en/latest/advanced-usage.html  # noqa: E501

        # cert_reqs
        if configuration.verify_ssl:
            cert_reqs = ssl.CERT_REQUIRED
        else:
            cert_reqs = ssl.CERT_NONE

        # ca_certs
        if configuration.ssl_ca_cert:
            ca_certs = configuration.ssl_ca_cert
        else:
            # if not set certificate file, use Mozilla's root certificates.
            ca_certs = certifi.where()

        addition_pool_args = {}
        if configuration.assert_hostname is not None:
            addition_pool_args['assert_hostname'] = configuration.assert_hostname  # noqa: E501

        if configuration.retries is not None:
            addition_pool_args['retries'] = configuration.retries

        if maxsize is None:
            if configuration.connection_pool_maxsize is not None:
                maxsize = configuration.connection_pool_maxsize
            else:
                maxsize = 4

        # https pool manager
        if configuration.proxy:
            self.pool_manager = urllib3.ProxyManager(
                num_pools=pools_size,
                maxsize=maxsize,
                cert_reqs=cert_reqs,
                ca_certs=ca_certs,
                cert_file=configuration.cert_file,
                key_file=configuration.key_file,
                proxy_url=configuration.proxy,
                proxy_headers=configuration.proxy_headers,
                **addition_pool_args
            )
        else:
            self.pool_manager = urllib3.PoolManager(
                num_pools=pools_size,
                maxsize=maxsize,
                cert_reqs=cert_reqs,
                ca_certs=ca_certs,
                cert_file=configuration.cert_file,
                key_file=configuration.key_file,
                **addition_pool_args
            )

    def request(self, method, url, query_params=None, headers=None,
                body=None, post_params=None, _preload_content=True,
                _request_timeout=None):
        """Perform requests.

        :param method: http request method
        :param url: http request url
        :param query_params: query parameters in the url
        :param headers: http request headers
        :param body: request json body, for `application/json`
        :param post_params: request post parameters,
                            `application/x-www-form-urlencoded`
                            and `multipart/form-data`
        :param _preload_content: if False, the urllib3.HTTPResponse object will
                                 be returned without reading/decoding response
                                 data. Default is True.
        :param _request_timeout: timeout setting for this request. If one
                                 number provided, it will be total request
                                 timeout. It can also be a pair (tuple) of
                                 (connection, read) timeouts.
        """
        method = method.upper()
        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT',
                          'PATCH', 'OPTIONS']

        if post_params and body:
            raise ApiValueError(
                "body parameter cannot be used with post_params parameter."
            )

        post_params = post_params or {}
        headers = headers or {}

        timeout = None
        if _request_timeout:
            if isinstance(_request_timeout, (int, ) if six.PY3 else (int, long)):  # noqa: E501,F821
                timeout = urllib3.Timeout(total=_request_timeout)
            elif (isinstance(_request_timeout, tuple) and
                  len(_request_timeout) == 2):
                timeout = urllib3.Timeout(
                    connect=_request_timeout[0], read=_request_timeout[1])

        if 'Content-Type' not in headers:
            headers['Content-Type'] = 'application/json'

        try:
            # For `POST`, `PUT`, `PATCH`, `OPTIONS`, `DELETE`
            if method in ['POST', 'PUT', 'PATCH', 'OPTIONS', 'DELETE']:
                if query_params:
                    url += '?' + urlencode(query_params)
                if re.search('json', headers['Content-Type'], re.IGNORECASE):
                    request_body = None
                    if body is not None:
                        request_body = json.dumps(body)
                    r = self.pool_manager.request(
                        method, url,
                        body=request_body,
                        preload_content=_preload_content,
                        timeout=timeout,
                        headers=headers)
                elif headers['Content-Type'] == 'application/x-www-form-urlencoded':  # noqa: E501
                    r = self.pool_manager.request(
                        method, url,
                        fields=post_params,
                        encode_multipart=False,
                        preload_content=_preload_content,
                        timeout=timeout,
                        headers=headers)
                elif headers['Content-Type'] == 'multipart/form-data':
                    # must del headers['Content-Type'], or the correct
                    # Content-Type which generated by urllib3 will be
                    # overwritten.
                    del headers['Content-Type']
                    r = self.pool_manager.request(
                        method, url,
                        fields=post_params,
                        encode_multipart=True,
                        preload_content=_preload_content,
                        timeout=timeout,
                        headers=headers)
                # Pass a `string` parameter directly in the body to support
                # other content types than Json when `body` argument is
                # provided in serialized form
                elif isinstance(body, str) or isinstance(body, bytes):
                    request_body = body
                    r = self.pool_manager.request(
                        method, url,
                        body=request_body,
                        preload_content=_preload_content,
                        timeout=timeout,
                        headers=headers)
                else:
                    # Cannot generate the request from given parameters
                    msg = """Cannot prepare a request message for provided
                             arguments. Please check that your arguments match
                             declared content type."""
                    raise ApiException(status=0, reason=msg)
            # For `GET`, `HEAD`
            else:
                r = self.pool_manager.request(method, url,
                                              fields=query_params,
                                              preload_content=_preload_content,
                                              timeout=timeout,
                                              headers=headers)
        except urllib3.exceptions.SSLError as e:
            msg = "{0}\n{1}".format(type(e).__name__, str(e))
            raise ApiException(status=0, reason=msg)

        if _preload_content:
            r = RESTResponse(r)

            # log response body
            logger.debug("response body: %s", r.data)

        if not 200 <= r.status <= 299:
            raise ApiException(http_resp=r)

        return r

    def GET(self, url, headers=None, query_params=None, _preload_content=True,
            _request_timeout=None):
        return self.request("GET", url,
                            headers=headers,
                            _preload_content=_preload_content,
                            _request_timeout=_request_timeout,
                            query_params=query_params)

    def HEAD(self, url, headers=None, query_params=None, _preload_content=True,
             _request_timeout=None):
        return self.request("HEAD", url,
                            headers=headers,
                            _preload_content=_preload_content,
                            _request_timeout=_request_timeout,
                            query_params=query_params)

    def OPTIONS(self, url, headers=None, query_params=None, post_params=None,
                body=None, _preload_content=True, _request_timeout=None):
        return self.request("OPTIONS", url,
                            headers=headers,
                            query_params=query_params,
                            post_params=post_params,
                            _preload_content=_preload_content,
                            _request_timeout=_request_timeout,
                            body=body)

    def DELETE(self, url, headers=None, query_params=None, body=None,
               _preload_content=True, _request_timeout=None):
        return self.request("DELETE", url,
                            headers=headers,
                            query_params=query_params,
                            _preload_content=_preload_content,
                            _request_timeout=_request_timeout,
                            body=body)

    def POST(self, url, headers=None, query_params=None, post_params=None,
             body=None, _preload_content=True, _request_timeout=None):
        return self.request("POST", url,
                            headers=headers,
                            query_params=query_params,
                            post_params=post_params,
                            _preload_content=_preload_content,
                            _request_timeout=_request_timeout,
                            body=body)

    def PUT(self, url, headers=None, query_params=None, post_params=None,
            body=None, _preload_content=True, _request_timeout=None):
        return self.request("PUT", url,
                            headers=headers,
                            query_params=query_params,
                            post_params=post_params,
                            _preload_content=_preload_content,
                            _request_timeout=_request_timeout,
                            body=body)

    def PATCH(self, url, headers=None, query_params=None, post_params=None,
              body=None, _preload_content=True, _request_timeout=None):
        return self.request("PATCH", url,
                            headers=headers,
                            query_params=query_params,
                            post_params=post_params,
                            _preload_content=_preload_content,
                            _request_timeout=_request_timeout,
                            body=body)



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/api/__init__.py
================================================
from __future__ import absolute_import

# flake8: noqa

# import apis into api package



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/api/katib_client_test.py
================================================
import multiprocessing
from typing import List, Optional
from unittest.mock import Mock, patch

import kubeflow.katib as katib
import kubeflow.katib.katib_api_pb2 as katib_api_pb2
import pytest
import transformers
from kubeflow.katib import (
    KatibClient,
    V1beta1AlgorithmSpec,
    V1beta1Experiment,
    V1beta1ExperimentSpec,
    V1beta1FeasibleSpace,
    V1beta1ObjectiveSpec,
    V1beta1ParameterSpec,
    V1beta1TrialParameterSpec,
    V1beta1TrialTemplate,
)
from kubeflow.katib.constants import constants
from kubeflow.katib.types import types
from kubeflow.storage_initializer.hugging_face import (
    HuggingFaceDatasetParams,
    HuggingFaceModelParams,
    HuggingFaceTrainerParams,
)
from kubeflow.training.models import KubeflowOrgV1PyTorchJob
from kubernetes.client import V1Job, V1ObjectMeta

PVC_FAILED = "pvc creation failed"

TEST_RESULT_SUCCESS = "success"


class ConflictException(Exception):
    def __init__(self):
        self.status = 409


def create_namespaced_custom_object_response(*args, **kwargs):
    if args[2] == "timeout":
        raise multiprocessing.TimeoutError()
    elif args[2] == "conflict":
        raise ConflictException()
    elif args[2] == "runtime":
        raise Exception()
    elif args[2] in ("test", "test-name"):
        return {"metadata": {"name": "experiment-mnist-ci-test"}}
    elif args[2] == "test-generate-name":
        return {"metadata": {"name": "12345-experiment-mnist-ci-test"}}


def get_observation_log_response(*args, **kwargs):
    if kwargs.get("timeout") == 0:
        raise TimeoutError
    elif args[0].trial_name == "invalid":
        raise RuntimeError
    else:
        return katib_api_pb2.GetObservationLogReply(
            observation_log=katib_api_pb2.ObservationLog(
                metric_logs=[
                    katib_api_pb2.MetricLog(
                        time_stamp="2024-07-29T15:09:08Z",
                        metric=katib_api_pb2.Metric(name="result", value="0.99"),
                    )
                ]
            )
        )


def create_namespaced_persistent_volume_claim_response(*args, **kwargs):
    if kwargs.get("namespace") == PVC_FAILED:
        raise Exception("PVC creation failed")
    else:
        return {"metadata": {"name": "tune_test"}}


def list_namespaced_persistent_volume_claim_response(*args, **kwargs):
    if kwargs.get("namespace") == PVC_FAILED:
        mock_pvc = Mock()
        mock_pvc.metadata.name = "pvc_failed"
        mock_list = Mock()
        mock_list.items = [mock_pvc]
    else:
        mock_pvc = Mock()
        mock_pvc.metadata.name = "tune_test"
        mock_list = Mock()
        mock_list.items = [mock_pvc]
    return mock_list


def generate_trial_template() -> V1beta1TrialTemplate:
    trial_spec = {
        "apiVersion": "batch/v1",
        "kind": "Job",
        "spec": {
            "template": {
                "metadata": {"labels": {"sidecar.istio.io/inject": "false"}},
                "spec": {
                    "containers": [
                        {
                            "name": "training-container",
                            "image": "ghcr.io/kubeflow/katib/pytorch-mnist-cpu:v0.14.0",
                            "command": [
                                "python3",
                                "/opt/pytorch-mnist/mnist.py",
                                "--epochs=1",
                                "--batch-size=64",
                                "--lr=${trialParameters.learningRate}",
                                "--momentum=${trialParameters.momentum}",
                            ],
                        }
                    ],
                    "restartPolicy": "Never",
                },
            }
        },
    }

    return V1beta1TrialTemplate(
        primary_container_name="training-container",
        trial_parameters=[
            V1beta1TrialParameterSpec(
                name="learningRate",
                description="Learning rate for the training model",
                reference="lr",
            ),
            V1beta1TrialParameterSpec(
                name="momentum",
                description="Momentum for the training model",
                reference="momentum",
            ),
        ],
        trial_spec=trial_spec,
    )


def generate_experiment(
    metadata: V1ObjectMeta,
    algorithm_spec: V1beta1AlgorithmSpec,
    objective_spec: V1beta1ObjectiveSpec,
    parameters: List[V1beta1ParameterSpec],
    trial_template: V1beta1TrialTemplate,
) -> V1beta1Experiment:
    return V1beta1Experiment(
        api_version=constants.API_VERSION,
        kind=constants.EXPERIMENT_KIND,
        metadata=metadata,
        spec=V1beta1ExperimentSpec(
            max_trial_count=3,
            parallel_trial_count=2,
            max_failed_trial_count=1,
            algorithm=algorithm_spec,
            objective=objective_spec,
            parameters=parameters,
            trial_template=trial_template,
        ),
    )


def create_experiment(
    name: Optional[str] = None, generate_name: Optional[str] = None
) -> V1beta1Experiment:
    experiment_namespace = "test"

    if name is not None:
        metadata = V1ObjectMeta(name=name, namespace=experiment_namespace)
    elif generate_name is not None:
        metadata = V1ObjectMeta(
            generate_name=generate_name, namespace=experiment_namespace
        )
    else:
        metadata = V1ObjectMeta(namespace=experiment_namespace)

    algorithm_spec = V1beta1AlgorithmSpec(algorithm_name="random")

    objective_spec = V1beta1ObjectiveSpec(
        type="minimize",
        goal=0.001,
        objective_metric_name="loss",
    )

    parameters = [
        V1beta1ParameterSpec(
            name="lr",
            parameter_type="double",
            feasible_space=V1beta1FeasibleSpace(min="0.01", max="0.06"),
        ),
        V1beta1ParameterSpec(
            name="momentum",
            parameter_type="double",
            feasible_space=V1beta1FeasibleSpace(min="0.5", max="0.9"),
        ),
    ]

    trial_template = generate_trial_template()

    experiment = generate_experiment(
        metadata, algorithm_spec, objective_spec, parameters, trial_template
    )
    return experiment


test_create_experiment_data = [
    (
        "experiment name and generate_name missing",
        {"experiment": create_experiment()},
        ValueError,
    ),
    (
        "create_namespaced_custom_object timeout error",
        {
            "experiment": create_experiment(name="experiment-mnist-ci-test"),
            "namespace": "timeout",
        },
        TimeoutError,
    ),
    (
        "create_namespaced_custom_object conflict error",
        {
            "experiment": create_experiment(name="experiment-mnist-ci-test"),
            "namespace": "conflict",
        },
        Exception,
    ),
    (
        "create_namespaced_custom_object runtime error",
        {
            "experiment": create_experiment(name="experiment-mnist-ci-test"),
            "namespace": "runtime",
        },
        RuntimeError,
    ),
    (
        "valid flow with experiment type V1beta1Experiment and name",
        {
            "experiment": create_experiment(name="experiment-mnist-ci-test"),
            "namespace": "test-name",
        },
        TEST_RESULT_SUCCESS,
    ),
    (
        "valid flow with experiment type V1beta1Experiment and generate_name",
        {
            "experiment": create_experiment(generate_name="experiment-mnist-ci-test"),
            "namespace": "test-generate-name",
        },
        TEST_RESULT_SUCCESS,
    ),
    (
        "valid flow with experiment JSON and name",
        {
            "experiment": {
                "metadata": {
                    "name": "experiment-mnist-ci-test",
                }
            },
            "namespace": "test-name",
        },
        TEST_RESULT_SUCCESS,
    ),
    (
        "valid flow with experiment JSON and generate_name",
        {
            "experiment": {
                "metadata": {
                    "generate_name": "experiment-mnist-ci-test",
                }
            },
            "namespace": "test-generate-name",
        },
        TEST_RESULT_SUCCESS,
    ),
]


test_get_trial_metrics_data = [
    (
        "valid trial name",
        {"name": "example", "namespace": "valid", "timeout": constants.DEFAULT_TIMEOUT},
        [
            katib_api_pb2.MetricLog(
                time_stamp="2024-07-29T15:09:08Z",
                metric=katib_api_pb2.Metric(name="result", value="0.99"),
            )
        ],
    ),
    (
        "invalid trial name",
        {
            "name": "invalid",
            "namespace": "invalid",
            "timeout": constants.DEFAULT_TIMEOUT,
        },
        RuntimeError,
    ),
    (
        "GetObservationLog timeout error",
        {"name": "example", "namespace": "valid", "timeout": 0},
        RuntimeError,
    ),
]


test_tune_data = [
    (
        "missing name",
        {
            "name": None,
            "objective": lambda x: print(f"a={x}"),
            "parameters": {"a": katib.search.int(min=10, max=100)},
        },
        ValueError,
    ),
    (
        "invalid name format",
        {
            "name": "Llama3.1-fine-tune",
        },
        ValueError,
    ),
    (
        "invalid hybrid parameters - objective and model_provider_parameters",
        {
            "name": "tune_test",
            "objective": lambda x: print(f"a={x}"),
            "model_provider_parameters": HuggingFaceModelParams(
                model_uri="hf://google-bert/bert-base-cased",
                transformer_type=transformers.AutoModelForSequenceClassification,
                num_labels=5,
            ),
        },
        ValueError,
    ),
    (
        "missing parameters - no custom objective or external model tuning",
        {
            "name": "tune_test",
        },
        ValueError,
    ),
    (
        "missing parameters in custom objective tuning - lack parameters",
        {
            "name": "tune_test",
            "objective": lambda x: print(f"a={x}"),
        },
        ValueError,
    ),
    (
        "missing parameters in custom objective tuning - lack objective",
        {
            "name": "tune_test",
            "parameters": {"a": katib.search.int(min=10, max=100)},
        },
        ValueError,
    ),
    (
        "missing parameters in external model tuning - lack dataset_provider_parameters "
        "and trainer_parameters",
        {
            "name": "tune_test",
            "model_provider_parameters": HuggingFaceModelParams(
                model_uri="hf://google-bert/bert-base-cased",
                transformer_type=transformers.AutoModelForSequenceClassification,
                num_labels=5,
            ),
        },
        ValueError,
    ),
    (
        "missing parameters in external model tuning - lack model_provider_parameters "
        "and trainer_parameters",
        {
            "name": "tune_test",
            "dataset_provider_parameters": HuggingFaceDatasetParams(
                repo_id="yelp_review_full",
                split="train[:3000]",
            ),
        },
        ValueError,
    ),
    (
        "missing parameters in external model tuning - lack model_provider_parameters "
        "and dataset_provider_parameters",
        {
            "name": "tune_test",
            "trainer_parameters": HuggingFaceTrainerParams(
                training_parameters=transformers.TrainingArguments(
                    output_dir="test_tune_api",
                    learning_rate=katib.search.double(min=1e-05, max=5e-05),
                ),
            ),
        },
        ValueError,
    ),
    (
        "invalid env_per_trial",
        {
            "name": "tune_test",
            "objective": lambda x: print(f"a={x}"),
            "parameters": {"a": katib.search.int(min=10, max=100)},
            "env_per_trial": "invalid",
        },
        ValueError,
    ),
    (
        "invalid model_provider_parameters",
        {
            "name": "tune_test",
            "model_provider_parameters": "invalid",
            "dataset_provider_parameters": HuggingFaceDatasetParams(
                repo_id="yelp_review_full",
                split="train[:3000]",
            ),
            "trainer_parameters": HuggingFaceTrainerParams(
                training_parameters=transformers.TrainingArguments(
                    output_dir="test_tune_api",
                    learning_rate=katib.search.double(min=1e-05, max=5e-05),
                ),
            ),
        },
        ValueError,
    ),
    (
        "invalid dataset_provider_parameters",
        {
            "name": "tune_test",
            "model_provider_parameters": HuggingFaceModelParams(
                model_uri="hf://google-bert/bert-base-cased",
                transformer_type=transformers.AutoModelForSequenceClassification,
                num_labels=5,
            ),
            "dataset_provider_parameters": "invalid",
            "trainer_parameters": HuggingFaceTrainerParams(
                training_parameters=transformers.TrainingArguments(
                    output_dir="test_tune_api",
                    learning_rate=katib.search.double(min=1e-05, max=5e-05),
                ),
            ),
        },
        ValueError,
    ),
    (
        "invalid trainer_parameters",
        {
            "name": "tune_test",
            "model_provider_parameters": HuggingFaceModelParams(
                model_uri="hf://google-bert/bert-base-cased",
                transformer_type=transformers.AutoModelForSequenceClassification,
                num_labels=5,
            ),
            "dataset_provider_parameters": HuggingFaceDatasetParams(
                repo_id="yelp_review_full",
                split="train[:3000]",
            ),
            "trainer_parameters": "invalid",
        },
        ValueError,
    ),
    (
        "pvc creation failed",
        {
            "name": "tune_test",
            "namespace": PVC_FAILED,
            "model_provider_parameters": HuggingFaceModelParams(
                model_uri="hf://google-bert/bert-base-cased",
                transformer_type=transformers.AutoModelForSequenceClassification,
                num_labels=5,
            ),
            "dataset_provider_parameters": HuggingFaceDatasetParams(
                repo_id="yelp_review_full",
                split="train[:3000]",
            ),
            "trainer_parameters": HuggingFaceTrainerParams(
                training_parameters=transformers.TrainingArguments(
                    output_dir="test_tune_api",
                    learning_rate=katib.search.double(min=1e-05, max=5e-05),
                ),
            ),
            "resources_per_trial": types.TrainerResources(
                num_workers=2,
                num_procs_per_worker=2,
                resources_per_worker={"gpu": "2"},
            ),
        },
        RuntimeError,
    ),
    (
        "valid flow with custom objective function and Job as Trial",
        {
            "name": "tune_test",
            "objective": lambda x: print(f"a={x}"),
            "parameters": {"a": katib.search.int(min=10, max=100)},
            "objective_metric_name": "a",
            "resources_per_trial": {"gpu": "2"},
        },
        TEST_RESULT_SUCCESS,
    ),
    (
        "valid flow with custom objective function and PyTorchJob as Trial",
        {
            "name": "tune_test",
            "objective": lambda x: print(f"a={x}"),
            "parameters": {"a": katib.search.int(min=10, max=100)},
            "objective_metric_name": "a",
            "resources_per_trial": types.TrainerResources(
                num_workers=2,
                num_procs_per_worker=2,
                resources_per_worker={"gpu": "2"},
            ),
        },
        TEST_RESULT_SUCCESS,
    ),
    (
        "valid flow with external model tuning",
        {
            "name": "tune_test",
            "model_provider_parameters": HuggingFaceModelParams(
                model_uri="hf://google-bert/bert-base-cased",
                transformer_type=transformers.AutoModelForSequenceClassification,
                num_labels=5,
            ),
            "dataset_provider_parameters": HuggingFaceDatasetParams(
                repo_id="yelp_review_full",
                split="train[:3000]",
            ),
            "trainer_parameters": HuggingFaceTrainerParams(
                training_parameters=transformers.TrainingArguments(
                    output_dir="test_tune_api",
                    learning_rate=katib.search.double(min=1e-05, max=5e-05),
                ),
            ),
            "resources_per_trial": types.TrainerResources(
                num_workers=2,
                num_procs_per_worker=2,
                resources_per_worker={"gpu": "2"},
            ),
            "objective_metric_name": "train_loss",
            "objective_type": "minimize",
        },
        TEST_RESULT_SUCCESS,
    ),
]


@pytest.fixture
def katib_client():
    with patch(
        "kubernetes.client.CustomObjectsApi",
        return_value=Mock(
            create_namespaced_custom_object=Mock(
                side_effect=create_namespaced_custom_object_response
            )
        ),
    ), patch("kubernetes.config.load_kube_config", return_value=Mock()), patch(
        "kubeflow.katib.katib_api_pb2_grpc.DBManagerStub",
        return_value=Mock(
            GetObservationLog=Mock(side_effect=get_observation_log_response)
        ),
    ), patch(
        "kubernetes.client.CoreV1Api",
        return_value=Mock(
            create_namespaced_persistent_volume_claim=Mock(
                side_effect=create_namespaced_persistent_volume_claim_response
            ),
            list_namespaced_persistent_volume_claim=Mock(
                side_effect=list_namespaced_persistent_volume_claim_response
            ),
        ),
    ):
        client = KatibClient()
        yield client


@pytest.mark.parametrize(
    "test_name,kwargs,expected_output", test_create_experiment_data
)
def test_create_experiment(katib_client, test_name, kwargs, expected_output):
    """
    test create_experiment function of katib client
    """
    print("\n\nExecuting test:", test_name)
    try:
        katib_client.create_experiment(**kwargs)
        assert expected_output == TEST_RESULT_SUCCESS
    except Exception as e:
        assert type(e) is expected_output
    print("test execution complete")


@pytest.mark.parametrize(
    "test_name,kwargs,expected_output", test_get_trial_metrics_data
)
def test_get_trial_metrics(katib_client, test_name, kwargs, expected_output):
    """
    test get_trial_metrics function of katib client
    """
    print("\n\nExecuting test:", test_name)
    try:
        metrics = katib_client.get_trial_metrics(**kwargs)
        for i in range(len(metrics)):
            assert metrics[i] == expected_output[i]
    except Exception as e:
        assert type(e) is expected_output
    print("test execution complete")


@pytest.mark.parametrize("test_name,kwargs,expected_output", test_tune_data)
def test_tune(katib_client, test_name, kwargs, expected_output):
    """
    test tune function of katib client
    """
    print("\n\nExecuting test:", test_name)

    with patch.object(
        katib_client, "create_experiment", return_value=Mock()
    ) as mock_create_experiment:
        try:
            katib_client.tune(**kwargs)
            mock_create_experiment.assert_called_once()

            if expected_output == TEST_RESULT_SUCCESS:
                assert expected_output == TEST_RESULT_SUCCESS
                call_args = mock_create_experiment.call_args
                experiment = call_args[0][0]

                if (
                    test_name
                    == "valid flow with custom objective function and Job as Trial"
                ):
                    # Verify input_params
                    args_content = "".join(
                        experiment.spec.trial_template.trial_spec.spec.template.spec.containers[
                            0
                        ].args
                    )
                    assert "'a': '${trialParameters.a}'" in args_content
                    # Verify trial_params
                    assert experiment.spec.trial_template.trial_parameters == [
                        V1beta1TrialParameterSpec(name="a", reference="a"),
                    ]
                    # Verify experiment_params
                    assert experiment.spec.parameters == [
                        V1beta1ParameterSpec(
                            name="a",
                            parameter_type="int",
                            feasible_space=V1beta1FeasibleSpace(min="10", max="100"),
                        ),
                    ]
                    # Verify objective_spec
                    assert experiment.spec.objective == V1beta1ObjectiveSpec(
                        type="maximize",
                        objective_metric_name="a",
                        additional_metric_names=[],
                    )
                    # Verity Trial spec
                    assert isinstance(experiment.spec.trial_template.trial_spec, V1Job)

                elif (
                    test_name
                    == "valid flow with custom objective function and PyTorchJob as Trial"
                ):
                    # Verity Trial spec
                    assert isinstance(
                        experiment.spec.trial_template.trial_spec,
                        KubeflowOrgV1PyTorchJob,
                    )

                elif test_name == "valid flow with external model tuning":
                    # Verify input_params
                    args_content = "".join(
                        experiment.spec.trial_template.trial_spec.spec.pytorch_replica_specs[
                            "Master"
                        ]
                        .template.spec.containers[0]
                        .args
                    )
                    assert (
                        '"learning_rate": "${trialParameters.learning_rate}"'
                        in args_content
                    )
                    # Verify trial_params
                    assert experiment.spec.trial_template.trial_parameters == [
                        V1beta1TrialParameterSpec(
                            name="learning_rate", reference="learning_rate"
                        ),
                    ]
                    # Verify experiment_params
                    assert experiment.spec.parameters == [
                        V1beta1ParameterSpec(
                            name="learning_rate",
                            parameter_type="double",
                            feasible_space=V1beta1FeasibleSpace(
                                min="1e-05", max="5e-05"
                            ),
                        ),
                    ]
                    # Verify objective_spec
                    assert experiment.spec.objective == V1beta1ObjectiveSpec(
                        type="minimize",
                        objective_metric_name="train_loss",
                        additional_metric_names=[],
                    )

        except Exception as e:
            assert type(e) is expected_output
        print("test execution complete")



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/api/report_metrics.py
================================================
# Copyright 2024 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
from datetime import datetime, timezone
from typing import Any, Dict

import grpc
import kubeflow.katib.katib_api_pb2 as katib_api_pb2
import kubeflow.katib.katib_api_pb2_grpc as katib_api_pb2_grpc
from kubeflow.katib.constants import constants
from kubeflow.katib.utils import utils


def report_metrics(
    metrics: Dict[str, Any],
    db_manager_address: str = constants.DEFAULT_DB_MANAGER_ADDRESS,
    timeout: int = constants.DEFAULT_TIMEOUT,
):
    """Push Metrics Directly to Katib DB

    Katib always passes Trial name as env variable `KATIB_TRIAL_NAME` to the training container.

    Args:
        metrics: Dict of metrics pushed to Katib DB.
            For examle, `metrics = {"loss": 0.01, "accuracy": 0.99}`.
        db-manager-address: Address for the Katib DB Manager in this format: `ip-address:port`.
        timeout: Optional, gRPC API Server timeout in seconds to report metrics.

    Raises:
        ValueError: The Trial name is not passed to environment variables or
            metrics value has incorrect format (cannot be converted to type `float`).
        RuntimeError: Unable to push Trial metrics to Katib DB.
    """

    # Get Trial's namespace and name
    namespace = utils.get_current_k8s_namespace()
    name = os.getenv("KATIB_TRIAL_NAME")
    if name is None:
        raise ValueError("The Trial name is not passed to environment variables")

    # Get channel for grpc call to db manager
    channel = grpc.insecure_channel(db_manager_address)

    # Validate metrics value in dict
    for value in metrics.values():
        utils.validate_metrics_value(value)

    # Dial katib db manager to report metrics
    client = katib_api_pb2_grpc.DBManagerStub(channel)
    try:
        timestamp = datetime.now(timezone.utc).strftime(constants.RFC3339_FORMAT)
        client.ReportObservationLog(
            request=katib_api_pb2.ReportObservationLogRequest(
                trial_name=name,
                observation_log=katib_api_pb2.ObservationLog(
                    metric_logs=[
                        katib_api_pb2.MetricLog(
                            time_stamp=timestamp,
                            metric=katib_api_pb2.Metric(name=name, value=str(value)),
                        )
                        for name, value in metrics.items()
                    ]
                ),
            ),
            timeout=timeout,
        )
    except Exception as e:
        raise RuntimeError(
            f"Unable to push metrics to Katib DB for Trial {namespace}/{name}. Exception: {e}"
        )



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/api/report_metrics_test.py
================================================
from unittest.mock import patch

import pytest
from kubeflow.katib import report_metrics
from kubeflow.katib.constants import constants

TEST_RESULT_SUCCESS = "success"
ENV_VARIABLE_EMPTY = True
ENV_VARIABLE_NOT_EMPTY = False


def report_observation_log_response(*args, **kwargs):
    if kwargs.get("timeout") == 0:
        raise TimeoutError


test_report_metrics_data = [
    (
        "valid metrics with float type",
        {"metrics": {"result": 0.99}, "timeout": constants.DEFAULT_TIMEOUT},
        TEST_RESULT_SUCCESS,
        ENV_VARIABLE_NOT_EMPTY,
    ),
    (
        "valid metrics with string type",
        {"metrics": {"result": "0.99"}, "timeout": constants.DEFAULT_TIMEOUT},
        TEST_RESULT_SUCCESS,
        ENV_VARIABLE_NOT_EMPTY,
    ),
    (
        "valid metrics with int type",
        {"metrics": {"result": 1}, "timeout": constants.DEFAULT_TIMEOUT},
        TEST_RESULT_SUCCESS,
        ENV_VARIABLE_NOT_EMPTY,
    ),
    (
        "ReportObservationLog timeout error",
        {"metrics": {"result": 0.99}, "timeout": 0},
        RuntimeError,
        ENV_VARIABLE_NOT_EMPTY,
    ),
    (
        "invalid metrics with type string",
        {"metrics": {"result": "abc"}, "timeout": constants.DEFAULT_TIMEOUT},
        ValueError,
        ENV_VARIABLE_NOT_EMPTY,
    ),
    (
        "Trial name is not passed to env variables",
        {"metrics": {"result": 0.99}, "timeout": constants.DEFAULT_TIMEOUT},
        ValueError,
        ENV_VARIABLE_EMPTY,
    ),
]


@pytest.fixture
def mock_getenv(request):
    with patch("os.getenv") as mock:
        if request.param is ENV_VARIABLE_EMPTY:
            mock.side_effect = ValueError
        else:
            mock.return_value = "example"
        yield mock


@pytest.fixture
def mock_get_current_k8s_namespace():
    with patch("kubeflow.katib.utils.utils.get_current_k8s_namespace") as mock:
        mock.return_value = "test"
        yield mock


@pytest.fixture
def mock_report_observation_log():
    with patch("kubeflow.katib.katib_api_pb2_grpc.DBManagerStub") as mock:
        mock_instance = mock.return_value
        mock_instance.ReportObservationLog.side_effect = report_observation_log_response
        yield mock_instance


@pytest.mark.parametrize(
    "test_name,kwargs,expected_output,mock_getenv",
    test_report_metrics_data,
    indirect=["mock_getenv"],
)
def test_report_metrics(
    test_name,
    kwargs,
    expected_output,
    mock_getenv,
    mock_get_current_k8s_namespace,
    mock_report_observation_log,
):
    """
    test report_metrics function
    """
    print("\n\nExecuting test:", test_name)
    try:
        report_metrics(**kwargs)
        assert expected_output == TEST_RESULT_SUCCESS
    except Exception as e:
        assert type(e) is expected_output
    print("test execution complete")



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/api/search.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from typing import List

from kubeflow.katib import models


def double(min: float, max: float, step: float = None):
    """Sample a float value uniformly between `min` and `max`.

    Args:
        min: Lower boundary for the float value.
        max: Upper boundary for the float value.
        step: Step between float values.
    """

    parameter = models.V1beta1ParameterSpec(
        parameter_type="double",
        feasible_space=models.V1beta1FeasibleSpace(min=str(min), max=str(max)),
    )
    if step is not None:
        parameter.feasible_space.step = str(step)
    return parameter


def int(min: int, max: int, step: int = None):
    """Sample an integer value uniformly between `min` and `max`.

    Args:
        min: Lower boundary for the integer value.
        max: Upper boundary for the integer value.
        step: Step between integer values.
    """

    parameter = models.V1beta1ParameterSpec(
        parameter_type="int",
        feasible_space=models.V1beta1FeasibleSpace(min=str(min), max=str(max)),
    )
    if step is not None:
        parameter.feasible_space.step = str(step)
    return parameter


def categorical(list: List):
    """Sample a categorical value from the `list`.

    Args:
        list: List of categorical values.
    """

    return models.V1beta1ParameterSpec(
        parameter_type="categorical",
        feasible_space=models.V1beta1FeasibleSpace(list),
    )



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/constants/__init__.py
================================================
[Empty file]


================================================
FILE: sdk/python/v1beta1/kubeflow/katib/constants/constants.py
================================================
# Copyright 2021 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os

# How long to wait in seconds for requests to the Kubernetes or gRPC API Server.
DEFAULT_TIMEOUT = 120

# RFC3339 time format
RFC3339_FORMAT = "%Y-%m-%dT%H:%M:%SZ"

# Global CRD version
KATIB_VERSION = os.environ.get("EXPERIMENT_VERSION", "v1beta1")

# Katib K8S constants
KUBEFLOW_GROUP = "kubeflow.org"
API_VERSION = f"{KUBEFLOW_GROUP}/{KATIB_VERSION}"
EXPERIMENT_KIND = "Experiment"
EXPERIMENT_PLURAL = "experiments"
SUGGESTION_PLURAL = "suggestions"
TRIAL_PLURAL = "trials"


DEFAULT_PRIMARY_CONTAINER_NAME = "training-container"

# Label to identify Experiment's resources.
EXPERIMENT_LABEL = "katib.kubeflow.org/experiment"

# True means that Katib CR is in this condition.
CONDITION_STATUS_TRUE = "True"

# Experiment conditions.
# TODO (andreyvelich): Use API enums when Katib SDK supports it.
# Ref: https://github.com/kubeflow/katib/issues/1969.
EXPERIMENT_CONDITION_CREATED = "Created"
EXPERIMENT_CONDITION_RUNNING = "Running"
EXPERIMENT_CONDITION_RESTARTING = "Restarting"
EXPERIMENT_CONDITION_SUCCEEDED = "Succeeded"
EXPERIMENT_CONDITION_FAILED = "Failed"

# Trial conditions.
TRIAL_CONDITION_SUCCEEDED = "Succeeded"

# Supported base images for the Katib Trials.
# TODO (andreyvelich): Implement list_base_images function to get each image description.
BASE_IMAGE_TENSORFLOW = "docker.io/tensorflow/tensorflow:2.13.0"
BASE_IMAGE_TENSORFLOW_GPU = "docker.io/tensorflow/tensorflow:2.13.0-gpu"
BASE_IMAGE_PYTORCH = "docker.io/pytorch/pytorch:2.2.1-cuda12.1-cudnn8-runtime"

DEFAULT_DB_MANAGER_ADDRESS = "katib-db-manager.kubeflow:6789"

# The default value for dataset and model storage PVC.
PVC_DEFAULT_SIZE = "10Gi"
# The default value for PVC access modes.
PVC_DEFAULT_ACCESS_MODES = ["ReadWriteOnce", "ReadOnlyMany"]



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/__init__.py
================================================
# coding: utf-8

# flake8: noqa
"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


from __future__ import absolute_import

# import models into model package
from kubeflow.katib.models.v1beta1_algorithm_setting import V1beta1AlgorithmSetting
from kubeflow.katib.models.v1beta1_algorithm_spec import V1beta1AlgorithmSpec
from kubeflow.katib.models.v1beta1_collector_spec import V1beta1CollectorSpec
from kubeflow.katib.models.v1beta1_config_map_source import V1beta1ConfigMapSource
from kubeflow.katib.models.v1beta1_early_stopping_rule import V1beta1EarlyStoppingRule
from kubeflow.katib.models.v1beta1_early_stopping_setting import V1beta1EarlyStoppingSetting
from kubeflow.katib.models.v1beta1_early_stopping_spec import V1beta1EarlyStoppingSpec
from kubeflow.katib.models.v1beta1_experiment import V1beta1Experiment
from kubeflow.katib.models.v1beta1_experiment_condition import V1beta1ExperimentCondition
from kubeflow.katib.models.v1beta1_experiment_list import V1beta1ExperimentList
from kubeflow.katib.models.v1beta1_experiment_spec import V1beta1ExperimentSpec
from kubeflow.katib.models.v1beta1_experiment_status import V1beta1ExperimentStatus
from kubeflow.katib.models.v1beta1_feasible_space import V1beta1FeasibleSpace
from kubeflow.katib.models.v1beta1_file_system_path import V1beta1FileSystemPath
from kubeflow.katib.models.v1beta1_filter_spec import V1beta1FilterSpec
from kubeflow.katib.models.v1beta1_graph_config import V1beta1GraphConfig
from kubeflow.katib.models.v1beta1_metric import V1beta1Metric
from kubeflow.katib.models.v1beta1_metric_strategy import V1beta1MetricStrategy
from kubeflow.katib.models.v1beta1_metrics_collector_spec import V1beta1MetricsCollectorSpec
from kubeflow.katib.models.v1beta1_nas_config import V1beta1NasConfig
from kubeflow.katib.models.v1beta1_objective_spec import V1beta1ObjectiveSpec
from kubeflow.katib.models.v1beta1_observation import V1beta1Observation
from kubeflow.katib.models.v1beta1_operation import V1beta1Operation
from kubeflow.katib.models.v1beta1_optimal_trial import V1beta1OptimalTrial
from kubeflow.katib.models.v1beta1_parameter_assignment import V1beta1ParameterAssignment
from kubeflow.katib.models.v1beta1_parameter_spec import V1beta1ParameterSpec
from kubeflow.katib.models.v1beta1_source_spec import V1beta1SourceSpec
from kubeflow.katib.models.v1beta1_suggestion import V1beta1Suggestion
from kubeflow.katib.models.v1beta1_suggestion_condition import V1beta1SuggestionCondition
from kubeflow.katib.models.v1beta1_suggestion_list import V1beta1SuggestionList
from kubeflow.katib.models.v1beta1_suggestion_spec import V1beta1SuggestionSpec
from kubeflow.katib.models.v1beta1_suggestion_status import V1beta1SuggestionStatus
from kubeflow.katib.models.v1beta1_trial import V1beta1Trial
from kubeflow.katib.models.v1beta1_trial_assignment import V1beta1TrialAssignment
from kubeflow.katib.models.v1beta1_trial_condition import V1beta1TrialCondition
from kubeflow.katib.models.v1beta1_trial_list import V1beta1TrialList
from kubeflow.katib.models.v1beta1_trial_parameter_spec import V1beta1TrialParameterSpec
from kubeflow.katib.models.v1beta1_trial_source import V1beta1TrialSource
from kubeflow.katib.models.v1beta1_trial_spec import V1beta1TrialSpec
from kubeflow.katib.models.v1beta1_trial_status import V1beta1TrialStatus
from kubeflow.katib.models.v1beta1_trial_template import V1beta1TrialTemplate

# Import Kubernetes models.
from kubernetes.client import *



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_algorithm_setting.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1AlgorithmSetting(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'name': 'str',
        'value': 'str'
    }

    attribute_map = {
        'name': 'name',
        'value': 'value'
    }

    def __init__(self, name=None, value=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1AlgorithmSetting - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._name = None
        self._value = None
        self.discriminator = None

        if name is not None:
            self.name = name
        if value is not None:
            self.value = value

    @property
    def name(self):
        """Gets the name of this V1beta1AlgorithmSetting.  # noqa: E501

        Name is setting name.  # noqa: E501

        :return: The name of this V1beta1AlgorithmSetting.  # noqa: E501
        :rtype: str
        """
        return self._name

    @name.setter
    def name(self, name):
        """Sets the name of this V1beta1AlgorithmSetting.

        Name is setting name.  # noqa: E501

        :param name: The name of this V1beta1AlgorithmSetting.  # noqa: E501
        :type: str
        """

        self._name = name

    @property
    def value(self):
        """Gets the value of this V1beta1AlgorithmSetting.  # noqa: E501

        Value is the setting value.  # noqa: E501

        :return: The value of this V1beta1AlgorithmSetting.  # noqa: E501
        :rtype: str
        """
        return self._value

    @value.setter
    def value(self, value):
        """Sets the value of this V1beta1AlgorithmSetting.

        Value is the setting value.  # noqa: E501

        :param value: The value of this V1beta1AlgorithmSetting.  # noqa: E501
        :type: str
        """

        self._value = value

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1AlgorithmSetting):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1AlgorithmSetting):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_algorithm_spec.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1AlgorithmSpec(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'algorithm_name': 'str',
        'algorithm_settings': 'list[V1beta1AlgorithmSetting]'
    }

    attribute_map = {
        'algorithm_name': 'algorithmName',
        'algorithm_settings': 'algorithmSettings'
    }

    def __init__(self, algorithm_name=None, algorithm_settings=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1AlgorithmSpec - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._algorithm_name = None
        self._algorithm_settings = None
        self.discriminator = None

        if algorithm_name is not None:
            self.algorithm_name = algorithm_name
        if algorithm_settings is not None:
            self.algorithm_settings = algorithm_settings

    @property
    def algorithm_name(self):
        """Gets the algorithm_name of this V1beta1AlgorithmSpec.  # noqa: E501

        HP or NAS algorithm name.  # noqa: E501

        :return: The algorithm_name of this V1beta1AlgorithmSpec.  # noqa: E501
        :rtype: str
        """
        return self._algorithm_name

    @algorithm_name.setter
    def algorithm_name(self, algorithm_name):
        """Sets the algorithm_name of this V1beta1AlgorithmSpec.

        HP or NAS algorithm name.  # noqa: E501

        :param algorithm_name: The algorithm_name of this V1beta1AlgorithmSpec.  # noqa: E501
        :type: str
        """

        self._algorithm_name = algorithm_name

    @property
    def algorithm_settings(self):
        """Gets the algorithm_settings of this V1beta1AlgorithmSpec.  # noqa: E501

        Key-value pairs representing settings for suggestion algorithms.  # noqa: E501

        :return: The algorithm_settings of this V1beta1AlgorithmSpec.  # noqa: E501
        :rtype: list[V1beta1AlgorithmSetting]
        """
        return self._algorithm_settings

    @algorithm_settings.setter
    def algorithm_settings(self, algorithm_settings):
        """Sets the algorithm_settings of this V1beta1AlgorithmSpec.

        Key-value pairs representing settings for suggestion algorithms.  # noqa: E501

        :param algorithm_settings: The algorithm_settings of this V1beta1AlgorithmSpec.  # noqa: E501
        :type: list[V1beta1AlgorithmSetting]
        """

        self._algorithm_settings = algorithm_settings

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1AlgorithmSpec):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1AlgorithmSpec):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_collector_spec.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1CollectorSpec(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'custom_collector': 'V1Container',
        'kind': 'str'
    }

    attribute_map = {
        'custom_collector': 'customCollector',
        'kind': 'kind'
    }

    def __init__(self, custom_collector=None, kind=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1CollectorSpec - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._custom_collector = None
        self._kind = None
        self.discriminator = None

        if custom_collector is not None:
            self.custom_collector = custom_collector
        if kind is not None:
            self.kind = kind

    @property
    def custom_collector(self):
        """Gets the custom_collector of this V1beta1CollectorSpec.  # noqa: E501


        :return: The custom_collector of this V1beta1CollectorSpec.  # noqa: E501
        :rtype: V1Container
        """
        return self._custom_collector

    @custom_collector.setter
    def custom_collector(self, custom_collector):
        """Sets the custom_collector of this V1beta1CollectorSpec.


        :param custom_collector: The custom_collector of this V1beta1CollectorSpec.  # noqa: E501
        :type: V1Container
        """

        self._custom_collector = custom_collector

    @property
    def kind(self):
        """Gets the kind of this V1beta1CollectorSpec.  # noqa: E501


        :return: The kind of this V1beta1CollectorSpec.  # noqa: E501
        :rtype: str
        """
        return self._kind

    @kind.setter
    def kind(self, kind):
        """Sets the kind of this V1beta1CollectorSpec.


        :param kind: The kind of this V1beta1CollectorSpec.  # noqa: E501
        :type: str
        """

        self._kind = kind

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1CollectorSpec):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1CollectorSpec):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_config_map_source.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1ConfigMapSource(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'config_map_name': 'str',
        'config_map_namespace': 'str',
        'template_path': 'str'
    }

    attribute_map = {
        'config_map_name': 'configMapName',
        'config_map_namespace': 'configMapNamespace',
        'template_path': 'templatePath'
    }

    def __init__(self, config_map_name=None, config_map_namespace=None, template_path=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1ConfigMapSource - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._config_map_name = None
        self._config_map_namespace = None
        self._template_path = None
        self.discriminator = None

        if config_map_name is not None:
            self.config_map_name = config_map_name
        if config_map_namespace is not None:
            self.config_map_namespace = config_map_namespace
        if template_path is not None:
            self.template_path = template_path

    @property
    def config_map_name(self):
        """Gets the config_map_name of this V1beta1ConfigMapSource.  # noqa: E501

        Name of config map where trial template is located  # noqa: E501

        :return: The config_map_name of this V1beta1ConfigMapSource.  # noqa: E501
        :rtype: str
        """
        return self._config_map_name

    @config_map_name.setter
    def config_map_name(self, config_map_name):
        """Sets the config_map_name of this V1beta1ConfigMapSource.

        Name of config map where trial template is located  # noqa: E501

        :param config_map_name: The config_map_name of this V1beta1ConfigMapSource.  # noqa: E501
        :type: str
        """

        self._config_map_name = config_map_name

    @property
    def config_map_namespace(self):
        """Gets the config_map_namespace of this V1beta1ConfigMapSource.  # noqa: E501

        Namespace of config map where trial template is located  # noqa: E501

        :return: The config_map_namespace of this V1beta1ConfigMapSource.  # noqa: E501
        :rtype: str
        """
        return self._config_map_namespace

    @config_map_namespace.setter
    def config_map_namespace(self, config_map_namespace):
        """Sets the config_map_namespace of this V1beta1ConfigMapSource.

        Namespace of config map where trial template is located  # noqa: E501

        :param config_map_namespace: The config_map_namespace of this V1beta1ConfigMapSource.  # noqa: E501
        :type: str
        """

        self._config_map_namespace = config_map_namespace

    @property
    def template_path(self):
        """Gets the template_path of this V1beta1ConfigMapSource.  # noqa: E501

        Path in config map where trial template is located  # noqa: E501

        :return: The template_path of this V1beta1ConfigMapSource.  # noqa: E501
        :rtype: str
        """
        return self._template_path

    @template_path.setter
    def template_path(self, template_path):
        """Sets the template_path of this V1beta1ConfigMapSource.

        Path in config map where trial template is located  # noqa: E501

        :param template_path: The template_path of this V1beta1ConfigMapSource.  # noqa: E501
        :type: str
        """

        self._template_path = template_path

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1ConfigMapSource):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1ConfigMapSource):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_early_stopping_rule.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1EarlyStoppingRule(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'comparison': 'str',
        'name': 'str',
        'start_step': 'int',
        'value': 'str'
    }

    attribute_map = {
        'comparison': 'comparison',
        'name': 'name',
        'start_step': 'startStep',
        'value': 'value'
    }

    def __init__(self, comparison=None, name=None, start_step=None, value=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1EarlyStoppingRule - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._comparison = None
        self._name = None
        self._start_step = None
        self._value = None
        self.discriminator = None

        if comparison is not None:
            self.comparison = comparison
        if name is not None:
            self.name = name
        if start_step is not None:
            self.start_step = start_step
        if value is not None:
            self.value = value

    @property
    def comparison(self):
        """Gets the comparison of this V1beta1EarlyStoppingRule.  # noqa: E501

        Comparison defines correlation between name and value.  # noqa: E501

        :return: The comparison of this V1beta1EarlyStoppingRule.  # noqa: E501
        :rtype: str
        """
        return self._comparison

    @comparison.setter
    def comparison(self, comparison):
        """Sets the comparison of this V1beta1EarlyStoppingRule.

        Comparison defines correlation between name and value.  # noqa: E501

        :param comparison: The comparison of this V1beta1EarlyStoppingRule.  # noqa: E501
        :type: str
        """

        self._comparison = comparison

    @property
    def name(self):
        """Gets the name of this V1beta1EarlyStoppingRule.  # noqa: E501

        Name contains metric name for the rule.  # noqa: E501

        :return: The name of this V1beta1EarlyStoppingRule.  # noqa: E501
        :rtype: str
        """
        return self._name

    @name.setter
    def name(self, name):
        """Sets the name of this V1beta1EarlyStoppingRule.

        Name contains metric name for the rule.  # noqa: E501

        :param name: The name of this V1beta1EarlyStoppingRule.  # noqa: E501
        :type: str
        """

        self._name = name

    @property
    def start_step(self):
        """Gets the start_step of this V1beta1EarlyStoppingRule.  # noqa: E501

        StartStep defines quantity of intermediate results that should be received before applying the rule. If start step is empty, rule is applied from the first recorded metric.  # noqa: E501

        :return: The start_step of this V1beta1EarlyStoppingRule.  # noqa: E501
        :rtype: int
        """
        return self._start_step

    @start_step.setter
    def start_step(self, start_step):
        """Sets the start_step of this V1beta1EarlyStoppingRule.

        StartStep defines quantity of intermediate results that should be received before applying the rule. If start step is empty, rule is applied from the first recorded metric.  # noqa: E501

        :param start_step: The start_step of this V1beta1EarlyStoppingRule.  # noqa: E501
        :type: int
        """

        self._start_step = start_step

    @property
    def value(self):
        """Gets the value of this V1beta1EarlyStoppingRule.  # noqa: E501

        Value contains metric value for the rule.  # noqa: E501

        :return: The value of this V1beta1EarlyStoppingRule.  # noqa: E501
        :rtype: str
        """
        return self._value

    @value.setter
    def value(self, value):
        """Sets the value of this V1beta1EarlyStoppingRule.

        Value contains metric value for the rule.  # noqa: E501

        :param value: The value of this V1beta1EarlyStoppingRule.  # noqa: E501
        :type: str
        """

        self._value = value

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1EarlyStoppingRule):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1EarlyStoppingRule):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_early_stopping_setting.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1EarlyStoppingSetting(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'name': 'str',
        'value': 'str'
    }

    attribute_map = {
        'name': 'name',
        'value': 'value'
    }

    def __init__(self, name=None, value=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1EarlyStoppingSetting - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._name = None
        self._value = None
        self.discriminator = None

        if name is not None:
            self.name = name
        if value is not None:
            self.value = value

    @property
    def name(self):
        """Gets the name of this V1beta1EarlyStoppingSetting.  # noqa: E501

        Name is the setting name.  # noqa: E501

        :return: The name of this V1beta1EarlyStoppingSetting.  # noqa: E501
        :rtype: str
        """
        return self._name

    @name.setter
    def name(self, name):
        """Sets the name of this V1beta1EarlyStoppingSetting.

        Name is the setting name.  # noqa: E501

        :param name: The name of this V1beta1EarlyStoppingSetting.  # noqa: E501
        :type: str
        """

        self._name = name

    @property
    def value(self):
        """Gets the value of this V1beta1EarlyStoppingSetting.  # noqa: E501

        Value is the setting value.  # noqa: E501

        :return: The value of this V1beta1EarlyStoppingSetting.  # noqa: E501
        :rtype: str
        """
        return self._value

    @value.setter
    def value(self, value):
        """Sets the value of this V1beta1EarlyStoppingSetting.

        Value is the setting value.  # noqa: E501

        :param value: The value of this V1beta1EarlyStoppingSetting.  # noqa: E501
        :type: str
        """

        self._value = value

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1EarlyStoppingSetting):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1EarlyStoppingSetting):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_early_stopping_spec.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1EarlyStoppingSpec(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'algorithm_name': 'str',
        'algorithm_settings': 'list[V1beta1EarlyStoppingSetting]'
    }

    attribute_map = {
        'algorithm_name': 'algorithmName',
        'algorithm_settings': 'algorithmSettings'
    }

    def __init__(self, algorithm_name=None, algorithm_settings=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1EarlyStoppingSpec - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._algorithm_name = None
        self._algorithm_settings = None
        self.discriminator = None

        if algorithm_name is not None:
            self.algorithm_name = algorithm_name
        if algorithm_settings is not None:
            self.algorithm_settings = algorithm_settings

    @property
    def algorithm_name(self):
        """Gets the algorithm_name of this V1beta1EarlyStoppingSpec.  # noqa: E501

        Early stopping algorithm name.  # noqa: E501

        :return: The algorithm_name of this V1beta1EarlyStoppingSpec.  # noqa: E501
        :rtype: str
        """
        return self._algorithm_name

    @algorithm_name.setter
    def algorithm_name(self, algorithm_name):
        """Sets the algorithm_name of this V1beta1EarlyStoppingSpec.

        Early stopping algorithm name.  # noqa: E501

        :param algorithm_name: The algorithm_name of this V1beta1EarlyStoppingSpec.  # noqa: E501
        :type: str
        """

        self._algorithm_name = algorithm_name

    @property
    def algorithm_settings(self):
        """Gets the algorithm_settings of this V1beta1EarlyStoppingSpec.  # noqa: E501

        Key-value pairs representing settings for early stopping algorithm.  # noqa: E501

        :return: The algorithm_settings of this V1beta1EarlyStoppingSpec.  # noqa: E501
        :rtype: list[V1beta1EarlyStoppingSetting]
        """
        return self._algorithm_settings

    @algorithm_settings.setter
    def algorithm_settings(self, algorithm_settings):
        """Sets the algorithm_settings of this V1beta1EarlyStoppingSpec.

        Key-value pairs representing settings for early stopping algorithm.  # noqa: E501

        :param algorithm_settings: The algorithm_settings of this V1beta1EarlyStoppingSpec.  # noqa: E501
        :type: list[V1beta1EarlyStoppingSetting]
        """

        self._algorithm_settings = algorithm_settings

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1EarlyStoppingSpec):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1EarlyStoppingSpec):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_experiment.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1Experiment(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'api_version': 'str',
        'kind': 'str',
        'metadata': 'V1ObjectMeta',
        'spec': 'V1beta1ExperimentSpec',
        'status': 'V1beta1ExperimentStatus'
    }

    attribute_map = {
        'api_version': 'apiVersion',
        'kind': 'kind',
        'metadata': 'metadata',
        'spec': 'spec',
        'status': 'status'
    }

    def __init__(self, api_version=None, kind=None, metadata=None, spec=None, status=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1Experiment - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._api_version = None
        self._kind = None
        self._metadata = None
        self._spec = None
        self._status = None
        self.discriminator = None

        if api_version is not None:
            self.api_version = api_version
        if kind is not None:
            self.kind = kind
        if metadata is not None:
            self.metadata = metadata
        if spec is not None:
            self.spec = spec
        if status is not None:
            self.status = status

    @property
    def api_version(self):
        """Gets the api_version of this V1beta1Experiment.  # noqa: E501

        APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources  # noqa: E501

        :return: The api_version of this V1beta1Experiment.  # noqa: E501
        :rtype: str
        """
        return self._api_version

    @api_version.setter
    def api_version(self, api_version):
        """Sets the api_version of this V1beta1Experiment.

        APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources  # noqa: E501

        :param api_version: The api_version of this V1beta1Experiment.  # noqa: E501
        :type: str
        """

        self._api_version = api_version

    @property
    def kind(self):
        """Gets the kind of this V1beta1Experiment.  # noqa: E501

        Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds  # noqa: E501

        :return: The kind of this V1beta1Experiment.  # noqa: E501
        :rtype: str
        """
        return self._kind

    @kind.setter
    def kind(self, kind):
        """Sets the kind of this V1beta1Experiment.

        Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds  # noqa: E501

        :param kind: The kind of this V1beta1Experiment.  # noqa: E501
        :type: str
        """

        self._kind = kind

    @property
    def metadata(self):
        """Gets the metadata of this V1beta1Experiment.  # noqa: E501


        :return: The metadata of this V1beta1Experiment.  # noqa: E501
        :rtype: V1ObjectMeta
        """
        return self._metadata

    @metadata.setter
    def metadata(self, metadata):
        """Sets the metadata of this V1beta1Experiment.


        :param metadata: The metadata of this V1beta1Experiment.  # noqa: E501
        :type: V1ObjectMeta
        """

        self._metadata = metadata

    @property
    def spec(self):
        """Gets the spec of this V1beta1Experiment.  # noqa: E501


        :return: The spec of this V1beta1Experiment.  # noqa: E501
        :rtype: V1beta1ExperimentSpec
        """
        return self._spec

    @spec.setter
    def spec(self, spec):
        """Sets the spec of this V1beta1Experiment.


        :param spec: The spec of this V1beta1Experiment.  # noqa: E501
        :type: V1beta1ExperimentSpec
        """

        self._spec = spec

    @property
    def status(self):
        """Gets the status of this V1beta1Experiment.  # noqa: E501


        :return: The status of this V1beta1Experiment.  # noqa: E501
        :rtype: V1beta1ExperimentStatus
        """
        return self._status

    @status.setter
    def status(self, status):
        """Sets the status of this V1beta1Experiment.


        :param status: The status of this V1beta1Experiment.  # noqa: E501
        :type: V1beta1ExperimentStatus
        """

        self._status = status

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1Experiment):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1Experiment):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_experiment_condition.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1ExperimentCondition(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'last_transition_time': 'datetime',
        'last_update_time': 'datetime',
        'message': 'str',
        'reason': 'str',
        'status': 'str',
        'type': 'str'
    }

    attribute_map = {
        'last_transition_time': 'lastTransitionTime',
        'last_update_time': 'lastUpdateTime',
        'message': 'message',
        'reason': 'reason',
        'status': 'status',
        'type': 'type'
    }

    def __init__(self, last_transition_time=None, last_update_time=None, message=None, reason=None, status='', type='', local_vars_configuration=None):  # noqa: E501
        """V1beta1ExperimentCondition - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._last_transition_time = None
        self._last_update_time = None
        self._message = None
        self._reason = None
        self._status = None
        self._type = None
        self.discriminator = None

        if last_transition_time is not None:
            self.last_transition_time = last_transition_time
        if last_update_time is not None:
            self.last_update_time = last_update_time
        if message is not None:
            self.message = message
        if reason is not None:
            self.reason = reason
        self.status = status
        self.type = type

    @property
    def last_transition_time(self):
        """Gets the last_transition_time of this V1beta1ExperimentCondition.  # noqa: E501


        :return: The last_transition_time of this V1beta1ExperimentCondition.  # noqa: E501
        :rtype: datetime
        """
        return self._last_transition_time

    @last_transition_time.setter
    def last_transition_time(self, last_transition_time):
        """Sets the last_transition_time of this V1beta1ExperimentCondition.


        :param last_transition_time: The last_transition_time of this V1beta1ExperimentCondition.  # noqa: E501
        :type: datetime
        """

        self._last_transition_time = last_transition_time

    @property
    def last_update_time(self):
        """Gets the last_update_time of this V1beta1ExperimentCondition.  # noqa: E501


        :return: The last_update_time of this V1beta1ExperimentCondition.  # noqa: E501
        :rtype: datetime
        """
        return self._last_update_time

    @last_update_time.setter
    def last_update_time(self, last_update_time):
        """Sets the last_update_time of this V1beta1ExperimentCondition.


        :param last_update_time: The last_update_time of this V1beta1ExperimentCondition.  # noqa: E501
        :type: datetime
        """

        self._last_update_time = last_update_time

    @property
    def message(self):
        """Gets the message of this V1beta1ExperimentCondition.  # noqa: E501

        A human readable message indicating details about the transition.  # noqa: E501

        :return: The message of this V1beta1ExperimentCondition.  # noqa: E501
        :rtype: str
        """
        return self._message

    @message.setter
    def message(self, message):
        """Sets the message of this V1beta1ExperimentCondition.

        A human readable message indicating details about the transition.  # noqa: E501

        :param message: The message of this V1beta1ExperimentCondition.  # noqa: E501
        :type: str
        """

        self._message = message

    @property
    def reason(self):
        """Gets the reason of this V1beta1ExperimentCondition.  # noqa: E501

        The reason for the condition's last transition.  # noqa: E501

        :return: The reason of this V1beta1ExperimentCondition.  # noqa: E501
        :rtype: str
        """
        return self._reason

    @reason.setter
    def reason(self, reason):
        """Sets the reason of this V1beta1ExperimentCondition.

        The reason for the condition's last transition.  # noqa: E501

        :param reason: The reason of this V1beta1ExperimentCondition.  # noqa: E501
        :type: str
        """

        self._reason = reason

    @property
    def status(self):
        """Gets the status of this V1beta1ExperimentCondition.  # noqa: E501

        Status of the condition, one of True, False, Unknown.  # noqa: E501

        :return: The status of this V1beta1ExperimentCondition.  # noqa: E501
        :rtype: str
        """
        return self._status

    @status.setter
    def status(self, status):
        """Sets the status of this V1beta1ExperimentCondition.

        Status of the condition, one of True, False, Unknown.  # noqa: E501

        :param status: The status of this V1beta1ExperimentCondition.  # noqa: E501
        :type: str
        """
        if self.local_vars_configuration.client_side_validation and status is None:  # noqa: E501
            raise ValueError("Invalid value for `status`, must not be `None`")  # noqa: E501

        self._status = status

    @property
    def type(self):
        """Gets the type of this V1beta1ExperimentCondition.  # noqa: E501

        Type of experiment condition.  # noqa: E501

        :return: The type of this V1beta1ExperimentCondition.  # noqa: E501
        :rtype: str
        """
        return self._type

    @type.setter
    def type(self, type):
        """Sets the type of this V1beta1ExperimentCondition.

        Type of experiment condition.  # noqa: E501

        :param type: The type of this V1beta1ExperimentCondition.  # noqa: E501
        :type: str
        """
        if self.local_vars_configuration.client_side_validation and type is None:  # noqa: E501
            raise ValueError("Invalid value for `type`, must not be `None`")  # noqa: E501

        self._type = type

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1ExperimentCondition):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1ExperimentCondition):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_experiment_list.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1ExperimentList(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'api_version': 'str',
        'items': 'list[V1beta1Experiment]',
        'kind': 'str',
        'metadata': 'V1ListMeta'
    }

    attribute_map = {
        'api_version': 'apiVersion',
        'items': 'items',
        'kind': 'kind',
        'metadata': 'metadata'
    }

    def __init__(self, api_version=None, items=None, kind=None, metadata=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1ExperimentList - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._api_version = None
        self._items = None
        self._kind = None
        self._metadata = None
        self.discriminator = None

        if api_version is not None:
            self.api_version = api_version
        self.items = items
        if kind is not None:
            self.kind = kind
        if metadata is not None:
            self.metadata = metadata

    @property
    def api_version(self):
        """Gets the api_version of this V1beta1ExperimentList.  # noqa: E501

        APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources  # noqa: E501

        :return: The api_version of this V1beta1ExperimentList.  # noqa: E501
        :rtype: str
        """
        return self._api_version

    @api_version.setter
    def api_version(self, api_version):
        """Sets the api_version of this V1beta1ExperimentList.

        APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources  # noqa: E501

        :param api_version: The api_version of this V1beta1ExperimentList.  # noqa: E501
        :type: str
        """

        self._api_version = api_version

    @property
    def items(self):
        """Gets the items of this V1beta1ExperimentList.  # noqa: E501


        :return: The items of this V1beta1ExperimentList.  # noqa: E501
        :rtype: list[V1beta1Experiment]
        """
        return self._items

    @items.setter
    def items(self, items):
        """Sets the items of this V1beta1ExperimentList.


        :param items: The items of this V1beta1ExperimentList.  # noqa: E501
        :type: list[V1beta1Experiment]
        """
        if self.local_vars_configuration.client_side_validation and items is None:  # noqa: E501
            raise ValueError("Invalid value for `items`, must not be `None`")  # noqa: E501

        self._items = items

    @property
    def kind(self):
        """Gets the kind of this V1beta1ExperimentList.  # noqa: E501

        Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds  # noqa: E501

        :return: The kind of this V1beta1ExperimentList.  # noqa: E501
        :rtype: str
        """
        return self._kind

    @kind.setter
    def kind(self, kind):
        """Sets the kind of this V1beta1ExperimentList.

        Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds  # noqa: E501

        :param kind: The kind of this V1beta1ExperimentList.  # noqa: E501
        :type: str
        """

        self._kind = kind

    @property
    def metadata(self):
        """Gets the metadata of this V1beta1ExperimentList.  # noqa: E501


        :return: The metadata of this V1beta1ExperimentList.  # noqa: E501
        :rtype: V1ListMeta
        """
        return self._metadata

    @metadata.setter
    def metadata(self, metadata):
        """Sets the metadata of this V1beta1ExperimentList.


        :param metadata: The metadata of this V1beta1ExperimentList.  # noqa: E501
        :type: V1ListMeta
        """

        self._metadata = metadata

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1ExperimentList):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1ExperimentList):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_experiment_spec.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1ExperimentSpec(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'algorithm': 'V1beta1AlgorithmSpec',
        'early_stopping': 'V1beta1EarlyStoppingSpec',
        'max_failed_trial_count': 'int',
        'max_trial_count': 'int',
        'metrics_collector_spec': 'V1beta1MetricsCollectorSpec',
        'nas_config': 'V1beta1NasConfig',
        'objective': 'V1beta1ObjectiveSpec',
        'parallel_trial_count': 'int',
        'parameters': 'list[V1beta1ParameterSpec]',
        'resume_policy': 'str',
        'trial_template': 'V1beta1TrialTemplate'
    }

    attribute_map = {
        'algorithm': 'algorithm',
        'early_stopping': 'earlyStopping',
        'max_failed_trial_count': 'maxFailedTrialCount',
        'max_trial_count': 'maxTrialCount',
        'metrics_collector_spec': 'metricsCollectorSpec',
        'nas_config': 'nasConfig',
        'objective': 'objective',
        'parallel_trial_count': 'parallelTrialCount',
        'parameters': 'parameters',
        'resume_policy': 'resumePolicy',
        'trial_template': 'trialTemplate'
    }

    def __init__(self, algorithm=None, early_stopping=None, max_failed_trial_count=None, max_trial_count=None, metrics_collector_spec=None, nas_config=None, objective=None, parallel_trial_count=None, parameters=None, resume_policy=None, trial_template=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1ExperimentSpec - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._algorithm = None
        self._early_stopping = None
        self._max_failed_trial_count = None
        self._max_trial_count = None
        self._metrics_collector_spec = None
        self._nas_config = None
        self._objective = None
        self._parallel_trial_count = None
        self._parameters = None
        self._resume_policy = None
        self._trial_template = None
        self.discriminator = None

        if algorithm is not None:
            self.algorithm = algorithm
        if early_stopping is not None:
            self.early_stopping = early_stopping
        if max_failed_trial_count is not None:
            self.max_failed_trial_count = max_failed_trial_count
        if max_trial_count is not None:
            self.max_trial_count = max_trial_count
        if metrics_collector_spec is not None:
            self.metrics_collector_spec = metrics_collector_spec
        if nas_config is not None:
            self.nas_config = nas_config
        if objective is not None:
            self.objective = objective
        if parallel_trial_count is not None:
            self.parallel_trial_count = parallel_trial_count
        if parameters is not None:
            self.parameters = parameters
        if resume_policy is not None:
            self.resume_policy = resume_policy
        if trial_template is not None:
            self.trial_template = trial_template

    @property
    def algorithm(self):
        """Gets the algorithm of this V1beta1ExperimentSpec.  # noqa: E501


        :return: The algorithm of this V1beta1ExperimentSpec.  # noqa: E501
        :rtype: V1beta1AlgorithmSpec
        """
        return self._algorithm

    @algorithm.setter
    def algorithm(self, algorithm):
        """Sets the algorithm of this V1beta1ExperimentSpec.


        :param algorithm: The algorithm of this V1beta1ExperimentSpec.  # noqa: E501
        :type: V1beta1AlgorithmSpec
        """

        self._algorithm = algorithm

    @property
    def early_stopping(self):
        """Gets the early_stopping of this V1beta1ExperimentSpec.  # noqa: E501


        :return: The early_stopping of this V1beta1ExperimentSpec.  # noqa: E501
        :rtype: V1beta1EarlyStoppingSpec
        """
        return self._early_stopping

    @early_stopping.setter
    def early_stopping(self, early_stopping):
        """Sets the early_stopping of this V1beta1ExperimentSpec.


        :param early_stopping: The early_stopping of this V1beta1ExperimentSpec.  # noqa: E501
        :type: V1beta1EarlyStoppingSpec
        """

        self._early_stopping = early_stopping

    @property
    def max_failed_trial_count(self):
        """Gets the max_failed_trial_count of this V1beta1ExperimentSpec.  # noqa: E501

        Max failed trials to mark experiment as failed.  # noqa: E501

        :return: The max_failed_trial_count of this V1beta1ExperimentSpec.  # noqa: E501
        :rtype: int
        """
        return self._max_failed_trial_count

    @max_failed_trial_count.setter
    def max_failed_trial_count(self, max_failed_trial_count):
        """Sets the max_failed_trial_count of this V1beta1ExperimentSpec.

        Max failed trials to mark experiment as failed.  # noqa: E501

        :param max_failed_trial_count: The max_failed_trial_count of this V1beta1ExperimentSpec.  # noqa: E501
        :type: int
        """

        self._max_failed_trial_count = max_failed_trial_count

    @property
    def max_trial_count(self):
        """Gets the max_trial_count of this V1beta1ExperimentSpec.  # noqa: E501

        Max completed trials to mark experiment as succeeded  # noqa: E501

        :return: The max_trial_count of this V1beta1ExperimentSpec.  # noqa: E501
        :rtype: int
        """
        return self._max_trial_count

    @max_trial_count.setter
    def max_trial_count(self, max_trial_count):
        """Sets the max_trial_count of this V1beta1ExperimentSpec.

        Max completed trials to mark experiment as succeeded  # noqa: E501

        :param max_trial_count: The max_trial_count of this V1beta1ExperimentSpec.  # noqa: E501
        :type: int
        """

        self._max_trial_count = max_trial_count

    @property
    def metrics_collector_spec(self):
        """Gets the metrics_collector_spec of this V1beta1ExperimentSpec.  # noqa: E501


        :return: The metrics_collector_spec of this V1beta1ExperimentSpec.  # noqa: E501
        :rtype: V1beta1MetricsCollectorSpec
        """
        return self._metrics_collector_spec

    @metrics_collector_spec.setter
    def metrics_collector_spec(self, metrics_collector_spec):
        """Sets the metrics_collector_spec of this V1beta1ExperimentSpec.


        :param metrics_collector_spec: The metrics_collector_spec of this V1beta1ExperimentSpec.  # noqa: E501
        :type: V1beta1MetricsCollectorSpec
        """

        self._metrics_collector_spec = metrics_collector_spec

    @property
    def nas_config(self):
        """Gets the nas_config of this V1beta1ExperimentSpec.  # noqa: E501


        :return: The nas_config of this V1beta1ExperimentSpec.  # noqa: E501
        :rtype: V1beta1NasConfig
        """
        return self._nas_config

    @nas_config.setter
    def nas_config(self, nas_config):
        """Sets the nas_config of this V1beta1ExperimentSpec.


        :param nas_config: The nas_config of this V1beta1ExperimentSpec.  # noqa: E501
        :type: V1beta1NasConfig
        """

        self._nas_config = nas_config

    @property
    def objective(self):
        """Gets the objective of this V1beta1ExperimentSpec.  # noqa: E501


        :return: The objective of this V1beta1ExperimentSpec.  # noqa: E501
        :rtype: V1beta1ObjectiveSpec
        """
        return self._objective

    @objective.setter
    def objective(self, objective):
        """Sets the objective of this V1beta1ExperimentSpec.


        :param objective: The objective of this V1beta1ExperimentSpec.  # noqa: E501
        :type: V1beta1ObjectiveSpec
        """

        self._objective = objective

    @property
    def parallel_trial_count(self):
        """Gets the parallel_trial_count of this V1beta1ExperimentSpec.  # noqa: E501

        How many trials can be processed in parallel. Defaults to 3  # noqa: E501

        :return: The parallel_trial_count of this V1beta1ExperimentSpec.  # noqa: E501
        :rtype: int
        """
        return self._parallel_trial_count

    @parallel_trial_count.setter
    def parallel_trial_count(self, parallel_trial_count):
        """Sets the parallel_trial_count of this V1beta1ExperimentSpec.

        How many trials can be processed in parallel. Defaults to 3  # noqa: E501

        :param parallel_trial_count: The parallel_trial_count of this V1beta1ExperimentSpec.  # noqa: E501
        :type: int
        """

        self._parallel_trial_count = parallel_trial_count

    @property
    def parameters(self):
        """Gets the parameters of this V1beta1ExperimentSpec.  # noqa: E501

        List of hyperparameter configurations.  # noqa: E501

        :return: The parameters of this V1beta1ExperimentSpec.  # noqa: E501
        :rtype: list[V1beta1ParameterSpec]
        """
        return self._parameters

    @parameters.setter
    def parameters(self, parameters):
        """Sets the parameters of this V1beta1ExperimentSpec.

        List of hyperparameter configurations.  # noqa: E501

        :param parameters: The parameters of this V1beta1ExperimentSpec.  # noqa: E501
        :type: list[V1beta1ParameterSpec]
        """

        self._parameters = parameters

    @property
    def resume_policy(self):
        """Gets the resume_policy of this V1beta1ExperimentSpec.  # noqa: E501

        Describes resuming policy which usually take effect after experiment terminated. Default value is Never.  # noqa: E501

        :return: The resume_policy of this V1beta1ExperimentSpec.  # noqa: E501
        :rtype: str
        """
        return self._resume_policy

    @resume_policy.setter
    def resume_policy(self, resume_policy):
        """Sets the resume_policy of this V1beta1ExperimentSpec.

        Describes resuming policy which usually take effect after experiment terminated. Default value is Never.  # noqa: E501

        :param resume_policy: The resume_policy of this V1beta1ExperimentSpec.  # noqa: E501
        :type: str
        """

        self._resume_policy = resume_policy

    @property
    def trial_template(self):
        """Gets the trial_template of this V1beta1ExperimentSpec.  # noqa: E501


        :return: The trial_template of this V1beta1ExperimentSpec.  # noqa: E501
        :rtype: V1beta1TrialTemplate
        """
        return self._trial_template

    @trial_template.setter
    def trial_template(self, trial_template):
        """Sets the trial_template of this V1beta1ExperimentSpec.


        :param trial_template: The trial_template of this V1beta1ExperimentSpec.  # noqa: E501
        :type: V1beta1TrialTemplate
        """

        self._trial_template = trial_template

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1ExperimentSpec):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1ExperimentSpec):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_experiment_status.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1ExperimentStatus(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'completion_time': 'datetime',
        'conditions': 'list[V1beta1ExperimentCondition]',
        'current_optimal_trial': 'V1beta1OptimalTrial',
        'early_stopped_trial_list': 'list[str]',
        'failed_trial_list': 'list[str]',
        'killed_trial_list': 'list[str]',
        'last_reconcile_time': 'datetime',
        'metrics_unavailable_trial_list': 'list[str]',
        'pending_trial_list': 'list[str]',
        'running_trial_list': 'list[str]',
        'start_time': 'datetime',
        'succeeded_trial_list': 'list[str]',
        'trial_metrics_unavailable': 'int',
        'trials': 'int',
        'trials_early_stopped': 'int',
        'trials_failed': 'int',
        'trials_killed': 'int',
        'trials_pending': 'int',
        'trials_running': 'int',
        'trials_succeeded': 'int'
    }

    attribute_map = {
        'completion_time': 'completionTime',
        'conditions': 'conditions',
        'current_optimal_trial': 'currentOptimalTrial',
        'early_stopped_trial_list': 'earlyStoppedTrialList',
        'failed_trial_list': 'failedTrialList',
        'killed_trial_list': 'killedTrialList',
        'last_reconcile_time': 'lastReconcileTime',
        'metrics_unavailable_trial_list': 'metricsUnavailableTrialList',
        'pending_trial_list': 'pendingTrialList',
        'running_trial_list': 'runningTrialList',
        'start_time': 'startTime',
        'succeeded_trial_list': 'succeededTrialList',
        'trial_metrics_unavailable': 'trialMetricsUnavailable',
        'trials': 'trials',
        'trials_early_stopped': 'trialsEarlyStopped',
        'trials_failed': 'trialsFailed',
        'trials_killed': 'trialsKilled',
        'trials_pending': 'trialsPending',
        'trials_running': 'trialsRunning',
        'trials_succeeded': 'trialsSucceeded'
    }

    def __init__(self, completion_time=None, conditions=None, current_optimal_trial=None, early_stopped_trial_list=None, failed_trial_list=None, killed_trial_list=None, last_reconcile_time=None, metrics_unavailable_trial_list=None, pending_trial_list=None, running_trial_list=None, start_time=None, succeeded_trial_list=None, trial_metrics_unavailable=None, trials=None, trials_early_stopped=None, trials_failed=None, trials_killed=None, trials_pending=None, trials_running=None, trials_succeeded=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1ExperimentStatus - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._completion_time = None
        self._conditions = None
        self._current_optimal_trial = None
        self._early_stopped_trial_list = None
        self._failed_trial_list = None
        self._killed_trial_list = None
        self._last_reconcile_time = None
        self._metrics_unavailable_trial_list = None
        self._pending_trial_list = None
        self._running_trial_list = None
        self._start_time = None
        self._succeeded_trial_list = None
        self._trial_metrics_unavailable = None
        self._trials = None
        self._trials_early_stopped = None
        self._trials_failed = None
        self._trials_killed = None
        self._trials_pending = None
        self._trials_running = None
        self._trials_succeeded = None
        self.discriminator = None

        if completion_time is not None:
            self.completion_time = completion_time
        if conditions is not None:
            self.conditions = conditions
        if current_optimal_trial is not None:
            self.current_optimal_trial = current_optimal_trial
        if early_stopped_trial_list is not None:
            self.early_stopped_trial_list = early_stopped_trial_list
        if failed_trial_list is not None:
            self.failed_trial_list = failed_trial_list
        if killed_trial_list is not None:
            self.killed_trial_list = killed_trial_list
        if last_reconcile_time is not None:
            self.last_reconcile_time = last_reconcile_time
        if metrics_unavailable_trial_list is not None:
            self.metrics_unavailable_trial_list = metrics_unavailable_trial_list
        if pending_trial_list is not None:
            self.pending_trial_list = pending_trial_list
        if running_trial_list is not None:
            self.running_trial_list = running_trial_list
        if start_time is not None:
            self.start_time = start_time
        if succeeded_trial_list is not None:
            self.succeeded_trial_list = succeeded_trial_list
        if trial_metrics_unavailable is not None:
            self.trial_metrics_unavailable = trial_metrics_unavailable
        if trials is not None:
            self.trials = trials
        if trials_early_stopped is not None:
            self.trials_early_stopped = trials_early_stopped
        if trials_failed is not None:
            self.trials_failed = trials_failed
        if trials_killed is not None:
            self.trials_killed = trials_killed
        if trials_pending is not None:
            self.trials_pending = trials_pending
        if trials_running is not None:
            self.trials_running = trials_running
        if trials_succeeded is not None:
            self.trials_succeeded = trials_succeeded

    @property
    def completion_time(self):
        """Gets the completion_time of this V1beta1ExperimentStatus.  # noqa: E501


        :return: The completion_time of this V1beta1ExperimentStatus.  # noqa: E501
        :rtype: datetime
        """
        return self._completion_time

    @completion_time.setter
    def completion_time(self, completion_time):
        """Sets the completion_time of this V1beta1ExperimentStatus.


        :param completion_time: The completion_time of this V1beta1ExperimentStatus.  # noqa: E501
        :type: datetime
        """

        self._completion_time = completion_time

    @property
    def conditions(self):
        """Gets the conditions of this V1beta1ExperimentStatus.  # noqa: E501

        List of observed runtime conditions for this Experiment.  # noqa: E501

        :return: The conditions of this V1beta1ExperimentStatus.  # noqa: E501
        :rtype: list[V1beta1ExperimentCondition]
        """
        return self._conditions

    @conditions.setter
    def conditions(self, conditions):
        """Sets the conditions of this V1beta1ExperimentStatus.

        List of observed runtime conditions for this Experiment.  # noqa: E501

        :param conditions: The conditions of this V1beta1ExperimentStatus.  # noqa: E501
        :type: list[V1beta1ExperimentCondition]
        """

        self._conditions = conditions

    @property
    def current_optimal_trial(self):
        """Gets the current_optimal_trial of this V1beta1ExperimentStatus.  # noqa: E501


        :return: The current_optimal_trial of this V1beta1ExperimentStatus.  # noqa: E501
        :rtype: V1beta1OptimalTrial
        """
        return self._current_optimal_trial

    @current_optimal_trial.setter
    def current_optimal_trial(self, current_optimal_trial):
        """Sets the current_optimal_trial of this V1beta1ExperimentStatus.


        :param current_optimal_trial: The current_optimal_trial of this V1beta1ExperimentStatus.  # noqa: E501
        :type: V1beta1OptimalTrial
        """

        self._current_optimal_trial = current_optimal_trial

    @property
    def early_stopped_trial_list(self):
        """Gets the early_stopped_trial_list of this V1beta1ExperimentStatus.  # noqa: E501

        List of trial names which have been early stopped.  # noqa: E501

        :return: The early_stopped_trial_list of this V1beta1ExperimentStatus.  # noqa: E501
        :rtype: list[str]
        """
        return self._early_stopped_trial_list

    @early_stopped_trial_list.setter
    def early_stopped_trial_list(self, early_stopped_trial_list):
        """Sets the early_stopped_trial_list of this V1beta1ExperimentStatus.

        List of trial names which have been early stopped.  # noqa: E501

        :param early_stopped_trial_list: The early_stopped_trial_list of this V1beta1ExperimentStatus.  # noqa: E501
        :type: list[str]
        """

        self._early_stopped_trial_list = early_stopped_trial_list

    @property
    def failed_trial_list(self):
        """Gets the failed_trial_list of this V1beta1ExperimentStatus.  # noqa: E501

        List of trial names which have already failed.  # noqa: E501

        :return: The failed_trial_list of this V1beta1ExperimentStatus.  # noqa: E501
        :rtype: list[str]
        """
        return self._failed_trial_list

    @failed_trial_list.setter
    def failed_trial_list(self, failed_trial_list):
        """Sets the failed_trial_list of this V1beta1ExperimentStatus.

        List of trial names which have already failed.  # noqa: E501

        :param failed_trial_list: The failed_trial_list of this V1beta1ExperimentStatus.  # noqa: E501
        :type: list[str]
        """

        self._failed_trial_list = failed_trial_list

    @property
    def killed_trial_list(self):
        """Gets the killed_trial_list of this V1beta1ExperimentStatus.  # noqa: E501

        List of trial names which have been killed.  # noqa: E501

        :return: The killed_trial_list of this V1beta1ExperimentStatus.  # noqa: E501
        :rtype: list[str]
        """
        return self._killed_trial_list

    @killed_trial_list.setter
    def killed_trial_list(self, killed_trial_list):
        """Sets the killed_trial_list of this V1beta1ExperimentStatus.

        List of trial names which have been killed.  # noqa: E501

        :param killed_trial_list: The killed_trial_list of this V1beta1ExperimentStatus.  # noqa: E501
        :type: list[str]
        """

        self._killed_trial_list = killed_trial_list

    @property
    def last_reconcile_time(self):
        """Gets the last_reconcile_time of this V1beta1ExperimentStatus.  # noqa: E501


        :return: The last_reconcile_time of this V1beta1ExperimentStatus.  # noqa: E501
        :rtype: datetime
        """
        return self._last_reconcile_time

    @last_reconcile_time.setter
    def last_reconcile_time(self, last_reconcile_time):
        """Sets the last_reconcile_time of this V1beta1ExperimentStatus.


        :param last_reconcile_time: The last_reconcile_time of this V1beta1ExperimentStatus.  # noqa: E501
        :type: datetime
        """

        self._last_reconcile_time = last_reconcile_time

    @property
    def metrics_unavailable_trial_list(self):
        """Gets the metrics_unavailable_trial_list of this V1beta1ExperimentStatus.  # noqa: E501

        List of trial names which have been metrics unavailable  # noqa: E501

        :return: The metrics_unavailable_trial_list of this V1beta1ExperimentStatus.  # noqa: E501
        :rtype: list[str]
        """
        return self._metrics_unavailable_trial_list

    @metrics_unavailable_trial_list.setter
    def metrics_unavailable_trial_list(self, metrics_unavailable_trial_list):
        """Sets the metrics_unavailable_trial_list of this V1beta1ExperimentStatus.

        List of trial names which have been metrics unavailable  # noqa: E501

        :param metrics_unavailable_trial_list: The metrics_unavailable_trial_list of this V1beta1ExperimentStatus.  # noqa: E501
        :type: list[str]
        """

        self._metrics_unavailable_trial_list = metrics_unavailable_trial_list

    @property
    def pending_trial_list(self):
        """Gets the pending_trial_list of this V1beta1ExperimentStatus.  # noqa: E501

        List of trial names which are pending.  # noqa: E501

        :return: The pending_trial_list of this V1beta1ExperimentStatus.  # noqa: E501
        :rtype: list[str]
        """
        return self._pending_trial_list

    @pending_trial_list.setter
    def pending_trial_list(self, pending_trial_list):
        """Sets the pending_trial_list of this V1beta1ExperimentStatus.

        List of trial names which are pending.  # noqa: E501

        :param pending_trial_list: The pending_trial_list of this V1beta1ExperimentStatus.  # noqa: E501
        :type: list[str]
        """

        self._pending_trial_list = pending_trial_list

    @property
    def running_trial_list(self):
        """Gets the running_trial_list of this V1beta1ExperimentStatus.  # noqa: E501

        List of trial names which are running.  # noqa: E501

        :return: The running_trial_list of this V1beta1ExperimentStatus.  # noqa: E501
        :rtype: list[str]
        """
        return self._running_trial_list

    @running_trial_list.setter
    def running_trial_list(self, running_trial_list):
        """Sets the running_trial_list of this V1beta1ExperimentStatus.

        List of trial names which are running.  # noqa: E501

        :param running_trial_list: The running_trial_list of this V1beta1ExperimentStatus.  # noqa: E501
        :type: list[str]
        """

        self._running_trial_list = running_trial_list

    @property
    def start_time(self):
        """Gets the start_time of this V1beta1ExperimentStatus.  # noqa: E501


        :return: The start_time of this V1beta1ExperimentStatus.  # noqa: E501
        :rtype: datetime
        """
        return self._start_time

    @start_time.setter
    def start_time(self, start_time):
        """Sets the start_time of this V1beta1ExperimentStatus.


        :param start_time: The start_time of this V1beta1ExperimentStatus.  # noqa: E501
        :type: datetime
        """

        self._start_time = start_time

    @property
    def succeeded_trial_list(self):
        """Gets the succeeded_trial_list of this V1beta1ExperimentStatus.  # noqa: E501

        List of trial names which have already succeeded.  # noqa: E501

        :return: The succeeded_trial_list of this V1beta1ExperimentStatus.  # noqa: E501
        :rtype: list[str]
        """
        return self._succeeded_trial_list

    @succeeded_trial_list.setter
    def succeeded_trial_list(self, succeeded_trial_list):
        """Sets the succeeded_trial_list of this V1beta1ExperimentStatus.

        List of trial names which have already succeeded.  # noqa: E501

        :param succeeded_trial_list: The succeeded_trial_list of this V1beta1ExperimentStatus.  # noqa: E501
        :type: list[str]
        """

        self._succeeded_trial_list = succeeded_trial_list

    @property
    def trial_metrics_unavailable(self):
        """Gets the trial_metrics_unavailable of this V1beta1ExperimentStatus.  # noqa: E501

        How many trials are currently metrics unavailable.  # noqa: E501

        :return: The trial_metrics_unavailable of this V1beta1ExperimentStatus.  # noqa: E501
        :rtype: int
        """
        return self._trial_metrics_unavailable

    @trial_metrics_unavailable.setter
    def trial_metrics_unavailable(self, trial_metrics_unavailable):
        """Sets the trial_metrics_unavailable of this V1beta1ExperimentStatus.

        How many trials are currently metrics unavailable.  # noqa: E501

        :param trial_metrics_unavailable: The trial_metrics_unavailable of this V1beta1ExperimentStatus.  # noqa: E501
        :type: int
        """

        self._trial_metrics_unavailable = trial_metrics_unavailable

    @property
    def trials(self):
        """Gets the trials of this V1beta1ExperimentStatus.  # noqa: E501

        Trials is the total number of trials owned by the experiment.  # noqa: E501

        :return: The trials of this V1beta1ExperimentStatus.  # noqa: E501
        :rtype: int
        """
        return self._trials

    @trials.setter
    def trials(self, trials):
        """Sets the trials of this V1beta1ExperimentStatus.

        Trials is the total number of trials owned by the experiment.  # noqa: E501

        :param trials: The trials of this V1beta1ExperimentStatus.  # noqa: E501
        :type: int
        """

        self._trials = trials

    @property
    def trials_early_stopped(self):
        """Gets the trials_early_stopped of this V1beta1ExperimentStatus.  # noqa: E501

        How many trials are currently early stopped.  # noqa: E501

        :return: The trials_early_stopped of this V1beta1ExperimentStatus.  # noqa: E501
        :rtype: int
        """
        return self._trials_early_stopped

    @trials_early_stopped.setter
    def trials_early_stopped(self, trials_early_stopped):
        """Sets the trials_early_stopped of this V1beta1ExperimentStatus.

        How many trials are currently early stopped.  # noqa: E501

        :param trials_early_stopped: The trials_early_stopped of this V1beta1ExperimentStatus.  # noqa: E501
        :type: int
        """

        self._trials_early_stopped = trials_early_stopped

    @property
    def trials_failed(self):
        """Gets the trials_failed of this V1beta1ExperimentStatus.  # noqa: E501

        How many trials have failed.  # noqa: E501

        :return: The trials_failed of this V1beta1ExperimentStatus.  # noqa: E501
        :rtype: int
        """
        return self._trials_failed

    @trials_failed.setter
    def trials_failed(self, trials_failed):
        """Sets the trials_failed of this V1beta1ExperimentStatus.

        How many trials have failed.  # noqa: E501

        :param trials_failed: The trials_failed of this V1beta1ExperimentStatus.  # noqa: E501
        :type: int
        """

        self._trials_failed = trials_failed

    @property
    def trials_killed(self):
        """Gets the trials_killed of this V1beta1ExperimentStatus.  # noqa: E501

        How many trials have been killed.  # noqa: E501

        :return: The trials_killed of this V1beta1ExperimentStatus.  # noqa: E501
        :rtype: int
        """
        return self._trials_killed

    @trials_killed.setter
    def trials_killed(self, trials_killed):
        """Sets the trials_killed of this V1beta1ExperimentStatus.

        How many trials have been killed.  # noqa: E501

        :param trials_killed: The trials_killed of this V1beta1ExperimentStatus.  # noqa: E501
        :type: int
        """

        self._trials_killed = trials_killed

    @property
    def trials_pending(self):
        """Gets the trials_pending of this V1beta1ExperimentStatus.  # noqa: E501

        How many trials are currently pending.  # noqa: E501

        :return: The trials_pending of this V1beta1ExperimentStatus.  # noqa: E501
        :rtype: int
        """
        return self._trials_pending

    @trials_pending.setter
    def trials_pending(self, trials_pending):
        """Sets the trials_pending of this V1beta1ExperimentStatus.

        How many trials are currently pending.  # noqa: E501

        :param trials_pending: The trials_pending of this V1beta1ExperimentStatus.  # noqa: E501
        :type: int
        """

        self._trials_pending = trials_pending

    @property
    def trials_running(self):
        """Gets the trials_running of this V1beta1ExperimentStatus.  # noqa: E501

        How many trials are currently running.  # noqa: E501

        :return: The trials_running of this V1beta1ExperimentStatus.  # noqa: E501
        :rtype: int
        """
        return self._trials_running

    @trials_running.setter
    def trials_running(self, trials_running):
        """Sets the trials_running of this V1beta1ExperimentStatus.

        How many trials are currently running.  # noqa: E501

        :param trials_running: The trials_running of this V1beta1ExperimentStatus.  # noqa: E501
        :type: int
        """

        self._trials_running = trials_running

    @property
    def trials_succeeded(self):
        """Gets the trials_succeeded of this V1beta1ExperimentStatus.  # noqa: E501

        How many trials have succeeded.  # noqa: E501

        :return: The trials_succeeded of this V1beta1ExperimentStatus.  # noqa: E501
        :rtype: int
        """
        return self._trials_succeeded

    @trials_succeeded.setter
    def trials_succeeded(self, trials_succeeded):
        """Sets the trials_succeeded of this V1beta1ExperimentStatus.

        How many trials have succeeded.  # noqa: E501

        :param trials_succeeded: The trials_succeeded of this V1beta1ExperimentStatus.  # noqa: E501
        :type: int
        """

        self._trials_succeeded = trials_succeeded

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1ExperimentStatus):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1ExperimentStatus):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_feasible_space.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1FeasibleSpace(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'distribution': 'str',
        'list': 'list[str]',
        'max': 'str',
        'min': 'str',
        'step': 'str'
    }

    attribute_map = {
        'distribution': 'distribution',
        'list': 'list',
        'max': 'max',
        'min': 'min',
        'step': 'step'
    }

    def __init__(self, distribution=None, list=None, max=None, min=None, step=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1FeasibleSpace - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._distribution = None
        self._list = None
        self._max = None
        self._min = None
        self._step = None
        self.discriminator = None

        if distribution is not None:
            self.distribution = distribution
        if list is not None:
            self.list = list
        if max is not None:
            self.max = max
        if min is not None:
            self.min = min
        if step is not None:
            self.step = step

    @property
    def distribution(self):
        """Gets the distribution of this V1beta1FeasibleSpace.  # noqa: E501


        :return: The distribution of this V1beta1FeasibleSpace.  # noqa: E501
        :rtype: str
        """
        return self._distribution

    @distribution.setter
    def distribution(self, distribution):
        """Sets the distribution of this V1beta1FeasibleSpace.


        :param distribution: The distribution of this V1beta1FeasibleSpace.  # noqa: E501
        :type: str
        """

        self._distribution = distribution

    @property
    def list(self):
        """Gets the list of this V1beta1FeasibleSpace.  # noqa: E501


        :return: The list of this V1beta1FeasibleSpace.  # noqa: E501
        :rtype: list[str]
        """
        return self._list

    @list.setter
    def list(self, list):
        """Sets the list of this V1beta1FeasibleSpace.


        :param list: The list of this V1beta1FeasibleSpace.  # noqa: E501
        :type: list[str]
        """

        self._list = list

    @property
    def max(self):
        """Gets the max of this V1beta1FeasibleSpace.  # noqa: E501


        :return: The max of this V1beta1FeasibleSpace.  # noqa: E501
        :rtype: str
        """
        return self._max

    @max.setter
    def max(self, max):
        """Sets the max of this V1beta1FeasibleSpace.


        :param max: The max of this V1beta1FeasibleSpace.  # noqa: E501
        :type: str
        """

        self._max = max

    @property
    def min(self):
        """Gets the min of this V1beta1FeasibleSpace.  # noqa: E501


        :return: The min of this V1beta1FeasibleSpace.  # noqa: E501
        :rtype: str
        """
        return self._min

    @min.setter
    def min(self, min):
        """Sets the min of this V1beta1FeasibleSpace.


        :param min: The min of this V1beta1FeasibleSpace.  # noqa: E501
        :type: str
        """

        self._min = min

    @property
    def step(self):
        """Gets the step of this V1beta1FeasibleSpace.  # noqa: E501


        :return: The step of this V1beta1FeasibleSpace.  # noqa: E501
        :rtype: str
        """
        return self._step

    @step.setter
    def step(self, step):
        """Sets the step of this V1beta1FeasibleSpace.


        :param step: The step of this V1beta1FeasibleSpace.  # noqa: E501
        :type: str
        """

        self._step = step

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1FeasibleSpace):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1FeasibleSpace):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_file_system_path.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1FileSystemPath(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'format': 'str',
        'kind': 'str',
        'path': 'str'
    }

    attribute_map = {
        'format': 'format',
        'kind': 'kind',
        'path': 'path'
    }

    def __init__(self, format=None, kind=None, path=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1FileSystemPath - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._format = None
        self._kind = None
        self._path = None
        self.discriminator = None

        if format is not None:
            self.format = format
        if kind is not None:
            self.kind = kind
        if path is not None:
            self.path = path

    @property
    def format(self):
        """Gets the format of this V1beta1FileSystemPath.  # noqa: E501


        :return: The format of this V1beta1FileSystemPath.  # noqa: E501
        :rtype: str
        """
        return self._format

    @format.setter
    def format(self, format):
        """Sets the format of this V1beta1FileSystemPath.


        :param format: The format of this V1beta1FileSystemPath.  # noqa: E501
        :type: str
        """

        self._format = format

    @property
    def kind(self):
        """Gets the kind of this V1beta1FileSystemPath.  # noqa: E501


        :return: The kind of this V1beta1FileSystemPath.  # noqa: E501
        :rtype: str
        """
        return self._kind

    @kind.setter
    def kind(self, kind):
        """Sets the kind of this V1beta1FileSystemPath.


        :param kind: The kind of this V1beta1FileSystemPath.  # noqa: E501
        :type: str
        """

        self._kind = kind

    @property
    def path(self):
        """Gets the path of this V1beta1FileSystemPath.  # noqa: E501


        :return: The path of this V1beta1FileSystemPath.  # noqa: E501
        :rtype: str
        """
        return self._path

    @path.setter
    def path(self, path):
        """Sets the path of this V1beta1FileSystemPath.


        :param path: The path of this V1beta1FileSystemPath.  # noqa: E501
        :type: str
        """

        self._path = path

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1FileSystemPath):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1FileSystemPath):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_filter_spec.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1FilterSpec(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'metrics_format': 'list[str]'
    }

    attribute_map = {
        'metrics_format': 'metricsFormat'
    }

    def __init__(self, metrics_format=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1FilterSpec - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._metrics_format = None
        self.discriminator = None

        if metrics_format is not None:
            self.metrics_format = metrics_format

    @property
    def metrics_format(self):
        """Gets the metrics_format of this V1beta1FilterSpec.  # noqa: E501

        When the metrics output follows format as this field specified, metricsCollector collects it and reports to metrics server, it can be \"<metric_name>: <float>\" or else  # noqa: E501

        :return: The metrics_format of this V1beta1FilterSpec.  # noqa: E501
        :rtype: list[str]
        """
        return self._metrics_format

    @metrics_format.setter
    def metrics_format(self, metrics_format):
        """Sets the metrics_format of this V1beta1FilterSpec.

        When the metrics output follows format as this field specified, metricsCollector collects it and reports to metrics server, it can be \"<metric_name>: <float>\" or else  # noqa: E501

        :param metrics_format: The metrics_format of this V1beta1FilterSpec.  # noqa: E501
        :type: list[str]
        """

        self._metrics_format = metrics_format

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1FilterSpec):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1FilterSpec):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_graph_config.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1GraphConfig(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'input_sizes': 'list[int]',
        'num_layers': 'int',
        'output_sizes': 'list[int]'
    }

    attribute_map = {
        'input_sizes': 'inputSizes',
        'num_layers': 'numLayers',
        'output_sizes': 'outputSizes'
    }

    def __init__(self, input_sizes=None, num_layers=None, output_sizes=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1GraphConfig - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._input_sizes = None
        self._num_layers = None
        self._output_sizes = None
        self.discriminator = None

        if input_sizes is not None:
            self.input_sizes = input_sizes
        if num_layers is not None:
            self.num_layers = num_layers
        if output_sizes is not None:
            self.output_sizes = output_sizes

    @property
    def input_sizes(self):
        """Gets the input_sizes of this V1beta1GraphConfig.  # noqa: E501


        :return: The input_sizes of this V1beta1GraphConfig.  # noqa: E501
        :rtype: list[int]
        """
        return self._input_sizes

    @input_sizes.setter
    def input_sizes(self, input_sizes):
        """Sets the input_sizes of this V1beta1GraphConfig.


        :param input_sizes: The input_sizes of this V1beta1GraphConfig.  # noqa: E501
        :type: list[int]
        """

        self._input_sizes = input_sizes

    @property
    def num_layers(self):
        """Gets the num_layers of this V1beta1GraphConfig.  # noqa: E501


        :return: The num_layers of this V1beta1GraphConfig.  # noqa: E501
        :rtype: int
        """
        return self._num_layers

    @num_layers.setter
    def num_layers(self, num_layers):
        """Sets the num_layers of this V1beta1GraphConfig.


        :param num_layers: The num_layers of this V1beta1GraphConfig.  # noqa: E501
        :type: int
        """

        self._num_layers = num_layers

    @property
    def output_sizes(self):
        """Gets the output_sizes of this V1beta1GraphConfig.  # noqa: E501


        :return: The output_sizes of this V1beta1GraphConfig.  # noqa: E501
        :rtype: list[int]
        """
        return self._output_sizes

    @output_sizes.setter
    def output_sizes(self, output_sizes):
        """Sets the output_sizes of this V1beta1GraphConfig.


        :param output_sizes: The output_sizes of this V1beta1GraphConfig.  # noqa: E501
        :type: list[int]
        """

        self._output_sizes = output_sizes

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1GraphConfig):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1GraphConfig):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_metric.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1Metric(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'latest': 'str',
        'max': 'str',
        'min': 'str',
        'name': 'str'
    }

    attribute_map = {
        'latest': 'latest',
        'max': 'max',
        'min': 'min',
        'name': 'name'
    }

    def __init__(self, latest=None, max=None, min=None, name=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1Metric - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._latest = None
        self._max = None
        self._min = None
        self._name = None
        self.discriminator = None

        if latest is not None:
            self.latest = latest
        if max is not None:
            self.max = max
        if min is not None:
            self.min = min
        if name is not None:
            self.name = name

    @property
    def latest(self):
        """Gets the latest of this V1beta1Metric.  # noqa: E501


        :return: The latest of this V1beta1Metric.  # noqa: E501
        :rtype: str
        """
        return self._latest

    @latest.setter
    def latest(self, latest):
        """Sets the latest of this V1beta1Metric.


        :param latest: The latest of this V1beta1Metric.  # noqa: E501
        :type: str
        """

        self._latest = latest

    @property
    def max(self):
        """Gets the max of this V1beta1Metric.  # noqa: E501


        :return: The max of this V1beta1Metric.  # noqa: E501
        :rtype: str
        """
        return self._max

    @max.setter
    def max(self, max):
        """Sets the max of this V1beta1Metric.


        :param max: The max of this V1beta1Metric.  # noqa: E501
        :type: str
        """

        self._max = max

    @property
    def min(self):
        """Gets the min of this V1beta1Metric.  # noqa: E501


        :return: The min of this V1beta1Metric.  # noqa: E501
        :rtype: str
        """
        return self._min

    @min.setter
    def min(self, min):
        """Sets the min of this V1beta1Metric.


        :param min: The min of this V1beta1Metric.  # noqa: E501
        :type: str
        """

        self._min = min

    @property
    def name(self):
        """Gets the name of this V1beta1Metric.  # noqa: E501


        :return: The name of this V1beta1Metric.  # noqa: E501
        :rtype: str
        """
        return self._name

    @name.setter
    def name(self, name):
        """Sets the name of this V1beta1Metric.


        :param name: The name of this V1beta1Metric.  # noqa: E501
        :type: str
        """

        self._name = name

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1Metric):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1Metric):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_metric_strategy.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1MetricStrategy(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'name': 'str',
        'value': 'str'
    }

    attribute_map = {
        'name': 'name',
        'value': 'value'
    }

    def __init__(self, name=None, value=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1MetricStrategy - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._name = None
        self._value = None
        self.discriminator = None

        if name is not None:
            self.name = name
        if value is not None:
            self.value = value

    @property
    def name(self):
        """Gets the name of this V1beta1MetricStrategy.  # noqa: E501


        :return: The name of this V1beta1MetricStrategy.  # noqa: E501
        :rtype: str
        """
        return self._name

    @name.setter
    def name(self, name):
        """Sets the name of this V1beta1MetricStrategy.


        :param name: The name of this V1beta1MetricStrategy.  # noqa: E501
        :type: str
        """

        self._name = name

    @property
    def value(self):
        """Gets the value of this V1beta1MetricStrategy.  # noqa: E501


        :return: The value of this V1beta1MetricStrategy.  # noqa: E501
        :rtype: str
        """
        return self._value

    @value.setter
    def value(self, value):
        """Sets the value of this V1beta1MetricStrategy.


        :param value: The value of this V1beta1MetricStrategy.  # noqa: E501
        :type: str
        """

        self._value = value

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1MetricStrategy):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1MetricStrategy):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_metrics_collector_spec.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1MetricsCollectorSpec(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'collector': 'V1beta1CollectorSpec',
        'source': 'V1beta1SourceSpec'
    }

    attribute_map = {
        'collector': 'collector',
        'source': 'source'
    }

    def __init__(self, collector=None, source=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1MetricsCollectorSpec - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._collector = None
        self._source = None
        self.discriminator = None

        if collector is not None:
            self.collector = collector
        if source is not None:
            self.source = source

    @property
    def collector(self):
        """Gets the collector of this V1beta1MetricsCollectorSpec.  # noqa: E501


        :return: The collector of this V1beta1MetricsCollectorSpec.  # noqa: E501
        :rtype: V1beta1CollectorSpec
        """
        return self._collector

    @collector.setter
    def collector(self, collector):
        """Sets the collector of this V1beta1MetricsCollectorSpec.


        :param collector: The collector of this V1beta1MetricsCollectorSpec.  # noqa: E501
        :type: V1beta1CollectorSpec
        """

        self._collector = collector

    @property
    def source(self):
        """Gets the source of this V1beta1MetricsCollectorSpec.  # noqa: E501


        :return: The source of this V1beta1MetricsCollectorSpec.  # noqa: E501
        :rtype: V1beta1SourceSpec
        """
        return self._source

    @source.setter
    def source(self, source):
        """Sets the source of this V1beta1MetricsCollectorSpec.


        :param source: The source of this V1beta1MetricsCollectorSpec.  # noqa: E501
        :type: V1beta1SourceSpec
        """

        self._source = source

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1MetricsCollectorSpec):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1MetricsCollectorSpec):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_nas_config.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1NasConfig(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'graph_config': 'V1beta1GraphConfig',
        'operations': 'list[V1beta1Operation]'
    }

    attribute_map = {
        'graph_config': 'graphConfig',
        'operations': 'operations'
    }

    def __init__(self, graph_config=None, operations=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1NasConfig - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._graph_config = None
        self._operations = None
        self.discriminator = None

        if graph_config is not None:
            self.graph_config = graph_config
        if operations is not None:
            self.operations = operations

    @property
    def graph_config(self):
        """Gets the graph_config of this V1beta1NasConfig.  # noqa: E501


        :return: The graph_config of this V1beta1NasConfig.  # noqa: E501
        :rtype: V1beta1GraphConfig
        """
        return self._graph_config

    @graph_config.setter
    def graph_config(self, graph_config):
        """Sets the graph_config of this V1beta1NasConfig.


        :param graph_config: The graph_config of this V1beta1NasConfig.  # noqa: E501
        :type: V1beta1GraphConfig
        """

        self._graph_config = graph_config

    @property
    def operations(self):
        """Gets the operations of this V1beta1NasConfig.  # noqa: E501


        :return: The operations of this V1beta1NasConfig.  # noqa: E501
        :rtype: list[V1beta1Operation]
        """
        return self._operations

    @operations.setter
    def operations(self, operations):
        """Sets the operations of this V1beta1NasConfig.


        :param operations: The operations of this V1beta1NasConfig.  # noqa: E501
        :type: list[V1beta1Operation]
        """

        self._operations = operations

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1NasConfig):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1NasConfig):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_objective_spec.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1ObjectiveSpec(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'additional_metric_names': 'list[str]',
        'goal': 'float',
        'metric_strategies': 'list[V1beta1MetricStrategy]',
        'objective_metric_name': 'str',
        'type': 'str'
    }

    attribute_map = {
        'additional_metric_names': 'additionalMetricNames',
        'goal': 'goal',
        'metric_strategies': 'metricStrategies',
        'objective_metric_name': 'objectiveMetricName',
        'type': 'type'
    }

    def __init__(self, additional_metric_names=None, goal=None, metric_strategies=None, objective_metric_name=None, type=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1ObjectiveSpec - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._additional_metric_names = None
        self._goal = None
        self._metric_strategies = None
        self._objective_metric_name = None
        self._type = None
        self.discriminator = None

        if additional_metric_names is not None:
            self.additional_metric_names = additional_metric_names
        if goal is not None:
            self.goal = goal
        if metric_strategies is not None:
            self.metric_strategies = metric_strategies
        if objective_metric_name is not None:
            self.objective_metric_name = objective_metric_name
        if type is not None:
            self.type = type

    @property
    def additional_metric_names(self):
        """Gets the additional_metric_names of this V1beta1ObjectiveSpec.  # noqa: E501

        AdditionalMetricNames represents metrics that should be collected from Trials. This can be empty if we only care about the objective metric. Note: If we adopt a push instead of pull mechanism, this can be omitted completely.  # noqa: E501

        :return: The additional_metric_names of this V1beta1ObjectiveSpec.  # noqa: E501
        :rtype: list[str]
        """
        return self._additional_metric_names

    @additional_metric_names.setter
    def additional_metric_names(self, additional_metric_names):
        """Sets the additional_metric_names of this V1beta1ObjectiveSpec.

        AdditionalMetricNames represents metrics that should be collected from Trials. This can be empty if we only care about the objective metric. Note: If we adopt a push instead of pull mechanism, this can be omitted completely.  # noqa: E501

        :param additional_metric_names: The additional_metric_names of this V1beta1ObjectiveSpec.  # noqa: E501
        :type: list[str]
        """

        self._additional_metric_names = additional_metric_names

    @property
    def goal(self):
        """Gets the goal of this V1beta1ObjectiveSpec.  # noqa: E501

        Goal is the Experiment's objective goal that should be reached. In case of empty goal, Experiment is running until MaxTrialCount = TrialsSucceeded.  # noqa: E501

        :return: The goal of this V1beta1ObjectiveSpec.  # noqa: E501
        :rtype: float
        """
        return self._goal

    @goal.setter
    def goal(self, goal):
        """Sets the goal of this V1beta1ObjectiveSpec.

        Goal is the Experiment's objective goal that should be reached. In case of empty goal, Experiment is running until MaxTrialCount = TrialsSucceeded.  # noqa: E501

        :param goal: The goal of this V1beta1ObjectiveSpec.  # noqa: E501
        :type: float
        """

        self._goal = goal

    @property
    def metric_strategies(self):
        """Gets the metric_strategies of this V1beta1ObjectiveSpec.  # noqa: E501

        MetricStrategies defines various rules (min, max or latest) to extract metrics values. This field is allowed to missing, experiment defaulter (webhook) will fill it.  # noqa: E501

        :return: The metric_strategies of this V1beta1ObjectiveSpec.  # noqa: E501
        :rtype: list[V1beta1MetricStrategy]
        """
        return self._metric_strategies

    @metric_strategies.setter
    def metric_strategies(self, metric_strategies):
        """Sets the metric_strategies of this V1beta1ObjectiveSpec.

        MetricStrategies defines various rules (min, max or latest) to extract metrics values. This field is allowed to missing, experiment defaulter (webhook) will fill it.  # noqa: E501

        :param metric_strategies: The metric_strategies of this V1beta1ObjectiveSpec.  # noqa: E501
        :type: list[V1beta1MetricStrategy]
        """

        self._metric_strategies = metric_strategies

    @property
    def objective_metric_name(self):
        """Gets the objective_metric_name of this V1beta1ObjectiveSpec.  # noqa: E501

        ObjectiveMetricName represents primary Experiment's metric to optimize.  # noqa: E501

        :return: The objective_metric_name of this V1beta1ObjectiveSpec.  # noqa: E501
        :rtype: str
        """
        return self._objective_metric_name

    @objective_metric_name.setter
    def objective_metric_name(self, objective_metric_name):
        """Sets the objective_metric_name of this V1beta1ObjectiveSpec.

        ObjectiveMetricName represents primary Experiment's metric to optimize.  # noqa: E501

        :param objective_metric_name: The objective_metric_name of this V1beta1ObjectiveSpec.  # noqa: E501
        :type: str
        """

        self._objective_metric_name = objective_metric_name

    @property
    def type(self):
        """Gets the type of this V1beta1ObjectiveSpec.  # noqa: E501

        Type for Experiment optimization.  # noqa: E501

        :return: The type of this V1beta1ObjectiveSpec.  # noqa: E501
        :rtype: str
        """
        return self._type

    @type.setter
    def type(self, type):
        """Sets the type of this V1beta1ObjectiveSpec.

        Type for Experiment optimization.  # noqa: E501

        :param type: The type of this V1beta1ObjectiveSpec.  # noqa: E501
        :type: str
        """

        self._type = type

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1ObjectiveSpec):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1ObjectiveSpec):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_observation.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1Observation(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'metrics': 'list[V1beta1Metric]'
    }

    attribute_map = {
        'metrics': 'metrics'
    }

    def __init__(self, metrics=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1Observation - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._metrics = None
        self.discriminator = None

        if metrics is not None:
            self.metrics = metrics

    @property
    def metrics(self):
        """Gets the metrics of this V1beta1Observation.  # noqa: E501

        Key-value pairs for metric names and values  # noqa: E501

        :return: The metrics of this V1beta1Observation.  # noqa: E501
        :rtype: list[V1beta1Metric]
        """
        return self._metrics

    @metrics.setter
    def metrics(self, metrics):
        """Sets the metrics of this V1beta1Observation.

        Key-value pairs for metric names and values  # noqa: E501

        :param metrics: The metrics of this V1beta1Observation.  # noqa: E501
        :type: list[V1beta1Metric]
        """

        self._metrics = metrics

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1Observation):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1Observation):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_operation.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1Operation(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'operation_type': 'str',
        'parameters': 'list[V1beta1ParameterSpec]'
    }

    attribute_map = {
        'operation_type': 'operationType',
        'parameters': 'parameters'
    }

    def __init__(self, operation_type=None, parameters=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1Operation - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._operation_type = None
        self._parameters = None
        self.discriminator = None

        if operation_type is not None:
            self.operation_type = operation_type
        if parameters is not None:
            self.parameters = parameters

    @property
    def operation_type(self):
        """Gets the operation_type of this V1beta1Operation.  # noqa: E501


        :return: The operation_type of this V1beta1Operation.  # noqa: E501
        :rtype: str
        """
        return self._operation_type

    @operation_type.setter
    def operation_type(self, operation_type):
        """Sets the operation_type of this V1beta1Operation.


        :param operation_type: The operation_type of this V1beta1Operation.  # noqa: E501
        :type: str
        """

        self._operation_type = operation_type

    @property
    def parameters(self):
        """Gets the parameters of this V1beta1Operation.  # noqa: E501


        :return: The parameters of this V1beta1Operation.  # noqa: E501
        :rtype: list[V1beta1ParameterSpec]
        """
        return self._parameters

    @parameters.setter
    def parameters(self, parameters):
        """Sets the parameters of this V1beta1Operation.


        :param parameters: The parameters of this V1beta1Operation.  # noqa: E501
        :type: list[V1beta1ParameterSpec]
        """

        self._parameters = parameters

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1Operation):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1Operation):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_optimal_trial.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1OptimalTrial(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'best_trial_name': 'str',
        'observation': 'V1beta1Observation',
        'parameter_assignments': 'list[V1beta1ParameterAssignment]'
    }

    attribute_map = {
        'best_trial_name': 'bestTrialName',
        'observation': 'observation',
        'parameter_assignments': 'parameterAssignments'
    }

    def __init__(self, best_trial_name=None, observation=None, parameter_assignments=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1OptimalTrial - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._best_trial_name = None
        self._observation = None
        self._parameter_assignments = None
        self.discriminator = None

        if best_trial_name is not None:
            self.best_trial_name = best_trial_name
        if observation is not None:
            self.observation = observation
        if parameter_assignments is not None:
            self.parameter_assignments = parameter_assignments

    @property
    def best_trial_name(self):
        """Gets the best_trial_name of this V1beta1OptimalTrial.  # noqa: E501

        BestTrialName is the name of the best trial.  # noqa: E501

        :return: The best_trial_name of this V1beta1OptimalTrial.  # noqa: E501
        :rtype: str
        """
        return self._best_trial_name

    @best_trial_name.setter
    def best_trial_name(self, best_trial_name):
        """Sets the best_trial_name of this V1beta1OptimalTrial.

        BestTrialName is the name of the best trial.  # noqa: E501

        :param best_trial_name: The best_trial_name of this V1beta1OptimalTrial.  # noqa: E501
        :type: str
        """

        self._best_trial_name = best_trial_name

    @property
    def observation(self):
        """Gets the observation of this V1beta1OptimalTrial.  # noqa: E501


        :return: The observation of this V1beta1OptimalTrial.  # noqa: E501
        :rtype: V1beta1Observation
        """
        return self._observation

    @observation.setter
    def observation(self, observation):
        """Sets the observation of this V1beta1OptimalTrial.


        :param observation: The observation of this V1beta1OptimalTrial.  # noqa: E501
        :type: V1beta1Observation
        """

        self._observation = observation

    @property
    def parameter_assignments(self):
        """Gets the parameter_assignments of this V1beta1OptimalTrial.  # noqa: E501

        Key-value pairs for hyperparameters and assignment values.  # noqa: E501

        :return: The parameter_assignments of this V1beta1OptimalTrial.  # noqa: E501
        :rtype: list[V1beta1ParameterAssignment]
        """
        return self._parameter_assignments

    @parameter_assignments.setter
    def parameter_assignments(self, parameter_assignments):
        """Sets the parameter_assignments of this V1beta1OptimalTrial.

        Key-value pairs for hyperparameters and assignment values.  # noqa: E501

        :param parameter_assignments: The parameter_assignments of this V1beta1OptimalTrial.  # noqa: E501
        :type: list[V1beta1ParameterAssignment]
        """

        self._parameter_assignments = parameter_assignments

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1OptimalTrial):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1OptimalTrial):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_parameter_assignment.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1ParameterAssignment(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'name': 'str',
        'value': 'str'
    }

    attribute_map = {
        'name': 'name',
        'value': 'value'
    }

    def __init__(self, name=None, value=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1ParameterAssignment - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._name = None
        self._value = None
        self.discriminator = None

        if name is not None:
            self.name = name
        if value is not None:
            self.value = value

    @property
    def name(self):
        """Gets the name of this V1beta1ParameterAssignment.  # noqa: E501


        :return: The name of this V1beta1ParameterAssignment.  # noqa: E501
        :rtype: str
        """
        return self._name

    @name.setter
    def name(self, name):
        """Sets the name of this V1beta1ParameterAssignment.


        :param name: The name of this V1beta1ParameterAssignment.  # noqa: E501
        :type: str
        """

        self._name = name

    @property
    def value(self):
        """Gets the value of this V1beta1ParameterAssignment.  # noqa: E501


        :return: The value of this V1beta1ParameterAssignment.  # noqa: E501
        :rtype: str
        """
        return self._value

    @value.setter
    def value(self, value):
        """Sets the value of this V1beta1ParameterAssignment.


        :param value: The value of this V1beta1ParameterAssignment.  # noqa: E501
        :type: str
        """

        self._value = value

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1ParameterAssignment):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1ParameterAssignment):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_parameter_spec.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1ParameterSpec(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'feasible_space': 'V1beta1FeasibleSpace',
        'name': 'str',
        'parameter_type': 'str'
    }

    attribute_map = {
        'feasible_space': 'feasibleSpace',
        'name': 'name',
        'parameter_type': 'parameterType'
    }

    def __init__(self, feasible_space=None, name=None, parameter_type=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1ParameterSpec - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._feasible_space = None
        self._name = None
        self._parameter_type = None
        self.discriminator = None

        if feasible_space is not None:
            self.feasible_space = feasible_space
        if name is not None:
            self.name = name
        if parameter_type is not None:
            self.parameter_type = parameter_type

    @property
    def feasible_space(self):
        """Gets the feasible_space of this V1beta1ParameterSpec.  # noqa: E501


        :return: The feasible_space of this V1beta1ParameterSpec.  # noqa: E501
        :rtype: V1beta1FeasibleSpace
        """
        return self._feasible_space

    @feasible_space.setter
    def feasible_space(self, feasible_space):
        """Sets the feasible_space of this V1beta1ParameterSpec.


        :param feasible_space: The feasible_space of this V1beta1ParameterSpec.  # noqa: E501
        :type: V1beta1FeasibleSpace
        """

        self._feasible_space = feasible_space

    @property
    def name(self):
        """Gets the name of this V1beta1ParameterSpec.  # noqa: E501


        :return: The name of this V1beta1ParameterSpec.  # noqa: E501
        :rtype: str
        """
        return self._name

    @name.setter
    def name(self, name):
        """Sets the name of this V1beta1ParameterSpec.


        :param name: The name of this V1beta1ParameterSpec.  # noqa: E501
        :type: str
        """

        self._name = name

    @property
    def parameter_type(self):
        """Gets the parameter_type of this V1beta1ParameterSpec.  # noqa: E501


        :return: The parameter_type of this V1beta1ParameterSpec.  # noqa: E501
        :rtype: str
        """
        return self._parameter_type

    @parameter_type.setter
    def parameter_type(self, parameter_type):
        """Sets the parameter_type of this V1beta1ParameterSpec.


        :param parameter_type: The parameter_type of this V1beta1ParameterSpec.  # noqa: E501
        :type: str
        """

        self._parameter_type = parameter_type

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1ParameterSpec):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1ParameterSpec):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_source_spec.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1SourceSpec(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'file_system_path': 'V1beta1FileSystemPath',
        'filter': 'V1beta1FilterSpec',
        'http_get': 'V1HTTPGetAction'
    }

    attribute_map = {
        'file_system_path': 'fileSystemPath',
        'filter': 'filter',
        'http_get': 'httpGet'
    }

    def __init__(self, file_system_path=None, filter=None, http_get=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1SourceSpec - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._file_system_path = None
        self._filter = None
        self._http_get = None
        self.discriminator = None

        if file_system_path is not None:
            self.file_system_path = file_system_path
        if filter is not None:
            self.filter = filter
        if http_get is not None:
            self.http_get = http_get

    @property
    def file_system_path(self):
        """Gets the file_system_path of this V1beta1SourceSpec.  # noqa: E501


        :return: The file_system_path of this V1beta1SourceSpec.  # noqa: E501
        :rtype: V1beta1FileSystemPath
        """
        return self._file_system_path

    @file_system_path.setter
    def file_system_path(self, file_system_path):
        """Sets the file_system_path of this V1beta1SourceSpec.


        :param file_system_path: The file_system_path of this V1beta1SourceSpec.  # noqa: E501
        :type: V1beta1FileSystemPath
        """

        self._file_system_path = file_system_path

    @property
    def filter(self):
        """Gets the filter of this V1beta1SourceSpec.  # noqa: E501


        :return: The filter of this V1beta1SourceSpec.  # noqa: E501
        :rtype: V1beta1FilterSpec
        """
        return self._filter

    @filter.setter
    def filter(self, filter):
        """Sets the filter of this V1beta1SourceSpec.


        :param filter: The filter of this V1beta1SourceSpec.  # noqa: E501
        :type: V1beta1FilterSpec
        """

        self._filter = filter

    @property
    def http_get(self):
        """Gets the http_get of this V1beta1SourceSpec.  # noqa: E501


        :return: The http_get of this V1beta1SourceSpec.  # noqa: E501
        :rtype: V1HTTPGetAction
        """
        return self._http_get

    @http_get.setter
    def http_get(self, http_get):
        """Sets the http_get of this V1beta1SourceSpec.


        :param http_get: The http_get of this V1beta1SourceSpec.  # noqa: E501
        :type: V1HTTPGetAction
        """

        self._http_get = http_get

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1SourceSpec):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1SourceSpec):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_suggestion.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1Suggestion(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'api_version': 'str',
        'kind': 'str',
        'metadata': 'V1ObjectMeta',
        'spec': 'V1beta1SuggestionSpec',
        'status': 'V1beta1SuggestionStatus'
    }

    attribute_map = {
        'api_version': 'apiVersion',
        'kind': 'kind',
        'metadata': 'metadata',
        'spec': 'spec',
        'status': 'status'
    }

    def __init__(self, api_version=None, kind=None, metadata=None, spec=None, status=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1Suggestion - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._api_version = None
        self._kind = None
        self._metadata = None
        self._spec = None
        self._status = None
        self.discriminator = None

        if api_version is not None:
            self.api_version = api_version
        if kind is not None:
            self.kind = kind
        if metadata is not None:
            self.metadata = metadata
        if spec is not None:
            self.spec = spec
        if status is not None:
            self.status = status

    @property
    def api_version(self):
        """Gets the api_version of this V1beta1Suggestion.  # noqa: E501

        APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources  # noqa: E501

        :return: The api_version of this V1beta1Suggestion.  # noqa: E501
        :rtype: str
        """
        return self._api_version

    @api_version.setter
    def api_version(self, api_version):
        """Sets the api_version of this V1beta1Suggestion.

        APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources  # noqa: E501

        :param api_version: The api_version of this V1beta1Suggestion.  # noqa: E501
        :type: str
        """

        self._api_version = api_version

    @property
    def kind(self):
        """Gets the kind of this V1beta1Suggestion.  # noqa: E501

        Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds  # noqa: E501

        :return: The kind of this V1beta1Suggestion.  # noqa: E501
        :rtype: str
        """
        return self._kind

    @kind.setter
    def kind(self, kind):
        """Sets the kind of this V1beta1Suggestion.

        Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds  # noqa: E501

        :param kind: The kind of this V1beta1Suggestion.  # noqa: E501
        :type: str
        """

        self._kind = kind

    @property
    def metadata(self):
        """Gets the metadata of this V1beta1Suggestion.  # noqa: E501


        :return: The metadata of this V1beta1Suggestion.  # noqa: E501
        :rtype: V1ObjectMeta
        """
        return self._metadata

    @metadata.setter
    def metadata(self, metadata):
        """Sets the metadata of this V1beta1Suggestion.


        :param metadata: The metadata of this V1beta1Suggestion.  # noqa: E501
        :type: V1ObjectMeta
        """

        self._metadata = metadata

    @property
    def spec(self):
        """Gets the spec of this V1beta1Suggestion.  # noqa: E501


        :return: The spec of this V1beta1Suggestion.  # noqa: E501
        :rtype: V1beta1SuggestionSpec
        """
        return self._spec

    @spec.setter
    def spec(self, spec):
        """Sets the spec of this V1beta1Suggestion.


        :param spec: The spec of this V1beta1Suggestion.  # noqa: E501
        :type: V1beta1SuggestionSpec
        """

        self._spec = spec

    @property
    def status(self):
        """Gets the status of this V1beta1Suggestion.  # noqa: E501


        :return: The status of this V1beta1Suggestion.  # noqa: E501
        :rtype: V1beta1SuggestionStatus
        """
        return self._status

    @status.setter
    def status(self, status):
        """Sets the status of this V1beta1Suggestion.


        :param status: The status of this V1beta1Suggestion.  # noqa: E501
        :type: V1beta1SuggestionStatus
        """

        self._status = status

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1Suggestion):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1Suggestion):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_suggestion_condition.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1SuggestionCondition(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'last_transition_time': 'datetime',
        'last_update_time': 'datetime',
        'message': 'str',
        'reason': 'str',
        'status': 'str',
        'type': 'str'
    }

    attribute_map = {
        'last_transition_time': 'lastTransitionTime',
        'last_update_time': 'lastUpdateTime',
        'message': 'message',
        'reason': 'reason',
        'status': 'status',
        'type': 'type'
    }

    def __init__(self, last_transition_time=None, last_update_time=None, message=None, reason=None, status='', type='', local_vars_configuration=None):  # noqa: E501
        """V1beta1SuggestionCondition - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._last_transition_time = None
        self._last_update_time = None
        self._message = None
        self._reason = None
        self._status = None
        self._type = None
        self.discriminator = None

        if last_transition_time is not None:
            self.last_transition_time = last_transition_time
        if last_update_time is not None:
            self.last_update_time = last_update_time
        if message is not None:
            self.message = message
        if reason is not None:
            self.reason = reason
        self.status = status
        self.type = type

    @property
    def last_transition_time(self):
        """Gets the last_transition_time of this V1beta1SuggestionCondition.  # noqa: E501


        :return: The last_transition_time of this V1beta1SuggestionCondition.  # noqa: E501
        :rtype: datetime
        """
        return self._last_transition_time

    @last_transition_time.setter
    def last_transition_time(self, last_transition_time):
        """Sets the last_transition_time of this V1beta1SuggestionCondition.


        :param last_transition_time: The last_transition_time of this V1beta1SuggestionCondition.  # noqa: E501
        :type: datetime
        """

        self._last_transition_time = last_transition_time

    @property
    def last_update_time(self):
        """Gets the last_update_time of this V1beta1SuggestionCondition.  # noqa: E501


        :return: The last_update_time of this V1beta1SuggestionCondition.  # noqa: E501
        :rtype: datetime
        """
        return self._last_update_time

    @last_update_time.setter
    def last_update_time(self, last_update_time):
        """Sets the last_update_time of this V1beta1SuggestionCondition.


        :param last_update_time: The last_update_time of this V1beta1SuggestionCondition.  # noqa: E501
        :type: datetime
        """

        self._last_update_time = last_update_time

    @property
    def message(self):
        """Gets the message of this V1beta1SuggestionCondition.  # noqa: E501

        A human readable message indicating details about the transition.  # noqa: E501

        :return: The message of this V1beta1SuggestionCondition.  # noqa: E501
        :rtype: str
        """
        return self._message

    @message.setter
    def message(self, message):
        """Sets the message of this V1beta1SuggestionCondition.

        A human readable message indicating details about the transition.  # noqa: E501

        :param message: The message of this V1beta1SuggestionCondition.  # noqa: E501
        :type: str
        """

        self._message = message

    @property
    def reason(self):
        """Gets the reason of this V1beta1SuggestionCondition.  # noqa: E501

        The reason for the condition's last transition.  # noqa: E501

        :return: The reason of this V1beta1SuggestionCondition.  # noqa: E501
        :rtype: str
        """
        return self._reason

    @reason.setter
    def reason(self, reason):
        """Sets the reason of this V1beta1SuggestionCondition.

        The reason for the condition's last transition.  # noqa: E501

        :param reason: The reason of this V1beta1SuggestionCondition.  # noqa: E501
        :type: str
        """

        self._reason = reason

    @property
    def status(self):
        """Gets the status of this V1beta1SuggestionCondition.  # noqa: E501

        Status of the condition, one of True, False, Unknown.  # noqa: E501

        :return: The status of this V1beta1SuggestionCondition.  # noqa: E501
        :rtype: str
        """
        return self._status

    @status.setter
    def status(self, status):
        """Sets the status of this V1beta1SuggestionCondition.

        Status of the condition, one of True, False, Unknown.  # noqa: E501

        :param status: The status of this V1beta1SuggestionCondition.  # noqa: E501
        :type: str
        """
        if self.local_vars_configuration.client_side_validation and status is None:  # noqa: E501
            raise ValueError("Invalid value for `status`, must not be `None`")  # noqa: E501

        self._status = status

    @property
    def type(self):
        """Gets the type of this V1beta1SuggestionCondition.  # noqa: E501

        Type of Suggestion condition.  # noqa: E501

        :return: The type of this V1beta1SuggestionCondition.  # noqa: E501
        :rtype: str
        """
        return self._type

    @type.setter
    def type(self, type):
        """Sets the type of this V1beta1SuggestionCondition.

        Type of Suggestion condition.  # noqa: E501

        :param type: The type of this V1beta1SuggestionCondition.  # noqa: E501
        :type: str
        """
        if self.local_vars_configuration.client_side_validation and type is None:  # noqa: E501
            raise ValueError("Invalid value for `type`, must not be `None`")  # noqa: E501

        self._type = type

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1SuggestionCondition):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1SuggestionCondition):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_suggestion_list.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1SuggestionList(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'api_version': 'str',
        'items': 'list[V1beta1Suggestion]',
        'kind': 'str',
        'metadata': 'V1ListMeta'
    }

    attribute_map = {
        'api_version': 'apiVersion',
        'items': 'items',
        'kind': 'kind',
        'metadata': 'metadata'
    }

    def __init__(self, api_version=None, items=None, kind=None, metadata=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1SuggestionList - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._api_version = None
        self._items = None
        self._kind = None
        self._metadata = None
        self.discriminator = None

        if api_version is not None:
            self.api_version = api_version
        self.items = items
        if kind is not None:
            self.kind = kind
        if metadata is not None:
            self.metadata = metadata

    @property
    def api_version(self):
        """Gets the api_version of this V1beta1SuggestionList.  # noqa: E501

        APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources  # noqa: E501

        :return: The api_version of this V1beta1SuggestionList.  # noqa: E501
        :rtype: str
        """
        return self._api_version

    @api_version.setter
    def api_version(self, api_version):
        """Sets the api_version of this V1beta1SuggestionList.

        APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources  # noqa: E501

        :param api_version: The api_version of this V1beta1SuggestionList.  # noqa: E501
        :type: str
        """

        self._api_version = api_version

    @property
    def items(self):
        """Gets the items of this V1beta1SuggestionList.  # noqa: E501


        :return: The items of this V1beta1SuggestionList.  # noqa: E501
        :rtype: list[V1beta1Suggestion]
        """
        return self._items

    @items.setter
    def items(self, items):
        """Sets the items of this V1beta1SuggestionList.


        :param items: The items of this V1beta1SuggestionList.  # noqa: E501
        :type: list[V1beta1Suggestion]
        """
        if self.local_vars_configuration.client_side_validation and items is None:  # noqa: E501
            raise ValueError("Invalid value for `items`, must not be `None`")  # noqa: E501

        self._items = items

    @property
    def kind(self):
        """Gets the kind of this V1beta1SuggestionList.  # noqa: E501

        Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds  # noqa: E501

        :return: The kind of this V1beta1SuggestionList.  # noqa: E501
        :rtype: str
        """
        return self._kind

    @kind.setter
    def kind(self, kind):
        """Sets the kind of this V1beta1SuggestionList.

        Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds  # noqa: E501

        :param kind: The kind of this V1beta1SuggestionList.  # noqa: E501
        :type: str
        """

        self._kind = kind

    @property
    def metadata(self):
        """Gets the metadata of this V1beta1SuggestionList.  # noqa: E501


        :return: The metadata of this V1beta1SuggestionList.  # noqa: E501
        :rtype: V1ListMeta
        """
        return self._metadata

    @metadata.setter
    def metadata(self, metadata):
        """Sets the metadata of this V1beta1SuggestionList.


        :param metadata: The metadata of this V1beta1SuggestionList.  # noqa: E501
        :type: V1ListMeta
        """

        self._metadata = metadata

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1SuggestionList):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1SuggestionList):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_suggestion_spec.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1SuggestionSpec(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'algorithm': 'V1beta1AlgorithmSpec',
        'early_stopping': 'V1beta1EarlyStoppingSpec',
        'requests': 'int',
        'resume_policy': 'str'
    }

    attribute_map = {
        'algorithm': 'algorithm',
        'early_stopping': 'earlyStopping',
        'requests': 'requests',
        'resume_policy': 'resumePolicy'
    }

    def __init__(self, algorithm=None, early_stopping=None, requests=None, resume_policy=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1SuggestionSpec - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._algorithm = None
        self._early_stopping = None
        self._requests = None
        self._resume_policy = None
        self.discriminator = None

        if algorithm is not None:
            self.algorithm = algorithm
        if early_stopping is not None:
            self.early_stopping = early_stopping
        if requests is not None:
            self.requests = requests
        if resume_policy is not None:
            self.resume_policy = resume_policy

    @property
    def algorithm(self):
        """Gets the algorithm of this V1beta1SuggestionSpec.  # noqa: E501


        :return: The algorithm of this V1beta1SuggestionSpec.  # noqa: E501
        :rtype: V1beta1AlgorithmSpec
        """
        return self._algorithm

    @algorithm.setter
    def algorithm(self, algorithm):
        """Sets the algorithm of this V1beta1SuggestionSpec.


        :param algorithm: The algorithm of this V1beta1SuggestionSpec.  # noqa: E501
        :type: V1beta1AlgorithmSpec
        """

        self._algorithm = algorithm

    @property
    def early_stopping(self):
        """Gets the early_stopping of this V1beta1SuggestionSpec.  # noqa: E501


        :return: The early_stopping of this V1beta1SuggestionSpec.  # noqa: E501
        :rtype: V1beta1EarlyStoppingSpec
        """
        return self._early_stopping

    @early_stopping.setter
    def early_stopping(self, early_stopping):
        """Sets the early_stopping of this V1beta1SuggestionSpec.


        :param early_stopping: The early_stopping of this V1beta1SuggestionSpec.  # noqa: E501
        :type: V1beta1EarlyStoppingSpec
        """

        self._early_stopping = early_stopping

    @property
    def requests(self):
        """Gets the requests of this V1beta1SuggestionSpec.  # noqa: E501

        Number of suggestions requested.  # noqa: E501

        :return: The requests of this V1beta1SuggestionSpec.  # noqa: E501
        :rtype: int
        """
        return self._requests

    @requests.setter
    def requests(self, requests):
        """Sets the requests of this V1beta1SuggestionSpec.

        Number of suggestions requested.  # noqa: E501

        :param requests: The requests of this V1beta1SuggestionSpec.  # noqa: E501
        :type: int
        """

        self._requests = requests

    @property
    def resume_policy(self):
        """Gets the resume_policy of this V1beta1SuggestionSpec.  # noqa: E501

        ResumePolicy describes resuming policy which usually take effect after experiment terminated. Default value is Never.  # noqa: E501

        :return: The resume_policy of this V1beta1SuggestionSpec.  # noqa: E501
        :rtype: str
        """
        return self._resume_policy

    @resume_policy.setter
    def resume_policy(self, resume_policy):
        """Sets the resume_policy of this V1beta1SuggestionSpec.

        ResumePolicy describes resuming policy which usually take effect after experiment terminated. Default value is Never.  # noqa: E501

        :param resume_policy: The resume_policy of this V1beta1SuggestionSpec.  # noqa: E501
        :type: str
        """

        self._resume_policy = resume_policy

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1SuggestionSpec):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1SuggestionSpec):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_suggestion_status.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1SuggestionStatus(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'algorithm_settings': 'list[V1beta1AlgorithmSetting]',
        'completion_time': 'datetime',
        'conditions': 'list[V1beta1SuggestionCondition]',
        'last_reconcile_time': 'datetime',
        'start_time': 'datetime',
        'suggestion_count': 'int',
        'suggestions': 'list[V1beta1TrialAssignment]'
    }

    attribute_map = {
        'algorithm_settings': 'algorithmSettings',
        'completion_time': 'completionTime',
        'conditions': 'conditions',
        'last_reconcile_time': 'lastReconcileTime',
        'start_time': 'startTime',
        'suggestion_count': 'suggestionCount',
        'suggestions': 'suggestions'
    }

    def __init__(self, algorithm_settings=None, completion_time=None, conditions=None, last_reconcile_time=None, start_time=None, suggestion_count=None, suggestions=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1SuggestionStatus - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._algorithm_settings = None
        self._completion_time = None
        self._conditions = None
        self._last_reconcile_time = None
        self._start_time = None
        self._suggestion_count = None
        self._suggestions = None
        self.discriminator = None

        if algorithm_settings is not None:
            self.algorithm_settings = algorithm_settings
        if completion_time is not None:
            self.completion_time = completion_time
        if conditions is not None:
            self.conditions = conditions
        if last_reconcile_time is not None:
            self.last_reconcile_time = last_reconcile_time
        if start_time is not None:
            self.start_time = start_time
        if suggestion_count is not None:
            self.suggestion_count = suggestion_count
        if suggestions is not None:
            self.suggestions = suggestions

    @property
    def algorithm_settings(self):
        """Gets the algorithm_settings of this V1beta1SuggestionStatus.  # noqa: E501

        AlgorithmSettings defines HP or NAS algorithm settings which suggestion gRPC service returns. These settings overwrites Experiment's settings before the gRPC request. It can be empty if settings haven't been changed.  # noqa: E501

        :return: The algorithm_settings of this V1beta1SuggestionStatus.  # noqa: E501
        :rtype: list[V1beta1AlgorithmSetting]
        """
        return self._algorithm_settings

    @algorithm_settings.setter
    def algorithm_settings(self, algorithm_settings):
        """Sets the algorithm_settings of this V1beta1SuggestionStatus.

        AlgorithmSettings defines HP or NAS algorithm settings which suggestion gRPC service returns. These settings overwrites Experiment's settings before the gRPC request. It can be empty if settings haven't been changed.  # noqa: E501

        :param algorithm_settings: The algorithm_settings of this V1beta1SuggestionStatus.  # noqa: E501
        :type: list[V1beta1AlgorithmSetting]
        """

        self._algorithm_settings = algorithm_settings

    @property
    def completion_time(self):
        """Gets the completion_time of this V1beta1SuggestionStatus.  # noqa: E501


        :return: The completion_time of this V1beta1SuggestionStatus.  # noqa: E501
        :rtype: datetime
        """
        return self._completion_time

    @completion_time.setter
    def completion_time(self, completion_time):
        """Sets the completion_time of this V1beta1SuggestionStatus.


        :param completion_time: The completion_time of this V1beta1SuggestionStatus.  # noqa: E501
        :type: datetime
        """

        self._completion_time = completion_time

    @property
    def conditions(self):
        """Gets the conditions of this V1beta1SuggestionStatus.  # noqa: E501

        List of observed runtime conditions for this Suggestion.  # noqa: E501

        :return: The conditions of this V1beta1SuggestionStatus.  # noqa: E501
        :rtype: list[V1beta1SuggestionCondition]
        """
        return self._conditions

    @conditions.setter
    def conditions(self, conditions):
        """Sets the conditions of this V1beta1SuggestionStatus.

        List of observed runtime conditions for this Suggestion.  # noqa: E501

        :param conditions: The conditions of this V1beta1SuggestionStatus.  # noqa: E501
        :type: list[V1beta1SuggestionCondition]
        """

        self._conditions = conditions

    @property
    def last_reconcile_time(self):
        """Gets the last_reconcile_time of this V1beta1SuggestionStatus.  # noqa: E501


        :return: The last_reconcile_time of this V1beta1SuggestionStatus.  # noqa: E501
        :rtype: datetime
        """
        return self._last_reconcile_time

    @last_reconcile_time.setter
    def last_reconcile_time(self, last_reconcile_time):
        """Sets the last_reconcile_time of this V1beta1SuggestionStatus.


        :param last_reconcile_time: The last_reconcile_time of this V1beta1SuggestionStatus.  # noqa: E501
        :type: datetime
        """

        self._last_reconcile_time = last_reconcile_time

    @property
    def start_time(self):
        """Gets the start_time of this V1beta1SuggestionStatus.  # noqa: E501


        :return: The start_time of this V1beta1SuggestionStatus.  # noqa: E501
        :rtype: datetime
        """
        return self._start_time

    @start_time.setter
    def start_time(self, start_time):
        """Sets the start_time of this V1beta1SuggestionStatus.


        :param start_time: The start_time of this V1beta1SuggestionStatus.  # noqa: E501
        :type: datetime
        """

        self._start_time = start_time

    @property
    def suggestion_count(self):
        """Gets the suggestion_count of this V1beta1SuggestionStatus.  # noqa: E501

        Number of suggestion results  # noqa: E501

        :return: The suggestion_count of this V1beta1SuggestionStatus.  # noqa: E501
        :rtype: int
        """
        return self._suggestion_count

    @suggestion_count.setter
    def suggestion_count(self, suggestion_count):
        """Sets the suggestion_count of this V1beta1SuggestionStatus.

        Number of suggestion results  # noqa: E501

        :param suggestion_count: The suggestion_count of this V1beta1SuggestionStatus.  # noqa: E501
        :type: int
        """

        self._suggestion_count = suggestion_count

    @property
    def suggestions(self):
        """Gets the suggestions of this V1beta1SuggestionStatus.  # noqa: E501

        Suggestion results  # noqa: E501

        :return: The suggestions of this V1beta1SuggestionStatus.  # noqa: E501
        :rtype: list[V1beta1TrialAssignment]
        """
        return self._suggestions

    @suggestions.setter
    def suggestions(self, suggestions):
        """Sets the suggestions of this V1beta1SuggestionStatus.

        Suggestion results  # noqa: E501

        :param suggestions: The suggestions of this V1beta1SuggestionStatus.  # noqa: E501
        :type: list[V1beta1TrialAssignment]
        """

        self._suggestions = suggestions

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1SuggestionStatus):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1SuggestionStatus):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_trial.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1Trial(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'api_version': 'str',
        'kind': 'str',
        'metadata': 'V1ObjectMeta',
        'spec': 'V1beta1TrialSpec',
        'status': 'V1beta1TrialStatus'
    }

    attribute_map = {
        'api_version': 'apiVersion',
        'kind': 'kind',
        'metadata': 'metadata',
        'spec': 'spec',
        'status': 'status'
    }

    def __init__(self, api_version=None, kind=None, metadata=None, spec=None, status=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1Trial - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._api_version = None
        self._kind = None
        self._metadata = None
        self._spec = None
        self._status = None
        self.discriminator = None

        if api_version is not None:
            self.api_version = api_version
        if kind is not None:
            self.kind = kind
        if metadata is not None:
            self.metadata = metadata
        if spec is not None:
            self.spec = spec
        if status is not None:
            self.status = status

    @property
    def api_version(self):
        """Gets the api_version of this V1beta1Trial.  # noqa: E501

        APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources  # noqa: E501

        :return: The api_version of this V1beta1Trial.  # noqa: E501
        :rtype: str
        """
        return self._api_version

    @api_version.setter
    def api_version(self, api_version):
        """Sets the api_version of this V1beta1Trial.

        APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources  # noqa: E501

        :param api_version: The api_version of this V1beta1Trial.  # noqa: E501
        :type: str
        """

        self._api_version = api_version

    @property
    def kind(self):
        """Gets the kind of this V1beta1Trial.  # noqa: E501

        Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds  # noqa: E501

        :return: The kind of this V1beta1Trial.  # noqa: E501
        :rtype: str
        """
        return self._kind

    @kind.setter
    def kind(self, kind):
        """Sets the kind of this V1beta1Trial.

        Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds  # noqa: E501

        :param kind: The kind of this V1beta1Trial.  # noqa: E501
        :type: str
        """

        self._kind = kind

    @property
    def metadata(self):
        """Gets the metadata of this V1beta1Trial.  # noqa: E501


        :return: The metadata of this V1beta1Trial.  # noqa: E501
        :rtype: V1ObjectMeta
        """
        return self._metadata

    @metadata.setter
    def metadata(self, metadata):
        """Sets the metadata of this V1beta1Trial.


        :param metadata: The metadata of this V1beta1Trial.  # noqa: E501
        :type: V1ObjectMeta
        """

        self._metadata = metadata

    @property
    def spec(self):
        """Gets the spec of this V1beta1Trial.  # noqa: E501


        :return: The spec of this V1beta1Trial.  # noqa: E501
        :rtype: V1beta1TrialSpec
        """
        return self._spec

    @spec.setter
    def spec(self, spec):
        """Sets the spec of this V1beta1Trial.


        :param spec: The spec of this V1beta1Trial.  # noqa: E501
        :type: V1beta1TrialSpec
        """

        self._spec = spec

    @property
    def status(self):
        """Gets the status of this V1beta1Trial.  # noqa: E501


        :return: The status of this V1beta1Trial.  # noqa: E501
        :rtype: V1beta1TrialStatus
        """
        return self._status

    @status.setter
    def status(self, status):
        """Sets the status of this V1beta1Trial.


        :param status: The status of this V1beta1Trial.  # noqa: E501
        :type: V1beta1TrialStatus
        """

        self._status = status

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1Trial):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1Trial):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_trial_assignment.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1TrialAssignment(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'early_stopping_rules': 'list[V1beta1EarlyStoppingRule]',
        'labels': 'dict(str, str)',
        'name': 'str',
        'parameter_assignments': 'list[V1beta1ParameterAssignment]'
    }

    attribute_map = {
        'early_stopping_rules': 'earlyStoppingRules',
        'labels': 'labels',
        'name': 'name',
        'parameter_assignments': 'parameterAssignments'
    }

    def __init__(self, early_stopping_rules=None, labels=None, name=None, parameter_assignments=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1TrialAssignment - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._early_stopping_rules = None
        self._labels = None
        self._name = None
        self._parameter_assignments = None
        self.discriminator = None

        if early_stopping_rules is not None:
            self.early_stopping_rules = early_stopping_rules
        if labels is not None:
            self.labels = labels
        if name is not None:
            self.name = name
        if parameter_assignments is not None:
            self.parameter_assignments = parameter_assignments

    @property
    def early_stopping_rules(self):
        """Gets the early_stopping_rules of this V1beta1TrialAssignment.  # noqa: E501

        Rules for early stopping techniques Contains rule name, value and comparison type  # noqa: E501

        :return: The early_stopping_rules of this V1beta1TrialAssignment.  # noqa: E501
        :rtype: list[V1beta1EarlyStoppingRule]
        """
        return self._early_stopping_rules

    @early_stopping_rules.setter
    def early_stopping_rules(self, early_stopping_rules):
        """Sets the early_stopping_rules of this V1beta1TrialAssignment.

        Rules for early stopping techniques Contains rule name, value and comparison type  # noqa: E501

        :param early_stopping_rules: The early_stopping_rules of this V1beta1TrialAssignment.  # noqa: E501
        :type: list[V1beta1EarlyStoppingRule]
        """

        self._early_stopping_rules = early_stopping_rules

    @property
    def labels(self):
        """Gets the labels of this V1beta1TrialAssignment.  # noqa: E501

        Suggestion label metadata to attach to Trial job  # noqa: E501

        :return: The labels of this V1beta1TrialAssignment.  # noqa: E501
        :rtype: dict(str, str)
        """
        return self._labels

    @labels.setter
    def labels(self, labels):
        """Sets the labels of this V1beta1TrialAssignment.

        Suggestion label metadata to attach to Trial job  # noqa: E501

        :param labels: The labels of this V1beta1TrialAssignment.  # noqa: E501
        :type: dict(str, str)
        """

        self._labels = labels

    @property
    def name(self):
        """Gets the name of this V1beta1TrialAssignment.  # noqa: E501

        Name of the suggestion  # noqa: E501

        :return: The name of this V1beta1TrialAssignment.  # noqa: E501
        :rtype: str
        """
        return self._name

    @name.setter
    def name(self, name):
        """Sets the name of this V1beta1TrialAssignment.

        Name of the suggestion  # noqa: E501

        :param name: The name of this V1beta1TrialAssignment.  # noqa: E501
        :type: str
        """

        self._name = name

    @property
    def parameter_assignments(self):
        """Gets the parameter_assignments of this V1beta1TrialAssignment.  # noqa: E501

        Suggestion results with Trial parameters  # noqa: E501

        :return: The parameter_assignments of this V1beta1TrialAssignment.  # noqa: E501
        :rtype: list[V1beta1ParameterAssignment]
        """
        return self._parameter_assignments

    @parameter_assignments.setter
    def parameter_assignments(self, parameter_assignments):
        """Sets the parameter_assignments of this V1beta1TrialAssignment.

        Suggestion results with Trial parameters  # noqa: E501

        :param parameter_assignments: The parameter_assignments of this V1beta1TrialAssignment.  # noqa: E501
        :type: list[V1beta1ParameterAssignment]
        """

        self._parameter_assignments = parameter_assignments

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1TrialAssignment):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1TrialAssignment):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_trial_condition.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1TrialCondition(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'last_transition_time': 'datetime',
        'last_update_time': 'datetime',
        'message': 'str',
        'reason': 'str',
        'status': 'str',
        'type': 'str'
    }

    attribute_map = {
        'last_transition_time': 'lastTransitionTime',
        'last_update_time': 'lastUpdateTime',
        'message': 'message',
        'reason': 'reason',
        'status': 'status',
        'type': 'type'
    }

    def __init__(self, last_transition_time=None, last_update_time=None, message=None, reason=None, status='', type='', local_vars_configuration=None):  # noqa: E501
        """V1beta1TrialCondition - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._last_transition_time = None
        self._last_update_time = None
        self._message = None
        self._reason = None
        self._status = None
        self._type = None
        self.discriminator = None

        if last_transition_time is not None:
            self.last_transition_time = last_transition_time
        if last_update_time is not None:
            self.last_update_time = last_update_time
        if message is not None:
            self.message = message
        if reason is not None:
            self.reason = reason
        self.status = status
        self.type = type

    @property
    def last_transition_time(self):
        """Gets the last_transition_time of this V1beta1TrialCondition.  # noqa: E501


        :return: The last_transition_time of this V1beta1TrialCondition.  # noqa: E501
        :rtype: datetime
        """
        return self._last_transition_time

    @last_transition_time.setter
    def last_transition_time(self, last_transition_time):
        """Sets the last_transition_time of this V1beta1TrialCondition.


        :param last_transition_time: The last_transition_time of this V1beta1TrialCondition.  # noqa: E501
        :type: datetime
        """

        self._last_transition_time = last_transition_time

    @property
    def last_update_time(self):
        """Gets the last_update_time of this V1beta1TrialCondition.  # noqa: E501


        :return: The last_update_time of this V1beta1TrialCondition.  # noqa: E501
        :rtype: datetime
        """
        return self._last_update_time

    @last_update_time.setter
    def last_update_time(self, last_update_time):
        """Sets the last_update_time of this V1beta1TrialCondition.


        :param last_update_time: The last_update_time of this V1beta1TrialCondition.  # noqa: E501
        :type: datetime
        """

        self._last_update_time = last_update_time

    @property
    def message(self):
        """Gets the message of this V1beta1TrialCondition.  # noqa: E501

        A human readable message indicating details about the transition.  # noqa: E501

        :return: The message of this V1beta1TrialCondition.  # noqa: E501
        :rtype: str
        """
        return self._message

    @message.setter
    def message(self, message):
        """Sets the message of this V1beta1TrialCondition.

        A human readable message indicating details about the transition.  # noqa: E501

        :param message: The message of this V1beta1TrialCondition.  # noqa: E501
        :type: str
        """

        self._message = message

    @property
    def reason(self):
        """Gets the reason of this V1beta1TrialCondition.  # noqa: E501

        The reason for the condition's last transition.  # noqa: E501

        :return: The reason of this V1beta1TrialCondition.  # noqa: E501
        :rtype: str
        """
        return self._reason

    @reason.setter
    def reason(self, reason):
        """Sets the reason of this V1beta1TrialCondition.

        The reason for the condition's last transition.  # noqa: E501

        :param reason: The reason of this V1beta1TrialCondition.  # noqa: E501
        :type: str
        """

        self._reason = reason

    @property
    def status(self):
        """Gets the status of this V1beta1TrialCondition.  # noqa: E501

        Status of the condition, one of True, False, Unknown.  # noqa: E501

        :return: The status of this V1beta1TrialCondition.  # noqa: E501
        :rtype: str
        """
        return self._status

    @status.setter
    def status(self, status):
        """Sets the status of this V1beta1TrialCondition.

        Status of the condition, one of True, False, Unknown.  # noqa: E501

        :param status: The status of this V1beta1TrialCondition.  # noqa: E501
        :type: str
        """
        if self.local_vars_configuration.client_side_validation and status is None:  # noqa: E501
            raise ValueError("Invalid value for `status`, must not be `None`")  # noqa: E501

        self._status = status

    @property
    def type(self):
        """Gets the type of this V1beta1TrialCondition.  # noqa: E501

        Type of trial condition.  # noqa: E501

        :return: The type of this V1beta1TrialCondition.  # noqa: E501
        :rtype: str
        """
        return self._type

    @type.setter
    def type(self, type):
        """Sets the type of this V1beta1TrialCondition.

        Type of trial condition.  # noqa: E501

        :param type: The type of this V1beta1TrialCondition.  # noqa: E501
        :type: str
        """
        if self.local_vars_configuration.client_side_validation and type is None:  # noqa: E501
            raise ValueError("Invalid value for `type`, must not be `None`")  # noqa: E501

        self._type = type

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1TrialCondition):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1TrialCondition):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_trial_list.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1TrialList(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'api_version': 'str',
        'items': 'list[V1beta1Trial]',
        'kind': 'str',
        'metadata': 'V1ListMeta'
    }

    attribute_map = {
        'api_version': 'apiVersion',
        'items': 'items',
        'kind': 'kind',
        'metadata': 'metadata'
    }

    def __init__(self, api_version=None, items=None, kind=None, metadata=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1TrialList - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._api_version = None
        self._items = None
        self._kind = None
        self._metadata = None
        self.discriminator = None

        if api_version is not None:
            self.api_version = api_version
        self.items = items
        if kind is not None:
            self.kind = kind
        if metadata is not None:
            self.metadata = metadata

    @property
    def api_version(self):
        """Gets the api_version of this V1beta1TrialList.  # noqa: E501

        APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources  # noqa: E501

        :return: The api_version of this V1beta1TrialList.  # noqa: E501
        :rtype: str
        """
        return self._api_version

    @api_version.setter
    def api_version(self, api_version):
        """Sets the api_version of this V1beta1TrialList.

        APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources  # noqa: E501

        :param api_version: The api_version of this V1beta1TrialList.  # noqa: E501
        :type: str
        """

        self._api_version = api_version

    @property
    def items(self):
        """Gets the items of this V1beta1TrialList.  # noqa: E501


        :return: The items of this V1beta1TrialList.  # noqa: E501
        :rtype: list[V1beta1Trial]
        """
        return self._items

    @items.setter
    def items(self, items):
        """Sets the items of this V1beta1TrialList.


        :param items: The items of this V1beta1TrialList.  # noqa: E501
        :type: list[V1beta1Trial]
        """
        if self.local_vars_configuration.client_side_validation and items is None:  # noqa: E501
            raise ValueError("Invalid value for `items`, must not be `None`")  # noqa: E501

        self._items = items

    @property
    def kind(self):
        """Gets the kind of this V1beta1TrialList.  # noqa: E501

        Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds  # noqa: E501

        :return: The kind of this V1beta1TrialList.  # noqa: E501
        :rtype: str
        """
        return self._kind

    @kind.setter
    def kind(self, kind):
        """Sets the kind of this V1beta1TrialList.

        Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds  # noqa: E501

        :param kind: The kind of this V1beta1TrialList.  # noqa: E501
        :type: str
        """

        self._kind = kind

    @property
    def metadata(self):
        """Gets the metadata of this V1beta1TrialList.  # noqa: E501


        :return: The metadata of this V1beta1TrialList.  # noqa: E501
        :rtype: V1ListMeta
        """
        return self._metadata

    @metadata.setter
    def metadata(self, metadata):
        """Sets the metadata of this V1beta1TrialList.


        :param metadata: The metadata of this V1beta1TrialList.  # noqa: E501
        :type: V1ListMeta
        """

        self._metadata = metadata

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1TrialList):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1TrialList):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_trial_parameter_spec.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1TrialParameterSpec(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'description': 'str',
        'name': 'str',
        'reference': 'str'
    }

    attribute_map = {
        'description': 'description',
        'name': 'name',
        'reference': 'reference'
    }

    def __init__(self, description=None, name=None, reference=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1TrialParameterSpec - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._description = None
        self._name = None
        self._reference = None
        self.discriminator = None

        if description is not None:
            self.description = description
        if name is not None:
            self.name = name
        if reference is not None:
            self.reference = reference

    @property
    def description(self):
        """Gets the description of this V1beta1TrialParameterSpec.  # noqa: E501

        Description of the parameter  # noqa: E501

        :return: The description of this V1beta1TrialParameterSpec.  # noqa: E501
        :rtype: str
        """
        return self._description

    @description.setter
    def description(self, description):
        """Sets the description of this V1beta1TrialParameterSpec.

        Description of the parameter  # noqa: E501

        :param description: The description of this V1beta1TrialParameterSpec.  # noqa: E501
        :type: str
        """

        self._description = description

    @property
    def name(self):
        """Gets the name of this V1beta1TrialParameterSpec.  # noqa: E501

        Name of the parameter that must be replaced in trial template  # noqa: E501

        :return: The name of this V1beta1TrialParameterSpec.  # noqa: E501
        :rtype: str
        """
        return self._name

    @name.setter
    def name(self, name):
        """Sets the name of this V1beta1TrialParameterSpec.

        Name of the parameter that must be replaced in trial template  # noqa: E501

        :param name: The name of this V1beta1TrialParameterSpec.  # noqa: E501
        :type: str
        """

        self._name = name

    @property
    def reference(self):
        """Gets the reference of this V1beta1TrialParameterSpec.  # noqa: E501

        Reference to the parameter in search space  # noqa: E501

        :return: The reference of this V1beta1TrialParameterSpec.  # noqa: E501
        :rtype: str
        """
        return self._reference

    @reference.setter
    def reference(self, reference):
        """Sets the reference of this V1beta1TrialParameterSpec.

        Reference to the parameter in search space  # noqa: E501

        :param reference: The reference of this V1beta1TrialParameterSpec.  # noqa: E501
        :type: str
        """

        self._reference = reference

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1TrialParameterSpec):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1TrialParameterSpec):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_trial_source.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1TrialSource(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'config_map': 'V1beta1ConfigMapSource',
        'trial_spec': 'object'
    }

    attribute_map = {
        'config_map': 'configMap',
        'trial_spec': 'trialSpec'
    }

    def __init__(self, config_map=None, trial_spec=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1TrialSource - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._config_map = None
        self._trial_spec = None
        self.discriminator = None

        if config_map is not None:
            self.config_map = config_map
        if trial_spec is not None:
            self.trial_spec = trial_spec

    @property
    def config_map(self):
        """Gets the config_map of this V1beta1TrialSource.  # noqa: E501


        :return: The config_map of this V1beta1TrialSource.  # noqa: E501
        :rtype: V1beta1ConfigMapSource
        """
        return self._config_map

    @config_map.setter
    def config_map(self, config_map):
        """Sets the config_map of this V1beta1TrialSource.


        :param config_map: The config_map of this V1beta1TrialSource.  # noqa: E501
        :type: V1beta1ConfigMapSource
        """

        self._config_map = config_map

    @property
    def trial_spec(self):
        """Gets the trial_spec of this V1beta1TrialSource.  # noqa: E501


        :return: The trial_spec of this V1beta1TrialSource.  # noqa: E501
        :rtype: object
        """
        return self._trial_spec

    @trial_spec.setter
    def trial_spec(self, trial_spec):
        """Sets the trial_spec of this V1beta1TrialSource.


        :param trial_spec: The trial_spec of this V1beta1TrialSource.  # noqa: E501
        :type: object
        """

        self._trial_spec = trial_spec

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1TrialSource):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1TrialSource):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_trial_spec.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1TrialSpec(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'early_stopping_rules': 'list[V1beta1EarlyStoppingRule]',
        'failure_condition': 'str',
        'labels': 'dict(str, str)',
        'metrics_collector': 'V1beta1MetricsCollectorSpec',
        'objective': 'V1beta1ObjectiveSpec',
        'parameter_assignments': 'list[V1beta1ParameterAssignment]',
        'primary_container_name': 'str',
        'primary_pod_labels': 'dict(str, str)',
        'retain_run': 'bool',
        'run_spec': 'object',
        'success_condition': 'str'
    }

    attribute_map = {
        'early_stopping_rules': 'earlyStoppingRules',
        'failure_condition': 'failureCondition',
        'labels': 'labels',
        'metrics_collector': 'metricsCollector',
        'objective': 'objective',
        'parameter_assignments': 'parameterAssignments',
        'primary_container_name': 'primaryContainerName',
        'primary_pod_labels': 'primaryPodLabels',
        'retain_run': 'retainRun',
        'run_spec': 'runSpec',
        'success_condition': 'successCondition'
    }

    def __init__(self, early_stopping_rules=None, failure_condition=None, labels=None, metrics_collector=None, objective=None, parameter_assignments=None, primary_container_name=None, primary_pod_labels=None, retain_run=None, run_spec=None, success_condition=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1TrialSpec - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._early_stopping_rules = None
        self._failure_condition = None
        self._labels = None
        self._metrics_collector = None
        self._objective = None
        self._parameter_assignments = None
        self._primary_container_name = None
        self._primary_pod_labels = None
        self._retain_run = None
        self._run_spec = None
        self._success_condition = None
        self.discriminator = None

        if early_stopping_rules is not None:
            self.early_stopping_rules = early_stopping_rules
        if failure_condition is not None:
            self.failure_condition = failure_condition
        if labels is not None:
            self.labels = labels
        if metrics_collector is not None:
            self.metrics_collector = metrics_collector
        if objective is not None:
            self.objective = objective
        if parameter_assignments is not None:
            self.parameter_assignments = parameter_assignments
        if primary_container_name is not None:
            self.primary_container_name = primary_container_name
        if primary_pod_labels is not None:
            self.primary_pod_labels = primary_pod_labels
        if retain_run is not None:
            self.retain_run = retain_run
        if run_spec is not None:
            self.run_spec = run_spec
        if success_condition is not None:
            self.success_condition = success_condition

    @property
    def early_stopping_rules(self):
        """Gets the early_stopping_rules of this V1beta1TrialSpec.  # noqa: E501

        Rules for early stopping techniques. Each rule should be met to early stop Trial.  # noqa: E501

        :return: The early_stopping_rules of this V1beta1TrialSpec.  # noqa: E501
        :rtype: list[V1beta1EarlyStoppingRule]
        """
        return self._early_stopping_rules

    @early_stopping_rules.setter
    def early_stopping_rules(self, early_stopping_rules):
        """Sets the early_stopping_rules of this V1beta1TrialSpec.

        Rules for early stopping techniques. Each rule should be met to early stop Trial.  # noqa: E501

        :param early_stopping_rules: The early_stopping_rules of this V1beta1TrialSpec.  # noqa: E501
        :type: list[V1beta1EarlyStoppingRule]
        """

        self._early_stopping_rules = early_stopping_rules

    @property
    def failure_condition(self):
        """Gets the failure_condition of this V1beta1TrialSpec.  # noqa: E501

        Condition when trial custom resource is failed. Condition must be in GJSON format, ref https://github.com/tidwall/gjson. For example for BatchJob: status.conditions.#(type==\"Failed\")#|#(status==\"True\")#  # noqa: E501

        :return: The failure_condition of this V1beta1TrialSpec.  # noqa: E501
        :rtype: str
        """
        return self._failure_condition

    @failure_condition.setter
    def failure_condition(self, failure_condition):
        """Sets the failure_condition of this V1beta1TrialSpec.

        Condition when trial custom resource is failed. Condition must be in GJSON format, ref https://github.com/tidwall/gjson. For example for BatchJob: status.conditions.#(type==\"Failed\")#|#(status==\"True\")#  # noqa: E501

        :param failure_condition: The failure_condition of this V1beta1TrialSpec.  # noqa: E501
        :type: str
        """

        self._failure_condition = failure_condition

    @property
    def labels(self):
        """Gets the labels of this V1beta1TrialSpec.  # noqa: E501

        Labels that provide additional metadata for services (e.g. Suggestions tracking)  # noqa: E501

        :return: The labels of this V1beta1TrialSpec.  # noqa: E501
        :rtype: dict(str, str)
        """
        return self._labels

    @labels.setter
    def labels(self, labels):
        """Sets the labels of this V1beta1TrialSpec.

        Labels that provide additional metadata for services (e.g. Suggestions tracking)  # noqa: E501

        :param labels: The labels of this V1beta1TrialSpec.  # noqa: E501
        :type: dict(str, str)
        """

        self._labels = labels

    @property
    def metrics_collector(self):
        """Gets the metrics_collector of this V1beta1TrialSpec.  # noqa: E501


        :return: The metrics_collector of this V1beta1TrialSpec.  # noqa: E501
        :rtype: V1beta1MetricsCollectorSpec
        """
        return self._metrics_collector

    @metrics_collector.setter
    def metrics_collector(self, metrics_collector):
        """Sets the metrics_collector of this V1beta1TrialSpec.


        :param metrics_collector: The metrics_collector of this V1beta1TrialSpec.  # noqa: E501
        :type: V1beta1MetricsCollectorSpec
        """

        self._metrics_collector = metrics_collector

    @property
    def objective(self):
        """Gets the objective of this V1beta1TrialSpec.  # noqa: E501


        :return: The objective of this V1beta1TrialSpec.  # noqa: E501
        :rtype: V1beta1ObjectiveSpec
        """
        return self._objective

    @objective.setter
    def objective(self, objective):
        """Sets the objective of this V1beta1TrialSpec.


        :param objective: The objective of this V1beta1TrialSpec.  # noqa: E501
        :type: V1beta1ObjectiveSpec
        """

        self._objective = objective

    @property
    def parameter_assignments(self):
        """Gets the parameter_assignments of this V1beta1TrialSpec.  # noqa: E501

        Key-value pairs for hyperparameters and assignment values.  # noqa: E501

        :return: The parameter_assignments of this V1beta1TrialSpec.  # noqa: E501
        :rtype: list[V1beta1ParameterAssignment]
        """
        return self._parameter_assignments

    @parameter_assignments.setter
    def parameter_assignments(self, parameter_assignments):
        """Sets the parameter_assignments of this V1beta1TrialSpec.

        Key-value pairs for hyperparameters and assignment values.  # noqa: E501

        :param parameter_assignments: The parameter_assignments of this V1beta1TrialSpec.  # noqa: E501
        :type: list[V1beta1ParameterAssignment]
        """

        self._parameter_assignments = parameter_assignments

    @property
    def primary_container_name(self):
        """Gets the primary_container_name of this V1beta1TrialSpec.  # noqa: E501

        Name of training container where actual model training is running  # noqa: E501

        :return: The primary_container_name of this V1beta1TrialSpec.  # noqa: E501
        :rtype: str
        """
        return self._primary_container_name

    @primary_container_name.setter
    def primary_container_name(self, primary_container_name):
        """Sets the primary_container_name of this V1beta1TrialSpec.

        Name of training container where actual model training is running  # noqa: E501

        :param primary_container_name: The primary_container_name of this V1beta1TrialSpec.  # noqa: E501
        :type: str
        """

        self._primary_container_name = primary_container_name

    @property
    def primary_pod_labels(self):
        """Gets the primary_pod_labels of this V1beta1TrialSpec.  # noqa: E501

        Label that determines if pod needs to be injected by Katib sidecar container  # noqa: E501

        :return: The primary_pod_labels of this V1beta1TrialSpec.  # noqa: E501
        :rtype: dict(str, str)
        """
        return self._primary_pod_labels

    @primary_pod_labels.setter
    def primary_pod_labels(self, primary_pod_labels):
        """Sets the primary_pod_labels of this V1beta1TrialSpec.

        Label that determines if pod needs to be injected by Katib sidecar container  # noqa: E501

        :param primary_pod_labels: The primary_pod_labels of this V1beta1TrialSpec.  # noqa: E501
        :type: dict(str, str)
        """

        self._primary_pod_labels = primary_pod_labels

    @property
    def retain_run(self):
        """Gets the retain_run of this V1beta1TrialSpec.  # noqa: E501

        Whether to retain the trial run object after completed.  # noqa: E501

        :return: The retain_run of this V1beta1TrialSpec.  # noqa: E501
        :rtype: bool
        """
        return self._retain_run

    @retain_run.setter
    def retain_run(self, retain_run):
        """Sets the retain_run of this V1beta1TrialSpec.

        Whether to retain the trial run object after completed.  # noqa: E501

        :param retain_run: The retain_run of this V1beta1TrialSpec.  # noqa: E501
        :type: bool
        """

        self._retain_run = retain_run

    @property
    def run_spec(self):
        """Gets the run_spec of this V1beta1TrialSpec.  # noqa: E501


        :return: The run_spec of this V1beta1TrialSpec.  # noqa: E501
        :rtype: object
        """
        return self._run_spec

    @run_spec.setter
    def run_spec(self, run_spec):
        """Sets the run_spec of this V1beta1TrialSpec.


        :param run_spec: The run_spec of this V1beta1TrialSpec.  # noqa: E501
        :type: object
        """

        self._run_spec = run_spec

    @property
    def success_condition(self):
        """Gets the success_condition of this V1beta1TrialSpec.  # noqa: E501

        Condition when trial custom resource is succeeded. Condition must be in GJSON format, ref https://github.com/tidwall/gjson. For example for BatchJob: status.conditions.#(type==\"Complete\")#|#(status==\"True\")#  # noqa: E501

        :return: The success_condition of this V1beta1TrialSpec.  # noqa: E501
        :rtype: str
        """
        return self._success_condition

    @success_condition.setter
    def success_condition(self, success_condition):
        """Sets the success_condition of this V1beta1TrialSpec.

        Condition when trial custom resource is succeeded. Condition must be in GJSON format, ref https://github.com/tidwall/gjson. For example for BatchJob: status.conditions.#(type==\"Complete\")#|#(status==\"True\")#  # noqa: E501

        :param success_condition: The success_condition of this V1beta1TrialSpec.  # noqa: E501
        :type: str
        """

        self._success_condition = success_condition

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1TrialSpec):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1TrialSpec):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_trial_status.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1TrialStatus(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'completion_time': 'datetime',
        'conditions': 'list[V1beta1TrialCondition]',
        'last_reconcile_time': 'datetime',
        'observation': 'V1beta1Observation',
        'start_time': 'datetime'
    }

    attribute_map = {
        'completion_time': 'completionTime',
        'conditions': 'conditions',
        'last_reconcile_time': 'lastReconcileTime',
        'observation': 'observation',
        'start_time': 'startTime'
    }

    def __init__(self, completion_time=None, conditions=None, last_reconcile_time=None, observation=None, start_time=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1TrialStatus - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._completion_time = None
        self._conditions = None
        self._last_reconcile_time = None
        self._observation = None
        self._start_time = None
        self.discriminator = None

        if completion_time is not None:
            self.completion_time = completion_time
        if conditions is not None:
            self.conditions = conditions
        if last_reconcile_time is not None:
            self.last_reconcile_time = last_reconcile_time
        if observation is not None:
            self.observation = observation
        if start_time is not None:
            self.start_time = start_time

    @property
    def completion_time(self):
        """Gets the completion_time of this V1beta1TrialStatus.  # noqa: E501


        :return: The completion_time of this V1beta1TrialStatus.  # noqa: E501
        :rtype: datetime
        """
        return self._completion_time

    @completion_time.setter
    def completion_time(self, completion_time):
        """Sets the completion_time of this V1beta1TrialStatus.


        :param completion_time: The completion_time of this V1beta1TrialStatus.  # noqa: E501
        :type: datetime
        """

        self._completion_time = completion_time

    @property
    def conditions(self):
        """Gets the conditions of this V1beta1TrialStatus.  # noqa: E501

        List of observed runtime conditions for this Trial.  # noqa: E501

        :return: The conditions of this V1beta1TrialStatus.  # noqa: E501
        :rtype: list[V1beta1TrialCondition]
        """
        return self._conditions

    @conditions.setter
    def conditions(self, conditions):
        """Sets the conditions of this V1beta1TrialStatus.

        List of observed runtime conditions for this Trial.  # noqa: E501

        :param conditions: The conditions of this V1beta1TrialStatus.  # noqa: E501
        :type: list[V1beta1TrialCondition]
        """

        self._conditions = conditions

    @property
    def last_reconcile_time(self):
        """Gets the last_reconcile_time of this V1beta1TrialStatus.  # noqa: E501


        :return: The last_reconcile_time of this V1beta1TrialStatus.  # noqa: E501
        :rtype: datetime
        """
        return self._last_reconcile_time

    @last_reconcile_time.setter
    def last_reconcile_time(self, last_reconcile_time):
        """Sets the last_reconcile_time of this V1beta1TrialStatus.


        :param last_reconcile_time: The last_reconcile_time of this V1beta1TrialStatus.  # noqa: E501
        :type: datetime
        """

        self._last_reconcile_time = last_reconcile_time

    @property
    def observation(self):
        """Gets the observation of this V1beta1TrialStatus.  # noqa: E501


        :return: The observation of this V1beta1TrialStatus.  # noqa: E501
        :rtype: V1beta1Observation
        """
        return self._observation

    @observation.setter
    def observation(self, observation):
        """Sets the observation of this V1beta1TrialStatus.


        :param observation: The observation of this V1beta1TrialStatus.  # noqa: E501
        :type: V1beta1Observation
        """

        self._observation = observation

    @property
    def start_time(self):
        """Gets the start_time of this V1beta1TrialStatus.  # noqa: E501


        :return: The start_time of this V1beta1TrialStatus.  # noqa: E501
        :rtype: datetime
        """
        return self._start_time

    @start_time.setter
    def start_time(self, start_time):
        """Sets the start_time of this V1beta1TrialStatus.


        :param start_time: The start_time of this V1beta1TrialStatus.  # noqa: E501
        :type: datetime
        """

        self._start_time = start_time

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1TrialStatus):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1TrialStatus):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/models/v1beta1_trial_template.py
================================================
# coding: utf-8

"""
    Katib

    Swagger description for Katib  # noqa: E501

    The version of the OpenAPI document: v1beta1-0.1
    Generated by: https://openapi-generator.tech
"""


import pprint
import re  # noqa: F401

import six

from kubeflow.katib.configuration import Configuration


class V1beta1TrialTemplate(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'config_map': 'V1beta1ConfigMapSource',
        'failure_condition': 'str',
        'primary_container_name': 'str',
        'primary_pod_labels': 'dict(str, str)',
        'retain': 'bool',
        'success_condition': 'str',
        'trial_parameters': 'list[V1beta1TrialParameterSpec]',
        'trial_spec': 'object'
    }

    attribute_map = {
        'config_map': 'configMap',
        'failure_condition': 'failureCondition',
        'primary_container_name': 'primaryContainerName',
        'primary_pod_labels': 'primaryPodLabels',
        'retain': 'retain',
        'success_condition': 'successCondition',
        'trial_parameters': 'trialParameters',
        'trial_spec': 'trialSpec'
    }

    def __init__(self, config_map=None, failure_condition=None, primary_container_name=None, primary_pod_labels=None, retain=None, success_condition=None, trial_parameters=None, trial_spec=None, local_vars_configuration=None):  # noqa: E501
        """V1beta1TrialTemplate - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._config_map = None
        self._failure_condition = None
        self._primary_container_name = None
        self._primary_pod_labels = None
        self._retain = None
        self._success_condition = None
        self._trial_parameters = None
        self._trial_spec = None
        self.discriminator = None

        if config_map is not None:
            self.config_map = config_map
        if failure_condition is not None:
            self.failure_condition = failure_condition
        if primary_container_name is not None:
            self.primary_container_name = primary_container_name
        if primary_pod_labels is not None:
            self.primary_pod_labels = primary_pod_labels
        if retain is not None:
            self.retain = retain
        if success_condition is not None:
            self.success_condition = success_condition
        if trial_parameters is not None:
            self.trial_parameters = trial_parameters
        if trial_spec is not None:
            self.trial_spec = trial_spec

    @property
    def config_map(self):
        """Gets the config_map of this V1beta1TrialTemplate.  # noqa: E501


        :return: The config_map of this V1beta1TrialTemplate.  # noqa: E501
        :rtype: V1beta1ConfigMapSource
        """
        return self._config_map

    @config_map.setter
    def config_map(self, config_map):
        """Sets the config_map of this V1beta1TrialTemplate.


        :param config_map: The config_map of this V1beta1TrialTemplate.  # noqa: E501
        :type: V1beta1ConfigMapSource
        """

        self._config_map = config_map

    @property
    def failure_condition(self):
        """Gets the failure_condition of this V1beta1TrialTemplate.  # noqa: E501

        Condition when trial custom resource is failed. Condition must be in GJSON format, ref https://github.com/tidwall/gjson. For example for BatchJob: status.conditions.#(type==\"Failed\")#|#(status==\"True\")#  # noqa: E501

        :return: The failure_condition of this V1beta1TrialTemplate.  # noqa: E501
        :rtype: str
        """
        return self._failure_condition

    @failure_condition.setter
    def failure_condition(self, failure_condition):
        """Sets the failure_condition of this V1beta1TrialTemplate.

        Condition when trial custom resource is failed. Condition must be in GJSON format, ref https://github.com/tidwall/gjson. For example for BatchJob: status.conditions.#(type==\"Failed\")#|#(status==\"True\")#  # noqa: E501

        :param failure_condition: The failure_condition of this V1beta1TrialTemplate.  # noqa: E501
        :type: str
        """

        self._failure_condition = failure_condition

    @property
    def primary_container_name(self):
        """Gets the primary_container_name of this V1beta1TrialTemplate.  # noqa: E501

        Name of training container where actual model training is running  # noqa: E501

        :return: The primary_container_name of this V1beta1TrialTemplate.  # noqa: E501
        :rtype: str
        """
        return self._primary_container_name

    @primary_container_name.setter
    def primary_container_name(self, primary_container_name):
        """Sets the primary_container_name of this V1beta1TrialTemplate.

        Name of training container where actual model training is running  # noqa: E501

        :param primary_container_name: The primary_container_name of this V1beta1TrialTemplate.  # noqa: E501
        :type: str
        """

        self._primary_container_name = primary_container_name

    @property
    def primary_pod_labels(self):
        """Gets the primary_pod_labels of this V1beta1TrialTemplate.  # noqa: E501

        Labels that determines if pod needs to be injected by Katib sidecar container. If PrimaryPodLabels is omitted, metrics collector wraps all Trial's pods.  # noqa: E501

        :return: The primary_pod_labels of this V1beta1TrialTemplate.  # noqa: E501
        :rtype: dict(str, str)
        """
        return self._primary_pod_labels

    @primary_pod_labels.setter
    def primary_pod_labels(self, primary_pod_labels):
        """Sets the primary_pod_labels of this V1beta1TrialTemplate.

        Labels that determines if pod needs to be injected by Katib sidecar container. If PrimaryPodLabels is omitted, metrics collector wraps all Trial's pods.  # noqa: E501

        :param primary_pod_labels: The primary_pod_labels of this V1beta1TrialTemplate.  # noqa: E501
        :type: dict(str, str)
        """

        self._primary_pod_labels = primary_pod_labels

    @property
    def retain(self):
        """Gets the retain of this V1beta1TrialTemplate.  # noqa: E501

        Retain indicates that trial resources must be not cleanup  # noqa: E501

        :return: The retain of this V1beta1TrialTemplate.  # noqa: E501
        :rtype: bool
        """
        return self._retain

    @retain.setter
    def retain(self, retain):
        """Sets the retain of this V1beta1TrialTemplate.

        Retain indicates that trial resources must be not cleanup  # noqa: E501

        :param retain: The retain of this V1beta1TrialTemplate.  # noqa: E501
        :type: bool
        """

        self._retain = retain

    @property
    def success_condition(self):
        """Gets the success_condition of this V1beta1TrialTemplate.  # noqa: E501

        Condition when trial custom resource is succeeded. Condition must be in GJSON format, ref https://github.com/tidwall/gjson. For example for BatchJob: status.conditions.#(type==\"Complete\")#|#(status==\"True\")#  # noqa: E501

        :return: The success_condition of this V1beta1TrialTemplate.  # noqa: E501
        :rtype: str
        """
        return self._success_condition

    @success_condition.setter
    def success_condition(self, success_condition):
        """Sets the success_condition of this V1beta1TrialTemplate.

        Condition when trial custom resource is succeeded. Condition must be in GJSON format, ref https://github.com/tidwall/gjson. For example for BatchJob: status.conditions.#(type==\"Complete\")#|#(status==\"True\")#  # noqa: E501

        :param success_condition: The success_condition of this V1beta1TrialTemplate.  # noqa: E501
        :type: str
        """

        self._success_condition = success_condition

    @property
    def trial_parameters(self):
        """Gets the trial_parameters of this V1beta1TrialTemplate.  # noqa: E501

        List of parameters that are used in trial template  # noqa: E501

        :return: The trial_parameters of this V1beta1TrialTemplate.  # noqa: E501
        :rtype: list[V1beta1TrialParameterSpec]
        """
        return self._trial_parameters

    @trial_parameters.setter
    def trial_parameters(self, trial_parameters):
        """Sets the trial_parameters of this V1beta1TrialTemplate.

        List of parameters that are used in trial template  # noqa: E501

        :param trial_parameters: The trial_parameters of this V1beta1TrialTemplate.  # noqa: E501
        :type: list[V1beta1TrialParameterSpec]
        """

        self._trial_parameters = trial_parameters

    @property
    def trial_spec(self):
        """Gets the trial_spec of this V1beta1TrialTemplate.  # noqa: E501


        :return: The trial_spec of this V1beta1TrialTemplate.  # noqa: E501
        :rtype: object
        """
        return self._trial_spec

    @trial_spec.setter
    def trial_spec(self, trial_spec):
        """Sets the trial_spec of this V1beta1TrialTemplate.


        :param trial_spec: The trial_spec of this V1beta1TrialTemplate.  # noqa: E501
        :type: object
        """

        self._trial_spec = trial_spec

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, V1beta1TrialTemplate):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, V1beta1TrialTemplate):
            return True

        return self.to_dict() != other.to_dict()



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/types/__init__.py
================================================
[Empty file]


================================================
FILE: sdk/python/v1beta1/kubeflow/katib/types/types.py
================================================
from dataclasses import dataclass
from typing import Dict


# Trainer resources for distributed training.
@dataclass
class TrainerResources:
    num_workers: int
    num_procs_per_worker: int
    resources_per_worker: Dict[str, str]



================================================
FILE: sdk/python/v1beta1/kubeflow/katib/utils/__init__.py
================================================
[Empty file]


================================================
FILE: sdk/python/v1beta1/kubeflow/katib/utils/utils.py
================================================
# Copyright 2021 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import copy
import inspect
import json
import logging
import os
import textwrap
from typing import Any, Callable, Dict, List, Optional, Union

from kubeflow.katib import models
from kubeflow.katib.constants import constants
from kubeflow.katib.types import types
from kubeflow.training import models as training_models
from kubeflow.training.constants.constants import (
    API_VERSION,
    JOB_PARAMETERS,
    PYTORCHJOB_KIND,
)
from kubernetes import client

logger = logging.getLogger(__name__)


def is_running_in_k8s():
    return os.path.isdir("/var/run/secrets/kubernetes.io/")


def get_current_k8s_namespace():
    with open("/var/run/secrets/kubernetes.io/serviceaccount/namespace", "r") as f:
        return f.readline()


def get_default_target_namespace():
    if not is_running_in_k8s():
        return "default"
    return get_current_k8s_namespace()


def set_katib_namespace(katib):
    katib_namespace = katib.metadata.namespace
    namespace = katib_namespace or get_default_target_namespace()
    return namespace


def has_condition(conditions, condition_type):
    """Verify if the condition list has the required condition.
    Condition should be valid object with `type` and `status`.
    """

    for c in conditions:
        if c.type == condition_type and c.status == constants.CONDITION_STATUS_TRUE:
            return True
    return False


def print_experiment_status(experiment: models.V1beta1Experiment):
    if experiment.status:
        print(
            "Experiment Trials status: {} Trials, {} Pending Trials, "
            "{} Running Trials, {} Succeeded Trials, {} Failed Trials, "
            "{} EarlyStopped Trials, {} MetricsUnavailable Trials".format(
                experiment.status.trials or 0,
                experiment.status.trials_pending or 0,
                experiment.status.trials_running or 0,
                experiment.status.trials_succeeded or 0,
                experiment.status.trials_failed or 0,
                experiment.status.trials_early_stopped or 0,
                experiment.status.trial_metrics_unavailable or 0,
            )
        )
        print(f"Current Optimal Trial:\n {experiment.status.current_optimal_trial}")
        print(f"Experiment conditions:\n {experiment.status.conditions}")


def validate_metrics_value(value: Any):
    """Validate if the metrics value can be converted to type `float`."""
    try:
        float(value)
    except Exception:
        raise ValueError(
            f"Invalid value {value} for metrics value. "
            "The metrics value should have or can be converted to type `float`. "
        )


def validate_objective_function(objective: Callable):
    # Check if objective function is callable.
    if not callable(objective):
        raise ValueError(
            f"Objective function must be callable, got function type: {type(objective)}"
        )

    # Verify the objective function arguments.
    objective_signature = inspect.signature(objective)
    try:
        objective_signature.bind({})
    except Exception:
        raise ValueError(
            "Invalid args in the Objective function. "
            "The function args must have only 'parameters' dictionary. "
            f"Current Objective arguments: {objective_signature}"
        )


def get_script_for_python_packages(packages_to_install, pip_index_url):
    packages_str = " ".join([str(package) for package in packages_to_install])

    script_for_python_packages = textwrap.dedent(
        f"""
        if ! [ -x "$(command -v pip)" ]; then
            python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
        fi

        PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --prefer-binary --quiet \
        --no-warn-script-location --index-url {pip_index_url} {packages_str}
        """
    )

    return script_for_python_packages


class FakeResponse:
    """Fake object of RESTResponse to deserialize
    Ref) https://github.com/kubeflow/katib/pull/1630#discussion_r697877815
    Ref) https://github.com/kubernetes-client/python/issues/977#issuecomment-592030030
    """

    def __init__(self, obj):
        self.data = json.dumps(obj)


class SetEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, set):
            return list(obj)
        if isinstance(obj, type):
            return obj.__name__
        return json.JSONEncoder.default(self, obj)


def get_trial_substitutions_from_dict(
    parameters: Dict[str, Any],
    experiment_parameters: List[models.V1beta1ParameterSpec],
    trial_parameters: List[models.V1beta1TrialParameterSpec],
) -> Dict[str, str]:
    for p_name, p_value in parameters.items():
        # If input parameter value is Katib Experiment parameter sample.
        if isinstance(p_value, models.V1beta1ParameterSpec):
            # Wrap value for the function input.
            parameters[p_name] = f"${{trialParameters.{p_name}}}"

            # Add value to the Katib Experiment parameters.
            p_value.name = p_name
            experiment_parameters.append(p_value)

            # Add value to the Katib Experiment's Trial parameters.
            trial_parameters.append(
                models.V1beta1TrialParameterSpec(name=p_name, reference=p_name)
            )
        else:
            # Otherwise, add value to the function input.
            parameters[p_name] = p_value

    return parameters


def get_trial_substitutions_from_trainer(
    parameters: Union["TrainingArguments", "LoraConfig"],  # noqa: F821
    experiment_params: List[models.V1beta1ParameterSpec],
    trial_params: List[models.V1beta1TrialParameterSpec],
) -> Dict[str, str]:
    from peft import LoraConfig  # noqa: F401
    from transformers import TrainingArguments  # noqa: F401

    if isinstance(parameters, TrainingArguments):
        parameters_dict = parameters.to_dict()
    else:
        parameters_dict = (
            parameters.to_dict() if hasattr(parameters, "to_dict") else vars(parameters)
        )
    for p_name, p_value in parameters_dict.items():
        if not hasattr(parameters, p_name):
            logger.warning(f"Training parameter {p_name} is not supported.")
            continue

        if isinstance(p_value, models.V1beta1ParameterSpec):
            old_attr = getattr(parameters, p_name, None)
            if old_attr is not None:
                value = f"${{trialParameters.{p_name}}}"
            setattr(parameters, p_name, value)
            p_value.name = p_name
            experiment_params.append(p_value)
            trial_params.append(
                models.V1beta1TrialParameterSpec(name=p_name, reference=p_name)
            )
        elif p_value is not None:
            old_attr = getattr(parameters, p_name, None)
            if old_attr is not None:
                if isinstance(p_value, dict):
                    # Update the existing dictionary without nesting
                    value = copy.deepcopy(p_value)
                else:
                    value = type(old_attr)(p_value)
            setattr(parameters, p_name, value)

    if isinstance(parameters, TrainingArguments):
        parameters = json.dumps(parameters.to_dict())
    else:
        parameters = (
            json.dumps(parameters.to_dict(), cls=SetEncoder)
            if hasattr(parameters, "to_dict")
            else json.dumps(vars(parameters), cls=SetEncoder)
        )

    return parameters


def get_exec_script_from_objective(
    objective: Callable,
    entrypoint: str,
    input_params: Dict[str, Any],
    packages_to_install: Optional[List[str]] = None,
    pip_index_url: str = "https://pypi.org/simple",
) -> str:
    """
    Get executable script for container args from the given objective function and parameters.
    """
    # Validate objective function.
    validate_objective_function(objective)

    # Extract objective function implementation.
    objective_code = inspect.getsource(objective)

    # Objective function might be defined in some indented scope
    # (e.g. in another function). We need to dedent the function code.
    objective_code = textwrap.dedent(objective_code)

    # Wrap objective function to execute it from the file. For example:
    # def objective(parameters):
    #     print(f'Parameters are {parameters}')
    # objective({
    #     'lr': '${trialParameters.lr}',
    #     'epochs': '${trialParameters.epochs}',
    #     'is_dist': False
    # })
    objective_code = f"{objective_code}\n{objective.__name__}({input_params})\n"

    # Prepare execute script template.
    exec_script = textwrap.dedent(
        """
                program_path=$(mktemp -d)
                read -r -d '' SCRIPT << EOM\n
                {objective_code}
                EOM
                printf "%s" \"$SCRIPT\" > \"$program_path/ephemeral_script.py\"
                {entrypoint} \"$program_path/ephemeral_script.py\""""
    )

    # Add objective code to the execute script.
    exec_script = exec_script.format(
        objective_code=objective_code, entrypoint=entrypoint
    )

    # Install Python packages if that is required.
    if packages_to_install is not None:
        exec_script = (
            get_script_for_python_packages(packages_to_install, pip_index_url)
            + exec_script
        )

    # Return executable script to execute objective function.
    return exec_script


def get_trial_template_with_job(
    retain_trials: bool,
    trial_parameters: List[models.V1beta1TrialParameterSpec],
    pod_template_spec: client.V1PodTemplateSpec,
) -> models.V1beta1TrialTemplate:
    """
    Get Trial template with Job as a Trial's Worker
    """

    # Restart policy must be set for the Job.
    pod_template_spec.spec.restart_policy = "Never"  # type: ignore

    # Use Job as a Trial spec.
    job = client.V1Job(
        api_version="batch/v1",
        kind="Job",
        spec=client.V1JobSpec(template=pod_template_spec),
    )

    trial_template = models.V1beta1TrialTemplate(
        primary_container_name=constants.DEFAULT_PRIMARY_CONTAINER_NAME,
        retain=retain_trials,
        trial_parameters=trial_parameters,
        trial_spec=job,
    )
    return trial_template


def get_trial_template_with_pytorchjob(
    retain_trials: bool,
    trial_parameters: List[models.V1beta1TrialParameterSpec],
    resources_per_trial: types.TrainerResources,
    master_pod_template_spec: models.V1PodTemplateSpec,
    worker_pod_template_spec: models.V1PodTemplateSpec,
) -> models.V1beta1TrialTemplate:
    """
    Get Trial template with PyTorchJob as a Trial's Worker
    """

    # Use PyTorchJob as a Trial spec.
    pytorchjob = training_models.KubeflowOrgV1PyTorchJob(
        api_version=API_VERSION,
        kind=PYTORCHJOB_KIND,
        spec=training_models.KubeflowOrgV1PyTorchJobSpec(
            run_policy=training_models.KubeflowOrgV1RunPolicy(clean_pod_policy=None),
            nproc_per_node=str(resources_per_trial.num_procs_per_worker),
            pytorch_replica_specs={
                "Master": training_models.KubeflowOrgV1ReplicaSpec(
                    replicas=1,
                    template=master_pod_template_spec,
                )
            },
        ),
    )

    # Add Worker replica if number of workers > 1
    if resources_per_trial.num_workers > 1:
        pytorchjob.spec.pytorch_replica_specs["Worker"] = (
            training_models.KubeflowOrgV1ReplicaSpec(
                replicas=resources_per_trial.num_workers - 1,
                template=worker_pod_template_spec,
            )
        )

    trial_template = models.V1beta1TrialTemplate(
        primary_container_name=JOB_PARAMETERS[PYTORCHJOB_KIND]["container"],
        retain=retain_trials,
        trial_parameters=trial_parameters,
        trial_spec=pytorchjob,
    )
    return trial_template



================================================
FILE: test/__init__.py
================================================
[Empty file]


================================================
FILE: test/conftest.py
================================================
import os
from sys import path

root = os.path.join(os.path.dirname(__file__), "..")
path.extend(
    [
        os.path.join(root, "pkg/apis/manager/v1beta1/python"),
        os.path.join(root, "pkg/apis/manager/health/python"),
        os.path.join(root, "pkg/metricscollector/v1beta1/common"),
        os.path.join(root, "pkg/metricscollector/v1beta1/tfevent-metricscollector"),
    ]
)



================================================
FILE: test/e2e/v1beta1/hack/aws/argo_workflow.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This script creates Argo Workflow for the e2e Katib tests.

from kubeflow.testing import argo_build_util

# Main worker image to execute Workflow.
IMAGE_WORKER = "public.ecr.aws/j1r0q0g6/kubeflow-testing:latest"
# Kaniko image to build Katib images.
IMAGE_KANIKO = "gcr.io/kaniko-project/executor:v1.0.0"

# Volume to store test data among the Workflow tasks.
VOLUME_TEST_DATA = "kubeflow-test-volume"
# Volume mount path to store test data among the Workflow tasks.
MOUNT_PATH = "/mnt/test-data-volume"
# Volume to store GitHub token to clone repos.
VOLUME_GITHUB_TOKEN = "github-token"
# Volume to store AWS secret for the Kaniko build.
VOLUME_AWS_SECRET = "aws-secret"
# Volume to store Docker config for Kaniko build.
VOLUME_DOCKER_CONFIG = "docker-config"

# Entrypoint for the Argo Workflow.
ENTRYPOINT = "e2e"
# The template that should always run when the Workflow is complete.
EXIT_HANDLER = "exit-handler"

# Dict with all Katib images.
# Key - image name, Value - dockerfile location.
KATIB_IMAGES = {
    "katib-controller":              "cmd/katib-controller/v1beta1/Dockerfile",
    "katib-db-manager":              "cmd/db-manager/v1beta1/Dockerfile",
    "katib-ui":                      "cmd/ui/v1beta1/Dockerfile",
    "file-metrics-collector":        "cmd/metricscollector/v1beta1/file-metricscollector/Dockerfile",
    "tfevent-metrics-collector":     "cmd/metricscollector/v1beta1/tfevent-metricscollector/Dockerfile",
    "suggestion-hyperopt":           "cmd/suggestion/hyperopt/v1beta1/Dockerfile",
    "suggestion-skopt":              "cmd/suggestion/skopt/v1beta1/Dockerfile",
    "suggestion-hyperband":          "cmd/suggestion/hyperband/v1beta1/Dockerfile",
    "suggestion-goptuna":            "cmd/suggestion/goptuna/v1beta1/Dockerfile",
    "suggestion-optuna":             "cmd/suggestion/optuna/v1beta1/Dockerfile",
    "suggestion-pbt":                "cmd/suggestion/pbt/v1beta1/Dockerfile",
    "suggestion-enas":               "cmd/suggestion/nas/enas/v1beta1/Dockerfile",
    "suggestion-darts":              "cmd/suggestion/nas/darts/v1beta1/Dockerfile",
    "earlystopping-medianstop":      "cmd/earlystopping/medianstop/v1beta1/Dockerfile",
    "trial-pytorch-mnist":           "examples/v1beta1/trial-images/pytorch-mnist/Dockerfile",
    "trial-tf-mnist-with-summaries": "examples/v1beta1/trial-images/tf-mnist-with-summaries/Dockerfile",
    "trial-enas-cnn-cifar10-gpu":    "examples/v1beta1/trial-images/enas-cnn-cifar10/Dockerfile.gpu",
    "trial-enas-cnn-cifar10-cpu":    "examples/v1beta1/trial-images/enas-cnn-cifar10/Dockerfile.cpu",
    "trial-darts-cnn-cifar10":       "examples/v1beta1/trial-images/darts-cnn-cifar10/Dockerfile",
    "trial-simple-pbt":              "examples/v1beta1/trial-images/simple-pbt/Dockerfile",
}

# Dict with Katib Experiments to run during the test.
# Key - image name, Value - dockerfile location.
KATIB_EXPERIMENTS = {
    "random":                                 "examples/v1beta1/hp-tuning/random.yaml",
    "grid":                                   "examples/v1beta1/hp-tuning/grid.yaml",
    "bayesianoptimization":                   "examples/v1beta1/hp-tuning/bayesian-optimization.yaml",
    "tpe":                                    "examples/v1beta1/hp-tuning/tpe.yaml",
    "multivariate-tpe":                       "examples/v1beta1/hp-tuning/multivariate-tpe.yaml",
    "cmaes":                                  "examples/v1beta1/hp-tuning/cma-es.yaml",
    "hyperband":                              "examples/v1beta1/hp-tuning/hyperband.yaml",
    "pbt":                                    "examples/v1beta1/hp-tuning/simple-pbt.yaml",
    "enas":                                   "examples/v1beta1/nas/enas-cpu.yaml",
    "darts":                                  "examples/v1beta1/nas/darts-cpu.yaml",
    "pytorchjob":                             "examples/v1beta1/kubeflow-training-operator/pytorchjob-mnist.yaml",
    "tfjob":                                  "examples/v1beta1/kubeflow-training-operator/tfjob-mnist-with-summaries.yaml",
    "file-metricscollector":                  "examples/v1beta1/metrics-collector/file-metrics-collector.yaml",
    "file-metricscollector-with-json-format": "examples/v1beta1/metrics-collector/file-metrics-collector-with-json-format.yaml",
    "never-resume":                           "examples/v1beta1/resume-experiment/never-resume.yaml",
    "from-volume-resume":                     "examples/v1beta1/resume-experiment/from-volume-resume.yaml",
    "median-stop":                            "examples/v1beta1/early-stopping/median-stop.yaml",
    "median-stop-with-json-format":           "examples/v1beta1/early-stopping/median-stop-with-json-format.yaml",
}
# How many Experiments are running in parallel.
PARALLEL_EXECUTION = 5


class WorkflowBuilder(object):
    def __init__(self, workflow_name, workflow_namespace, test_dir, ecr_registry):
        """WorkflowBuilder constructor.

        :param workflow_name: Argo Workflow name.
        :param workflow_namespace: Argo Workflow namespace.
        :param test_dir: Root directory to store all data for a particular test run.
        :param ecr_registry: ECR registry to push the test images.
        """

        self.workflow_name = workflow_name
        self.workflow_namespace = workflow_namespace
        self.test_dir = test_dir
        self.katib_dir = test_dir + "/src/github.com/kubeflow/katib"
        self.manifest_dir = test_dir + "/src/github.com/kubeflow/manifests"
        self.ecr_registry = ecr_registry

    def create_task_template(self, task_name, exec_image, command):
        """Creates template for all the Workflow tasks.

        :param task_name: Template name for the task.
        :param exec_image: Container image to execute the task.
        :param command: List of container commands.

        :return: Created task template.
        """

        # Container environment variables.
        # TODO (andreyvelich): Add PYTHONPATH ?
        env = [
            {
                "name": "AWS_ACCESS_KEY_ID",
                "valueFrom": {
                    "secretKeyRef": {
                        "name": "aws-credentials",
                        "key": "AWS_ACCESS_KEY_ID"
                    }
                }
            },
            {
                "name": "AWS_SECRET_ACCESS_KEY",
                "valueFrom": {
                    "secretKeyRef": {
                        "name": "aws-credentials",
                        "key": "AWS_SECRET_ACCESS_KEY"
                    }
                }
            },
            {
                "name": "AWS_REGION",
                "value": "us-west-2"
            },
            {
                "name": "CLUSTER_NAME",
                "value": self.workflow_name
            },
            {
                "name": "EKS_CLUSTER_VERSION",
                "value": "1.19"
            },
            {
                "name": "ECR_REGISTRY",
                "value": self.ecr_registry
            },
            {
                "name": "GIT_TOKEN",
                "valueFrom": {
                    "secretKeyRef": {
                        "name": "github-token",
                        "key": "github_token"
                    }
                }
            },
            {
                "name": "MANIFESTS_DIR",
                "value": self.manifest_dir
            },
            {
                "name": "EXTRA_REPOS",
                "value": "kubeflow/testing@HEAD;kubeflow/manifests@v1.5-branch"
            },
            # Set GOPATH to test_dir because Katib repo is located under /src/github.com/kubeflow/katib
            {
                "name": "GOPATH",
                "value": self.test_dir
            }
        ]

        # Container volume mounts.
        volume_mounts = [
            {
                "name": VOLUME_TEST_DATA,
                "mountPath": MOUNT_PATH
            },
            {
                "name": VOLUME_GITHUB_TOKEN,
                "mountPath": "/secret/github-token"
            },
            {
                "name": VOLUME_AWS_SECRET,
                "mountPath": "/root/.aws/"
            },
            {
                "name": VOLUME_DOCKER_CONFIG,
                "mountPath": "/kaniko/.docker/"
            },
        ]

        task_template = {
            "name": task_name,
            # Each container can be alive for 40 minutes.
            "retryStrategy": {
                "limit": "3",
                "retryPolicy": "Always",
                "backoff": {
                    "duration": "1",
                    "factor": "2",
                    "maxDuration": "1m",
                },
            },
            "container": {
                "command": command,
                "image": exec_image,
                "workingDir": self.katib_dir,
                "env": env,
                "volumeMounts": volume_mounts,
            }
        }

        # Add prow env to the task template.
        prow_env_dict = argo_build_util.get_prow_dict()
        for k, v in prow_env_dict.items():
            task_template["container"]["env"].append({"name": k, "value": v})

        return task_template

    def create_init_workflow(self):
        """Creates initial structure for the Argo Workflow.

        :return: Initial Argo Workflow.
        """

        # Volumes which are used in Argo Workflow.
        volumes = [
            {
                "name": VOLUME_TEST_DATA,
                "persistentVolumeClaim": {
                    "claimName": "nfs-external"
                },
            },
            {
                "name": VOLUME_GITHUB_TOKEN,
                "secret": {
                    "secretName": VOLUME_GITHUB_TOKEN
                },
            },
            {
                "name": VOLUME_AWS_SECRET,
                "secret": {
                    "secretName": VOLUME_AWS_SECRET
                },
            },
            {
                "name": VOLUME_DOCKER_CONFIG,
                "configMap": {
                    "name": VOLUME_DOCKER_CONFIG
                },
            },
        ]

        workflow = {
            "apiVersion": "argoproj.io/v1alpha1",
            "kind": "Workflow",
            "metadata": {
                "name": self.workflow_name,
                "namespace": self.workflow_namespace,
            },
            "spec": {
                "entrypoint": ENTRYPOINT,
                "volumes": volumes,
                "templates": [
                    {
                        "name": ENTRYPOINT,
                        "dag": {
                            "tasks": []
                        }
                    },
                    {
                        "name": EXIT_HANDLER,
                        "dag": {
                            "tasks": []
                        }
                    }
                ],
                "onExit": EXIT_HANDLER
            },
        }

        return workflow


def create_workflow(name, namespace, **kwargs):
    """Main function which returns Argo Workflow.

    :param name: Argo Workflow name.
    :param namespace: Argo Workflow namespace.
    :param kwargs: Argo Workflow additional arguments.

    :return: Created Argo Workflow.
    """

    test_dir = MOUNT_PATH + "/" + name
    ecr_registry = kwargs["registry"]
    builder = WorkflowBuilder(name, namespace, test_dir, ecr_registry)

    # Build initial structure for the Workflow.
    workflow = builder.create_init_workflow()

    # Delete AWS Cluster in the exit handler step.
    delete_cluster = builder.create_task_template(
        task_name="delete-cluster",
        exec_image=IMAGE_WORKER,
        command=[
            "/usr/local/bin/delete-eks-cluster.sh",
        ]
    )
    argo_build_util.add_task_to_dag(workflow, EXIT_HANDLER, delete_cluster, [])

    # Step 1. Checkout GitHub repositories.
    checkout = builder.create_task_template(
        task_name="checkout",
        exec_image=IMAGE_WORKER,
        command=[
            "/usr/local/bin/checkout.sh",
            test_dir + "/src/github.com"
        ]
    )
    argo_build_util.add_task_to_dag(workflow, ENTRYPOINT, checkout, [])

    # Step 2.1 Build all Katib images.
    depends = []
    for image, dockerfile in KATIB_IMAGES.items():
        build_image = builder.create_task_template(
            task_name="build-"+image,
            exec_image=IMAGE_KANIKO,
            command=[
                "/kaniko/executor",
                "--dockerfile={}/{}".format(builder.katib_dir, dockerfile),
                "--context=dir://" + builder.katib_dir,
                "--destination={}/katib/v1beta1/{}:$(PULL_PULL_SHA)".format(ecr_registry, image)
            ]
        )
        argo_build_util.add_task_to_dag(workflow, ENTRYPOINT, build_image, [checkout["name"]])
        depends.append(build_image["name"])

    # Step 2.2 Create AWS cluster.
    create_cluster = builder.create_task_template(
        task_name="create-cluster",
        exec_image=IMAGE_WORKER,
        command=[
            "/usr/local/bin/create-eks-cluster.sh",
        ]
    )
    argo_build_util.add_task_to_dag(workflow, ENTRYPOINT, create_cluster, [checkout["name"]])
    depends.append(create_cluster["name"])

    # Step 3. Setup Katib on AWS cluster.
    setup_katib = builder.create_task_template(
        task_name="setup-katib",
        exec_image=IMAGE_WORKER,
        command=[
            "test/e2e/v1beta1/scripts/setup-katib.sh"
        ]
    )

    # Installing Katib after cluster is created and images are built.
    argo_build_util.add_task_to_dag(workflow, ENTRYPOINT, setup_katib, depends)

    # Step 4. Run Katib Experiments.
    depends = [setup_katib["name"]]
    tmp_depends = []
    for index, (experiment, location) in enumerate(KATIB_EXPERIMENTS.items()):
        run_experiment = builder.create_task_template(
            task_name="run-e2e-experiment-"+experiment,
            exec_image=IMAGE_WORKER,
            command=[
                "test/e2e/v1beta1/scripts/run-e2e-experiment.sh",
                location
            ]
        )
        argo_build_util.add_task_to_dag(workflow, ENTRYPOINT, run_experiment, depends)
        tmp_depends.append(run_experiment["name"])
        # We run only X number of Experiments at the same time. index starts with 0
        if (index+1) % PARALLEL_EXECUTION == 0:
            depends, tmp_depends = tmp_depends, []

    return workflow



================================================
FILE: test/e2e/v1beta1/hack/aws/run-e2e-experiment.go
================================================
/*
Copyright 2022 The Kubeflow Authors.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package main

import (
	"bytes"
	"context"
	"fmt"
	"log"
	"os"
	"os/exec"
	"strconv"
	"strings"
	"time"

	appsv1 "k8s.io/api/apps/v1"
	corev1 "k8s.io/api/core/v1"
	"k8s.io/apimachinery/pkg/api/equality"
	"k8s.io/apimachinery/pkg/api/errors"
	"k8s.io/apimachinery/pkg/types"
	k8syaml "k8s.io/apimachinery/pkg/util/yaml"
	_ "k8s.io/client-go/plugin/pkg/client/auth/gcp" // For GCP testing
	"sigs.k8s.io/controller-runtime/pkg/client"

	commonv1beta1 "github.com/kubeflow/katib/pkg/apis/controller/common/v1beta1"
	experimentsv1beta1 "github.com/kubeflow/katib/pkg/apis/controller/experiments/v1beta1"
	controllerUtil "github.com/kubeflow/katib/pkg/controller.v1beta1/util"
	"github.com/kubeflow/katib/pkg/util/v1beta1/katibclient"
)

func main() {
	// For AWS we should point KUBECONFIG env to correct folder.
	err := os.Setenv("KUBECONFIG", "/root/.kube/config")
	if err != nil {
		log.Fatalf("Unable to set KUBECONFIG env variable, error: %v", err)
	}

	// First argument should be Experiment yaml path.
	if len(os.Args) != 2 {
		log.Fatal("Path to Experiment yaml is missing")
	}
	expPath := os.Args[1]
	byteExp, err := os.ReadFile(expPath)
	if err != nil {
		log.Fatalf("Error in reading file: %v", err)
	}

	// Replace batch size to number of epochs for faster execution.
	strExp := strings.Replace(string(byteExp), "--batch-size=64", "--num-epochs=2", -1)

	exp := &experimentsv1beta1.Experiment{}
	buf := bytes.NewBufferString(strExp)
	if err := k8syaml.NewYAMLOrJSONDecoder(buf, 1024).Decode(exp); err != nil {
		log.Fatal("Yaml decode error ", err)
	}

	kclient, err := katibclient.NewClient(client.Options{})
	if err != nil {
		log.Fatal("Create NewClient for Katib failed: ", err)
	}

	var maxTrials int32 = 2
	var parallelTrials int32 = 1
	// For random we test 2 parallel execution.
	if exp.Name == "random" {
		maxTrials = 3
		parallelTrials = 2
	}
	if exp.Spec.Algorithm.AlgorithmName != "hyperband" && exp.Spec.Algorithm.AlgorithmName != "darts" {
		// Hyperband will validate the parallel trial count,
		// thus we should not change it.
		// Not necessary to test parallel Trials for Darts.
		exp.Spec.MaxTrialCount = &maxTrials
		exp.Spec.ParallelTrialCount = &parallelTrials
	}
	log.Printf("Creating Experiment %v with MaxTrialCount: %v, ParallelTrialCount: %v", exp.Name, maxTrials, parallelTrials)
	err = kclient.CreateRuntimeObject(exp)
	if err != nil {
		log.Fatalf("CreateRuntimeObject failed: %v", err)
	}

	// Wait until Experiment is finished.
	exp, err = waitExperimentFinish(kclient, exp)
	if err != nil {
		// Delete Experiment in case of error.
		log.Printf("Deleting Experiment %v\n", exp.Name)
		if kclient.DeleteRuntimeObject(exp) != nil {
			log.Fatalf("Unable to delete Experiment %v, error: %v", exp.Name, err)
		}
		log.Fatalf("Wait Experiment finish failed: %v", err)
	}

	// For random example and from volume we restart Experiment.
	if exp.Name == "random" || exp.Name == "from-volume-resume" {
		// Increase parallel Trials and max Trials counts.
		parallelTrials++
		maxTrials += parallelTrials + 1
		exp.Spec.MaxTrialCount = &maxTrials
		exp.Spec.ParallelTrialCount = &parallelTrials

		// Update Experiment with new info.
		err := kclient.UpdateRuntimeObject(exp)
		if err != nil {
			log.Fatalf("UpdateRuntimeObject failed: %v", err)
			// Delete Experiment in case of error.
			log.Printf("Deleting Experiment %v\n", exp.Name)
			if kclient.DeleteRuntimeObject(exp) != nil {
				log.Fatalf("Unable to delete Experiment %v, error: %v", exp.Name, err)
			}
		}

		log.Printf("Restarting Experiment %v with MaxTrialCount: %v, ParallelTrialCount: %v\n\n",
			exp.Name, maxTrials, parallelTrials)

		// Wait until Experiment is restarted.
		timeout := 60 * time.Second
		endTime := time.Now().Add(timeout)
		for time.Now().Before(endTime) {
			exp, err = kclient.GetExperiment(exp.Name, exp.Namespace)
			if err != nil {
				log.Fatalf("Get Experiment error: %v", err)
				// Delete Experiment in case of error
				log.Printf("Deleting Experiment %v\n", exp.Name)
				if kclient.DeleteRuntimeObject(exp) != nil {
					log.Fatalf("Unable to delete Experiment %v, error: %v", exp.Name, err)
				}
			}
			// Once Experiment is restarted stop the waiting loop.
			if exp.IsRestarting() {
				break
			}
			time.Sleep(1 * time.Second)
		}
		// Check if Experiment is not restarting and is not running.
		if !exp.IsRestarting() && !exp.IsRunning() {
			log.Fatalf("Unable to restart Experiment %v, Experiment conditions: %v", exp.Name, exp.Status.Conditions)
			// Delete experiment in case of error.
			log.Printf("Deleting Experiment %v\n", exp.Name)
			if kclient.DeleteRuntimeObject(exp) != nil {
				log.Fatalf("Unable to delete Experiment %v, error: %v", exp.Name, err)
			}
		}
		// Wait until Experiment is finished.
		exp, err = waitExperimentFinish(kclient, exp)
		if err != nil {
			log.Fatalf("Wait Experiment finish failed: %v", err)
			// Delete experiment in case of error
			log.Printf("Deleting Experiment %v\n", exp.Name)
			if kclient.DeleteRuntimeObject(exp) != nil {
				log.Fatalf("Unable to delete Experiment %v, error: %v", exp.Name, err)
			}
		}
	}

	// Verify Experiment results
	err = verifyExperimentResults(kclient, exp)
	if err != nil {
		// Delete Experiment in case of error
		log.Printf("Deleting Experiment %v\n", exp.Name)
		if kclient.DeleteRuntimeObject(exp) != nil {
			log.Fatalf("Unable to delete Experiment %v, error: %v", exp.Name, err)
		}
		log.Fatalf("Verify Experiment results failed: %v", err)
	}

	// Print results.
	err = printResults(exp)
	if err != nil {
		// Delete Experiment in case of error.
		log.Printf("Deleting Experiment %v\n", exp.Name)
		if kclient.DeleteRuntimeObject(exp) != nil {
			log.Fatalf("Unable to delete Experiment %v, error: %v", exp.Name, err)
		}
		log.Fatalf("Print Experiment results failed: %v", err)
	}

	// Delete Experiment.
	log.Printf("Deleting Experiment %v\n", exp.Name)
	if kclient.DeleteRuntimeObject(exp) != nil {
		log.Fatalf("Unable to delete Experiment %v, error: %v", exp.Name, err)
	}

}

func waitExperimentFinish(kclient katibclient.Client, exp *experimentsv1beta1.Experiment) (*experimentsv1beta1.Experiment, error) {
	// Experiment should be completed before the timeout.
	timeout := 50 * time.Minute
	for endTime := time.Now().Add(timeout); time.Now().Before(endTime); {
		exp, err := kclient.GetExperiment(exp.Name, exp.Namespace)
		if err != nil {
			return exp, fmt.Errorf("Get Experiment error: %v", err)
		}

		log.Printf("Waiting for Experiment %s to finish", exp.Name)
		log.Printf(`Experiment is running: %v Trials, %v Pending Trials, %v Running Trials, %v Succeeded Trials, %v Failed Trials, %v EarlyStopped Trials`,
			exp.Status.Trials, exp.Status.TrialsPending, exp.Status.TrialsRunning, exp.Status.TrialsSucceeded, exp.Status.TrialsFailed, exp.Status.TrialsEarlyStopped)
		log.Printf("Current optimal Trial: %v", exp.Status.CurrentOptimalTrial)
		log.Printf("Experiment conditions: %v\n\n\n", exp.Status.Conditions)

		// Check if Experiment is completed.
		if exp.IsCompleted() {
			log.Printf("Experiment %v is finished", exp.Name)
			if exp.IsFailed() {
				return exp, fmt.Errorf("Experiment %v is failed", exp.Name)
			}
			// Print latest condition message.
			log.Printf("%v\n\n", exp.Status.Conditions[len(exp.Status.Conditions)-1].Message)
			// Print Suggestion conditions.
			suggestion, err := kclient.GetSuggestion(exp.Name, exp.Namespace)
			if err != nil {
				return exp, fmt.Errorf("Get Suggestion error: %v", err)
			}
			log.Printf("Suggestion %v. Conditions: %v", suggestion.Name, suggestion.Status.Conditions)
			log.Printf("Suggestion %v. Suggestions: %v\n\n", suggestion.Name, suggestion.Status.Suggestions)

			// Return succeeded Experiment.
			return exp, nil
		}
		time.Sleep(20 * time.Second)
	}

	// If loop is end, Experiment is not finished.
	return exp, fmt.Errorf("Experiment run timed out")
}

func verifyExperimentResults(kclient katibclient.Client, exp *experimentsv1beta1.Experiment) error {

	// Current optimal Trial should be set.
	if equality.Semantic.DeepEqual(exp.Status.CurrentOptimalTrial, experimentsv1beta1.OptimalTrial{}) {
		return fmt.Errorf("Current optimal Trial is empty. Experiment status: %v", exp.Status)
	}

	// Best objective metric should be set.
	var bestObjectiveMetric *commonv1beta1.Metric
	for _, metric := range exp.Status.CurrentOptimalTrial.Observation.Metrics {
		if metric.Name == exp.Spec.Objective.ObjectiveMetricName {
			bestObjectiveMetric = &metric
			break
		}
	}
	if bestObjectiveMetric == nil {
		return fmt.Errorf("Unable to get best metrics for objective: %v", exp.Spec.Objective.ObjectiveMetricName)
	}

	// Verify objective metric.
	objectiveType := exp.Spec.Objective.Type
	goal := exp.Spec.Objective.Goal
	// If min metric is set, max be set also.
	minMetric, err := strconv.ParseFloat(bestObjectiveMetric.Min, 64)
	maxMetric, _ := strconv.ParseFloat(bestObjectiveMetric.Max, 64)

	// If metrics can't be parsed to float or goal is empty, succeeded Trials should be equal to MaxTrialCount.
	if (err != nil || goal == nil) && exp.Status.TrialsSucceeded != *exp.Spec.MaxTrialCount {
		return fmt.Errorf("All trials are not successful. MaxTrialCount: %v, TrialsSucceeded: %v",
			*exp.Spec.MaxTrialCount, exp.Status.TrialsSucceeded)
	}

	trialsCompleted := exp.Status.TrialsSucceeded
	if exp.Spec.EarlyStopping != nil {
		trialsCompleted += exp.Status.TrialsEarlyStopped
	}

	// Otherwise, Goal should be reached.
	if trialsCompleted != *exp.Spec.MaxTrialCount &&
		((objectiveType == commonv1beta1.ObjectiveTypeMinimize && minMetric > *goal) ||
			(objectiveType == commonv1beta1.ObjectiveTypeMaximize && maxMetric < *goal)) {
		return fmt.Errorf(`Objective Goal is not reached and Succeeded Trials: %v != %v MaxTrialCount.
			ObjectiveType: %v, Goal: %v, MinMetric: %v, MaxMetric: %v`,
			exp.Status.TrialsSucceeded, *exp.Spec.MaxTrialCount,
			objectiveType, *goal, minMetric, maxMetric)
	}

	err = verifySuggestion(kclient, exp)
	if err != nil {
		return fmt.Errorf("Verify Suggestion failed: %v", err)
	}
	return nil
}

func verifySuggestion(kclient katibclient.Client, exp *experimentsv1beta1.Experiment) error {

	// Verify Suggestion's resources.
	sug, err := kclient.GetSuggestion(exp.Name, exp.Namespace)
	if err != nil {
		return fmt.Errorf("GetSuggestion failed: %v", err)
	}

	// When Suggestion is LongRunning, it can't be succeeded.
	if exp.Spec.ResumePolicy == experimentsv1beta1.LongRunning && sug.IsSucceeded() {
		return fmt.Errorf("Suggestion is succeeded while ResumePolicy = %v", experimentsv1beta1.LongRunning)
	}

	// Verify Suggestion with resume policy Never and FromVolume.
	if exp.Spec.ResumePolicy == experimentsv1beta1.NeverResume || exp.Spec.ResumePolicy == experimentsv1beta1.FromVolume {

		// Give controller time to delete Suggestion resources and change Suggestion status.
		// TODO (andreyvelich): Think about better way to handle this.
		time.Sleep(10 * time.Second)

		// When Suggestion has resume policy Never or FromVolume, it should be not running.
		if sug.IsRunning() {
			return fmt.Errorf("Suggestion is still running while ResumePolicy = %v", exp.Spec.ResumePolicy)
		}

		// Suggestion service should be deleted.
		serviceName := controllerUtil.GetSuggestionServiceName(sug)
		namespacedName := types.NamespacedName{Name: serviceName, Namespace: sug.Namespace}
		err = kclient.GetClient().Get(context.TODO(), namespacedName, &corev1.Service{})
		if errors.IsNotFound(err) {
			log.Printf("Suggestion service %v has been deleted", serviceName)
		} else {
			return fmt.Errorf("Suggestion service: %v is still alive while ResumePolicy: %v, error: %v", serviceName, exp.Spec.ResumePolicy, err)
		}

		// Suggestion deployment should be deleted.
		deploymentName := controllerUtil.GetSuggestionDeploymentName(sug)
		namespacedName = types.NamespacedName{Name: deploymentName, Namespace: sug.Namespace}
		err = kclient.GetClient().Get(context.TODO(), namespacedName, &appsv1.Deployment{})
		if errors.IsNotFound(err) {
			log.Printf("Suggestion deployment %v has been deleted", deploymentName)
		} else {
			return fmt.Errorf("Suggestion deployment: %v is still alive while ResumePolicy: %v, error: %v", deploymentName, exp.Spec.ResumePolicy, err)
		}

		// PVC should not be deleted for Suggestion with resume policy FromVolume.
		if exp.Spec.ResumePolicy == experimentsv1beta1.FromVolume {
			pvcName := controllerUtil.GetSuggestionPersistentVolumeClaimName(sug)
			namespacedName = types.NamespacedName{Name: pvcName, Namespace: sug.Namespace}
			err = kclient.GetClient().Get(context.TODO(), namespacedName, &corev1.PersistentVolumeClaim{})
			if errors.IsNotFound(err) {
				return fmt.Errorf("suggestion PVC: %v is not alive while ResumePolicy: %v", pvcName, exp.Spec.ResumePolicy)
			}
		}
	}
	return nil
}

func printResults(exp *experimentsv1beta1.Experiment) error {
	log.Printf("Experiment has recorded best current Optimal Trial %v\n\n", exp.Status.CurrentOptimalTrial)

	// Describe the Experiment.
	cmd := exec.Command("kubectl", "describe", "experiment", exp.Name, "-n", exp.Namespace)
	out, err := cmd.Output()
	if err != nil {
		return fmt.Errorf("Execute \"kubectl describe suggestion\" failed: %v", err)
	}
	log.Println(cmd.String())
	log.Printf("\n%v\n\n", string(out))

	// Describe the Suggestion.
	cmd = exec.Command("kubectl", "describe", "suggestion", exp.Name, "-n", exp.Namespace)
	out, err = cmd.Output()
	if err != nil {
		return fmt.Errorf("Execute \"kubectl describe experiment\" failed: %v", err)
	}
	log.Println(cmd.String())
	log.Printf("\n%v", string(out))

	return nil
}



================================================
FILE: test/e2e/v1beta1/scripts/aws/run-e2e-experiment.sh
================================================
#!/usr/bin/env bash

# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This shell script is used to run Katib Experiment.
# Input parameter - path to Experiment yaml.

set -o errexit
set -o nounset
set -o pipefail

EXPERIMENT_FILE=$1

echo "Configuring kubeconfig.."
aws eks update-kubeconfig --region="${AWS_REGION}" --name="${CLUSTER_NAME}"

echo "Katib deployments"
kubectl -n kubeflow get deploy
echo "Katib services"
kubectl -n kubeflow get svc
echo "Katib pods"
kubectl -n kubeflow get pod
echo "Katib persistent volume claims"
kubectl get pvc -n kubeflow
echo "Available CRDs"
kubectl get crd

echo "Running Experiment from ${EXPERIMENT_FILE} file"
./run-e2e-experiment "${EXPERIMENT_FILE}"

exit 0



================================================
FILE: test/e2e/v1beta1/scripts/aws/setup-katib.sh
================================================
#!/usr/bin/env bash

# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This shell script is used to setup Katib deployment.

set -o errexit
set -o nounset
set -o pipefail

echo "Start to install Katib"
echo "CLUSTER_NAME: ${CLUSTER_NAME}"
echo "AWS_REGION: ${AWS_REGION}"
echo "ECR_REGISTRY: ${ECR_REGISTRY}"
echo "VERSION: ${PULL_PULL_SHA}"

echo "Configuring kubeconfig.."
aws eks update-kubeconfig --region="${AWS_REGION}" --name="${CLUSTER_NAME}"
kubectl version
kubectl cluster-info

# Update Katib images with the current PULL SHA.
make update-images OLD_PREFIX="ghcr.io/kubeflow/katib/" NEW_PREFIX="${ECR_REGISTRY}/${REPO_NAME}/v1beta1/" TAG="${PULL_PULL_SHA}"

echo -e "\n The Katib will be deployed with the following configs"
cat "manifests/v1beta1/installs/katib-standalone/kustomization.yaml"
cat "manifests/v1beta1/installs/katib-standalone/katib-config.yaml"

echo "Creating Kubeflow namespace"
kubectl create namespace kubeflow

cd "${MANIFESTS_DIR}/apps/training-operator/upstream/overlays/kubeflow"
echo "Deploying Training Operator from kubeflow/manifests $(git rev-parse --abbrev-ref HEAD)"
kustomize build . | kubectl apply -f -

echo "Deploying Katib"
cd "${GOPATH}/src/github.com/kubeflow/katib"
make deploy

# Wait until all Katib pods is running.
TIMEOUT=120s
kubectl wait --for=condition=ready --timeout=${TIMEOUT} -l "katib.kubeflow.org/component in (controller,db-manager,mysql,ui)" -n kubeflow pod

echo "All Katib components are running."
echo "Katib deployments"
kubectl -n kubeflow get deploy
echo "Katib services"
kubectl -n kubeflow get svc
echo "Katib pods"
kubectl -n kubeflow get pod

# We should update Trial images after Katib is deployed since they have "trial-" in private ECR image name.
make update-images OLD_PREFIX="${ECR_REGISTRY}/${REPO_NAME}/v1beta1/" NEW_PREFIX="${ECR_REGISTRY}/${REPO_NAME}/v1beta1/trial-" TAG="${PULL_PULL_SHA}"

# Check that Katib is working with 2 Experiments.
kubectl apply -f test/e2e/v1beta1/valid-experiment.yaml
kubectl delete -f test/e2e/v1beta1/valid-experiment.yaml

set +o errexit
kubectl apply -f test/e2e/v1beta1/invalid-experiment.yaml
if [ $? -ne 1 ]; then
  echo "Failed to create invalid-experiment: return code $?"
  exit 1
fi

# TODO (tenzen-y): Once the changes on https://github.com/kubeflow/testing/pull/974 are reflected in the `public.ecr.aws` registry, we must remove this process.
# To avoid the `../../../../pkg/mod/k8s.io/client-go@v0.22.2/plugin/pkg/client/auth/exec/metrics.go:21:2: package io/fs is not in GOROOT (/usr/local/go/src/io/fs)` error,
# we must use Go v1.16 or later, but as described in https://github.com/kubeflow/training-operator/issues/1581,
# we do not have permission to update `public.ecr.aws/j1r0q0g6/kubeflow-testing:latest` so we need to update it in this.
rm -rf /usr/local/go
wget -O /tmp/go.tar.gz https://dl.google.com/go/go1.17.10.linux-amd64.tar.gz && tar -C /usr/local -xzf /tmp/go.tar.gz

# Build the binary for e2e test
echo "Building run-e2e-experiment for e2e test cases"
go build -o run-e2e-experiment test/e2e/v1beta1/run-e2e-experiment.go

exit 0



================================================
FILE: test/e2e/v1beta1/scripts/gh-actions/build-load.sh
================================================
#!/usr/bin/env bash

# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This script is used to build all Katib images.
# Run ./scripts/v1beta1/build.sh <IMAGE_REGISTRY> <TAG> to execute it.

set -o errexit
set -o pipefail
set -o nounset

pushd .
cd "$(dirname "$0")/../../../../.."
trap popd EXIT

DEPLOY_KATIB_UI=${1:-false}
TUNE_API=${2:-false}
TRIAL_IMAGES=${3:-""}
EXPERIMENTS=${4:-""}

REGISTRY="ghcr.io/kubeflow/katib"
TAG="e2e-test"
VERSION="v1beta1"
CMD_PREFIX="cmd"
SPECIFIED_DEVICE_TYPE_IMAGES=("enas-cnn-cifar10-cpu" "darts-cnn-cifar10-cpu" "pytorch-mnist-cpu")

IFS="," read -r -a TRIAL_IMAGE_ARRAY <<< "$TRIAL_IMAGES"
IFS="," read -r -a EXPERIMENT_ARRAY <<< "$EXPERIMENTS"

_build_containers() {
  CONTAINER_NAME=${1:-"katib-controller"}
  DOCKERFILE=${2:-"$CMD_PREFIX/katib-controller/$VERSION/Dockerfile"}

  for image in "${SPECIFIED_DEVICE_TYPE_IMAGES[@]}"; do
    if [ "$image" = "$CONTAINER_NAME" ]; then
      DOCKERFILE="${DOCKERFILE//-cpu/}"
      DOCKERFILE="${DOCKERFILE}.cpu"
      break
    fi
  done

  echo -e "\nBuilding $CONTAINER_NAME image with $DOCKERFILE...\n"
  DOCKER_BUILDKIT=1 minikube image build --build-opt platform=linux/amd64 --all -t "$REGISTRY/$CONTAINER_NAME:$TAG" -f "$DOCKERFILE" .
}

_install_tools() {
  # install yq
  if [ -z "$(command -v yq)" ]; then
    wget -O /usr/local/bin/yq "https://github.com/mikefarah/yq/releases/download/v4.25.2/yq_$(uname -s)_$(uname -m)"
    chmod +x /usr/local/bin/yq
  fi
}

run() {
  CONTAINER_NAME=${1:-"katib-controller"}
  DOCKERFILE=${2:-"$CMD_PREFIX/katib-controller/$VERSION/Dockerfile"}

  _install_tools

  # CONTAINER_NAME is image for suggestion services
  if echo "$CONTAINER_NAME" | grep -q "^suggestion-"; then

    suggestions=()

    # Search for Suggestion Images required for Trial.
    for exp_name in "${EXPERIMENT_ARRAY[@]}"; do

      exp_path=$(find examples/v1beta1 -name "${exp_name}.yaml")
      algorithm_name="$(yq eval '.spec.algorithm.algorithmName' "$exp_path")"

      suggestion_image_name="$(algorithm_name=$algorithm_name yq eval '.runtime.suggestions.[] | select(.algorithmName == env(algorithm_name)) | .image' \
        manifests/v1beta1/installs/katib-standalone/katib-config.yaml | cut -d: -f1)"
      suggestion_name="$(basename "$suggestion_image_name")"

      suggestions+=("$suggestion_name")

    done

    for s in "${suggestions[@]}"; do
      if [ "$s" == "$CONTAINER_NAME" ]; then
        _build_containers "$CONTAINER_NAME" "$DOCKERFILE"
        break
      fi
    done

  # $CONTAINER_NAME is image for earlystopping services
  elif echo "$CONTAINER_NAME" | grep -q "^earlystopping-"; then

    earlystoppings=()

    # Search for EarlyStopping Images required for Trial.
    for exp_name in "${EXPERIMENT_ARRAY[@]}"; do

      exp_path=$(find examples/v1beta1 -name "${exp_name}.yaml")
      algorithm_name="$(yq eval '.spec.earlyStopping.algorithmName' "$exp_path")"

      earlystopping_image_name="$(algorithm_name=$algorithm_name yq eval '.runtime.earlyStoppings.[] | select(.algorithmName == env(algorithm_name)) | .image' \
        manifests/v1beta1/installs/katib-standalone/katib-config.yaml | cut -d: -f1)"
      earlystopping_name="$(basename "$earlystopping_image_name")"

      earlystoppings+=("$earlystopping_name")

    done

    for e in "${earlystoppings[@]}"; do
      if [ "$e" == "$CONTAINER_NAME" ]; then
        _build_containers "$CONTAINER_NAME" "$DOCKERFILE"
        break
      fi
    done

  # Others
  else
    _build_containers "$CONTAINER_NAME" "$DOCKERFILE"
  fi
}

echo "Building images for Katib ${VERSION}..."
echo "Image registry: ${REGISTRY}"
echo "Image tag: ${TAG}"

# Katib core images
run "katib-controller" "$CMD_PREFIX/katib-controller/$VERSION/Dockerfile"
run "katib-db-manager" "$CMD_PREFIX/db-manager/$VERSION/Dockerfile"

if "$DEPLOY_KATIB_UI"; then
  run "katib-ui" "${CMD_PREFIX}/ui/${VERSION}/Dockerfile"
fi

run "file-metrics-collector" "$CMD_PREFIX/metricscollector/$VERSION/file-metricscollector/Dockerfile"
run "tfevent-metrics-collector" "$CMD_PREFIX/metricscollector/$VERSION/tfevent-metricscollector/Dockerfile"

# Suggestion images
echo -e "\nBuilding suggestion images..."
run "suggestion-hyperopt" "$CMD_PREFIX/suggestion/hyperopt/$VERSION/Dockerfile"
run "suggestion-hyperband" "$CMD_PREFIX/suggestion/hyperband/$VERSION/Dockerfile"
run "suggestion-skopt" "$CMD_PREFIX/suggestion/skopt/$VERSION/Dockerfile"
run "suggestion-goptuna" "$CMD_PREFIX/suggestion/goptuna/$VERSION/Dockerfile"
run "suggestion-optuna" "$CMD_PREFIX/suggestion/optuna/$VERSION/Dockerfile"
run "suggestion-pbt" "$CMD_PREFIX/suggestion/pbt/$VERSION/Dockerfile"
run "suggestion-enas" "$CMD_PREFIX/suggestion/nas/enas/$VERSION/Dockerfile"
run "suggestion-darts" "$CMD_PREFIX/suggestion/nas/darts/$VERSION/Dockerfile"

# Early stopping images
echo -e "\nBuilding early stopping images...\n"
run "earlystopping-medianstop" "$CMD_PREFIX/earlystopping/medianstop/$VERSION/Dockerfile"

# Training container images
echo -e "\nBuilding training container images..."
for name in "${TRIAL_IMAGE_ARRAY[@]}"; do
  run "$name" "examples/$VERSION/trial-images/$name/Dockerfile"
done

# Testing image for tune function
if "$TUNE_API"; then
  echo -e "\nPulling and building testing image for tune function..."
  _build_containers "suggestion-hyperopt" "$CMD_PREFIX/suggestion/hyperopt/$VERSION/Dockerfile"
fi

echo -e "\nCleanup Build Cache...\n"
docker buildx prune -f

echo -e "\nAll Katib images with ${TAG} tag have been built successfully!\n"



================================================
FILE: test/e2e/v1beta1/scripts/gh-actions/run-e2e-experiment.py
================================================
import argparse
import logging

import yaml
from kubeflow.katib import ApiClient, KatibClient, models
from kubeflow.katib.constants import constants
from kubeflow.katib.utils.utils import FakeResponse
from kubernetes import client
from verify import verify_experiment_results

# Experiment timeout is 40 min.
EXPERIMENT_TIMEOUT = 60 * 40

# The default logging config.
logging.basicConfig(level=logging.INFO)


def run_e2e_experiment(
    katib_client: KatibClient,
    experiment: models.V1beta1Experiment,
    exp_name: str,
    exp_namespace: str,
):

    # Create Katib Experiment and wait until it is finished.
    logging.debug(
        "Creating Experiment: {}/{} with MaxTrialCount: {}, ParallelTrialCount: {}".format(
            exp_namespace,
            exp_name,
            experiment.spec.max_trial_count,
            experiment.spec.parallel_trial_count,
        )
    )

    # Wait until Experiment reaches Succeeded condition.
    katib_client.create_experiment(experiment, exp_namespace)
    experiment = katib_client.wait_for_experiment_condition(
        exp_name, exp_namespace, timeout=EXPERIMENT_TIMEOUT
    )

    # Test resume feature for "FromVolume" and "LongRunning" Experiments.
    if exp_name == "from-volume-resume" or exp_name == "long-running-resume":
        max_trial_count = experiment.spec.max_trial_count + 1
        parallel_trial_count = experiment.spec.parallel_trial_count + 1
        logging.debug(
            f"Restarting Experiment {exp_namespace}/{exp_name} "
            f"with MaxTrialCount: {max_trial_count} and ParallelTrialCount: {parallel_trial_count}"
        )

        # Modify Experiment budget.
        katib_client.edit_experiment_budget(
            exp_name, exp_namespace, max_trial_count, parallel_trial_count
        )
        # Wait until Experiment is Restarted.
        katib_client.wait_for_experiment_condition(
            exp_name,
            exp_namespace,
            constants.EXPERIMENT_CONDITION_RESTARTING,
            EXPERIMENT_TIMEOUT,
        )
        # Wait until Experiment is Succeeded.
        experiment = katib_client.wait_for_experiment_condition(
            exp_name, exp_namespace, timeout=EXPERIMENT_TIMEOUT
        )

    # Verify the Experiment results.
    verify_experiment_results(katib_client, experiment, exp_name, exp_namespace)

    # Print the Experiment and Suggestion.
    logging.debug(katib_client.get_experiment(exp_name, exp_namespace))
    logging.debug(katib_client.get_suggestion(exp_name, exp_namespace))


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--experiment-path",
        type=str,
        required=True,
        help="Path to the Katib Experiment.",
    )
    parser.add_argument(
        "--namespace", type=str, required=True, help="Namespace for the Katib E2E test",
    )
    parser.add_argument(
        "--trial-pod-annotations", type=str, help="Annotation for the pod created by trial",
    )
    parser.add_argument(
        "--verbose", action="store_true", help="Verbose output for the Katib E2E test",
    )
    args = parser.parse_args()

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    logging.info("---------------------------------------------------------------")
    logging.info("---------------------------------------------------------------")
    logging.info(f"Start E2E test for the Katib Experiment: {args.experiment_path}")

    # Read Experiment YAML to Fake Response object.
    with open(args.experiment_path, "r") as file:
        experiment = FakeResponse(yaml.safe_load(file))

    # Replace batch size to number of epochs for faster execution.
    experiment.data = experiment.data.replace("--batch-size=64", "--num-epochs=2")

    # Convert to the Katib Experiment object.
    experiment = ApiClient().deserialize(experiment, "V1beta1Experiment")
    experiment.metadata.namespace = args.namespace
    exp_name = experiment.metadata.name
    exp_namespace = experiment.metadata.namespace

    # Set Trial threshold for Katib Experiments.
    MAX_TRIAL_COUNT = 2
    PARALLEL_TRIAL_COUNT = 1
    MAX_FAILED_TRIAL_COUNT = 0

    # For one random search Experiment we test parallel execution.
    if experiment.metadata.name == "random":
        MAX_TRIAL_COUNT += 1
        PARALLEL_TRIAL_COUNT += 1
        if args.trial_pod_annotations:
            kind = experiment.spec.trial_template.trial_spec['kind']
            if kind != "Job":
                raise NotImplementedError(f'Trail pod annotations not implemented for {kind}!')

            trial_spec_metadata = experiment.spec.trial_template.trial_spec['spec']['template'].get('metadata', {})
            trial_spec_pod_annotations = trial_spec_metadata.get('annotations', {})
            trial_spec_pod_annotations.update(eval(args.trial_pod_annotations))
            trial_spec_metadata['annotations'] = trial_spec_pod_annotations
            experiment.spec.trial_template.trial_spec['spec']['template']['metadata'] = trial_spec_metadata

    # Hyperband will validate the parallel trial count, thus we should not change it.
    # We don't need to test parallel Trials for Darts.
    if (
        experiment.spec.algorithm.algorithm_name != "hyperband"
        and experiment.spec.algorithm.algorithm_name != "darts"
    ):
        experiment.spec.max_trial_count = MAX_TRIAL_COUNT
        experiment.spec.parallel_trial_count = PARALLEL_TRIAL_COUNT
        experiment.spec.max_failed_trial_count = MAX_FAILED_TRIAL_COUNT

    katib_client = KatibClient()

    namespace_labels = client.CoreV1Api().read_namespace(args.namespace).metadata.labels
    if 'katib.kubeflow.org/metrics-collector-injection' not in namespace_labels:
        namespace_labels['katib.kubeflow.org/metrics-collector-injection'] = 'enabled'
        client.CoreV1Api().patch_namespace(args.namespace, {'metadata': {'labels': namespace_labels}})

    try:
        run_e2e_experiment(katib_client, experiment, exp_name, exp_namespace)
        logging.info("---------------------------------------------------------------")
        logging.info(f"E2E is succeeded for Experiment: {exp_namespace}/{exp_name}")
    except Exception as e:
        logging.info("---------------------------------------------------------------")
        logging.info(f"E2E is failed for Experiment: {exp_namespace}/{exp_name}")
        raise e
    finally:
        # Delete the Experiment.
        logging.info("---------------------------------------------------------------")
        logging.info("---------------------------------------------------------------")
        katib_client.delete_experiment(exp_name, exp_namespace)



================================================
FILE: test/e2e/v1beta1/scripts/gh-actions/run-e2e-experiment.sh
================================================
#!/usr/bin/env bash

# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This shell script is used to run Katib Experiment.
# Input parameter - path to Experiment yaml.

set -o errexit
set -o nounset
set -o pipefail

cd "$(dirname "$0")"
EXPERIMENT_FILES=${1:-""}
IFS="," read -r -a EXPERIMENT_FILE_ARRAY <<< "$EXPERIMENT_FILES"

echo "Katib deployments"
kubectl -n kubeflow get deploy
echo "Katib services"
kubectl -n kubeflow get svc
echo "Katib pods"
kubectl -n kubeflow get pod
echo "Katib persistent volume claims"
kubectl get pvc -n kubeflow
echo "Available CRDs"
kubectl get crd

if [ -z "$EXPERIMENT_FILES" ]; then
  echo "Skip Test for Experiment"
  exit 0
fi

for exp_name in "${EXPERIMENT_FILE_ARRAY[@]}"; do
  echo "Running Experiment from $exp_name file"
  exp_path=$(find ../../../../../examples/v1beta1 -name "${exp_name}.yaml")
  python run-e2e-experiment.py --experiment-path "${exp_path}" --namespace default \
  --verbose || (kubectl get pods -n kubeflow && exit 1)
done

exit 0



================================================
FILE: test/e2e/v1beta1/scripts/gh-actions/run-e2e-tune-api.py
================================================
import argparse
import logging
from pprint import pformat

import kubeflow.katib as katib
from kubeflow.katib import KatibClient, search
from kubeflow.katib.types.types import TrainerResources
from kubernetes import client
from verify import verify_experiment_results

# Experiment timeout is 40 min.
EXPERIMENT_TIMEOUT = 60 * 40

# The default logging config.
logging.basicConfig(level=logging.INFO)

def run_e2e_experiment_create_by_tune(
    katib_client: KatibClient,
    exp_name: str,
    exp_namespace: str,
):
    # Create Katib Experiment and wait until it is finished.
    logging.debug("Creating Experiment: {}/{}".format(exp_namespace, exp_name))

    # Use the test case from get-started tutorial.
    # https://www.kubeflow.org/docs/components/katib/getting-started/#getting-started-with-katib-python-sdk
    # [1] Create an objective function.
    def objective(parameters):
        import time

        time.sleep(5)
        result = 4 * int(parameters["a"]) - float(parameters["b"]) ** 2
        print(f"result={result}")

    # [2] Create hyperparameter search space.
    parameters = {"a": search.int(min=10, max=20), "b": search.double(min=0.1, max=0.2)}

    # [3] Create Katib Experiment with 4 Trials and 2 CPUs per Trial.
    # And Wait until Experiment reaches Succeeded condition.
    katib_client.tune(
        name=exp_name,
        namespace=exp_namespace,
        objective=objective,
        parameters=parameters,
        objective_metric_name="result",
        max_trial_count=4,
        resources_per_trial={"cpu": "100m"},
    )
    experiment = katib_client.wait_for_experiment_condition(
        exp_name, exp_namespace, timeout=EXPERIMENT_TIMEOUT
    )

    # Verify the Experiment results.
    verify_experiment_results(katib_client, experiment, exp_name, exp_namespace)

    # Print the Experiment and Suggestion.
    logging.debug("Experiment:\n%s", pformat(katib_client.get_experiment(exp_name, exp_namespace)))
    logging.debug("Suggestion:\n%s", pformat(katib_client.get_suggestion(exp_name, exp_namespace)))

def run_e2e_experiment_create_by_tune_pytorchjob(
    katib_client: KatibClient,
    exp_name: str,
    exp_namespace: str,
):
    # Create Katib Experiment and wait until it is finished.
    logging.debug("Creating Experiment: {}/{}".format(exp_namespace, exp_name))

    # Verify the PyTorchJob distributed.
    def objective(parameters):
        import os
        import time

        import torch.distributed as dist

        # Setup PyTorch distributed.
        dist.init_process_group(backend="gloo")

        print(
            "PyTorch Dist. WORLD_SIZE: {}, RANK: {}, LOCAL_RANK: {}".format(
                dist.get_world_size(), dist.get_rank(), os.getenv("LOCAL_RANK")
            )
        )

        time.sleep(5)
        # Only get results from the process with RANK=0.
        if dist.get_rank() == 0:
            result = 4 * int(parameters["a"]) - float(parameters["b"]) ** 2
            print(f"result={result}")
        dist.destroy_process_group()

    # Create Katib Experiment with 3 Trials. Every Trial runs PyTorchJob with 2 workers.
    katib_client.tune(
        name=exp_name,
        namespace=exp_namespace,
        objective=objective,
        parameters={
            "a": search.int(min=10, max=20),
            "b": search.double(min=0.1, max=0.2),
        },
        objective_metric_name="result",
        max_trial_count=3,
        parallel_trial_count=2,
        resources_per_trial=TrainerResources(
            num_workers=2,
            num_procs_per_worker=2,
            resources_per_worker={"cpu": "100m"},
        ),
    )

    experiment = katib_client.wait_for_experiment_condition(
        exp_name, exp_namespace, timeout=EXPERIMENT_TIMEOUT
    )

    # Verify the Experiment results.
    verify_experiment_results(katib_client, experiment, exp_name, exp_namespace)

    # Print the Experiment and Suggestion.
    logging.debug("Experiment:\n%s", pformat(katib_client.get_experiment(exp_name, exp_namespace)))
    logging.debug("Suggestion:\n%s", pformat(katib_client.get_suggestion(exp_name, exp_namespace)))

def run_e2e_experiment_create_by_tune_with_llm_optimization(
    katib_client: KatibClient,
    exp_name: str,
    exp_namespace: str,
):
    import transformers
    from kubeflow.storage_initializer.hugging_face import (
        HuggingFaceDatasetParams,
        HuggingFaceModelParams,
        HuggingFaceTrainerParams,
    )
    from peft import LoraConfig

    # Create Katib Experiment and wait until it is finished.
    logging.debug("Creating Experiment: {}/{}".format(exp_namespace, exp_name))
    
    # Use the test case from fine-tuning API tutorial.
    # https://www.kubeflow.org/docs/components/training/user-guides/fine-tuning/
    # Create Katib Experiment.
    # And Wait until Experiment reaches Succeeded condition.
    katib_client.tune(
        name=exp_name,
        namespace=exp_namespace,
        # BERT model URI and type of Transformer to train it.
        model_provider_parameters=HuggingFaceModelParams(
            model_uri="hf://google-bert/bert-base-cased",
            transformer_type=transformers.AutoModelForSequenceClassification,
            num_labels=5,
        ),
        # In order to save test time, use 8 samples from Yelp dataset.
        dataset_provider_parameters=HuggingFaceDatasetParams(
            repo_id="yelp_review_full",
            split="train[:8]",
        ),
        # Specify HuggingFace Trainer parameters.
        trainer_parameters=HuggingFaceTrainerParams(
            training_parameters=transformers.TrainingArguments(
                output_dir="test_tune_api",
                save_strategy="no",
                learning_rate = search.double(min=1e-05, max=5e-05),
                num_train_epochs=1,
            ),
            # Set LoRA config to reduce number of trainable model parameters.
            lora_config=LoraConfig(
                r = search.int(min=8, max=32),
                lora_alpha=8,
                lora_dropout=0.1,
                bias="none",
            ),
        ),
        objective_metric_name = "train_loss", 
        objective_type = "minimize", 
        algorithm_name = "random",
        max_trial_count = 1,
        parallel_trial_count = 1,
        resources_per_trial=katib.TrainerResources(
            num_workers=1,
            num_procs_per_worker=1,
            resources_per_worker={"cpu": "2", "memory": "10G",},
        ),
        storage_config={
            "size": "10Gi",
            "access_modes": ["ReadWriteOnce"],
        },
        retain_trials=True,
    )
    experiment = katib_client.wait_for_experiment_condition(
        exp_name, exp_namespace, timeout=EXPERIMENT_TIMEOUT
    )

    # Verify the Experiment results.
    verify_experiment_results(katib_client, experiment, exp_name, exp_namespace)

    # Print the Experiment and Suggestion.
    logging.debug("Experiment:\n%s", pformat(katib_client.get_experiment(exp_name, exp_namespace)))
    logging.debug("Suggestion:\n%s", pformat(katib_client.get_suggestion(exp_name, exp_namespace)))

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--namespace",
        type=str,
        required=True,
        help="Namespace for the Katib E2E test",
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Verbose output for the Katib E2E test",
    )
    args = parser.parse_args()

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    katib_client = KatibClient()

    namespace_labels = client.CoreV1Api().read_namespace(args.namespace).metadata.labels
    if "katib.kubeflow.org/metrics-collector-injection" not in namespace_labels:
        namespace_labels["katib.kubeflow.org/metrics-collector-injection"] = "enabled"
        client.CoreV1Api().patch_namespace(
            args.namespace, {"metadata": {"labels": namespace_labels}}
        )

    # Test with run_e2e_experiment_create_by_tune
    exp_name = "tune-example"
    exp_namespace = args.namespace
    try:
        run_e2e_experiment_create_by_tune(katib_client, exp_name, exp_namespace)
        logging.info("---------------------------------------------------------------")
        logging.info(
            f"E2E is succeeded for Experiment created by tune: {exp_namespace}/{exp_name}"
        )
    except Exception as e:
        logging.info("---------------------------------------------------------------")
        logging.info(
            f"E2E is failed for Experiment created by tune: {exp_namespace}/{exp_name}"
        )
        raise e
    finally:
        # Delete the Experiment.
        logging.info("---------------------------------------------------------------")
        logging.info("---------------------------------------------------------------")
        katib_client.delete_experiment(exp_name, exp_namespace)

    # Test with run_e2e_experiment_create_by_tune_pytorchjob
    exp_name = "tune-example-pytorchjob"
    exp_namespace = args.namespace
    try:
        run_e2e_experiment_create_by_tune_pytorchjob(
            katib_client, exp_name, exp_namespace
        )
        logging.info("---------------------------------------------------------------")
        logging.info(
            f"E2E is succeeded for Experiment created by tune with PyTorchJob: {exp_namespace}/{exp_name}"
        )
    except Exception as e:
        logging.info("---------------------------------------------------------------")
        logging.info(
            f"E2E is failed for Experiment created by tune with PyTorchJob: {exp_namespace}/{exp_name}"
        )
        raise e
    finally:
        # Delete the Experiment.
        logging.info("---------------------------------------------------------------")
        logging.info("---------------------------------------------------------------")
        katib_client.delete_experiment(exp_name, exp_namespace)

    exp_name = "tune-example-llm-optimization"
    exp_namespace = args.namespace
    try:
        run_e2e_experiment_create_by_tune_with_llm_optimization(katib_client, exp_name, exp_namespace)
        logging.info("---------------------------------------------------------------")
        logging.info(f"E2E is succeeded for Experiment created by tune: {exp_namespace}/{exp_name}")
    except Exception as e:
        logging.info("---------------------------------------------------------------")
        logging.info(f"E2E is failed for Experiment created by tune: {exp_namespace}/{exp_name}")
        raise e
    finally:
        # Delete the Experiment.
        logging.info("---------------------------------------------------------------")
        logging.info("---------------------------------------------------------------")
        katib_client.delete_experiment(exp_name, exp_namespace)



================================================
FILE: test/e2e/v1beta1/scripts/gh-actions/run-e2e-tune-api.sh
================================================
#!/usr/bin/env bash

# Copyright 2024 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This shell script is used to run Katib Experiment.
# Input parameter - path to Experiment yaml.

set -o errexit
set -o nounset
set -o pipefail

cd "$(dirname "$0")"

echo "Katib deployments"
kubectl -n kubeflow get deploy
echo "Katib services"
kubectl -n kubeflow get svc
echo "Katib pods"
kubectl -n kubeflow get pod
echo "Katib persistent volume claims"
kubectl get pvc -n kubeflow
echo "Available CRDs"
kubectl get crd

python run-e2e-tune-api.py --namespace default \
--verbose || (kubectl get pods -n kubeflow && exit 1)



================================================
FILE: test/e2e/v1beta1/scripts/gh-actions/setup-katib.sh
================================================
#!/usr/bin/env bash

# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This shell script is used to setup Katib deployment.
set -o errexit
set -o pipefail
set -o nounset
cd "$(dirname "$0")"

DEPLOY_KATIB_UI=${1:-false}
DEPLOY_TRAINING_OPERATOR=${2:-false}
WITH_DATABASE_TYPE=${3:-mysql}

E2E_TEST_IMAGE_TAG="e2e-test"
TRAINING_OPERATOR_VERSION="v1.9.0"

echo "Start to install Katib"

# Update Katib images with `e2e-test`.
cd ../../../../../ && make update-images OLD_PREFIX="ghcr.io/kubeflow/katib/" NEW_PREFIX="ghcr.io/kubeflow/katib/" TAG="$E2E_TEST_IMAGE_TAG" && cd -

# first declare the which kustomization file to use, by default use mysql.
KUSTOMIZATION_FILE="../../../../../manifests/v1beta1/installs/katib-standalone/kustomization.yaml"
PVC_FILE="../../../../../manifests/v1beta1/components/mysql/pvc.yaml"

# If the database type is postgres, then use postgres.
if [ "$WITH_DATABASE_TYPE" == "postgres" ]; then
  KUSTOMIZATION_FILE="../../../../../manifests/v1beta1/installs/katib-standalone-postgres/kustomization.yaml"
  PVC_FILE="../../../../../manifests/v1beta1/components/postgres/pvc.yaml"
fi

# If the user wants to deploy Katib UI, then use the kustomization file for Katib UI.
if ! "$DEPLOY_KATIB_UI"; then
  index="$(yq eval '.resources.[] | select(. == "../../components/ui/") | path | .[-1]' $KUSTOMIZATION_FILE)"
  index="$index" yq eval -i 'del(.resources.[env(index)])' $KUSTOMIZATION_FILE
fi

# Since e2e test doesn't need to large storage, we use a small PVC for Katib.
yq eval -i '.spec.resources.requests.storage|="2Gi"' $PVC_FILE

echo -e "\n The Katib will be deployed with the following configs"
cat $KUSTOMIZATION_FILE
cat ../../../../../manifests/v1beta1/installs/katib-standalone/katib-config.yaml

# If the user wants to deploy training operator, then use the kustomization file for training operator.
if "$DEPLOY_TRAINING_OPERATOR"; then
  echo "Deploying Training Operator $TRAINING_OPERATOR_VERSION"
  kubectl apply --server-side -k "github.com/kubeflow/training-operator/manifests/overlays/standalone?ref=$TRAINING_OPERATOR_VERSION"
fi

echo "Deploying Katib"
cd ../../../../../ && WITH_DATABASE_TYPE=$WITH_DATABASE_TYPE make deploy && cd -

# Wait until all Katib pods is running.
TIMEOUT=120s

kubectl wait --for=condition=ContainersReady=True --timeout=${TIMEOUT} -l "katib.kubeflow.org/component in ($WITH_DATABASE_TYPE,controller,db-manager,ui)" -n kubeflow pod ||
  (kubectl get pods -n kubeflow && kubectl describe pods -n kubeflow && exit 1)

echo "All Katib components are running."
echo "Katib deployments"
kubectl -n kubeflow get deploy
echo "Katib services"
kubectl -n kubeflow get svc
echo "Katib pods"
kubectl -n kubeflow get pod

# Check that Katib is working with 2 Experiments.
kubectl apply -f ../../testdata/valid-experiment.yaml
kubectl delete -f ../../testdata/valid-experiment.yaml

# Check the ValidatingWebhookConfiguration works well.
set +o errexit
kubectl apply -f ../../testdata/invalid-experiment.yaml
if [ $? -ne 1 ]; then
  echo "Failed to create invalid-experiment: return code $?"
  exit 1
fi
set -o errexit

exit 0



================================================
FILE: test/e2e/v1beta1/scripts/gh-actions/setup-minikube.sh
================================================
#!/usr/bin/env bash

# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This shell script is used to setup Katib deployment.

set -o errexit
set -o pipefail
set -o nounset
cd "$(dirname "$0")"

DEPLOY_KATIB_UI=${1:-false}
TUNE_API=${2:-false}
TRIAL_IMAGES=${3:-""}
EXPERIMENTS=${4:-""}

echo "Start to setup Minikube Kubernetes Cluster"
kubectl version
kubectl cluster-info
kubectl get nodes

echo "Build and Load container images"
./build-load.sh "$DEPLOY_KATIB_UI" "$TUNE_API" "$TRIAL_IMAGES" "$EXPERIMENTS" 



================================================
FILE: test/e2e/v1beta1/scripts/gh-actions/verify.py
================================================
import time

from kubeflow.katib import KatibClient, models
from kubeflow.katib.constants import constants
from kubernetes import client


def verify_experiment_results(
    katib_client: KatibClient,
    experiment: models.V1beta1Experiment,
    exp_name: str,
    exp_namespace: str,
):

    # Get the best objective metric.
    best_objective_metric = None
    for metric in experiment.status.current_optimal_trial.observation.metrics:
        if metric.name == experiment.spec.objective.objective_metric_name:
            best_objective_metric = metric
            break

    if best_objective_metric is None:
        raise Exception(
            "Unable to get the best metrics for objective: {}. Current Optimal Trial: {}".format(
                experiment.spec.objective.objective_metric_name,
                experiment.status.current_optimal_trial,
            )
        )

    # Get Experiment Succeeded reason.
    for c in experiment.status.conditions:
        if (
            c.type == constants.EXPERIMENT_CONDITION_SUCCEEDED
            and c.status == constants.CONDITION_STATUS_TRUE
        ):
            succeeded_reason = c.reason
            break

    trials_completed = experiment.status.trials_succeeded or 0
    trials_completed += experiment.status.trials_early_stopped or 0
    max_trial_count = experiment.spec.max_trial_count

    # If Experiment is Succeeded because of Max Trial Reached, all Trials must be completed.
    if (
        succeeded_reason == "ExperimentMaxTrialsReached"
        and trials_completed != max_trial_count
    ):
        raise Exception(
            "All Trials must be Completed. Max Trial count: {}, Experiment status: {}".format(
                max_trial_count, experiment.status
            )
        )

    # If Experiment is Succeeded because of Goal reached, the metrics must be correct.
    if succeeded_reason == "ExperimentGoalReached" and (
        (
            experiment.spec.objective.type == "minimize"
            and float(best_objective_metric.min) > float(experiment.spec.objective.goal)
        )
        or (
            experiment.spec.objective.type == "maximize"
            and float(best_objective_metric.max) < float(experiment.spec.objective.goal)
        )
    ):
        raise Exception(
            "Experiment goal is reached, but metrics are incorrect. "
            f"Experiment objective: {experiment.spec.objective}. "
            f"Experiment best objective metric: {best_objective_metric}"
        )

    # Verify Suggestion's resources. Suggestion name = Experiment name.
    suggestion = katib_client.get_suggestion(exp_name, exp_namespace)

    # For the Never or FromVolume resume policies Suggestion must be Succeeded.
    # For the LongRunning resume policy Suggestion must be always Running.
    for c in suggestion.status.conditions:
        if (
            c.type == constants.EXPERIMENT_CONDITION_SUCCEEDED
            and c.status == constants.CONDITION_STATUS_TRUE
            and experiment.spec.resume_policy == "LongRunning"
        ):
            raise Exception(
                f"Suggestion is Succeeded while Resume Policy is {experiment.spec.resume_policy}."
                f"Suggestion conditions: {suggestion.status.conditions}"
            )
        elif (
            c.type == constants.EXPERIMENT_CONDITION_RUNNING
            and c.status == constants.CONDITION_STATUS_TRUE
            and experiment.spec.resume_policy != "LongRunning"
        ):
            raise Exception(
                f"Suggestion is Running while Resume Policy is {experiment.spec.resume_policy}."
                f"Suggestion conditions: {suggestion.status.conditions}"
            )

    # For Never and FromVolume resume policies verify Suggestion's resources.
    if (
        experiment.spec.resume_policy == "Never"
        or experiment.spec.resume_policy == "FromVolume"
    ):
        resource_name = exp_name + "-" + experiment.spec.algorithm.algorithm_name

        # Suggestion's Service and Deployment should be deleted.
        for i in range(10):
            try:
                client.AppsV1Api().read_namespaced_deployment(
                    resource_name, exp_namespace
                )
            except client.ApiException as e:
                if e.status == 404:
                    break
                else:
                    raise e
        if i == 10:
            raise Exception(
                "Suggestion Deployment is still alive for Resume Policy: {}".format(
                    experiment.spec.resume_policy
                )
            )

        try:
            client.CoreV1Api().read_namespaced_service(resource_name, exp_namespace)
        except client.ApiException as e:
            if e.status != 404:
                raise e
        else:
            raise Exception(
                "Suggestion Service is still alive for Resume Policy: {}".format(
                    experiment.spec.resume_policy
                )
            )

        # For FromVolume resume policy PVC should not be deleted.
        if experiment.spec.resume_policy == "FromVolume":
            try:
                client.CoreV1Api().read_namespaced_persistent_volume_claim(
                    resource_name, exp_namespace
                )
            except client.ApiException:
                raise Exception("PVC is deleted for FromVolume Resume Policy")



================================================
FILE: test/e2e/v1beta1/testdata/invalid-experiment.yaml
================================================
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: invalid-experiment
spec:
  maxTrialCount: 13
  maxFailedTrialCount: 3
  objective:
    type: minimize
    goal: 0.001
    objectiveMetricName: loss
  algorithm:
    algorithmName: invalid-algorithm # Invalid Algorithm to check that validation webhook is working
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.05"
    - name: momentum
      parameterType: double
      feasibleSpace:
        min: "0.5"
        max: "0.9"
  trialTemplate:
    primaryContainerName: training-container
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: momentum
        description: Momentum for the training model
        reference: momentum
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
                command:
                  - "python3"
                  - "/opt/pytorch-mnist/mnist.py"
                  - "--epochs=1"
                  - "--batch-size=16"
                  - "--lr=${trialParameters.learningRate}"
                  - "--momentum=${trialParameters.momentum}"
            restartPolicy: Never



================================================
FILE: test/e2e/v1beta1/testdata/valid-experiment.yaml
================================================
apiVersion: kubeflow.org/v1beta1
kind: Experiment
metadata:
  namespace: kubeflow
  name: valid-experiment
spec:
  maxTrialCount: 13
  maxFailedTrialCount: 3
  objective:
    type: minimize
    goal: 0.001
    objectiveMetricName: loss
  algorithm:
    algorithmName: random
  parameters:
    - name: lr
      parameterType: double
      feasibleSpace:
        min: "0.01"
        max: "0.05"
    - name: momentum
      parameterType: double
      feasibleSpace:
        min: "0.5"
        max: "0.9"
  trialTemplate:
    primaryContainerName: training-container
    trialParameters:
      - name: learningRate
        description: Learning rate for the training model
        reference: lr
      - name: momentum
        description: Momentum for the training model
        reference: momentum
    trialSpec:
      apiVersion: batch/v1
      kind: Job
      spec:
        template:
          spec:
            containers:
              - name: training-container
                image: ghcr.io/kubeflow/katib/pytorch-mnist-cpu:latest
                command:
                  - "python3"
                  - "/opt/pytorch-mnist/mnist.py"
                  - "--epochs=1"
                  - "--batch-size=16"
                  - "--lr=${trialParameters.learningRate}"
                  - "--momentum=${trialParameters.momentum}"
            restartPolicy: Never



================================================
FILE: test/unit/v1beta1/requirements.txt
================================================
grpcio-testing==1.64.1
pytest==7.2.0
tensorboardX==2.6.2.2
kubeflow-training[huggingface]==1.9.0



================================================
FILE: test/unit/v1beta1/earlystopping/test_medianstop_service.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import unittest
from unittest.mock import patch

import grpc
import grpc_testing
import utils

from pkg.apis.manager.v1beta1.python import api_pb2
from pkg.earlystopping.v1beta1.medianstop.service import MedianStopService


class TestMedianStop(unittest.TestCase):
    def setUp(self):
        # Mock load Kubernetes config.
        patcher = patch('pkg.earlystopping.v1beta1.medianstop.service.config.load_kube_config')
        self.mock_sum = patcher.start()
        self.addCleanup(patcher.stop)

        servicers = {
            api_pb2.DESCRIPTOR.services_by_name['EarlyStopping']: MedianStopService(
            )
        }

        self.test_server = grpc_testing.server_from_dictionary(
            servicers, grpc_testing.strict_real_time())

    def test_validate_early_stopping_settings(self):
        # Valid cases
        early_stopping = api_pb2.EarlyStoppingSpec(
            algorithm_name="medianstop",
            algorithm_settings=[
                api_pb2.EarlyStoppingSetting(
                    name="min_trials_required",
                    value="2",
                ),
                api_pb2.EarlyStoppingSetting(
                    name="start_step",
                    value="5",
                ),
            ],
        )

        _, _, code, _ = utils.call_validate(self.test_server, early_stopping)
        self.assertEqual(code, grpc.StatusCode.OK)

        # Invalid cases
        # Unknown algorithm name
        early_stopping = api_pb2.EarlyStoppingSpec(algorithm_name="unknown")

        _, _, code, details = utils.call_validate(self.test_server, early_stopping)
        self.assertEqual(code, grpc.StatusCode.INVALID_ARGUMENT)
        self.assertEqual(details, "unknown algorithm name unknown")

        # Unknown config name
        early_stopping = api_pb2.EarlyStoppingSpec(
            algorithm_name="medianstop",
            algorithm_settings=[
                api_pb2.EarlyStoppingSetting(
                    name="unknown_conf",
                    value="100",
                ),
            ],
        )

        _, _, code, details = utils.call_validate(self.test_server, early_stopping)
        self.assertEqual(code, grpc.StatusCode.INVALID_ARGUMENT)
        self.assertEqual(details, "unknown setting unknown_conf for algorithm medianstop")

        # Wrong min_trials_required
        early_stopping = api_pb2.EarlyStoppingSpec(
            algorithm_name="medianstop",
            algorithm_settings=[
                api_pb2.EarlyStoppingSetting(
                    name="min_trials_required",
                    value="0",
                ),
            ],
        )

        _, _, code, details = utils.call_validate(self.test_server, early_stopping)
        self.assertEqual(code, grpc.StatusCode.INVALID_ARGUMENT)
        self.assertEqual(details, "min_trials_required must be greater than zero (>0)")

        # Wrong start_step
        early_stopping = api_pb2.EarlyStoppingSpec(
            algorithm_name="medianstop",
            algorithm_settings=[
                api_pb2.EarlyStoppingSetting(
                    name="start_step",
                    value="0",
                ),
            ],
        )
        _, _, code, details = utils.call_validate(self.test_server, early_stopping)
        self.assertEqual(code, grpc.StatusCode.INVALID_ARGUMENT)
        self.assertEqual(details, "start_step must be greater or equal than one (>=1)")

    def test_get_earlystopping_rules(self):
        # TODO (andreyvelich): Add more informative tests.
        trials = [
            api_pb2.Trial(
                name="test-asfjh",
            ),
            api_pb2.Trial(
                name="test-234hs",
            )
        ]

        experiment = api_pb2.Experiment(
            name="test",
        )

        request = api_pb2.GetEarlyStoppingRulesRequest(
            experiment=experiment,
            trials=trials,
            db_manager_address="katib-db-manager.kubeflow:6789"
        )

        get_earlystopping_rules = self.test_server.invoke_unary_unary(
            method_descriptor=(api_pb2.DESCRIPTOR
                .services_by_name['EarlyStopping']
                .methods_by_name['GetEarlyStoppingRules']),
            invocation_metadata={},
            request=request, timeout=1)

        _, _, code, _ = get_earlystopping_rules.termination()

        self.assertEqual(code, grpc.StatusCode.OK)


if __name__ == '__main__':
    unittest.main()



================================================
FILE: test/unit/v1beta1/earlystopping/utils.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from pkg.apis.manager.v1beta1.python import api_pb2


def call_validate(test_server, early_stopping):
    request = api_pb2.ValidateEarlyStoppingSettingsRequest(early_stopping=early_stopping)
    validate_early_stopping_settings = test_server.invoke_unary_unary(
        method_descriptor=(api_pb2.DESCRIPTOR
                           .services_by_name['EarlyStopping']
                           .methods_by_name['ValidateEarlyStoppingSettings']),
        invocation_metadata={},
        request=request, timeout=1)

    response, metadata, code, details = validate_early_stopping_settings.termination()

    return response, metadata, code, details



================================================
FILE: test/unit/v1beta1/metricscollector/test_tfevent_metricscollector.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import tempfile
import unittest

import tensorboardX
import utils

METRIC_DIR_NAMES = ("train", "test")
METRIC_NAMES = ("accuracy", "loss")
QUALIFIED_METRIC_NAMES = tuple(
    f"{dir}/{metric}"
    for dir in METRIC_DIR_NAMES
    for metric in METRIC_NAMES
)

class TestTFEventMetricsCollector(unittest.TestCase):
    def test_parse_file(self):

        current_dir = os.path.dirname(os.path.abspath(__file__))
        logs_dir = os.path.join(current_dir, "testdata/tfevent-metricscollector/logs")


        metric_logs = utils.get_metric_logs(logs_dir, QUALIFIED_METRIC_NAMES)
        self.assertEqual(20, len(metric_logs))

        for log in metric_logs:
            actual = log["metric"]["name"]
            self.assertIn(actual, QUALIFIED_METRIC_NAMES)

        train_metric_logs = utils.get_metric_logs(
            os.path.join(logs_dir, "train"), METRIC_NAMES)
        self.assertEqual(10, len(train_metric_logs))

        for log in train_metric_logs:
            actual = log["metric"]["name"]
            self.assertIn(actual, METRIC_NAMES)

    def test_parse_file_with_tensorboardX(self):
        logs_dir = tempfile.mkdtemp()
        num_iters = 3

        for dir_name in METRIC_DIR_NAMES:
            with tensorboardX.SummaryWriter(os.path.join(logs_dir, dir_name)) as writer:
                for metric_name in METRIC_NAMES:
                    for iter in range(num_iters):
                        writer.add_scalar(metric_name, 0.1, iter)


        metric_logs = utils.get_metric_logs(logs_dir, QUALIFIED_METRIC_NAMES)
        self.assertEqual(num_iters * len(QUALIFIED_METRIC_NAMES), len(metric_logs))

        for log in metric_logs:
            actual = log["metric"]["name"]
            self.assertIn(actual, QUALIFIED_METRIC_NAMES)

        train_metric_logs = utils.get_metric_logs(
            os.path.join(logs_dir, "train"), METRIC_NAMES)
        self.assertEqual(num_iters * len(METRIC_NAMES), len(train_metric_logs))

        for log in train_metric_logs:
            actual = log["metric"]["name"]
            self.assertIn(actual, METRIC_NAMES)


if __name__ == '__main__':
    unittest.main()



================================================
FILE: test/unit/v1beta1/metricscollector/utils.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from google.protobuf import json_format
from tfevent_loader import MetricsCollector


def get_metric_logs(logs_dir, metric_names):
    mc = MetricsCollector(metric_names)
    observation_log = mc.parse_file(logs_dir)
    dict_observation_log = json_format.MessageToDict(observation_log)
    return dict_observation_log["metricLogs"]



================================================
FILE: test/unit/v1beta1/suggestion/test_darts_service.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import json
import unittest

import grpc
import grpc_testing

from pkg.apis.manager.v1beta1.python import api_pb2
from pkg.suggestion.v1beta1.nas.darts.service import (
    DartsService,
    validate_algorithm_settings,
)


class TestDarts(unittest.TestCase):
    def setUp(self):
        services = {
            api_pb2.DESCRIPTOR.services_by_name['Suggestion']: DartsService(
            )
        }

        self.test_server = grpc_testing.server_from_dictionary(
            services, grpc_testing.strict_real_time())

    def test_get_suggestion(self):
        experiment = api_pb2.Experiment(
            name="darts-experiment",
            spec=api_pb2.ExperimentSpec(
                algorithm=api_pb2.AlgorithmSpec(
                    algorithm_name="darts",
                    algorithm_settings=[
                        api_pb2.AlgorithmSetting(
                            name="num_epoch",
                            value="10"
                        )
                    ],
                ),
                objective=api_pb2.ObjectiveSpec(
                    type=api_pb2.MAXIMIZE,
                    objective_metric_name="Best-Genotype"
                ),
                parallel_trial_count=1,
                max_trial_count=1,
                nas_config=api_pb2.NasConfig(
                    graph_config=api_pb2.GraphConfig(
                        num_layers=3,
                    ),
                    operations=api_pb2.NasConfig.Operations(
                        operation=[
                            api_pb2.Operation(
                                operation_type="separable_convolution",
                                parameter_specs=api_pb2.Operation.ParameterSpecs(
                                    parameters=[
                                        api_pb2.ParameterSpec(
                                            name="filter_size",
                                            parameter_type=api_pb2.CATEGORICAL,
                                            feasible_space=api_pb2.FeasibleSpace(
                                                max=None, min=None, list=["3", "5"])
                                        ),
                                    ]
                                )
                            ),
                        ],
                    )
                )
            )
        )

        request = api_pb2.GetSuggestionsRequest(
            experiment=experiment,
            current_request_number=1,
        )

        get_suggestion = self.test_server.invoke_unary_unary(
            method_descriptor=(api_pb2.DESCRIPTOR
                               .services_by_name['Suggestion']
                               .methods_by_name['GetSuggestions']),
            invocation_metadata={},
            request=request, timeout=100)

        response, metadata, code, details = get_suggestion.termination()
        print(response.parameter_assignments)

        self.assertEqual(code, grpc.StatusCode.OK)
        self.assertEqual(1, len(response.parameter_assignments))

        exp_algorithm_settings = {}
        for setting in experiment.spec.algorithm.algorithm_settings:
            exp_algorithm_settings[setting.name] = setting.value

        exp_num_layers = experiment.spec.nas_config.graph_config.num_layers

        exp_search_space = ["separable_convolution_3x3", "separable_convolution_5x5"]
        for pa in response.parameter_assignments[0].assignments:
            if pa.name == "algorithm-settings":
                algorithm_settings = pa.value.replace("\'", "\"")
                algorithm_settings = json.loads(algorithm_settings)
                self.assertDictContainsSubset(exp_algorithm_settings, algorithm_settings)
            elif pa.name == "num-layers":
                self.assertEqual(exp_num_layers, int(pa.value))
            elif pa.name == "search-space":
                search_space = pa.value.replace("\'", "\"")
                search_space = json.loads(search_space)
                self.assertEqual(exp_search_space, search_space)

    def test_validate_algorithm_spec(self):

        # Valid Case
        valid = [
            api_pb2.AlgorithmSetting(name="num_epoch", value="10"),
            api_pb2.AlgorithmSetting(name="w_lr", value="0.01"),
            api_pb2.AlgorithmSetting(name="w_lr_min", value="0.01"),
            api_pb2.AlgorithmSetting(name="alpha_lr", value="0.01"),
            api_pb2.AlgorithmSetting(name="w_weight_decay", value="0.25"),
            api_pb2.AlgorithmSetting(name="alpha_weight_decay", value="0.25"),
            api_pb2.AlgorithmSetting(name="w_momentum", value="0.9"),
            api_pb2.AlgorithmSetting(name="w_grad_clip", value="5.0"),
            api_pb2.AlgorithmSetting(name="batch_size", value="100"),
            api_pb2.AlgorithmSetting(name="num_workers", value="0"),
            api_pb2.AlgorithmSetting(name="init_channels", value="1"),
            api_pb2.AlgorithmSetting(name="print_step", value="100"),
            api_pb2.AlgorithmSetting(name="num_nodes", value="4"),
            api_pb2.AlgorithmSetting(name="stem_multiplier", value="3"),
        ]
        is_valid, _ = validate_algorithm_settings(valid)
        self.assertEqual(is_valid, True)

        # Invalid num_epochs
        invalid = [api_pb2.AlgorithmSetting(name="num_epochs", value="0")]
        is_valid, _ = validate_algorithm_settings(invalid)
        self.assertEqual(is_valid, False)

        # Invalid w_lr
        invalid = [api_pb2.AlgorithmSetting(name="w_lr", value="-0.1")]
        is_valid, _ = validate_algorithm_settings(invalid)
        self.assertEqual(is_valid, False)

        # Invalid alpha_weight_decay
        invalid = [api_pb2.AlgorithmSetting(name="alpha_weight_decay", value="-0.02")]
        is_valid, _ = validate_algorithm_settings(invalid)
        self.assertEqual(is_valid, False)

        # Invalid w_momentum
        invalid = [api_pb2.AlgorithmSetting(name="w_momentum", value="-0.8")]
        is_valid, _ = validate_algorithm_settings(invalid)
        self.assertEqual(is_valid, False)

        # Invalid batch_size
        invalid = [api_pb2.AlgorithmSetting(name="batch_size", value="0")]
        is_valid, _ = validate_algorithm_settings(invalid)
        self.assertEqual(is_valid, False)

        # Valid batch_size
        valid = [api_pb2.AlgorithmSetting(name="batch_size", value="None")]
        is_valid, _ = validate_algorithm_settings(valid)
        self.assertEqual(is_valid, True)

        # Invalid print_step
        invalid = [api_pb2.AlgorithmSetting(name="print_step", value="0")]
        is_valid, _ = validate_algorithm_settings(invalid)
        self.assertEqual(is_valid, False)


if __name__ == '__main__':
    unittest.main()



================================================
FILE: test/unit/v1beta1/suggestion/test_enas_service.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import shutil
import unittest

import grpc
import grpc_testing
import pytest

from pkg.apis.manager.v1beta1.python import api_pb2
from pkg.suggestion.v1beta1.nas.enas.service import EnasService


class TestEnas(unittest.TestCase):
    def setUp(self):
        services = {
            api_pb2.DESCRIPTOR.services_by_name['Suggestion']: EnasService(
            )
        }

        self.test_server = grpc_testing.server_from_dictionary(
            services, grpc_testing.strict_real_time())

    def test_get_suggestion(self):
        trials = [
            api_pb2.Trial(
                name="first-trial",
                spec=api_pb2.TrialSpec(
                    objective=api_pb2.ObjectiveSpec(
                     type=api_pb2.MAXIMIZE,
                     objective_metric_name="Validation-Accuracy",
                     goal=0.99
                    ),
                    parameter_assignments=api_pb2.TrialSpec.ParameterAssignments(
                        assignments=[
                            api_pb2.ParameterAssignment(
                                name="architecture",
                                value="[[3], [0, 1], [0, 0, 1], [2, 1, 0, 0]]",
                            ),
                            api_pb2.ParameterAssignment(
                                name="nn_config",
                                value="{'num_layers': 4}",
                            ),
                        ]
                    )
                ),
                status=api_pb2.TrialStatus(
                    observation=api_pb2.Observation(
                        metrics=[
                            api_pb2.Metric(
                                name="Validation-Accuracy",
                                value="0.88"
                            ),
                        ]
                    ),
                    condition=api_pb2.TrialStatus.TrialConditionType.SUCCEEDED,

                )
            ),
            api_pb2.Trial(
                name="second-trial",
                spec=api_pb2.TrialSpec(
                    objective=api_pb2.ObjectiveSpec(
                     type=api_pb2.MAXIMIZE,
                     objective_metric_name="Validation-Accuracy",
                     goal=0.99
                    ),
                    parameter_assignments=api_pb2.TrialSpec.ParameterAssignments(
                        assignments=[
                            api_pb2.ParameterAssignment(
                                name="architecture",
                                value="[[1], [0, 1], [2, 1, 1], [2, 1, 1, 0]]",
                            ),
                            api_pb2.ParameterAssignment(
                                name="nn_config",
                                value="{'num_layers': 4}",
                            ),
                        ],
                    )
                ),
                status=api_pb2.TrialStatus(
                    observation=api_pb2.Observation(
                        metrics=[
                            api_pb2.Metric(
                                name="Validation-Accuracy",
                                value="0.84"
                            ),
                        ]
                    ),
                    condition=api_pb2.TrialStatus.TrialConditionType.SUCCEEDED,
                )
            )
        ]
        experiment = api_pb2.Experiment(
            name="enas-experiment",
            spec=api_pb2.ExperimentSpec(
                algorithm=api_pb2.AlgorithmSpec(
                    algorithm_name="enas",
                ),
                objective=api_pb2.ObjectiveSpec(
                    type=api_pb2.MAXIMIZE,
                    goal=0.9,
                    objective_metric_name="Validation-Accuracy"
                ),
                parallel_trial_count=2,
                max_trial_count=10,
                nas_config=api_pb2.NasConfig(
                    graph_config=api_pb2.GraphConfig(
                        num_layers=4,
                        input_sizes=[32, 32, 8],
                        output_sizes=[10]
                    ),
                    operations=api_pb2.NasConfig.Operations(
                        operation=[
                            api_pb2.Operation(
                                operation_type="convolution",
                                parameter_specs=api_pb2.Operation.ParameterSpecs(
                                    parameters=[
                                        api_pb2.ParameterSpec(
                                            name="filter_size",
                                            parameter_type=api_pb2.CATEGORICAL,
                                            feasible_space=api_pb2.FeasibleSpace(
                                                max=None, min=None, list=["5"])
                                        ),
                                        api_pb2.ParameterSpec(
                                            name="num_filter",
                                            parameter_type=api_pb2.CATEGORICAL,
                                            feasible_space=api_pb2.FeasibleSpace(
                                                max=None, min=None, list=["128"])
                                        ),
                                        api_pb2.ParameterSpec(
                                            name="stride",
                                            parameter_type=api_pb2.CATEGORICAL,
                                            feasible_space=api_pb2.FeasibleSpace(
                                                max=None, min=None, list=["1", "2"])
                                        ),
                                    ]
                                )
                            ),
                            api_pb2.Operation(
                                operation_type="reduction",
                                parameter_specs=api_pb2.Operation.ParameterSpecs(
                                    parameters=[
                                        api_pb2.ParameterSpec(
                                            name="reduction_type",
                                            parameter_type=api_pb2.CATEGORICAL,
                                            feasible_space=api_pb2.FeasibleSpace(
                                                max=None, min=None, list=["max_pooling"])
                                        ),
                                        api_pb2.ParameterSpec(
                                            name="pool_size",
                                            parameter_type=api_pb2.INT,
                                            feasible_space=api_pb2.FeasibleSpace(
                                                min="2", max="3", step="1", list=[])
                                        ),
                                    ]
                                )
                            ),
                        ],
                    )
                )
            )
        )

        request = api_pb2.GetSuggestionsRequest(
            experiment=experiment,
            trials=trials,
            current_request_number=2,
        )

        get_suggestion = self.test_server.invoke_unary_unary(
            method_descriptor=(api_pb2.DESCRIPTOR
                               .services_by_name['Suggestion']
                               .methods_by_name['GetSuggestions']),
            invocation_metadata={},
            request=request, timeout=100)

        response, metadata, code, details = get_suggestion.termination()
        print(response.parameter_assignments)
        self.assertEqual(code, grpc.StatusCode.OK)
        self.assertEqual(2, len(response.parameter_assignments))


@pytest.fixture(scope='function', autouse=True)
def tear_down():
    yield
    working_dir = os.getcwd()
    target_path = os.path.join(working_dir, "ctrl_cache")
    if os.path.isdir(target_path):
        shutil.rmtree(target_path)


if __name__ == '__main__':
    unittest.main()



================================================
FILE: test/unit/v1beta1/suggestion/test_hyperband_service.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import unittest

import grpc
import grpc_testing

from pkg.apis.manager.v1beta1.python import api_pb2
from pkg.suggestion.v1beta1.hyperband.service import HyperbandService


class TestHyperband(unittest.TestCase):
    def setUp(self):
        servicers = {
            api_pb2.DESCRIPTOR.services_by_name['Suggestion']: HyperbandService(
            )
        }

        self.test_server = grpc_testing.server_from_dictionary(
            servicers, grpc_testing.strict_real_time())

    def test_get_suggestion(self):
        trials = [
            api_pb2.Trial(
                name="test-asfjh",
                spec=api_pb2.TrialSpec(
                    objective=api_pb2.ObjectiveSpec(
                        type=api_pb2.MAXIMIZE,
                        objective_metric_name="metric-2",
                        goal=0.9
                    ),
                    parameter_assignments=api_pb2.TrialSpec.ParameterAssignments(
                        assignments=[
                            api_pb2.ParameterAssignment(
                                name="param-1",
                                value="2",
                            ),
                            api_pb2.ParameterAssignment(
                                name="param-2",
                                value="cat1",
                            ),
                            api_pb2.ParameterAssignment(
                                name="param-3",
                                value="2",
                            ),
                            api_pb2.ParameterAssignment(
                                name="param-4",
                                value="3.44",
                            )
                        ]
                    )
                ),
                status=api_pb2.TrialStatus(
                    observation=api_pb2.Observation(
                        metrics=[
                            api_pb2.Metric(
                                name="metric=1",
                                value="435"
                            ),
                            api_pb2.Metric(
                                name="metric=2",
                                value="5643"
                            ),
                        ]
                    )
                )
            ),
            api_pb2.Trial(
                name="test-234hs",
                spec=api_pb2.TrialSpec(
                    objective=api_pb2.ObjectiveSpec(
                        type=api_pb2.MAXIMIZE,
                        objective_metric_name="metric-2",
                        goal=0.9
                    ),
                    parameter_assignments=api_pb2.TrialSpec.ParameterAssignments(
                        assignments=[
                            api_pb2.ParameterAssignment(
                                name="param-1",
                                value="3",
                            ),
                            api_pb2.ParameterAssignment(
                                name="param-2",
                                value="cat2",
                            ),
                            api_pb2.ParameterAssignment(
                                name="param-3",
                                value="6",
                            ),
                            api_pb2.ParameterAssignment(
                                name="param-4",
                                value="4.44",
                            )
                        ]
                    )
                ),
                status=api_pb2.TrialStatus(
                    observation=api_pb2.Observation(
                        metrics=[
                            api_pb2.Metric(
                                name="metric=1",
                                value="123"
                            ),
                            api_pb2.Metric(
                                name="metric=2",
                                value="3028"
                            ),
                        ]
                    )
                )
            )
        ]
        experiment = api_pb2.Experiment(
            name="test",
            spec=api_pb2.ExperimentSpec(
                algorithm=api_pb2.AlgorithmSpec(
                    algorithm_name="hyperband",
                    algorithm_settings=[
                        api_pb2.AlgorithmSetting(
                            name="r_l",
                            value="10"
                        ),
                        api_pb2.AlgorithmSetting(
                            name="resource_name",
                            value="--num-epochs"
                        )
                    ],
                ),
                objective=api_pb2.ObjectiveSpec(
                    type=api_pb2.MAXIMIZE,
                    goal=0.9
                ),
                parameter_specs=api_pb2.ExperimentSpec.ParameterSpecs(
                    parameters=[
                        api_pb2.ParameterSpec(
                            name="param-1",
                            parameter_type=api_pb2.INT,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="5", min="1", list=[]),
                        ),
                        api_pb2.ParameterSpec(
                            name="param-2",
                            parameter_type=api_pb2.CATEGORICAL,
                            feasible_space=api_pb2.FeasibleSpace(
                                max=None, min=None, list=["cat1", "cat2", "cat3"])
                        ),
                        api_pb2.ParameterSpec(
                            name="param-3",
                            parameter_type=api_pb2.DISCRETE,
                            feasible_space=api_pb2.FeasibleSpace(
                                max=None, min=None, list=["3", "2", "6"])
                        ),
                        api_pb2.ParameterSpec(
                            name="param-4",
                            parameter_type=api_pb2.DOUBLE,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="5", min="1", list=[])
                        )
                    ]
                )
            )
        )

        request = api_pb2.GetSuggestionsRequest(
            experiment=experiment,
            trials=trials,
            current_request_number=2,
        )

        get_suggestion = self.test_server.invoke_unary_unary(
            method_descriptor=(api_pb2.DESCRIPTOR
                               .services_by_name['Suggestion']
                               .methods_by_name['GetSuggestions']),
            invocation_metadata={},
            request=request, timeout=1)

        response, metadata, code, details = get_suggestion.termination()
        print(response.parameter_assignments)
        self.assertEqual(code, grpc.StatusCode.OK)
        self.assertEqual(2, len(response.parameter_assignments))


if __name__ == '__main__':
    unittest.main()



================================================
FILE: test/unit/v1beta1/suggestion/test_hyperopt_service.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import unittest

import grpc
import grpc_testing
import utils

from pkg.apis.manager.v1beta1.python import api_pb2
from pkg.suggestion.v1beta1.hyperopt.service import HyperoptService
from pkg.suggestion.v1beta1.internal.constant import LOG_UNIFORM


class TestHyperopt(unittest.TestCase):
    def setUp(self):
        servicers = {
            api_pb2.DESCRIPTOR.services_by_name["Suggestion"]: HyperoptService(
            )
        }

        self.test_server = grpc_testing.server_from_dictionary(
            servicers, grpc_testing.strict_real_time())

    def test_get_suggestion(self):
        trials = [
            api_pb2.Trial(
                name="test-asfjh",
                spec=api_pb2.TrialSpec(
                    objective=api_pb2.ObjectiveSpec(
                        type=api_pb2.MAXIMIZE,
                        objective_metric_name="metric-2",
                        goal=0.9
                    ),
                    parameter_assignments=api_pb2.TrialSpec.ParameterAssignments(
                        assignments=[
                            api_pb2.ParameterAssignment(
                                name="param-1",
                                value="2",
                            ),
                            api_pb2.ParameterAssignment(
                                name="param-2",
                                value="cat1",
                            ),
                            api_pb2.ParameterAssignment(
                                name="param-3",
                                value="2",
                            ),
                            api_pb2.ParameterAssignment(
                                name="param-4",
                                value="3.44",
                            )
                        ]
                    )
                ),
                status=api_pb2.TrialStatus(
                    observation=api_pb2.Observation(
                        metrics=[
                            api_pb2.Metric(
                                name="metric=1",
                                value="435"
                            ),
                            api_pb2.Metric(
                                name="metric=2",
                                value="5643"
                            ),
                        ]
                    )
                )
            ),
            api_pb2.Trial(
                name="test-234hs",
                spec=api_pb2.TrialSpec(
                    objective=api_pb2.ObjectiveSpec(
                        type=api_pb2.MAXIMIZE,
                        objective_metric_name="metric-2",
                        goal=0.9
                    ),
                    parameter_assignments=api_pb2.TrialSpec.ParameterAssignments(
                        assignments=[
                            api_pb2.ParameterAssignment(
                                name="param-1",
                                value="3",
                            ),
                            api_pb2.ParameterAssignment(
                                name="param-2",
                                value="cat2",
                            ),
                            api_pb2.ParameterAssignment(
                                name="param-3",
                                value="6",
                            ),
                            api_pb2.ParameterAssignment(
                                name="param-4",
                                value="4.44",
                            )
                        ]
                    )
                ),
                status=api_pb2.TrialStatus(
                    observation=api_pb2.Observation(
                        metrics=[
                            api_pb2.Metric(
                                name="metric=1",
                                value="123"
                            ),
                            api_pb2.Metric(
                                name="metric=2",
                                value="3028"
                            ),
                        ]
                    )
                )
            )
        ]
        experiment = api_pb2.Experiment(
            name="test",
            spec=api_pb2.ExperimentSpec(
                algorithm=api_pb2.AlgorithmSpec(
                    algorithm_name="tpe",
                    algorithm_settings=[
                        api_pb2.AlgorithmSetting(
                            name="random_state",
                            value="10"
                        ),
                        api_pb2.AlgorithmSetting(
                            name="gamma",
                            value="0.25"
                        ),
                        api_pb2.AlgorithmSetting(
                            name="prior_weight",
                            value="1.0"
                        ),
                        api_pb2.AlgorithmSetting(
                            name="n_EI_candidates",
                            value="24"
                        ),
                    ],
                ),
                objective=api_pb2.ObjectiveSpec(
                    type=api_pb2.MAXIMIZE,
                    goal=0.9
                ),
                parameter_specs=api_pb2.ExperimentSpec.ParameterSpecs(
                    parameters=[
                        api_pb2.ParameterSpec(
                            name="param-1",
                            parameter_type=api_pb2.INT,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="5", min="1", list=[]),
                        ),
                        api_pb2.ParameterSpec(
                            name="param-2",
                            parameter_type=api_pb2.CATEGORICAL,
                            feasible_space=api_pb2.FeasibleSpace(
                                max=None, min=None, list=["cat1", "cat2", "cat3"])
                        ),
                        api_pb2.ParameterSpec(
                            name="param-3",
                            parameter_type=api_pb2.DISCRETE,
                            feasible_space=api_pb2.FeasibleSpace(
                                max=None, min=None, list=["3", "2", "6"])
                        ),
                        api_pb2.ParameterSpec(
                            name="param-4",
                            parameter_type=api_pb2.DOUBLE,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="5", min="1", list=[])
                        ),
                        api_pb2.ParameterSpec(
                            name="param-5",
                            parameter_type=api_pb2.DOUBLE,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="5", min="1", list=[], step="0.5", distribution=api_pb2.LOG_UNIFORM)
                        ),
                        api_pb2.ParameterSpec(
                            name="param-6",
                            parameter_type=api_pb2.DOUBLE,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="5", min="1", list=[], distribution=api_pb2.LOG_UNIFORM)
                        ),
                        api_pb2.ParameterSpec(
                            name="param-7",
                            parameter_type=api_pb2.DOUBLE,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="10", min="5", list=[], step="0.8", distribution=api_pb2.UNIFORM)
                        ),
                        api_pb2.ParameterSpec(
                            name="param-8",
                            parameter_type=api_pb2.DOUBLE,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="10", min="5", list=[], distribution=api_pb2.UNIFORM)
                        ),
                        api_pb2.ParameterSpec(
                            name="param-9",
                            parameter_type=api_pb2.DOUBLE,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="10", min="5", list=[], step="0.8", distribution=api_pb2.NORMAL)
                        ),
                        api_pb2.ParameterSpec(
                            name="param-10",
                            parameter_type=api_pb2.DOUBLE,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="10", min="5", list=[], distribution=api_pb2.NORMAL)
                        ),
                        api_pb2.ParameterSpec(
                            name="param-11",
                            parameter_type=api_pb2.DOUBLE,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="10", min="5", list=[], step="0.8", distribution=api_pb2.LOG_NORMAL)
                        ),
                        api_pb2.ParameterSpec(
                            name="param-12",
                            parameter_type=api_pb2.DOUBLE,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="10", min="5", list=[], distribution=api_pb2.LOG_NORMAL)
                        ),
                        api_pb2.ParameterSpec(
                            name="param-13",
                            parameter_type=api_pb2.INT,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="5", min="1", list=[], distribution=api_pb2.UNIFORM)
                        ),
                        api_pb2.ParameterSpec(
                            name="param-14",
                            parameter_type=api_pb2.INT,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="5", min="1", list=[], step="0.8", distribution=api_pb2.UNIFORM)
                        ),
                        api_pb2.ParameterSpec(
                            name="param-15",
                            parameter_type=api_pb2.INT,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="10", min="5", list=[], distribution=api_pb2.LOG_UNIFORM)
                        ),
                        api_pb2.ParameterSpec(
                            name="param-16",
                            parameter_type=api_pb2.INT,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="10", min="5", list=[], step="0.01", distribution=api_pb2.LOG_UNIFORM)
                        ),
                        api_pb2.ParameterSpec(
                            name="param-17",
                            parameter_type=api_pb2.INT,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="100", min="5", list=[], distribution=api_pb2.NORMAL)
                        ),
                        api_pb2.ParameterSpec(
                            name="param-18",
                            parameter_type=api_pb2.INT,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="100", min="5", list=[], step="0.01", distribution=api_pb2.NORMAL)
                        ),
                        api_pb2.ParameterSpec(
                            name="param-19",
                            parameter_type=api_pb2.INT,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="64", min="32", distribution=api_pb2.LOG_NORMAL)
                        ),
                        api_pb2.ParameterSpec(
                            name="param-20",
                            parameter_type=api_pb2.INT,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="64", min="32", step="0.01", distribution=api_pb2.LOG_NORMAL)
                        ),
                        api_pb2.ParameterSpec(
                            name="param-21",
                            parameter_type=api_pb2.DOUBLE,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="64", min="32", step="0.01")
                        ),
                        api_pb2.ParameterSpec(
                            name="param-22",
                            parameter_type=api_pb2.INT,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="64", min="32", step="0.01")
                        )
                    ]
                )
            )
        )

        request = api_pb2.GetSuggestionsRequest(
            experiment=experiment,
            trials=trials,
            current_request_number=2,
        )

        get_suggestion = self.test_server.invoke_unary_unary(
            method_descriptor=(api_pb2.DESCRIPTOR
                               .services_by_name["Suggestion"]
                               .methods_by_name["GetSuggestions"]),
            invocation_metadata={},
            request=request, timeout=1)

        response, metadata, code, details = get_suggestion.termination()
        print(response.parameter_assignments)
        self.assertEqual(code, grpc.StatusCode.OK)
        self.assertEqual(2, len(response.parameter_assignments))

    def test_validate_algorithm_settings(self):
        # Valid cases.
        experiment_spec = api_pb2.ExperimentSpec(
            algorithm=api_pb2.AlgorithmSpec(
                algorithm_name="tpe",
                algorithm_settings=[
                    api_pb2.AlgorithmSetting(
                        name="random_state",
                        value="10"
                    ),
                    api_pb2.AlgorithmSetting(
                        name="gamma",
                        value="0.25"
                    ),
                    api_pb2.AlgorithmSetting(
                        name="prior_weight",
                        value="1.0"
                    ),
                    api_pb2.AlgorithmSetting(
                        name="n_EI_candidates",
                        value="24"
                    ),
                ]
            )
        )

        _, _, code, _ = utils.call_validate(self.test_server, experiment_spec)
        self.assertEqual(code, grpc.StatusCode.OK)

        # Invalid cases.
        # Unknown algorithm name.
        experiment_spec = api_pb2.ExperimentSpec(
            algorithm=api_pb2.AlgorithmSpec(
                algorithm_name="unknown"
            )
        )

        _, _, code, details = utils.call_validate(self.test_server, experiment_spec)
        self.assertEqual(code, grpc.StatusCode.INVALID_ARGUMENT)
        self.assertEqual(details, "unknown algorithm name unknown")

        # Unknown algorithm setting name.
        experiment_spec = api_pb2.ExperimentSpec(
            algorithm=api_pb2.AlgorithmSpec(
                algorithm_name="random",
                algorithm_settings=[
                    api_pb2.AlgorithmSetting(name="unknown_conf", value="1111")
                ]
            )
        )

        _, _, code, details = utils.call_validate(self.test_server, experiment_spec)
        self.assertEqual(code, grpc.StatusCode.INVALID_ARGUMENT)
        self.assertEqual(details, "unknown setting unknown_conf for algorithm random")

        # Invalid gamma value.
        experiment_spec = api_pb2.ExperimentSpec(
            algorithm=api_pb2.AlgorithmSpec(
                algorithm_name="tpe",
                algorithm_settings=[
                    api_pb2.AlgorithmSetting(name="gamma", value="1.5")
                ]
            )
        )

        _, _, code, details = utils.call_validate(self.test_server, experiment_spec)
        self.assertEqual(code, grpc.StatusCode.INVALID_ARGUMENT)
        self.assertEqual(details, "gamma should be in the range of (0, 1)")

        # Invalid n_EI_candidates value.
        experiment_spec = api_pb2.ExperimentSpec(
            algorithm=api_pb2.AlgorithmSpec(
                algorithm_name="tpe",
                algorithm_settings=[
                    api_pb2.AlgorithmSetting(name="n_EI_candidates", value="0")
                ]
            )
        )

        _, _, code, details = utils.call_validate(self.test_server, experiment_spec)
        self.assertEqual(code, grpc.StatusCode.INVALID_ARGUMENT)
        self.assertEqual(details, "n_EI_candidates should be great than zero")

        # Invalid random_state value.
        experiment_spec = api_pb2.ExperimentSpec(
            algorithm=api_pb2.AlgorithmSpec(
                algorithm_name="tpe",
                algorithm_settings=[
                    api_pb2.AlgorithmSetting(name="random_state", value="-1")
                ]
            )
        )

        _, _, code, details = utils.call_validate(self.test_server, experiment_spec)
        self.assertEqual(code, grpc.StatusCode.INVALID_ARGUMENT)
        self.assertEqual(details, "random_state should be great or equal than zero")

        # Invalid prior_weight value.
        experiment_spec = api_pb2.ExperimentSpec(
            algorithm=api_pb2.AlgorithmSpec(
                algorithm_name="tpe",
                algorithm_settings=[
                    api_pb2.AlgorithmSetting(name="prior_weight", value="aaa")
                ]
            )
        )

        _, _, code, details = utils.call_validate(self.test_server, experiment_spec)
        self.assertEqual(code, grpc.StatusCode.INVALID_ARGUMENT)
        self.assertTrue(details.startswith("failed to validate prior_weight(aaa)"))


if __name__ == "__main__":
    unittest.main()



================================================
FILE: test/unit/v1beta1/suggestion/test_nas_common.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import unittest

from pkg.apis.manager.v1beta1.python import api_pb2
from pkg.suggestion.v1beta1.nas.common.validation import validate_operations


class TestNasCommon(unittest.TestCase):

    def test_validate_operations(self):

        # Valid Case
        valid_operations = [
            api_pb2.Operation(
                operation_type="separable_convolution",
                parameter_specs=api_pb2.Operation.ParameterSpecs(
                    parameters=[
                        api_pb2.ParameterSpec(
                            name="filter_size",
                            parameter_type=api_pb2.CATEGORICAL,
                            feasible_space=api_pb2.FeasibleSpace(
                                max=None, min=None, list=["3", "5"]),
                        ),
                        api_pb2.ParameterSpec(
                            name="pool_size",
                            parameter_type=api_pb2.INT,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="2", min="3", step="1", list=[]),
                        ),
                        api_pb2.ParameterSpec(
                            name="valid_type_double_example",
                            parameter_type=api_pb2.DOUBLE,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="1.0", min="3.0", step="0.1", list=[]),
                        ),
                    ],
                ),
            ),
        ]
        is_valid, _ = validate_operations(valid_operations)
        self.assertEqual(is_valid, True)

        # Invalid OperationType
        invalid_operation_type = [
            api_pb2.Operation(
                parameter_specs=api_pb2.Operation.ParameterSpecs(
                    parameters=[
                        api_pb2.ParameterSpec(
                            name="filter_size",
                            parameter_type=api_pb2.CATEGORICAL,
                            feasible_space=api_pb2.FeasibleSpace(
                                max=None, min=None, list=["3", "5"])
                        ),
                    ],
                ),
            ),
        ]
        is_valid, _ = validate_operations(invalid_operation_type)
        self.assertEqual(is_valid, False)

        # Invalid ParameterConfigs
        invalid_parameter_configs = [
            api_pb2.Operation(
                operation_type="separable_convolution",
                parameter_specs=api_pb2.Operation.ParameterSpecs(),
            ),
        ]
        is_valid, _ = validate_operations(invalid_parameter_configs)
        self.assertEqual(is_valid, False)

        # Invalid ParameterName
        invalid_parameter_name = [
            api_pb2.Operation(
                operation_type="separable_convolution",
                parameter_specs=api_pb2.Operation.ParameterSpecs(
                    parameters=[
                        api_pb2.ParameterSpec(
                            name="",
                            parameter_type=api_pb2.CATEGORICAL,
                            feasible_space=api_pb2.FeasibleSpace(
                                max=None, min=None, list=["3", "5"]),
                        ),
                    ],
                ),
            ),
        ]
        is_valid, _ = validate_operations(invalid_parameter_name)
        self.assertEqual(is_valid, False)

        # Invalid ParameterType
        invalid_parameter_type = [
            api_pb2.Operation(
                operation_type="separable_convolution",
                parameter_specs=api_pb2.Operation.ParameterSpecs(
                    parameters=[
                        api_pb2.ParameterSpec(
                            name="filter_size",
                            feasible_space=api_pb2.FeasibleSpace(
                                max=None, min=None, list=["3", "5"]),
                        ),
                    ],
                ),
            ),
        ]
        is_valid, _ = validate_operations(invalid_parameter_type)
        self.assertEqual(is_valid, False)

        # invalid List in Categorical
        invalid_categorical_list = [
            api_pb2.Operation(
                operation_type="separable_convolution",
                parameter_specs=api_pb2.Operation.ParameterSpecs(
                    parameters=[
                        api_pb2.ParameterSpec(
                            name="filter_size",
                            parameter_type=api_pb2.CATEGORICAL,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="1", min="2", list=None),
                        ),
                    ],
                ),
            ),
        ]
        is_valid, _ = validate_operations(invalid_categorical_list)
        self.assertEqual(is_valid, False)

        # invalid Min and Max
        invalid_min_max = [
            api_pb2.Operation(
                operation_type="separable_convolution",
                parameter_specs=api_pb2.Operation.ParameterSpecs(
                    parameters=[
                        api_pb2.ParameterSpec(
                            name="pool_size",
                            parameter_type=api_pb2.INT,
                            feasible_space=api_pb2.FeasibleSpace(
                                max=None, min=None, step=None, list=["1", "2"]),
                        ),
                    ],
                ),
            ),
        ]
        is_valid, _ = validate_operations(invalid_min_max)
        self.assertEqual(is_valid, False)

        # Invalid Double type parameter
        invalid_double_parameter = [
            api_pb2.Operation(
                operation_type="separable_convolution",
                parameter_specs=api_pb2.Operation.ParameterSpecs(
                    parameters=[
                        api_pb2.ParameterSpec(
                            name="invalid_type_double_example",
                            parameter_type=api_pb2.DOUBLE,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="1.0", min="3.0", step=None, list=None),
                        ),
                    ],
                ),
            ),
        ]
        is_valid, _ = validate_operations(invalid_double_parameter)
        self.assertEqual(is_valid, False)


if __name__ == '__main__':
    unittest.main()



================================================
FILE: test/unit/v1beta1/suggestion/test_optuna_service.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import grpc
import grpc_testing
import pytest
import utils

from pkg.apis.manager.v1beta1.python import api_pb2
from pkg.suggestion.v1beta1.optuna.service import OptunaService


class TestOptuna:
    def setup_method(self):
        services = {api_pb2.DESCRIPTOR.services_by_name["Suggestion"]: OptunaService()}

        self.test_server = grpc_testing.server_from_dictionary(
            services, grpc_testing.strict_real_time()
        )

    @pytest.mark.parametrize(
        ["algorithm_name", "algorithm_settings"],
        [
            [
                "tpe",
                {
                    "n_startup_trials": "20",
                    "n_ei_candidates": "10",
                    "random_state": "71",
                },
            ],
            [
                "multivariate-tpe",
                {
                    "n_startup_trials": "20",
                    "n_ei_candidates": "10",
                    "random_state": "71",
                },
            ],
            ["cmaes", {"restart_strategy": "ipop", "sigma": "2", "random_state": "71"}],
            ["random", {"random_state": "71"}],
            # ["grid", {"random_state": "71"}],
        ],
    )
    def test_get_suggestion(self, algorithm_name, algorithm_settings):
        experiment = api_pb2.Experiment(
            name="test",
            spec=api_pb2.ExperimentSpec(
                algorithm=api_pb2.AlgorithmSpec(
                    algorithm_name=algorithm_name,
                    algorithm_settings=[
                        api_pb2.AlgorithmSetting(name=name, value=value)
                        for name, value in algorithm_settings.items()
                    ],
                ),
                objective=api_pb2.ObjectiveSpec(type=api_pb2.MAXIMIZE, goal=0.9),
                parameter_specs=api_pb2.ExperimentSpec.ParameterSpecs(
                    parameters=[
                        api_pb2.ParameterSpec(
                            name="param-1",
                            parameter_type=api_pb2.INT,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="5", min="1", list=[]
                            ),
                        ),
                        api_pb2.ParameterSpec(
                            name="param-2",
                            parameter_type=api_pb2.CATEGORICAL,
                            feasible_space=api_pb2.FeasibleSpace(
                                max=None, min=None, list=["cat1", "cat2", "cat3"]
                            ),
                        ),
                        api_pb2.ParameterSpec(
                            name="param-3",
                            parameter_type=api_pb2.DISCRETE,
                            feasible_space=api_pb2.FeasibleSpace(
                                max=None, min=None, list=["3", "2", "6"]
                            ),
                        ),
                        api_pb2.ParameterSpec(
                            name="param-4",
                            parameter_type=api_pb2.DOUBLE,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="5", min="1", step="1", list=[]
                            ),
                        ),
                        api_pb2.ParameterSpec(
                            name="param-5",
                            parameter_type=api_pb2.INT,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="5", min="1", step="2", distribution=api_pb2.UNIFORM
                            ),
                        ),
                        api_pb2.ParameterSpec(
                            name="param-6",
                            parameter_type=api_pb2.INT,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="5", min="1", distribution=api_pb2.UNIFORM
                            ),
                        ),
                        api_pb2.ParameterSpec(
                            name="param-7",
                            parameter_type=api_pb2.INT,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="5", min="1", step="2", distribution=api_pb2.LOG_UNIFORM
                            ),
                        ),
                        api_pb2.ParameterSpec(
                            name="param-8",
                            parameter_type=api_pb2.INT,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="5", min="1", distribution=api_pb2.LOG_UNIFORM
                            ),
                        ),
                        api_pb2.ParameterSpec(
                            name="param-9",
                            parameter_type=api_pb2.DOUBLE,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="11", min="1", step="2.5", distribution=api_pb2.UNIFORM
                            ),
                        ),
                        api_pb2.ParameterSpec(
                            name="param-10",
                            parameter_type=api_pb2.DOUBLE,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="11", min="1", step="2.5", distribution=api_pb2.LOG_UNIFORM
                            ),
                        ),
                        api_pb2.ParameterSpec(
                            name="param-11",
                            parameter_type=api_pb2.DOUBLE,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="5", min="1", distribution=api_pb2.UNIFORM
                            ),
                        ),
                        api_pb2.ParameterSpec(
                            name="param-12",
                            parameter_type=api_pb2.DOUBLE,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="5", min="1", distribution=api_pb2.LOG_UNIFORM
                            ),
                        ),
                    ]
                ),
            ),
        )

        # Run the first suggestion with no previous trials in the request
        request = api_pb2.GetSuggestionsRequest(
            experiment=experiment,
            trials=[],
            current_request_number=2,
        )

        get_suggestion = self.test_server.invoke_unary_unary(
            method_descriptor=(
                api_pb2.DESCRIPTOR.services_by_name["Suggestion"].methods_by_name[
                    "GetSuggestions"
                ]
            ),
            invocation_metadata={},
            request=request,
            timeout=1,
        )

        response, metadata, code, details = get_suggestion.termination()
        assert code == grpc.StatusCode.OK
        assert 2 == len(response.parameter_assignments)

        # Run the second suggestion with trials whose parameters are assigned in the first request
        trials = [
            api_pb2.Trial(
                name="test-asfjh",
                spec=api_pb2.TrialSpec(
                    objective=api_pb2.ObjectiveSpec(
                        type=api_pb2.MAXIMIZE,
                        objective_metric_name="metric-2",
                        goal=0.9,
                    ),
                    parameter_assignments=api_pb2.TrialSpec.ParameterAssignments(
                        assignments=response.parameter_assignments[0].assignments
                    ),
                ),
                status=api_pb2.TrialStatus(
                    condition=api_pb2.TrialStatus.TrialConditionType.SUCCEEDED,
                    observation=api_pb2.Observation(
                        metrics=[
                            api_pb2.Metric(name="metric-1", value="435"),
                            api_pb2.Metric(name="metric-2", value="5643"),
                        ]
                    ),
                ),
            ),
            api_pb2.Trial(
                name="test-234hs",
                spec=api_pb2.TrialSpec(
                    objective=api_pb2.ObjectiveSpec(
                        type=api_pb2.MAXIMIZE,
                        objective_metric_name="metric-2",
                        goal=0.9,
                    ),
                    parameter_assignments=api_pb2.TrialSpec.ParameterAssignments(
                        assignments=response.parameter_assignments[1].assignments
                    ),
                ),
                status=api_pb2.TrialStatus(
                    condition=api_pb2.TrialStatus.TrialConditionType.SUCCEEDED,
                    observation=api_pb2.Observation(
                        metrics=[
                            api_pb2.Metric(name="metric-1", value="123"),
                            api_pb2.Metric(name="metric-2", value="3028"),
                        ]
                    ),
                ),
            ),
        ]

        request = api_pb2.GetSuggestionsRequest(
            experiment=experiment,
            trials=trials,
            current_request_number=2,
        )

        get_suggestion = self.test_server.invoke_unary_unary(
            method_descriptor=(
                api_pb2.DESCRIPTOR.services_by_name["Suggestion"].methods_by_name[
                    "GetSuggestions"
                ]
            ),
            invocation_metadata={},
            request=request,
            timeout=1,
        )

        response, metadata, code, details = get_suggestion.termination()
        assert code == grpc.StatusCode.OK
        assert 2 == len(response.parameter_assignments)

    @pytest.mark.parametrize(
        [
            "algorithm_name",
            "algorithm_settings",
            "max_trial_count",
            "parameters",
            "result",
        ],
        [
            # Invalid algorithm name
            ["invalid", {}, 1, [], grpc.StatusCode.INVALID_ARGUMENT],
            # [TPE] Valid case
            [
                "tpe",
                {"n_startup_trials": "5", "n_ei_candidates": "24", "random_state": "1"},
                100,
                [],
                grpc.StatusCode.OK,
            ],
            # [TPE] Invalid parameter name
            ["tpe", {"invalid": "5"}, 100, [], grpc.StatusCode.INVALID_ARGUMENT],
            # [TPE] Invalid n_startup_trials
            [
                "tpe",
                {"n_startup_trials": "-1"},
                100,
                [],
                grpc.StatusCode.INVALID_ARGUMENT,
            ],
            # [TPE] Invalid n_ei_candidate
            [
                "tpe",
                {"n_ei_candidate": "-1"},
                100,
                [],
                grpc.StatusCode.INVALID_ARGUMENT,
            ],
            # [TPE] Invalid random_state
            ["tpe", {"random_state": "-1"}, 100, [], grpc.StatusCode.INVALID_ARGUMENT],
            # [Multivariate-TPE] Valid case
            [
                "multivariate-tpe",
                {"n_startup_trials": "5", "n_ei_candidates": "24", "random_state": "1"},
                100,
                [],
                grpc.StatusCode.OK,
            ],
            # [CMAES] Valid case
            [
                "cmaes",
                {"restart_strategy": "ipop", "sigma": "0.1", "random_state": "10"},
                20,
                [
                    {
                        "name": "param-1",
                        "type": api_pb2.INT,
                        "feasible_space": api_pb2.FeasibleSpace(
                            max="5", min="1", list=[]
                        ),
                    },
                    {
                        "name": "param-2",
                        "type": api_pb2.INT,
                        "feasible_space": api_pb2.FeasibleSpace(
                            max="10", min="9", list=[]
                        ),
                    },
                ],
                grpc.StatusCode.OK,
            ],
            # [CMAES] Invalid parameter name
            [
                "cmaes",
                {"invalid": "invalid", "sigma": "0.1"},
                100,
                [
                    {
                        "name": "param-1",
                        "type": api_pb2.INT,
                        "feasible_space": api_pb2.FeasibleSpace(
                            max="5", min="1", list=[]
                        ),
                    },
                    {
                        "name": "param-2",
                        "type": api_pb2.INT,
                        "feasible_space": api_pb2.FeasibleSpace(
                            max="10", min="9", list=[]
                        ),
                    },
                ],
                grpc.StatusCode.INVALID_ARGUMENT,
            ],
            # [CMAES] Invalid restart_strategy
            [
                "cmaes",
                {"restart_strategy": "invalid", "sigma": "0.1"},
                15,
                [
                    {
                        "name": "param-1",
                        "type": api_pb2.INT,
                        "feasible_space": api_pb2.FeasibleSpace(
                            max="5", min="1", list=[]
                        ),
                    },
                    {
                        "name": "param-2",
                        "type": api_pb2.INT,
                        "feasible_space": api_pb2.FeasibleSpace(
                            max="10", min="9", list=[]
                        ),
                    },
                ],
                grpc.StatusCode.INVALID_ARGUMENT,
            ],
            # [CMAES] Invalid sigma
            [
                "cmaes",
                {"restart_strategy": "None", "sigma": "-10"},
                55,
                [
                    {
                        "name": "param-1",
                        "type": api_pb2.INT,
                        "feasible_space": api_pb2.FeasibleSpace(
                            max="5", min="1", list=[]
                        ),
                    },
                    {
                        "name": "param-2",
                        "type": api_pb2.INT,
                        "feasible_space": api_pb2.FeasibleSpace(
                            max="10", min="9", list=[]
                        ),
                    },
                ],
                grpc.StatusCode.INVALID_ARGUMENT,
            ],
            # [CMAES] Invalid random_state
            [
                "cmaes",
                {"sigma": "0.2", "random_state": "-20"},
                25,
                [
                    {
                        "name": "param-1",
                        "type": api_pb2.INT,
                        "feasible_space": api_pb2.FeasibleSpace(
                            max="5", min="1", list=[]
                        ),
                    },
                    {
                        "name": "param-2",
                        "type": api_pb2.INT,
                        "feasible_space": api_pb2.FeasibleSpace(
                            max="10", min="9", list=[]
                        ),
                    },
                ],
                grpc.StatusCode.INVALID_ARGUMENT,
            ],
            # [CMAES] Invalid number of parameters
            [
                "cmaes",
                {"sigma": "0.2"},
                5,
                [
                    {
                        "name": "param-1",
                        "type": api_pb2.INT,
                        "feasible_space": api_pb2.FeasibleSpace(
                            max="5", min="1", list=[]
                        ),
                    }
                ],
                grpc.StatusCode.INVALID_ARGUMENT,
            ],
            # [RANDOM] Valid Case
            [
                "random",
                {"random_state": "10"},
                23,
                [
                    {
                        "name": "param-1",
                        "type": api_pb2.INT,
                        "feasible_space": api_pb2.FeasibleSpace(
                            max="5", min="1", list=[]
                        ),
                    },
                    {
                        "name": "param-2",
                        "type": api_pb2.INT,
                        "feasible_space": api_pb2.FeasibleSpace(
                            max="10", min="9", list=[]
                        ),
                    },
                ],
                grpc.StatusCode.OK,
            ],
            # [RANDOM] Invalid parameter name
            [
                "random",
                {"invalid": "invalid"},
                33,
                [],
                grpc.StatusCode.INVALID_ARGUMENT,
            ],
            # [RANDOM] Invalid random_state
            [
                "random",
                {"random_state": "-1"},
                33,
                [],
                grpc.StatusCode.INVALID_ARGUMENT,
            ],
            # [GRID] Valid Case
            [
                "grid",
                {"random_state": "10"},
                5,
                [
                    {
                        "name": "param-1",
                        "type": api_pb2.INT,
                        "feasible_space": api_pb2.FeasibleSpace(
                            max="5", min="1", list=[]
                        ),
                    },
                ],
                grpc.StatusCode.OK,
            ],
            # [GRID] Invalid parameter name
            ["grid", {"invalid": "invalid"}, 33, [], grpc.StatusCode.INVALID_ARGUMENT],
            # [GRID] Invalid random_state
            ["grid", {"random_state": "-1"}, 10, [], grpc.StatusCode.INVALID_ARGUMENT],
            # [GRID] Invalid feasible_space
            [
                "grid",
                {"random_state": "1"},
                26,
                [
                    {
                        "name": "param-1",
                        "type": api_pb2.DOUBLE,
                        "feasible_space": api_pb2.FeasibleSpace(
                            max="5", min="1", list=[]
                        ),
                    },
                ],
                grpc.StatusCode.INVALID_ARGUMENT,
            ],
            # [GRID] Invalid max_trial_count
            [
                "grid",
                {"random_state": "1"},
                26,
                [
                    {
                        "name": "param-1",
                        "type": api_pb2.INT,
                        "feasible_space": api_pb2.FeasibleSpace(
                            max="5", min="1", list=[]
                        ),
                    },
                    {
                        "name": "param-2",
                        "type": api_pb2.DOUBLE,
                        "feasible_space": api_pb2.FeasibleSpace(
                            max="5", min="1", step="1", list=[]
                        ),
                    },
                ],
                grpc.StatusCode.INVALID_ARGUMENT,
            ],
        ],
    )
    def test_validate_algorithm_settings(
        self, algorithm_name, algorithm_settings, max_trial_count, parameters, result
    ):
        experiment_spec = api_pb2.ExperimentSpec(
            max_trial_count=max_trial_count,
            algorithm=api_pb2.AlgorithmSpec(
                algorithm_name=algorithm_name,
                algorithm_settings=[
                    api_pb2.AlgorithmSetting(name=name, value=value)
                    for name, value in algorithm_settings.items()
                ],
            ),
            parameter_specs=api_pb2.ExperimentSpec.ParameterSpecs(
                parameters=[
                    api_pb2.ParameterSpec(
                        name=param["name"],
                        parameter_type=param["type"],
                        feasible_space=param["feasible_space"],
                    )
                    for param in parameters
                ]
            ),
        )
        _, _, code, _ = utils.call_validate(self.test_server, experiment_spec)
        assert code == result


if __name__ == "__main__":
    pytest.main()



================================================
FILE: test/unit/v1beta1/suggestion/test_skopt_service.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import unittest

import grpc
import grpc_testing
import utils

from pkg.apis.manager.v1beta1.python import api_pb2
from pkg.suggestion.v1beta1.skopt.service import SkoptService


class TestSkopt(unittest.TestCase):
    def setUp(self):
        servicers = {
            api_pb2.DESCRIPTOR.services_by_name["Suggestion"]: SkoptService(
            )
        }

        self.test_server = grpc_testing.server_from_dictionary(
            servicers, grpc_testing.strict_real_time())

    def test_get_suggestion(self):
        trials = [
            api_pb2.Trial(
                name="test-asfjh",
                spec=api_pb2.TrialSpec(
                    objective=api_pb2.ObjectiveSpec(
                        type=api_pb2.MAXIMIZE,
                        objective_metric_name="metric-2",
                        goal=0.9
                    ),
                    parameter_assignments=api_pb2.TrialSpec.ParameterAssignments(
                        assignments=[
                            api_pb2.ParameterAssignment(
                                name="param-1",
                                value="2",
                            ),
                            api_pb2.ParameterAssignment(
                                name="param-2",
                                value="cat1",
                            ),
                            api_pb2.ParameterAssignment(
                                name="param-3",
                                value="2",
                            ),
                            api_pb2.ParameterAssignment(
                                name="param-4",
                                value="3.44",
                            )
                        ]
                    )
                ),
                status=api_pb2.TrialStatus(
                    observation=api_pb2.Observation(
                        metrics=[
                            api_pb2.Metric(
                                name="metric=1",
                                value="435"
                            ),
                            api_pb2.Metric(
                                name="metric=2",
                                value="5643"
                            ),
                        ]
                    )
                )
            ),
            api_pb2.Trial(
                name="test-234hs",
                spec=api_pb2.TrialSpec(
                    objective=api_pb2.ObjectiveSpec(
                        type=api_pb2.MAXIMIZE,
                        objective_metric_name="metric-2",
                        goal=0.9
                    ),
                    parameter_assignments=api_pb2.TrialSpec.ParameterAssignments(
                        assignments=[
                            api_pb2.ParameterAssignment(
                                name="param-1",
                                value="3",
                            ),
                            api_pb2.ParameterAssignment(
                                name="param-2",
                                value="cat2",
                            ),
                            api_pb2.ParameterAssignment(
                                name="param-3",
                                value="6",
                            ),
                            api_pb2.ParameterAssignment(
                                name="param-4",
                                value="4.44",
                            )
                        ]
                    )
                ),
                status=api_pb2.TrialStatus(
                    observation=api_pb2.Observation(
                        metrics=[
                            api_pb2.Metric(
                                name="metric=1",
                                value="123"
                            ),
                            api_pb2.Metric(
                                name="metric=2",
                                value="3028"
                            ),
                        ]
                    )
                )
            )
        ]
        experiment = api_pb2.Experiment(
            name="test",
            spec=api_pb2.ExperimentSpec(
                algorithm=api_pb2.AlgorithmSpec(
                    algorithm_name="bayesianoptimization",
                    algorithm_settings=[
                        api_pb2.AlgorithmSetting(
                            name="random_state",
                            value="10"
                        )
                    ],
                ),
                objective=api_pb2.ObjectiveSpec(
                    type=api_pb2.MAXIMIZE,
                    goal=0.9
                ),
                parameter_specs=api_pb2.ExperimentSpec.ParameterSpecs(
                    parameters=[
                        api_pb2.ParameterSpec(
                            name="param-1",
                            parameter_type=api_pb2.INT,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="5", min="1", list=[]),
                        ),
                        api_pb2.ParameterSpec(
                            name="param-2",
                            parameter_type=api_pb2.CATEGORICAL,
                            feasible_space=api_pb2.FeasibleSpace(
                                max=None, min=None, list=["cat1", "cat2", "cat3"])
                        ),
                        api_pb2.ParameterSpec(
                            name="param-3",
                            parameter_type=api_pb2.DISCRETE,
                            feasible_space=api_pb2.FeasibleSpace(
                                max=None, min=None, list=["3", "2", "6"])
                        ),
                        api_pb2.ParameterSpec(
                            name="param-4",
                            parameter_type=api_pb2.DOUBLE,
                            feasible_space=api_pb2.FeasibleSpace(
                                max="5", min="1", list=[])
                        )
                    ]
                )
            )
        )

        request = api_pb2.GetSuggestionsRequest(
            experiment=experiment,
            trials=trials,
            current_request_number=2,
        )

        get_suggestion = self.test_server.invoke_unary_unary(
            method_descriptor=(api_pb2.DESCRIPTOR
                               .services_by_name["Suggestion"]
                               .methods_by_name["GetSuggestions"]),
            invocation_metadata={},
            request=request, timeout=1)

        response, metadata, code, details = get_suggestion.termination()
        print(response.parameter_assignments)
        self.assertEqual(code, grpc.StatusCode.OK)
        self.assertEqual(2, len(response.parameter_assignments))

    def test_validate_algorithm_settings(self):
        # Valid cases.
        experiment_spec = api_pb2.ExperimentSpec(
            algorithm=api_pb2.AlgorithmSpec(
                algorithm_name="bayesianoptimization",
                algorithm_settings=[
                    api_pb2.AlgorithmSetting(
                        name="random_state",
                        value="10"
                    )
                ],
            )
        )

        _, _, code, _ = utils.call_validate(self.test_server, experiment_spec)
        self.assertEqual(code, grpc.StatusCode.OK)

        # Invalid cases.
        # Unknown algorithm name.
        experiment_spec = api_pb2.ExperimentSpec(
            algorithm=api_pb2.AlgorithmSpec(algorithm_name="unknown")
        )

        _, _, code, details = utils.call_validate(self.test_server, experiment_spec)
        self.assertEqual(code, grpc.StatusCode.INVALID_ARGUMENT)
        self.assertEqual(details, "unknown algorithm name unknown")

        # Unknown config name.
        experiment_spec = api_pb2.ExperimentSpec(
            algorithm=api_pb2.AlgorithmSpec(
                algorithm_name="bayesianoptimization",
                algorithm_settings=[
                    api_pb2.AlgorithmSetting(name="unknown_conf", value="1111")]
            )
        )

        _, _, code, details = utils.call_validate(self.test_server, experiment_spec)
        self.assertEqual(code, grpc.StatusCode.INVALID_ARGUMENT)
        self.assertEqual(details, "unknown setting unknown_conf for algorithm bayesianoptimization")

        # Unknown base_estimator
        experiment_spec = api_pb2.ExperimentSpec(
            algorithm=api_pb2.AlgorithmSpec(
                algorithm_name="bayesianoptimization",
                algorithm_settings=[
                    api_pb2.AlgorithmSetting(name="base_estimator", value="unknown estimator")]
            )
        )
        wrong_algorithm_setting = experiment_spec.algorithm.algorithm_settings[0]

        _, _, code, details = utils.call_validate(self.test_server, experiment_spec)
        self.assertEqual(code, grpc.StatusCode.INVALID_ARGUMENT)
        self.assertEqual(details,
                         "{name} {value} is not supported in Bayesian optimization".format(
                             name=wrong_algorithm_setting.name,
                             value=wrong_algorithm_setting.value))

        # Wrong n_initial_points
        experiment_spec = api_pb2.ExperimentSpec(
            algorithm=api_pb2.AlgorithmSpec(
                algorithm_name="bayesianoptimization",
                algorithm_settings=[
                    api_pb2.AlgorithmSetting(name="n_initial_points", value="-1")]
            )
        )
        wrong_algorithm_setting = experiment_spec.algorithm.algorithm_settings[0]

        _, _, code, details = utils.call_validate(self.test_server, experiment_spec)
        self.assertEqual(code, grpc.StatusCode.INVALID_ARGUMENT)
        self.assertEqual(details, "{name} should be great or equal than zero".format(name=wrong_algorithm_setting.name))

        # Unknown acq_func
        experiment_spec = api_pb2.ExperimentSpec(
            algorithm=api_pb2.AlgorithmSpec(
                algorithm_name="bayesianoptimization",
                algorithm_settings=[
                    api_pb2.AlgorithmSetting(name="acq_func", value="unknown")]
            )
        )
        wrong_algorithm_setting = experiment_spec.algorithm.algorithm_settings[0]

        _, _, code, details = utils.call_validate(self.test_server, experiment_spec)
        self.assertEqual(code, grpc.StatusCode.INVALID_ARGUMENT)
        self.assertEqual(details,
                         "{name} {value} is not supported in Bayesian optimization".format(
                             name=wrong_algorithm_setting.name,
                             value=wrong_algorithm_setting.value
                         ))

        # Unknown acq_optimizer
        experiment_spec = api_pb2.ExperimentSpec(
            algorithm=api_pb2.AlgorithmSpec(
                algorithm_name="bayesianoptimization",
                algorithm_settings=[
                    api_pb2.AlgorithmSetting(name="acq_optimizer", value="unknown")]
            )
        )
        wrong_algorithm_setting = experiment_spec.algorithm.algorithm_settings[0]

        _, _, code, details = utils.call_validate(self.test_server, experiment_spec)
        self.assertEqual(code, grpc.StatusCode.INVALID_ARGUMENT)
        self.assertEqual(details,
                         "{name} {value} is not supported in Bayesian optimization".format(
                             name=wrong_algorithm_setting.name,
                             value=wrong_algorithm_setting.value
                         ))

        # Wrong random_state
        experiment_spec = api_pb2.ExperimentSpec(
            algorithm=api_pb2.AlgorithmSpec(
                algorithm_name="bayesianoptimization",
                algorithm_settings=[
                    api_pb2.AlgorithmSetting(name="random_state", value="-1")]
            )
        )
        wrong_algorithm_setting = experiment_spec.algorithm.algorithm_settings[0]

        _, _, code, details = utils.call_validate(self.test_server, experiment_spec)
        self.assertEqual(code, grpc.StatusCode.INVALID_ARGUMENT)
        self.assertEqual(details, "{name} should be great or equal than zero".format(name=wrong_algorithm_setting.name))


if __name__ == "__main__":
    unittest.main()



================================================
FILE: test/unit/v1beta1/suggestion/utils.py
================================================
# Copyright 2022 The Kubeflow Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from pkg.apis.manager.v1beta1.python import api_pb2


def call_validate(test_server, experiment_spec):
    experiment = api_pb2.Experiment(name="validation-test", spec=experiment_spec)

    request = api_pb2.ValidateAlgorithmSettingsRequest(experiment=experiment)
    validate_algorithm_settings = test_server.invoke_unary_unary(
        method_descriptor=(api_pb2.DESCRIPTOR
                           .services_by_name['Suggestion']
                           .methods_by_name['ValidateAlgorithmSettings']),
        invocation_metadata={},
        request=request, timeout=1)

    response, metadata, code, details = validate_algorithm_settings.termination()

    return response, metadata, code, details



================================================
FILE: .github/PULL_REQUEST_TEMPLATE.md
================================================
<!--  Thanks for sending a pull request! Here are some tips for you:
1. If this is your first time, check our contributor guidelines https://www.kubeflow.org/docs/about/contributing
2. To know more about Katib components, check developer guide https://github.com/kubeflow/katib/blob/master/CONTRIBUTING.md
3. If you want *faster* PR reviews, check how: https://git.k8s.io/community/contributors/guide/pull-requests.md#best-practices-for-faster-reviews
-->

**What this PR does / why we need it**:

**Which issue(s) this PR fixes** _(optional, in `fixes #<issue number>(, fixes #<issue_number>, ...)` format, will close the issue(s) when PR gets merged)_:
Fixes #

**Checklist:**

- [ ] [Docs](https://www.kubeflow.org/docs/components/katib/) included if any changes are user facing



================================================
FILE: .github/ISSUE_TEMPLATE/bug_report.yaml
================================================
name: Bug Report
description: Tell us about a problem you are experiencing with Katib
labels: ["kind/bug", "lifecycle/needs-triage"]
body:
  - type: markdown
    attributes:
      value: |
        Thanks for taking the time to fill out this Katib bug report!
  - type: textarea
    id: problem
    attributes:
      label: What happened?
      description: |
        Please provide as much info as possible. Not doing so may result in your bug not being
        addressed in a timely manner.
    validations:
      required: true
  - type: textarea
    id: expected
    attributes:
      label: What did you expect to happen?
    validations:
      required: true
  - type: textarea
    id: environment
    attributes:
      label: Environment
      value: |
        Kubernetes version:
        ```bash
        $ kubectl version

        ```
        Katib controller version:
        ```bash
        $ kubectl get pods -n kubeflow -l katib.kubeflow.org/component=controller -o jsonpath="{.items[*].spec.containers[*].image}"

        ```
        Katib Python SDK version:
        ```bash
        $ pip show kubeflow-katib

        ```
    validations:
      required: true
  - type: input
    id: votes
    attributes:
      label: Impacted by this bug?
      value: Give it a 👍 We prioritize the issues with most 👍



================================================
FILE: .github/ISSUE_TEMPLATE/config.yml
================================================
blank_issues_enabled: true

contact_links:
  - name: Katib Documentation
    url: https://www.kubeflow.org/docs/components/katib/
    about: Much help can be found in the docs
  - name: Kubeflow Katib Slack Channel
    url: https://www.kubeflow.org/docs/about/community/#kubeflow-slack-channels
    about: Ask the Katib community on CNCF Slack
  - name: Kubeflow Katib Community Meeting
    url: https://bit.ly/2PWVCkV
    about: Join the Kubeflow AutoML working group meeting



================================================
FILE: .github/ISSUE_TEMPLATE/feature_request.yaml
================================================
name: Feature Request
description: Suggest an idea for Katib
labels: ["kind/feature", "lifecycle/needs-triage"]
body:
  - type: markdown
    attributes:
      value: |
        Thanks for taking the time to fill out this Katib feature request!
  - type: textarea
    id: feature
    attributes:
      label: What you would like to be added?
      description: |
        A clear and concise description of what you want to add to Katib.
        Please consider to write Katib enhancement proposal if it is a large feature request.
    validations:
      required: true
  - type: textarea
    id: rationale
    attributes:
      label: Why is this needed?
    validations:
      required: true
  - type: input
    id: votes
    attributes:
      label: Love this feature?
      value: Give it a 👍 We prioritize the features with most 👍



================================================
FILE: .github/workflows/build-and-publish-images.yaml
================================================
# Reusable workflows for publishing Katib images.
name: Build and Publish Images

on:
  workflow_call:
    inputs:
      component-name:
        required: true
        type: string
      platforms:
        required: true
        type: string
      dockerfile:
        required: true
        type: string
    secrets:
      DOCKERHUB_USERNAME:
        required: false
      DOCKERHUB_TOKEN:
        required: false

jobs:
  build-and-publish:
    name: Build and Publish Images
    runs-on: ubuntu-22.04

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set Publish Condition
        id: publish-condition
        shell: bash
        run: |
          if [[ "${{ github.repository }}" == 'kubeflow/katib' && \
                ( "${{ github.ref }}" == 'refs/heads/master' || \
                  "${{ github.ref }}" =~ ^refs/heads/release- || \
                  "${{ github.ref }}" =~ ^refs/tags/v ) ]]; then
            echo "should_publish=true" >> $GITHUB_OUTPUT
          else
            echo "should_publish=false" >> $GITHUB_OUTPUT
          fi

      - name: GHCR Login
        if: steps.publish-condition.outputs.should_publish == 'true'
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: DockerHub Login
        if: steps.publish-condition.outputs.should_publish == 'true'
        uses: docker/login-action@v3
        with:
          registry: docker.io
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Publish Component ${{ inputs.component-name }}
        if: steps.publish-condition.outputs.should_publish == 'true'
        id: publish
        uses: ./.github/workflows/template-publish-image
        with:
          image: |
            ghcr.io/kubeflow/katib/${{ inputs.component-name }}
            docker.io/kubeflowkatib/${{ inputs.component-name }}
          dockerfile: ${{ inputs.dockerfile }}
          platforms: ${{ inputs.platforms }}
          push: true

      - name: Test Build For Component ${{ inputs.component-name }}
        if: steps.publish.outcome == 'skipped'
        uses: ./.github/workflows/template-publish-image
        with:
          image: |
            ghcr.io/kubeflow/katib/${{ inputs.component-name }}
            docker.io/kubeflowkatib/${{ inputs.component-name }}
          dockerfile: ${{ inputs.dockerfile }}
          platforms: ${{ inputs.platforms }}
          push: false



================================================
FILE: .github/workflows/e2e-test-darts-cifar10.yaml
================================================
name: E2E Test with darts-cnn-cifar10

on:
  pull_request:
    paths-ignore:
      - "pkg/ui/v1beta1/frontend/**"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  e2e:
    runs-on: ubuntu-22.04
    timeout-minutes: 120
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Test Env
        uses: ./.github/workflows/template-setup-e2e-test
        with:
          kubernetes-version: ${{ matrix.kubernetes-version }}
          python-version: "3.11"

      - name: Run e2e test with ${{ matrix.experiments }} experiments
        uses: ./.github/workflows/template-e2e-test
        with:
          experiments: ${{ matrix.experiments }}
          # Comma Delimited
          trial-images: darts-cnn-cifar10-cpu

    strategy:
      fail-fast: false
      matrix:
        kubernetes-version: ["v1.31.3", "v1.32.2", "v1.33.1", "v1.34.0"]
        # Comma Delimited
        experiments: ["darts-cpu"]



================================================
FILE: .github/workflows/e2e-test-enas-cifar10.yaml
================================================
name: E2E Test with enas-cnn-cifar10

on:
  pull_request:
    paths-ignore:
      - "pkg/ui/v1beta1/frontend/**"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  e2e:
    runs-on: ubuntu-22.04
    timeout-minutes: 120
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Test Env
        uses: ./.github/workflows/template-setup-e2e-test
        with:
          kubernetes-version: ${{ matrix.kubernetes-version }}
          python-version: "3.8"

      - name: Run e2e test with ${{ matrix.experiments }} experiments
        uses: ./.github/workflows/template-e2e-test
        with:
          experiments: ${{ matrix.experiments }}
          # Comma Delimited
          trial-images: enas-cnn-cifar10-cpu

    strategy:
      fail-fast: false
      matrix:
        kubernetes-version: ["v1.31.3", "v1.32.2", "v1.33.1", "v1.34.0"]
        # Comma Delimited
        experiments: ["enas-cpu"]



================================================
FILE: .github/workflows/e2e-test-pytorch-mnist.yaml
================================================
name: E2E Test with pytorch-mnist

on:
  pull_request:
    paths-ignore:
      - "pkg/ui/v1beta1/frontend/**"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  e2e:
    runs-on: ubuntu-22.04
    timeout-minutes: 120
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Test Env
        uses: ./.github/workflows/template-setup-e2e-test
        with:
          kubernetes-version: ${{ matrix.kubernetes-version }}
          python-version: "3.10"

      - name: Run e2e test with ${{ matrix.experiments }} experiments
        uses: ./.github/workflows/template-e2e-test
        with:
          experiments: ${{ matrix.experiments }}
          training-operator: true
          # Comma Delimited
          trial-images: pytorch-mnist-cpu

    strategy:
      fail-fast: false
      matrix:
        kubernetes-version: ["v1.31.3", "v1.32.2", "v1.33.1", "v1.34.0"]
        # Comma Delimited
        experiments:
          # suggestion-hyperopt
          - "long-running-resume,from-volume-resume,median-stop"
          # others
          - "grid,bayesian-optimization,tpe,multivariate-tpe,cma-es,hyperband"
          - "hyperopt-distribution,optuna-distribution"
          - "file-metrics-collector,pytorchjob-mnist"
          - "median-stop-with-json-format,file-metrics-collector-with-json-format"



================================================
FILE: .github/workflows/e2e-test-simple-pbt.yaml
================================================
name: E2E Test with simple-pbt

on:
  pull_request:
    paths-ignore:
      - "pkg/ui/v1beta1/frontend/**"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  e2e:
    runs-on: ubuntu-22.04
    timeout-minutes: 120
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Test Env
        uses: ./.github/workflows/template-setup-e2e-test
        with:
          kubernetes-version: ${{ matrix.kubernetes-version }}

      - name: Run e2e test with ${{ matrix.experiments }} experiments
        uses: ./.github/workflows/template-e2e-test
        with:
          experiments: ${{ matrix.experiments }}
          # Comma Delimited
          trial-images: simple-pbt

    strategy:
      fail-fast: false
      matrix:
        # Detail: https://hub.docker.com/r/kindest/node
        kubernetes-version: ["v1.31.3", "v1.32.2", "v1.33.1", "v1.34.0"]
        # Comma Delimited
        experiments: ["simple-pbt"]



================================================
FILE: .github/workflows/e2e-test-tf-mnist-with-summaries.yaml
================================================
name: E2E Test with tf-mnist-with-summaries

on:
  pull_request:
    paths-ignore:
      - "pkg/ui/v1beta1/frontend/**"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  e2e:
    runs-on: ubuntu-22.04
    timeout-minutes: 120
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Test Env
        uses: ./.github/workflows/template-setup-e2e-test
        with:
          kubernetes-version: ${{ matrix.kubernetes-version }}

      - name: Run e2e test with ${{ matrix.experiments }} experiments
        uses: ./.github/workflows/template-e2e-test
        with:
          experiments: ${{ matrix.experiments }}
          training-operator: true
          # Comma Delimited
          trial-images: tf-mnist-with-summaries

    strategy:
      fail-fast: false
      matrix:
        kubernetes-version: ["v1.31.3", "v1.32.2", "v1.33.1", "v1.34.0"]
        # Comma Delimited
        experiments: ["tfjob-mnist-with-summaries"]



================================================
FILE: .github/workflows/e2e-test-tune-api.yaml
================================================
name: E2E Test with tune API

on:
  pull_request:
    paths-ignore:
      - "pkg/ui/v1beta1/frontend/**"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  e2e:
    runs-on: ubuntu-22.04
    timeout-minutes: 120
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Test Env
        uses: ./.github/workflows/template-setup-e2e-test
        with:
          kubernetes-version: ${{ matrix.kubernetes-version }}
      
      - name: Install Katib SDK with extra requires
        shell: bash
        run: |
          pip install --prefer-binary -e 'sdk/python/v1beta1[huggingface]'
      
      - name: Run e2e test with tune API
        uses: ./.github/workflows/template-e2e-test
        with:
          tune-api: true
          training-operator: true

    strategy:
      fail-fast: false
      matrix:
        # Detail: https://hub.docker.com/r/kindest/node
        kubernetes-version: ["v1.31.3", "v1.32.2", "v1.33.1", "v1.34.0"]



================================================
FILE: .github/workflows/e2e-test-ui-random-search-postgres.yaml
================================================
name: E2E Test with Katib UI, random search, and postgres

on:
  - pull_request

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  e2e:
    runs-on: ubuntu-22.04
    timeout-minutes: 120
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Test Env
        uses: ./.github/workflows/template-setup-e2e-test
        with:
          kubernetes-version: ${{ matrix.kubernetes-version }}

      - name: Run e2e test with ${{ matrix.experiments }} experiments
        uses: ./.github/workflows/template-e2e-test
        with:
          experiments: random
          # Comma Delimited
          trial-images: pytorch-mnist-cpu
          katib-ui: true
          database-type: postgres

    strategy:
      fail-fast: false
      matrix:
        kubernetes-version: ["v1.31.3", "v1.32.2", "v1.33.1", "v1.34.0"]



================================================
FILE: .github/workflows/publish-algorithm-images.yaml
================================================
name: Publish AutoML Algorithm Images

on:
  push:
  pull_request:
    paths-ignore:
      - "pkg/ui/v1beta1/frontend/**"

jobs:
  algorithm:
    name: Publish Image
    uses: ./.github/workflows/build-and-publish-images.yaml
    with:
      component-name: ${{ matrix.component-name }}
      platforms: linux/amd64,linux/arm64
      dockerfile: ${{ matrix.dockerfile }}
    secrets:
      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}

    strategy:
      fail-fast: false
      matrix:
        include:
          - component-name: suggestion-hyperopt
            dockerfile: cmd/suggestion/hyperopt/v1beta1/Dockerfile
          - component-name: suggestion-hyperband
            dockerfile: cmd/suggestion/hyperband/v1beta1/Dockerfile
          - component-name: suggestion-skopt
            dockerfile: cmd/suggestion/skopt/v1beta1/Dockerfile
          - component-name: suggestion-goptuna
            dockerfile: cmd/suggestion/goptuna/v1beta1/Dockerfile
          - component-name: suggestion-optuna
            dockerfile: cmd/suggestion/optuna/v1beta1/Dockerfile
          - component-name: suggestion-pbt
            dockerfile: cmd/suggestion/pbt/v1beta1/Dockerfile
          - component-name: suggestion-enas
            dockerfile: cmd/suggestion/nas/enas/v1beta1/Dockerfile
          - component-name: suggestion-darts
            dockerfile: cmd/suggestion/nas/darts/v1beta1/Dockerfile
          - component-name: earlystopping-medianstop
            dockerfile: cmd/earlystopping/medianstop/v1beta1/Dockerfile



================================================
FILE: .github/workflows/publish-conformance-images.yaml
================================================
name: Publish Katib Conformance Test Images

on:
  - push
  - pull_request

jobs:
  core:
    name: Publish Image
    uses: ./.github/workflows/build-and-publish-images.yaml
    with:
      component-name: ${{ matrix.component-name }}
      platforms: linux/amd64,linux/arm64
      dockerfile: ${{ matrix.dockerfile }}
    secrets:
      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}

    strategy:
      fail-fast: false
      matrix:
        include:
          - component-name: katib-conformance
            dockerfile: Dockerfile.conformance



================================================
FILE: .github/workflows/publish-core-images.yaml
================================================
name: Publish Katib Core Images

on:
  - push
  - pull_request

jobs:
  core:
    name: Publish Image
    uses: ./.github/workflows/build-and-publish-images.yaml
    with:
      component-name: ${{ matrix.component-name }}
      platforms: linux/amd64,linux/arm64
      dockerfile: ${{ matrix.dockerfile }}
    secrets:
      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}

    strategy:
      fail-fast: false
      matrix:
        include:
          - component-name: katib-controller
            dockerfile: cmd/katib-controller/v1beta1/Dockerfile
          - component-name: katib-db-manager
            dockerfile: cmd/db-manager/v1beta1/Dockerfile
          - component-name: katib-ui
            dockerfile: cmd/ui/v1beta1/Dockerfile
          - component-name: file-metrics-collector
            dockerfile: cmd/metricscollector/v1beta1/file-metricscollector/Dockerfile
          - component-name: tfevent-metrics-collector
            dockerfile: cmd/metricscollector/v1beta1/tfevent-metricscollector/Dockerfile



================================================
FILE: .github/workflows/publish-trial-images.yaml
================================================
name: Publish Trial Images

on:
  push:
  pull_request:
    paths-ignore:
      - "pkg/ui/v1beta1/frontend/**"

jobs:
  trial:
    name: Publish Image
    uses: ./.github/workflows/build-and-publish-images.yaml
    with:
      component-name: ${{ matrix.trial-name }}
      platforms: ${{ matrix.platforms }}
      dockerfile: ${{ matrix.dockerfile }}
    secrets:
      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}

    strategy:
      fail-fast: false
      matrix:
        include:
          - trial-name: pytorch-mnist-cpu
            platforms: linux/amd64,linux/arm64
            dockerfile: examples/v1beta1/trial-images/pytorch-mnist/Dockerfile.cpu
          - trial-name: pytorch-mnist-gpu
            platforms: linux/amd64
            dockerfile: examples/v1beta1/trial-images/pytorch-mnist/Dockerfile.gpu
          - trial-name: tf-mnist-with-summaries
            platforms: linux/amd64,linux/arm64
            dockerfile: examples/v1beta1/trial-images/tf-mnist-with-summaries/Dockerfile
          - trial-name: enas-cnn-cifar10-gpu
            platforms: linux/amd64
            dockerfile: examples/v1beta1/trial-images/enas-cnn-cifar10/Dockerfile.gpu
          - trial-name: enas-cnn-cifar10-cpu
            platforms: linux/amd64,linux/arm64
            dockerfile: examples/v1beta1/trial-images/enas-cnn-cifar10/Dockerfile.cpu
          - trial-name: darts-cnn-cifar10-cpu
            platforms: linux/amd64,linux/arm64
            dockerfile: examples/v1beta1/trial-images/darts-cnn-cifar10/Dockerfile.cpu
          - trial-name: darts-cnn-cifar10-gpu
            platforms: linux/amd64
            dockerfile: examples/v1beta1/trial-images/darts-cnn-cifar10/Dockerfile.gpu
          - trial-name: simple-pbt
            platforms: linux/amd64,linux/arm64
            dockerfile: examples/v1beta1/trial-images/simple-pbt/Dockerfile



================================================
FILE: .github/workflows/stale.yaml
================================================
# This workflow warns and then closes issues and PRs that have had no activity for a specified amount of time.
#
# You can adjust the behavior by modifying this file.
# For more information, see:
# https://github.com/actions/stale
name: Mark stale issues and pull requests

on:
  schedule:
    - cron: "0 */5 * * *"

jobs:
  stale:
    runs-on: ubuntu-22.04
    permissions:
      issues: write
      pull-requests: write

    steps:
      - uses: actions/stale@v5
        with:
          repo-token: ${{ secrets.GITHUB_TOKEN }}
          days-before-stale: 90
          days-before-close: 20
          stale-issue-message: >
            This issue has been automatically marked as stale because it has not had
            recent activity. It will be closed if no further activity occurs. Thank you
            for your contributions.
          close-issue-message: >
            This issue has been automatically closed because it has not had recent
            activity. Please comment "/reopen" to reopen it.
          stale-issue-label: lifecycle/stale
          exempt-issue-labels: lifecycle/frozen
          stale-pr-message: >
            This pull request has been automatically marked as stale because it has not had
            recent activity. It will be closed if no further activity occurs. Thank you
            for your contributions.
          close-pr-message: >
            This pull request has been automatically closed because it has not had recent
            activity. Please comment "/reopen" to reopen it.
          stale-pr-label: lifecycle/stale
          exempt-pr-labels: lifecycle/frozen



================================================
FILE: .github/workflows/test-go.yaml
================================================
name: Go Test

on:
  pull_request:
    paths-ignore:
      - "pkg/ui/v1beta1/frontend/**"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  generatetests:
    name: Generate And Format Test
    runs-on: ubuntu-22.04
    env:
      GOPATH: ${{ github.workspace }}/go
    defaults:
      run:
        working-directory: ${{ env.GOPATH }}/src/github.com/kubeflow/katib
    steps:
      - name: Check out code
        uses: actions/checkout@v4
        with:
          path: ${{ env.GOPATH }}/src/github.com/kubeflow/katib

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version-file: ${{ env.GOPATH }}/src/github.com/kubeflow/katib/go.mod
          cache-dependency-path: ${{ env.GOPATH }}/src/github.com/kubeflow/katib/go.sum

      - name: Check Go Modules, Generated Go/Python codes, and Format
        run: make check

  unittests:
    name: Unit Test
    runs-on: ubuntu-22.04
    env:
      GOPATH: ${{ github.workspace }}/go
    defaults:
      run:
        working-directory: ${{ env.GOPATH }}/src/github.com/kubeflow/katib
    steps:
      - name: Check out code
        uses: actions/checkout@v4
        with:
          path: ${{ env.GOPATH }}/src/github.com/kubeflow/katib

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version-file: ${{ env.GOPATH }}/src/github.com/kubeflow/katib/go.mod
          cache-dependency-path: ${{ env.GOPATH }}/src/github.com/kubeflow/katib/go.sum

      - name: Run Go test
        run: go mod download && make test ENVTEST_K8S_VERSION=${{ matrix.kubernetes-version }}

      - name: Coveralls report
        uses: shogo82148/actions-goveralls@v1
        with:
          path-to-profile: coverage.out
          working-directory: ${{ env.GOPATH }}/src/github.com/kubeflow/katib
          parallel: true

    strategy:
      fail-fast: false
      matrix:
        # Detail: `setup-envtest list`
        kubernetes-version: ["1.31.0", "1.32.0", "1.33.0", "1.34.0"]

  # notifies that all test jobs are finished.
  finish:
    needs: unittests
    runs-on: ubuntu-22.04
    steps:
      - uses: shogo82148/actions-goveralls@v1
        with:
          parallel-finished: true



================================================
FILE: .github/workflows/test-lint.yaml
================================================
name: Lint Files

on:
  pull_request:
    paths-ignore:
      - "pkg/ui/v1beta1/frontend/**"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  lint:
    name: Lint
    runs-on: ubuntu-22.04

    steps:
      - name: Check out code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: 3.9

      - name: Check shell scripts
        run: make shellcheck

      - name: Run pre-commit
        uses: pre-commit/action@v3.0.1



================================================
FILE: .github/workflows/test-node.yaml
================================================
name: Frontend Test

on:
  pull_request:
    paths:
      - pkg/ui/v1beta1/frontend/**

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  test:
    name: Code format and lint
    runs-on: ubuntu-22.04

    steps:
      - name: Check out code
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: 16.20.2

      - name: Format katib code
        run: |
          npm install prettier --prefix ./pkg/ui/v1beta1/frontend
          make prettier-check

      - name: Lint katib code
        run: |
          cd pkg/ui/v1beta1/frontend
          npm run lint-check

  frontend-unit-tests:
    name: Frontend Unit Tests
    runs-on: ubuntu-22.04

    steps:
      - name: Check out code
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: 16.20.2

      - name: Fetch Kubeflow and install common code dependencies
        run: |
          COMMIT=$(cat pkg/ui/v1beta1/frontend/COMMIT)
          cd /tmp && git clone https://github.com/kubeflow/kubeflow.git
          cd kubeflow
          git checkout $COMMIT
          cd components/crud-web-apps/common/frontend/kubeflow-common-lib
          npm i
          npm run build
          npm link ./dist/kubeflow

      - name: Install KWA dependencies
        run: |
          cd pkg/ui/v1beta1/frontend
          npm i
          npm link kubeflow

      - name: Run unit tests
        run: |
          cd pkg/ui/v1beta1/frontend
          npm run test:prod

  frontend-ui-tests:
    name: UI tests with Cypress
    runs-on: ubuntu-22.04
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Setup node version to 16
        uses: actions/setup-node@v4
        with:
          node-version: 16

      - name: Fetch Kubeflow and install common code dependencies
        run: |
          COMMIT=$(cat pkg/ui/v1beta1/frontend/COMMIT)
          cd /tmp && git clone https://github.com/kubeflow/kubeflow.git
          cd kubeflow
          git checkout $COMMIT
          cd components/crud-web-apps/common/frontend/kubeflow-common-lib
          npm i
          npm run build
          npm link ./dist/kubeflow
      - name: Install KWA dependencies
        run: |
          cd pkg/ui/v1beta1/frontend
          npm i
          npm link kubeflow
      - name: Serve UI & run Cypress tests in Chrome and Firefox
        run: |
          cd pkg/ui/v1beta1/frontend
          npm run start & npx wait-on http://localhost:4200
          npm run ui-test-ci-all



================================================
FILE: .github/workflows/test-python.yaml
================================================
name: Python Test

on:
  pull_request:
    paths-ignore:
      - "pkg/ui/v1beta1/frontend/**"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  test:
    name: Test
    runs-on: ubuntu-22.04

    steps:
      - name: Check out code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: 3.11

      - name: Run Python test
        run: make pytest

  # The skopt service doesn't work appropriately with Python 3.11.
  # So, we need to run the test with Python 3.9.
  # TODO (tenzen-y): Once we stop to support skopt, we can remove this test.
  # REF: https://github.com/kubeflow/katib/issues/2280
  test-skopt:
    name: Test Skopt
    runs-on: ubuntu-22.04

    steps:
      - name: Check out code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: 3.9

      - name: Run Python test
        run: make pytest-skopt



================================================
FILE: .github/workflows/trivy-scan.yaml
================================================
name: Trivy Vulnerability Scan
on:
  push:
    branches:
      - master
  pull_request:
jobs:
  build:
    name: Build
    runs-on: ubuntu-24.04
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner in repo mode
        uses: aquasecurity/trivy-action@0.28.0
        with:
          scan-type: "fs"
          ignore-unfixed: true
          format: "sarif"
          output: "trivy-results.sarif"
          severity: "CRITICAL,HIGH"

      - name: Upload Trivy scan results to GitHub Security tab
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: "trivy-results.sarif"



================================================
FILE: .github/workflows/free-up-disk-space/action.yaml
================================================
name: Free-Up Disk Space
description: Remove Non-Essential Tools And Move Docker Data Directory to /mnt/docker

runs:
  using: composite
  steps:
    # This step is a Workaround to avoid the "No space left on device" error.
    # ref: https://github.com/actions/runner-images/issues/2840
    - name: Remove unnecessary files
      shell: bash
      run: |
        echo "Disk usage before cleanup:"
        df -hT

        sudo rm -rf /usr/share/dotnet
        sudo rm -rf /opt/ghc
        sudo rm -rf /usr/local/share/boost
        sudo rm -rf "$AGENT_TOOLSDIRECTORY"
        sudo rm -rf /usr/local/lib/android
        sudo rm -rf /usr/local/share/powershell
        sudo rm -rf /usr/share/swift

        echo "Disk usage after cleanup:"
        df -hT

    - name: Prune docker images
      shell: bash
      run: |
        docker image prune -a -f
        docker system df
        df -hT

    - name: Move docker data directory
      shell: bash
      run: |
        echo "Stopping docker service ..."
        sudo systemctl stop docker
        DOCKER_DEFAULT_ROOT_DIR=/var/lib/docker
        DOCKER_ROOT_DIR=/mnt/docker
        echo "Moving ${DOCKER_DEFAULT_ROOT_DIR} -> ${DOCKER_ROOT_DIR}"
        sudo mv ${DOCKER_DEFAULT_ROOT_DIR} ${DOCKER_ROOT_DIR}
        echo "Creating symlink ${DOCKER_DEFAULT_ROOT_DIR} -> ${DOCKER_ROOT_DIR}"
        sudo ln -s ${DOCKER_ROOT_DIR} ${DOCKER_DEFAULT_ROOT_DIR}
        echo "$(sudo ls -l ${DOCKER_DEFAULT_ROOT_DIR})"
        echo "Starting docker service ..."
        sudo systemctl daemon-reload
        sudo systemctl start docker
        echo "Docker service status:"
        sudo systemctl --no-pager -l -o short status docker



================================================
FILE: .github/workflows/template-e2e-test/action.yaml
================================================
# Composite action for e2e tests.
name: Run E2E Test
description: Run e2e test using the minikube cluster

inputs:
  experiments:
    required: false
    description: comma delimited experiment name
    default: ""
  training-operator:
    required: false
    description: whether to deploy training-operator or not
    default: false
  trial-images:
    required: false
    description: comma delimited trial image name
    default: ""
  katib-ui:
    required: true
    description: whether to deploy katib-ui or not
    default: false
  database-type:
    required: false
    description: mysql or postgres
    default: mysql
  tune-api:
    required: true
    description: whether to execute tune-api test or not
    default: false

runs:
  using: composite
  steps:
    - name: Setup Minikube Cluster
      shell: bash
      run: ./test/e2e/v1beta1/scripts/gh-actions/setup-minikube.sh ${{ inputs.katib-ui }} ${{ inputs.tune-api }} ${{ inputs.trial-images }} ${{ inputs.experiments }}

    - name: Setup Katib
      shell: bash
      run: ./test/e2e/v1beta1/scripts/gh-actions/setup-katib.sh ${{ inputs.katib-ui }} ${{ inputs.training-operator }} ${{ inputs.database-type }}

    - name: Run E2E Experiment
      shell: bash
      run: |
        if "${{ inputs.tune-api }}"; then
          ./test/e2e/v1beta1/scripts/gh-actions/run-e2e-tune-api.sh
        else
          ./test/e2e/v1beta1/scripts/gh-actions/run-e2e-experiment.sh ${{ inputs.experiments }}
        fi



================================================
FILE: .github/workflows/template-publish-image/action.yaml
================================================
# Composite action for publishing Katib images.
name: Build And Publish Container Images
description: Build MultiPlatform Supporting Container Images

inputs:
  image:
    required: true
    description: image tag
  dockerfile:
    required: true
    description: path for dockerfile
  platforms:
    required: true
    description: linux/amd64 or linux/amd64,linux/arm64
  push:
    required: true
    description: whether to push container images or not

runs:
  using: composite
  steps:
      # This step is a Workaround to avoid the "No space left on device" error.
      # ref: https://github.com/actions/runner-images/issues/2840
    - name: Remove unnecessary files
      shell: bash
      run: |
        sudo rm -rf /usr/share/dotnet
        sudo rm -rf /opt/ghc
        sudo rm -rf "/usr/local/share/boost"
        sudo rm -rf "$AGENT_TOOLSDIRECTORY"
        sudo rm -rf /usr/local/lib/android
        sudo rm -rf /usr/local/share/powershell
        sudo rm -rf /usr/share/swift

        echo "Disk usage after cleanup:"
        df -h

    - name: Set up QEMU
      uses: docker/setup-qemu-action@v3

    - name: Set Up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Add Docker Tags
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ inputs.image }}
        tags: |
          type=raw,latest
          type=sha,prefix=v1beta1-

    - name: Build and Push
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ${{ inputs.dockerfile }}
        push: ${{ inputs.push }}
        tags: ${{ steps.meta.outputs.tags }}
        cache-from: type=gha
        cache-to: type=gha,mode=max,ignore-error=true
        platforms: ${{ inputs.platforms }}



================================================
FILE: .github/workflows/template-setup-e2e-test/action.yaml
================================================
# Composite action to setup e2e tests.
name: Setup E2E Test
description: setup env for e2e test using the minikube cluster

inputs:
  kubernetes-version:
    required: true
    description: kubernetes version
  python-version:
    required: false
    description: Python version
    # Most latest supporting version
    default: "3.10"

runs:
  using: composite
  steps:
    # This step is a Workaround to avoid the "No space left on device" error.
    # ref: https://github.com/actions/runner-images/issues/2840
    - name: Free-Up Disk Space
      uses: ./.github/workflows/free-up-disk-space

    - name: Setup kubectl
      uses: azure/setup-kubectl@v4
      with:
        version: ${{ inputs.kubernetes-version }}

    - name: Setup Minikube Cluster
      uses: medyagh/setup-minikube@v0.0.20
      with:
        network-plugin: cni
        cni: flannel
        driver: none
        kubernetes-version: ${{ inputs.kubernetes-version }}
        minikube-version: 1.37.0
        start-args: --wait-timeout=120s

    - name: Setup Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ inputs.python-version }}

    - name: Install Katib SDK
      shell: bash
      run: pip install --prefer-binary -e sdk/python/v1beta1


